{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0106lam_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8JyAPX99TVE"
      },
      "outputs": [],
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "IPython.display.Image(url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8khKcphAC_M"
      },
      "source": [
        "# 1 準備作業\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms2UwCT3Ax9O"
      },
      "source": [
        "## 1.1 シミュレーションに必要なパラメータの設定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHGHvjIP-EEp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "params = {\n",
        "    'traindata_size':   10000,    # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    #'traindata_size': 301612,    # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    'epochs': 20,                # 学習のためのエポック数\n",
        "    'hidden_size': 24,           # 中間層のニューロン数\n",
        "    'random_seed': 42,           # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "    # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "    'source': 'orthography',        # ['orthography', 'phonology', 'mora', 'mora_p', 'mora_p_r']\n",
        "    'target': 'mora_p_r',          # ['orthography', 'phonology', 'mora', 'mora_p', 'mora_p_r']\n",
        "    # 'orthography': 書記素, \n",
        "    # 'phonology': 音韻, \n",
        "    # 'mora': モーラ\n",
        "    # 'mora_p': モーラを silius による音分解\n",
        "    # 'mora_p_r': モーラの silius 音分解の逆\n",
        "    'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "    #'pretrained': True,          # True であれば訓練済ファイルを読み込む\n",
        "    'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "    #'path_saved': '2022_0829lam_p2p_hid24_vocab10k.pt',\n",
        "    'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "    # 結果の散布図を保存するファイル名    \n",
        "    'path_graph': '2022_0829lam_p2p_hid24_vocab10k.pdf',\n",
        "    #'path_graph': False,                      # 保存しない場合\n",
        "\n",
        "    'lr': 0.001,                              # 学習率\n",
        "    'dropout_p': 0.0,                         # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,             # 教師強制を行う確率\n",
        "    'optim_func': torch.optim.Adam,           # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :torch.nn.CrossEntropyLoss(), # 交差エントロピー損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM1cBobVAKF_"
      },
      "source": [
        "## 1.2 ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGgy0mta3D3V"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    wakati = MeCab.Tagger('-Owakati').parse\n",
        "    yomi = MeCab.Tagger('-Oyomi').parse\n",
        "else:\n",
        "    from ccap.mecab_settings import yomi\n",
        "    from ccap.mecab_settings import wakati\n",
        "\n",
        "# 自作ライブラリ LAM の読み込み\n",
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    !git clone https://github.com/ShinAsakawa/lam.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WneoWyJdAaSU"
      },
      "source": [
        "## 1.3. データセットのアップロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mydF09TND7yg"
      },
      "outputs": [],
      "source": [
        "# データセットのアップロード\n",
        "# upload `2022_1018lam_traindata10k.json.gz` from local drive\n",
        "\n",
        "if isColab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P7F-C1SAl0b"
      },
      "source": [
        "## 1.4 アップロードしたデータセットの展開"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iaThuOu56b7"
      },
      "outputs": [],
      "source": [
        "# アップロードしたデータセットの展開\n",
        "import torch\n",
        "import lam\n",
        "\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "from termcolor import colored\n",
        "\n",
        "gz_fname = '2022_1018lam_traindata10k.json.gz'\n",
        "with gzip.open(gz_fname, 'rt', encoding='utf-8') as fp:\n",
        "    A = json.loads(fp.readlines()[0])\n",
        "_keys = list(A.keys())\n",
        "\n",
        "print(_keys)\n",
        "class makeA:\n",
        "    def __init__(self, X):\n",
        "        self.c1 = X['c1']\n",
        "        self.c2 = X['c2']\n",
        "        self.c3 = X['c3']\n",
        "        self.c4 = X['c4']\n",
        "        self.cond = X['cond']\n",
        "        self.excluded_data = X['excluded_data']\n",
        "        self.ja_symbols = X['ja_symbols']\n",
        "        \n",
        "        self.ja_symbols_normalized = X['ja_symbols_normalized']\n",
        "        self.max_mora_length = X['max_mora_length']\n",
        "        self.max_mora_p_length = X['max_mora_p_length']\n",
        "        self.max_ortho_length = X['max_ortho_length']\n",
        "        self.max_phone_length = X['max_phone_length']\n",
        "        self.mora2jul = X['mora2jul']\n",
        "        self.mora_freq = X['mora_freq']\n",
        "        self.mora_p = X['mora_p']\n",
        "        self.mora_p_vocab = X['mora_p_vocab']\n",
        "        self.mora_vocab = X['mora_vocab']\n",
        "        self.ntt_freq = X['ntt_freq']\n",
        "        self.ntt_freq_vocab = X['ntt_freq_vocab']\n",
        "        self.ntt_orth2hira = X['ntt_orth2hira']\n",
        "        self.ortho_vocab = X['ortho_vocab']\n",
        "        self.phone_vocab = X['phone_vocab']\n",
        "        self.train_data = X['train_data']\n",
        "        self.traindata_size = X['traindata_size']\n",
        "        self.vow2hira = X['vow2hira']\n",
        "        \n",
        "_vocab = makeA(A)\n",
        "#print(dir(_vocab))\n",
        "#_vocab.vow2hira"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwEx07oAArU5"
      },
      "source": [
        "## 1.5 検証データセットの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xU2WXv17KAc"
      },
      "outputs": [],
      "source": [
        "__vocab = lam.VOCAB(traindata_size=0, w2v=None, yomi=yomi) \n",
        "\n",
        "source = params['source']\n",
        "target = params['target']\n",
        "\n",
        "# _max_len はアテンション機構のデコーダで必要になるため，全条件で最長の長さを指定する必要がある\n",
        "_max_len = _vocab.max_ortho_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_phone_length else _vocab.max_phone_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_length else _vocab.max_mora_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_p_length else _vocab.max_mora_p_length\n",
        "_vocab.max_length = _max_len + 1\n",
        "print(colored(f'_vocab.max_length: {_vocab.max_length}', 'blue', attrs=['bold']))\n",
        "\n",
        "# ソース，すなわち encoder 側の，項目番号，項目 ID，decoder 側の項目，項目 ID を設定\n",
        "source_vocab, source_ids, target_vocab, target_ids = lam.get_soure_and_target_from_params(\n",
        "    params=None,\n",
        "    _vocab=_vocab,\n",
        "    source=source,\n",
        "    target=target,\n",
        "    is_print=False)\n",
        "\n",
        "print(colored(f'source:{source}','blue', attrs=['bold']), f'{source_vocab}')\n",
        "print(colored(f'target:{target}','cyan', attrs=['bold']), f'{target_vocab}')\n",
        "print(colored(f'source_ids:{source_ids}','blue', attrs=['bold']), f'{source_ids}')\n",
        "print(colored(f'target_ids:{target_ids}','cyan', attrs=['bold']), f'{target_ids}')\n",
        "\n",
        "# 検証データとして，TLPA と SALA のデータを用いる\n",
        "tlpa1, tlpa2, tlpa3, tlpa4, sala_r29, sala_r30, sala_r31 = lam.read_json_tlpa1234_sala_r29_30_31(\n",
        "    json_fname='lam/2022_0508SALA_TLPA.json')\n",
        "\n",
        "_dataset = {}\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']\n",
        "for data in _data_names:\n",
        "    _dataset[data] = {'rawdata':eval(data),\n",
        "                      'pdata': lam.make_vocab_dataset(eval(data),vocab=__vocab)}\n",
        "\n",
        "# 以下は後から付け足したので，コードが汚くなっている。\n",
        "# 時間ができたらコードの整理をすること\n",
        "X_vals = lam.make_X_vals(_dataset=_dataset,\n",
        "                         source_vocab=source_vocab,\n",
        "                         target_vocab=target_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEgncN1BBA8W"
      },
      "source": [
        "## 1.6 PyTorch 用 データセットの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASA9ynsv99v4"
      },
      "outputs": [],
      "source": [
        "# 訓練データセットと検証データセットを作成\n",
        "train_dataset = lam.Train_dataset(data=_vocab.train_data,\n",
        "                                  source_vocab=source_vocab, \n",
        "                                  target_vocab=target_vocab)\n",
        "\n",
        "val_dataset = lam.Val_dataset(data=_dataset['sala_r29']['pdata'],\n",
        "                               source_vocab=source_vocab, \n",
        "                               target_vocab=target_vocab)\n",
        "                \n",
        "print(f'len(train_dataset):{len(train_dataset)}',\n",
        "      f'len(val_dataset):{len(val_dataset)}')      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrkqbM42BJaJ"
      },
      "source": [
        "# 2 モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DxmMIQq-WNq"
      },
      "outputs": [],
      "source": [
        "# 自作ライブラリ LAM の読み込み\n",
        "import lam \n",
        "from lam import EncoderRNN\n",
        "from lam import AttnDecoderRNN\n",
        "# from lam import convert_ids2tensor\n",
        "# from lam import train\n",
        "# from lam import asMinutes, timeSince\n",
        "# #from lam import fit\n",
        "# from lam import convert_ids2tensor\n",
        "# from lam import fix_seed\n",
        "# from lam import worker_init_fn\n",
        "# from lam import make_vocab_dataset\n",
        "\n",
        "device = lam.device  # CPU or GPU の選択\n",
        "\n",
        "from lam import calc_accuracy\n",
        "\n",
        "if (params['pretrained']) and (params['path_saved'] != False) and os.path.exists(params['path_saved']):\n",
        "    \"\"\"セーブした学習済のモデルがあれば読み込む\"\"\"\n",
        "    \n",
        "    checkpoint = torch.load(params['path_saved'])\n",
        "    encoder = EncoderRNN(len(source_vocab), params['hidden_size']).to(device)\n",
        "    decoder = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                             n_out=len(target_vocab), \n",
        "                             dropout_p=params['dropout_p'],\n",
        "                             max_length=_vocab.max_length).to(device)\n",
        "    encoder.load_state_dict(checkpoint['encoder'])\n",
        "    decoder.load_state_dict(checkpoint['decoder'])\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    losses = []\n",
        "    \n",
        "    encoder2 = EncoderRNN(len(target_vocab), params['hidden_size']).to(device)\n",
        "    decoder2 = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                              n_out=len(target_vocab), \n",
        "                              dropout_p=params['dropout_p'],\n",
        "                              max_length=_vocab.max_length).to(device)\n",
        "    encoder2.load_state_dict(checkpoint['encoder'])\n",
        "    decoder2.load_state_dict(checkpoint['decoder'])\n",
        "    encoder2.eval()\n",
        "    decoder2.eval()\n",
        "    \n",
        "    print(colored(f\"セーブした学習済のモデル {params['path_saved']} があるので読み込みました\",\n",
        "          color='blue', attrs=['bold']))\n",
        "    # print(encoder)\n",
        "    # print(decoder)\n",
        "    # print(encoder2)\n",
        "    # print(decoder2)\n",
        "\n",
        "else:\n",
        "    encoder = EncoderRNN(len(source_vocab), params['hidden_size']).to(device)\n",
        "    decoder = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                             n_out=len(target_vocab), \n",
        "                             dropout_p=params['dropout_p'],\n",
        "                             max_length=_vocab.max_length\n",
        "                            ).to(device)\n",
        "\n",
        "# モデルの概要を印字\n",
        "print(f'encoder:{encoder}')\n",
        "print(f'decoder:{decoder}')\n",
        "_param = {}\n",
        "for _model in ['encoder', 'decoder']:\n",
        "    _param[_model] = {}\n",
        "    for __name, __param in eval(_model).named_parameters():\n",
        "        _param[_model][__name] = __param.detach().numpy()\n",
        "\n",
        "for _model, _val in _param.items():\n",
        "    print(colored(f'{_model}','red', attrs=['bold']))\n",
        "    for w_name, w_val in _param[_model].items():\n",
        "        print((w_name, _param[_model][w_name].shape, w_val.dtype)) #_param[model][)) # (k,_k))\n",
        "        \n",
        "for test_name, val_dataset in X_vals.items():\n",
        "    acc = calc_accuracy(_dataset=val_dataset,\n",
        "                        encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        #decoder=decoder2,\n",
        "                        max_length=_vocab.max_length,\n",
        "                        source_vocab=source_vocab,\n",
        "                        target_vocab=target_vocab)\n",
        "    print(colored(f'{test_name} の精度:{acc:.3f}','blue', attrs=['bold']))\n",
        "\n",
        "\n",
        "# params の印刷\n",
        "print(colored(params,'blue',attrs=['bold']))    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oktg4ILjBO0W"
      },
      "source": [
        "# 3 訓練の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUjOGlRE_iq1"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "losses += lam.fit(encoder, \n",
        "                  decoder, \n",
        "                  device=device,\n",
        "                  epochs=params['epochs'], \n",
        "                  max_length=_vocab.max_length,\n",
        "                  n_sample=0,\n",
        "                  params=params,\n",
        "                  source_vocab=source_vocab,\n",
        "                  target_vocab=target_vocab,\n",
        "                  teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "                  train_dataset=train_dataset,\n",
        "                  val_dataset=X_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZHhqns7U_gL"
      },
      "outputs": [],
      "source": [
        "# torch.save(encoder, '2023_0106lam_encoder.pt')\n",
        "# torch.save(decoder, '2023_0106lam_decoder.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mKDwmakU_gM"
      },
      "outputs": [],
      "source": [
        "encoder2 = EncoderRNN(len(source_vocab), \n",
        "                      params['hidden_size']).to(device)\n",
        "decoder2 = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                          n_out=len(target_vocab), \n",
        "                          dropout_p=params['dropout_p'],\n",
        "                          max_length=_vocab.max_length\n",
        "                         ).to(device)\n",
        "\n",
        "with open('2023_0106lam_encoder.pt', 'rb') as f:\n",
        "    encoder2 = torch.load(f)\n",
        "    \n",
        "with open('2023_0106lam_decoder.pt', 'rb') as f:\n",
        "    decoder2 = torch.load(f)\n",
        "    \n",
        "for test_name, val_dataset in X_vals.items():\n",
        "    acc = calc_accuracy(_dataset=val_dataset,\n",
        "                        encoder=encoder2,\n",
        "                        decoder=decoder2,\n",
        "                        max_length=_vocab.max_length,\n",
        "                        source_vocab=source_vocab,\n",
        "                        target_vocab=target_vocab)\n",
        "    print(colored(f'{test_name} の精度:{acc:.3f}','blue', attrs=['bold']))\n",
        "    \n",
        "for k, v in params.items():\n",
        "    print(k, colored(v, 'green', attrs=['bold']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIwcDd24U_gU"
      },
      "outputs": [],
      "source": [
        "from lam import evaluate\n",
        "\n",
        "TEST_DATA = 'tlpa4val'  # 'sala_r29val', 'sala_r30val', sala_r31val, 'tlpa2val', 'tlpa3val', 'tlpa4val'\n",
        "calc_accuracy(_dataset=X_vals[TEST_DATA],\n",
        "              encoder=encoder2,\n",
        "              decoder=decoder2,\n",
        "              max_length=_vocab.max_length,\n",
        "              source_vocab=source_vocab,\n",
        "              target_vocab=target_vocab)\n",
        "\n",
        "dataset = X_vals[TEST_DATA]\n",
        "for i in range(5):\n",
        "    x, y = dataset.__getitem__(i)\n",
        "    print(i, [target_vocab[_x] for _x in x], end=\": \")\n",
        "    print([target_vocab[_y] for _y in y], end=\":: \")    \n",
        "    _output_words, _output_ids, _attentions = evaluate(encoder=encoder2,\n",
        "                                                       decoder=decoder2,\n",
        "                                                       input_ids=x,\n",
        "                                                       max_length=_vocab.max_length,             \n",
        "                                                       source_vocab=source_vocab,\n",
        "                                                       target_vocab=target_vocab)\n",
        "    print(_output_words)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jVWvDGGU_gU"
      },
      "outputs": [],
      "source": [
        "#print(source_vocab)\n",
        "print(target_vocab)\n",
        "word = '戦争'\n",
        "for x in word:\n",
        "    print(x) # ,source_vocab[x])\n",
        "source_vocab.index('戦')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLZzEuG09wVj"
      },
      "outputs": [],
      "source": [
        "fushimi1998 = {\n",
        "    'HF___consist__': ['戦争', '倉庫', '医学', '注意', '記念', '番号', '料理', '完全', '開始', '印刷',\n",
        "                       '連続', '予約', '多少', '教員', '当局', '材料', '夕刊', '労働', '運送', '電池' ], # consistent, 'high-frequency words\n",
        "    'HF___inconsist': ['反対', '失敗', '作品', '指定', '実験', '決定', '独占', '独身', '固定', '食品',\n",
        "                       '表明', '安定', '各種', '役所', '海岸', '決算', '地帯', '道路', '安打', '楽団' ], # inconsistent, 'high-frequency words\n",
        "    'HF___atypical_': ['仲間', '夫婦', '人間', '神経', '相手', '反発', '化粧', '建物', '彼女', '毛糸', \n",
        "                       '場合', '台風', '夜間', '人形', '東西', '地元', '松原', '競馬', '大幅', '貸家' ], # inconsistent atypical, 'high-frequency words\n",
        "    'LF___consist__': ['集計', '観察', '予告', '動脈', '理学', '信任', '任務', '返信', '医局', '低温', \n",
        "                       '区別', '永続', '持続', '試練', '満開', '軍備', '製材', '銀貨', '急送', '改選' ], # consistent, 'low-frequecy words\n",
        "    'LF___inconsist': ['表紙', '指針', '熱帯', '作詞', '決着', '食費', '古代', '地形', '役場', '品種', \n",
        "                       '祝福', '金銭', '根底', '接種', '経由', '郷土', '街路', '宿直', '曲折', '越境' ], # inconsistent, 'low-frequency words\n",
        "    'LF___atypical_': ['強引', '寿命', '豆腐', '出前', '歌声', '近道', '間口', '風物', '面影', '眼鏡', \n",
        "                       '居所', '献立', '小雨', '毛皮', '鳥居', '仲買', '頭取', '極上', '奉行', '夢路' ], # inconsistent atypical, 'low-frequncy words\n",
        "    'HFNW_consist__': ['集学', '信別', '製信', '運学', '番送', '電続', '完意', '軍開', '動選', '当働', \n",
        "                       '予続', '倉理', '予少', '教池', '理任', '銀務', '連料', '開員', '注全', '記争' ], # consistent, 'high-character-frequency nonwords\n",
        "    'HFNW_inconsist': ['作明', '風行', '失定', '指団', '決所', '各算', '海身', '東発', '楽験', '作代',\n",
        "                       '反原', '独対', '歌上', '反定', '独定', '場家', '安種', '経着', '決土', '松合' ], # inconsistent biased, 'high-character-frequency nonwords\n",
        "    'HFNW_ambiguous': ['表品', '実定', '人風', '神間', '相経', '人元', '小引', '指場', '毛所', '台手',\n",
        "                       '間物', '道品', '出取', '建馬', '大婦', '地打', '化間', '面口', '金由', '彼間' ], # inconsistent ambigous, 'high-character-frequency nonwords\n",
        "    'LFNW_consist__': ['急材', '戦刊', '返計', '印念', '低局', '労号', '満送', '永告', '試脈', '観備',\n",
        "                       '材約', '夕局', '医庫', '任続', '医貨', '改練', '区温', '多始', '材刷', '持察' ], # consistent, 'low-character-frequency nonwords\n",
        "    'LFNW_inconsist': ['食占', '表底', '宿帯', '決帯', '古費', '安敗', '役針', '近命', '眼道', '豆立',\n",
        "                       '街直', '固路', '郷種', '品路', '曲銭', '献居', '奉買', '根境', '役岸', '祝折' ], # inconsistent biased, 'low-character-frequency nonwords\n",
        "    'LFNW_ambiguous': ['食形', '接紙', '競物', '地詞', '強腐', '頭路', '毛西', '夜糸', '仲影', '熱福',\n",
        "                       '寿前', '鳥雨', '地粧', '越種', '仲女', '極鏡', '夢皮', '居声', '貸形', '夫幅' ], # inconsistent ambigous, 'low-character-frequency nonwords\n",
        "}\n",
        "\n",
        "for k, v in fushimi1998.items():\n",
        "    print(k, v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XcHRKwJMwHs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    !pip install --upgrade openpyxl\n",
        "    !pip install --upgrade pandas\n",
        "    !pip install --upgrade fugashi[unidic-lite]\n",
        "    !pip install --upgrade ipadic\n",
        "    !python -m unidic download\n",
        "    !pip install transformers\n",
        "    !pip install --upgrade jaconv\n",
        "    \n",
        "from tqdm.notebook import tqdm    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1xt28bsU_gX"
      },
      "outputs": [],
      "source": [
        "!gls -lt ../*.xls*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5JkQAOTU_gY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "excel_fname = '../単語リスト（扱い注意）.xlsx'\n",
        "corpus_pd = pd.read_excel(excel_fname, engine='openpyxl')\n",
        "corpus_pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iEmmLfoU_gY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}