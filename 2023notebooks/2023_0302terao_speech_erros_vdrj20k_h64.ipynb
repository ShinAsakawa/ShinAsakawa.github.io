{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0302terao_speech_erros_vdrj20k_h64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc6967e-ef73-42b4-a309-7af774085dd2",
      "metadata": {
        "id": "bcc6967e-ef73-42b4-a309-7af774085dd2"
      },
      "source": [
        "# 寺尾先生の言い誤りデータ `成人　音交換　機械学習.xlsx` を用いて，言い誤りを微調整\n",
        "\n",
        "* date: 2023_0306\n",
        "* filename: 2023_0302terao_speech_erros_vdrj20k_h64.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f40bf94-6df9-4c94-9ec7-d39e1378b28c",
      "metadata": {
        "id": "1f40bf94-6df9-4c94-9ec7-d39e1378b28c"
      },
      "source": [
        "## 0.1. 下準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd598b8f-9a95-4b05-9388-56bd71789364",
      "metadata": {
        "id": "bd598b8f-9a95-4b05-9388-56bd71789364"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from itertools import chain\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import gzip\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv\n",
        "\n",
        "if isColab:\n",
        "\n",
        "    # termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    import termcolor\n",
        "\n",
        "    # 結果を保存するために Google Drive をマウントする\n",
        "    #import google.colab\n",
        "    #google.colab.drive.mount('/content/drive/')\n",
        "\n",
        "    # GPU 情報を表示\n",
        "    #!nvidia-smi -L\n",
        "    #!pip install ipynbname --upgrade > /dev/null\n",
        "    !pip install japanize_matplotlib\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で MeCab を動作させるために，C コンパイラを起動して，MeCab の構築を行う\n",
        "    # そのため時間がかかる。\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    mecab_wakati = MeCab.Tagger('-Owakati').parse\n",
        "    mecab_yomi = MeCab.Tagger('-Oyomi').parse\n",
        "    \n",
        "else:\n",
        "    from ccap.mecab_settings import yomi as mecab_yomi\n",
        "    from ccap.mecab_settings import wakati as mecab_wakati\n",
        "\n",
        "\n",
        "# ここから下は，コード実行に関するバージョン情報などの情報源の取得と表示\\n\",\n",
        "from termcolor import colored\n",
        "import platform\n",
        "HOSTNAME = platform.node().split('.')[0]\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname\n",
        "    import ipynbname\n",
        "FILEPATH = str(ipynbname.path()).replace(HOME+'/','')\n",
        "\n",
        "import pwd\n",
        "USER=pwd.getpwuid(os.geteuid())[0]\n",
        "\n",
        "from datetime import date\n",
        "TODAY=date.today()\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "\n",
        "color = 'green'\n",
        "print('日付:',colored(f'{TODAY}', color=color, attrs=['bold']))\n",
        "print('HOSTNAME:',colored(f'{HOSTNAME}', color=color, attrs=['bold']))\n",
        "print('ユーザ名:',colored(f'{USER}', color=color, attrs=['bold']))\n",
        "print('HOME:',colored(f'{HOME}', color=color,attrs=['bold']))\n",
        "print('ファイル名:',colored(f'{FILEPATH}', color=color, attrs=['bold']))\n",
        "print('torch.__version__:',colored(f'{TORCH_VERSION}', color=color, attrs=['bold']))\n",
        "\n",
        "# 自作ライブラリの読み込み\n",
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d8ce9d-816c-4c3c-8ff2-d3f9cbb0e140",
      "metadata": {
        "id": "f9d8ce9d-816c-4c3c-8ff2-d3f9cbb0e140"
      },
      "source": [
        "## 1. `RAM/terao_speech_error` データセットの読み込み\n",
        "\n",
        "事前訓練は `RAM/2023_0302vdrj_20k_p2p_h64.pt` に保存されている"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e3f5406c-d781-4e3e-91da-ba742c0dae51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3f5406c-d781-4e3e-91da-ba742c0dae51",
        "outputId": "f0009b36-cd5a-4e14-ceb6-11fc15ecd879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset \u001b[1m\u001b[34m<RAM.dataset.VDRJ_Dataset object at 0x7fa444e2e850>\u001b[0m\n",
            "dataset_name \u001b[1m\u001b[34mterao_speech_error\u001b[0m\n",
            "dropout_p \u001b[1m\u001b[34m0.0\u001b[0m\n",
            "epochs \u001b[1m\u001b[34m100\u001b[0m\n",
            "hidden_size \u001b[1m\u001b[34m64\u001b[0m\n",
            "loss_func \u001b[1m\u001b[34mNLLLoss()\u001b[0m\n",
            "lr \u001b[1m\u001b[34m0.001\u001b[0m\n",
            "optim_func \u001b[1m\u001b[34m<class 'torch.optim.adam.Adam'>\u001b[0m\n",
            "path_saved \u001b[1m\u001b[34m2023_0302tera_speech_errors_vdrj_20k_p2p_h64.pt\u001b[0m\n",
            "pretrained \u001b[1m\u001b[34mRAM/2023_0302vdrj_20k_p2p_h64.pt\u001b[0m\n",
            "random_seed \u001b[1m\u001b[34m42\u001b[0m\n",
            "source \u001b[1m\u001b[34mphon\u001b[0m\n",
            "stop_list \u001b[1m\u001b[34mNone\u001b[0m\n",
            "target \u001b[1m\u001b[34mphon\u001b[0m\n",
            "teacher_forcing_ratio \u001b[1m\u001b[34m0.5\u001b[0m\n",
            "traindata_ratio \u001b[1m\u001b[34m0.9\u001b[0m\n",
            "traindata_size \u001b[1m\u001b[34m10000\u001b[0m\n",
            "verbose \u001b[1m\u001b[34mTrue\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# シミュレーションに必要なパラメータの設定ユーティリティ\n",
        "from RAM import set_params_from_file\n",
        "from RAM import set_params_from_config\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "configs = {\n",
        "    'dataset_name'  : 'vdrj',   # ['pyslex71', 'vdrj', 'onechar', 'fushimi1999']\n",
        "    'traindata_size':  10000,    # 訓練データ (語彙) 数，\n",
        "    'traindata_ratio': 0.9,     # 訓練データと検証データを分割する比率。ただし onechar データセットでは無効\n",
        "    'stop_list': None,\n",
        "    'epochs': 100,               # 学習のためのエポック数\n",
        "    'lr': 1e-3,                       # 学習率\n",
        "    \n",
        "    # 以下 `source` と `rget` を定義することで，別の課題を実行可能\n",
        "    'source': 'phon',          # ['orth', 'phon']\n",
        "    'target': 'phon',          # ['orth', 'phon']\n",
        "    'hidden_size': 64,        # 中間層のニューロン数\n",
        "\n",
        "    'dropout_p': 0.0,                 # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,     # 教師強制を行う確率\n",
        "    'optim_func': \"torch.optim.Adam\",   # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :\"torch.nn.NLLLoss\",  # 負の対数尤度損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "    #'loss_func' :torch.nn.NLLLoss(),\n",
        "\n",
        "    'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "    'pretrained': 'RAM/2023_0302vdrj_20k_p2p_h64.pt',\n",
        "    #'isTrain'   : True,       # True であれば学習する\n",
        "    'verbose'   : True,\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    'path_saved': '2023_0302tera_speech_errors_vdrj_20k_p2p_h64.pt', \n",
        "}\n",
        "\n",
        "\n",
        "X = set_params_from_config(configs=configs, device=device)\n",
        "configs = X['params']\n",
        "configs['dataset_name'] = 'terao_speech_error'\n",
        "encoder = X['encoder']\n",
        "decoder = X['decoder']\n",
        "ds = X['dataset']\n",
        "configs['dataset'] = ds\n",
        "torch.manual_seed(configs['random_seed'])\n",
        "\n",
        "# encoder_optimizer = X['encoder_optimizer']\n",
        "# decoder_optimizer = X['decoder_optimizer']\n",
        "N_train = X['N_train']\n",
        "N_val   = X['N_val']\n",
        "\n",
        "for k, v in sorted(configs.items()):\n",
        "    print(k, colored(v, 'blue', attrs=['bold']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5a49dc6b-cf25-41a9-9931-00f82a43df95",
      "metadata": {
        "id": "5a49dc6b-cf25-41a9-9931-00f82a43df95"
      },
      "outputs": [],
      "source": [
        "# 言い誤りデータの読み込み\n",
        "from RAM import terao_speech_error_dataset\n",
        "terao_se_ds = terao_speech_error_dataset()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb82abc-62c2-4f79-ac27-0ef3006fadd3",
      "metadata": {
        "tags": [],
        "id": "adb82abc-62c2-4f79-ac27-0ef3006fadd3"
      },
      "outputs": [],
      "source": [
        "from RAM import save_model_and_configs\n",
        "from RAM import EncoderRNN, AttnDecoderRNN\n",
        "from RAM import eval_input_seq2seq\n",
        "\n",
        "X = torch.load(configs['pretrained'])\n",
        "    \n",
        "encoder0 = EncoderRNN(\n",
        "    n_inp=len(ds.source_list),                # 符号化器への入力データ次元数の特徴数 (語彙数): int\n",
        "    n_hid=configs['hidden_size']).to(device)  # 符号化器の中間層数，埋め込みベクトルとして復号化器へ渡される次元数: int\n",
        "\n",
        "decoder0 = AttnDecoderRNN(\n",
        "    n_hid=configs['hidden_size'],             # 復号化器の中間層次元数: int\n",
        "    n_out=len(ds.target_list),                # 復号化器の出力層次元数，入力層の次元と等しいので入力層次元を指定せず: int\n",
        "    dropout_p=configs['dropout_p'],\n",
        "    max_length=ds.maxlen).to(device)\n",
        "\n",
        "encoder0_optimizer = torch.optim.Adam(params=encoder0.parameters(), lr=configs['lr'])\n",
        "decoder0_optimizer = torch.optim.Adam(params=decoder0.parameters(), lr=configs['lr'])\n",
        "encoder0.load_state_dict(X['encoder'])\n",
        "decoder0.load_state_dict(X['decoder'])\n",
        "\n",
        "#_ = eval_input_seq2seq(encoder=encoder0, decoder=decoder0, ds=ds)\n",
        "\n",
        "encoder1 = EncoderRNN(\n",
        "    n_inp=len(ds.source_list),                # 符号化器への入力データ次元数の特徴数 (語彙数): int\n",
        "    n_hid=configs['hidden_size']).to(device)  # 符号化器の中間層数，埋め込みベクトルとして復号化器へ渡される次元数: int\n",
        "\n",
        "decoder1 = AttnDecoderRNN(\n",
        "    n_hid=configs['hidden_size'],             # 復号化器の中間層次元数: int\n",
        "    n_out=len(ds.target_list),                # 復号化器の出力層次元数，入力層の次元と等しいので入力層次元を指定せず: int\n",
        "    dropout_p=configs['dropout_p'],\n",
        "    max_length=ds.maxlen).to(device)\n",
        "\n",
        "encoder1_optimizer = torch.optim.Adam(params=encoder1.parameters(), lr=configs['lr'])\n",
        "decoder1_optimizer = torch.optim.Adam(params=decoder1.parameters(), lr=configs['lr'])\n",
        "encoder1.load_state_dict(X['encoder'])\n",
        "decoder1.load_state_dict(X['decoder'])\n",
        "\n",
        "#_ = eval_input_seq2seq(encoder=encoder1, decoder=decoder1, ds=ds)\n",
        "\n",
        "X = torch.load('RAM/2023_0302vdrj_20k_p2p_h64.pt')\n",
        "    \n",
        "encoder2 = EncoderRNN(\n",
        "    n_inp=len(ds.source_list),                # 符号化器への入力データ次元数の特徴数 (語彙数): int\n",
        "    n_hid=configs['hidden_size']).to(device)  # 符号化器の中間層数，埋め込みベクトルとして復号化器へ渡される次元数: int\n",
        "\n",
        "decoder2 = AttnDecoderRNN(\n",
        "    n_hid=configs['hidden_size'],             # 復号化器の中間層次元数: int\n",
        "    n_out=len(ds.target_list),                # 復号化器の出力層次元数，入力層の次元と等しいので入力層次元を指定せず: int\n",
        "    dropout_p=configs['dropout_p'],\n",
        "    max_length=ds.maxlen).to(device)\n",
        "\n",
        "encoder2_optimizer = torch.optim.Adam(params=encoder2.parameters(), lr=configs['lr'])\n",
        "decoder2_optimizer = torch.optim.Adam(params=decoder2.parameters(), lr=configs['lr'])\n",
        "encoder2.load_state_dict(X['encoder'])\n",
        "decoder2.load_state_dict(X['decoder'])\n",
        "\n",
        "#_ = eval_input_seq2seq(encoder=encoder2, decoder=decoder2, ds=ds)\n",
        "\n",
        "_ds = terao_se_ds\n",
        "inputs = [v['ひら'] for k, v in _ds.data_dict.items()]\n",
        "counter = 0\n",
        "for i, inp in enumerate(inputs):\n",
        "    tgt = ds.target_ids2tkn(_ds.__getitem__(i)[-1])\n",
        "    out = eval_input_seq2seq(encoder=encoder0, decoder=decoder0, ds=ds, inp_wrd=inp, isPrint=False)\n",
        "    yesno = out[0] == tgt\n",
        "    if yesno:\n",
        "        color = 'blue'\n",
        "        counter += 1\n",
        "    else:\n",
        "        color = 'red'\n",
        "    if yesno:\n",
        "        print(f'{i:3d}: {inp}->/{\"\".join(ph for ph in out[0][:-1])}/',\n",
        "              f'{colored(yesno, color,attrs=[\"bold\"])}',\n",
        "              f' tgt:{\"\".join(ph for ph in tgt[:-1])}')\n",
        "\n",
        "p = counter/_ds.data_dict.__len__()\n",
        "print(f'counter:{counter}/{_ds.data_dict.__len__()} = {p * 100:6.2f} 正しくいい間違えた割合%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 議論: 下の最後の出力の最後の数値が語彙判断課題のシミュレーションに使えるのかもしれない，という妄想はどう思うか？\n"
      ],
      "metadata": {
        "id": "YBKBJEEBzw1p"
      },
      "id": "YBKBJEEBzw1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a582153d-f700-4532-b1be-52ef51d1cda6",
      "metadata": {
        "id": "a582153d-f700-4532-b1be-52ef51d1cda6"
      },
      "outputs": [],
      "source": [
        "outwrd, l = eval_input_seq2seq(encoder=encoder0, decoder=decoder0, ds=ds, isPrint=False)\n",
        "print(\" \".join(p for p in outwrd[:-1]), np.exp(np.array(l)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "448a1192-e325-478e-ab6c-6bf3d3d31ff8",
      "metadata": {
        "id": "448a1192-e325-478e-ab6c-6bf3d3d31ff8"
      },
      "source": [
        "## 0 model0 (encoder0, decoder0) を訓練\n",
        "`model0` は，純粋微調整"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acad9f29-e2d7-43a4-a15e-60375bd3c90a",
      "metadata": {
        "id": "acad9f29-e2d7-43a4-a15e-60375bd3c90a"
      },
      "outputs": [],
      "source": [
        "from RAM import train_epochs\n",
        "from RAM import eval_input_seq2seq\n",
        "\n",
        "# model0 (encoder0, decoder0) を訓練\n",
        "losses = train_epochs( \n",
        "    epochs=configs['epochs'], \n",
        "    lr=configs['lr'],\n",
        "    train_dataset=terao_se_ds,\n",
        "    val_dataset={'terao_sp_ds': terao_se_ds},\n",
        "    encoder=encoder0, decoder=decoder0,\n",
        "    encoder_optimizer=encoder0_optimizer, decoder_optimizer=decoder0_optimizer,\n",
        "    source_vocab=ds.source_list, target_vocab=ds.target_list,\n",
        "    source_ids=ds.source, target_ids=ds.target,\n",
        "    criterion=configs['loss_func'],\n",
        "    params=configs,\n",
        "    device=device,\n",
        "    max_length=ds.maxlen,\n",
        "    #n_sample=0,\n",
        "    teacher_forcing_ratio=configs['teacher_forcing_ratio'],\n",
        ")\n",
        "\n",
        "plt.plot(losses) \n",
        "\n",
        "_ds = terao_se_ds\n",
        "inputs = [v['ひら'] for k, v in _ds.data_dict.items()]\n",
        "counter = 0\n",
        "for i, inp in enumerate(inputs):\n",
        "    tgt = ds.target_ids2tkn(_ds.__getitem__(i)[-1])\n",
        "    out = eval_input_seq2seq(encoder=encoder0, decoder=decoder0, ds=ds, inp_wrd=inp, isPrint=False)\n",
        "    yesno = out[0] == tgt\n",
        "    if yesno:\n",
        "        color = 'blue'\n",
        "        counter += 1\n",
        "    else:\n",
        "        color = 'red'\n",
        "    if not yesno:\n",
        "        print(f'{i:3d}: {inp}->/{\"\".join(ph for ph in out[0][:-1])}/',\n",
        "              f'{colored(yesno, color,attrs=[\"bold\"])}',\n",
        "              f' tgt:{\"\".join(ph for ph in tgt[:-1])}')\n",
        "\n",
        "p = counter/_ds.data_dict.__len__()\n",
        "print(f'counter:{counter}/{_ds.data_dict.__len__()} = {p * 100:6.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faaa1462-7928-45ff-8318-3df2fbea3a7f",
      "metadata": {
        "id": "faaa1462-7928-45ff-8318-3df2fbea3a7f"
      },
      "outputs": [],
      "source": [
        "for k, v in sorted(X.items()):\n",
        "    if isinstance(v, dict):\n",
        "        print(k, len(v))\n",
        "    else:\n",
        "        print(k, v)\n",
        "\n",
        "X.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#_ds.data_dict\n",
        "for i in tqdm(range(ds.__len__()>>factor)):\n",
        "    _inp, _tch = ds.__getitem__(i)\n",
        "    lex = ds.source_ids2tkn(_inp)\n",
        "    wrd = ds.source_ids2tkn(_inp)\n",
        "    kana = ds.data_dict[i]['yomi']\n",
        "    hira = jaconv.kata2hira(kana)\n",
        "    out = eval_input_seq2seq(encoder=encoder0, decoder=decoder0, ds=ds, inp_wrd=hira, isPrint=False)\n",
        "    \n",
        "    _tch_wrd = \"\".join(c for c in ds.target_ids2tkn(_tch)[:-1])\n",
        "    _out_wrd = \"\".join(c for c in out[0][:-1])\n",
        "    yesno = _out_wrd == _tch_wrd\n",
        "    if yesno:\n",
        "        color = 'blue'\n",
        "        counter += 1\n",
        "    else:\n",
        "        color = 'red'\n",
        "    if not yesno:\n",
        "        resps.append((i,hira,_out_wrd,_tch_wrd)) \n",
        "        #print(f'{i:4d} {hira}->/{_out_wrd}/({_tch_wrd})', \n",
        "        #      f'{colored(yesno, color,attrs=[\"bold\"])}')\n",
        "              \n",
        "p = counter/(ds.__len__()>>factor)\n",
        "print(f'counter:{counter}/{ds.__len__()>>factor}={p:6.3f}')"
      ],
      "metadata": {
        "id": "sIIBgGHqv5Dn"
      },
      "id": "sIIBgGHqv5Dn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7b8f2fcd-3ad4-40b7-84d5-322379e69f09",
      "metadata": {
        "id": "7b8f2fcd-3ad4-40b7-84d5-322379e69f09"
      },
      "source": [
        "## 1 パラメータの一部を凍結させて，転移学習 `model1` GRU を訓練可能とし，注意を凍結"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c1413b-4b40-435a-9ccd-a0eeebbdee7e",
      "metadata": {
        "id": "b7c1413b-4b40-435a-9ccd-a0eeebbdee7e"
      },
      "outputs": [],
      "source": [
        "def freeze_enc_dec_param(encoder:torch.nn.Module=encoder,\n",
        "                         decoder:torch.nn.Module=decoder,\n",
        "                         attn_flg:bool=True,\n",
        "                         gru_flg:bool=False,\n",
        "                        ):\n",
        "                         \n",
        "    encoder_parameters = {name:param for name, param in encoder.named_parameters()}\n",
        "    encoder_modules = {name:param for name, param in encoder.named_modules()}\n",
        "\n",
        "    decoder_parameters = {name:param for name, param in decoder.named_parameters()}\n",
        "    decoder_modules = {name:param for name, param in decoder.named_modules()}\n",
        "\n",
        "    # 転移学習で学習させるパラメータを、変数params_to_updateに格納する\n",
        "    params_to_update = {}\n",
        "    params_not_to_update = {}\n",
        "\n",
        "    # 学習させるパラメータ名\n",
        "    if attn_flg:\n",
        "        update_param_names = [\"attn.bias\", \"attn.weight\", \"attn_combine.bias\", \"attn_combine.weight\"]\n",
        "    elif gru_flg:\n",
        "        update_param_names = ['gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0']\n",
        "    else:\n",
        "        update_param_names = []\n",
        "\n",
        "    # 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "    for name, param in decoder.named_parameters():\n",
        "        if name in update_param_names:\n",
        "            param.requires_grad = True\n",
        "            params_to_update[name] = param\n",
        "        else:\n",
        "            param.requires_grad = False\n",
        "            params_not_to_update[name] = param\n",
        "\n",
        "    for name, param in encoder.named_parameters():\n",
        "        param.requires_grad = True\n",
        "        params_to_update[name] =  param\n",
        "                    \n",
        "    return encoder, decoder, params_to_update\n",
        "\n",
        "\n",
        "# model1 は GRU を訓練可能とし，attenion を fix\n",
        "encoder1, decoder1, _params_to_update = freeze_enc_dec_param(\n",
        "    encoder1, decoder1, \n",
        "    attn_flg=False,\n",
        "    gru_flg=True)\n",
        "print(_params_to_update.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63402cf0-e757-4d02-89a4-71898941b145",
      "metadata": {
        "id": "63402cf0-e757-4d02-89a4-71898941b145"
      },
      "source": [
        "### 1.1 再訓練の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a024214c-2aab-42a1-82e5-316bfda8a8a9",
      "metadata": {
        "id": "a024214c-2aab-42a1-82e5-316bfda8a8a9"
      },
      "outputs": [],
      "source": [
        "from RAM import train_epochs\n",
        "\n",
        "# model1 (encoder1, decoder1) を訓練\n",
        "losses = train_epochs( \n",
        "    epochs=100, # configs['epochs'], \n",
        "    lr=configs['lr'],\n",
        "    train_dataset=terao_se_ds,\n",
        "    val_dataset={'terao_sp_ds': terao_se_ds},\n",
        "    encoder=encoder1, decoder=decoder1,\n",
        "    encoder_optimizer=encoder1_optimizer, decoder_optimizer=decoder1_optimizer,\n",
        "    source_vocab=ds.source_list, target_vocab=ds.target_list,\n",
        "    source_ids=ds.source, target_ids=ds.target,\n",
        "    criterion=configs['loss_func'],\n",
        "    params=configs,\n",
        "    device=device,\n",
        "    max_length=ds.maxlen,\n",
        "    #n_sample=0,\n",
        "    teacher_forcing_ratio=configs['teacher_forcing_ratio'],\n",
        ")\n",
        "\n",
        "plt.plot(losses) \n",
        "\n",
        "_ds = terao_se_ds\n",
        "inputs = [v['ひら'] for k, v in _ds.data_dict.items()]\n",
        "counter = 0\n",
        "for i, inp in enumerate(inputs):\n",
        "    tgt = ds.target_ids2tkn(_ds.__getitem__(i)[-1])\n",
        "    out = eval_input_seq2seq(encoder=encoder1, decoder=decoder1, ds=ds, inp_wrd=inp, isPrint=False)\n",
        "    yesno = out[0] == tgt\n",
        "    if yesno:\n",
        "        color = 'blue'\n",
        "        counter += 1\n",
        "    else:\n",
        "        color = 'red'\n",
        "    if not yesno:\n",
        "        print(f'{i:3d}: {inp}->/{\"\".join(ph for ph in out[0][:-1])}/',\n",
        "              f'{colored(yesno, color,attrs=[\"bold\"])}',\n",
        "              f' tgt:{\"\".join(ph for ph in tgt[:-1])}')\n",
        "\n",
        "p = counter/_ds.data_dict.__len__()\n",
        "        \n",
        "print(f'counter:{counter}/{_ds.data_dict.__len__()} = {p * 100:6.2f}')    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outwrd, l = eval_input_seq2seq(encoder=encoder1, decoder=decoder1, ds=ds, isPrint=False)\n",
        "print(\" \".join(p for p in outwrd[:-1]), np.exp(np.array(l)))"
      ],
      "metadata": {
        "id": "6tZZ5cf8za9v"
      },
      "id": "6tZZ5cf8za9v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e66ef28b-7541-48b8-8793-d94fcedf0c06",
      "metadata": {
        "id": "e66ef28b-7541-48b8-8793-d94fcedf0c06"
      },
      "source": [
        "## 2 パラメータの一部を凍結させて，転移学習 `model2` GRU を凍結し，注意を訓練可能とする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc453edd-7fb4-4851-b432-65cb16850dfb",
      "metadata": {
        "id": "fc453edd-7fb4-4851-b432-65cb16850dfb"
      },
      "outputs": [],
      "source": [
        "# model2 は GRU を訓練可能とし，attenion を fix\n",
        "encoder2, decoder2, _params_to_update = freeze_enc_dec_param(\n",
        "    encoder2, decoder2, \n",
        "    attn_flg=True,\n",
        "    gru_flg=False)\n",
        "print(_params_to_update.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173cbd52-6723-46c6-b067-66977ace82da",
      "metadata": {
        "id": "173cbd52-6723-46c6-b067-66977ace82da"
      },
      "source": [
        "### 2.1. 再訓練の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4568e8-aff7-41f0-8e61-65f437e0f9a3",
      "metadata": {
        "id": "8f4568e8-aff7-41f0-8e61-65f437e0f9a3"
      },
      "outputs": [],
      "source": [
        "# model2 は GRU を fix, attention を訓練可能\n",
        "encoder2, decoder2, _params_to_update = freeze_enc_dec_param(\n",
        "    encoder2, decoder2, \n",
        "    attn_flg=True,\n",
        "    gru_flg=False)\n",
        "print(_params_to_update.keys())\n",
        "\n",
        "# model2 (encoder2, decoder2) を訓練\n",
        "losses = train_epochs( \n",
        "    epochs=configs['epochs'], \n",
        "    lr=configs['lr'],\n",
        "    train_dataset=terao_se_ds,\n",
        "    val_dataset={'terao_sp_ds': terao_se_ds},\n",
        "    encoder=encoder2, decoder=decoder2,\n",
        "    encoder_optimizer=encoder2_optimizer, decoder_optimizer=decoder2_optimizer,\n",
        "    source_vocab=ds.source_list, target_vocab=ds.target_list,\n",
        "    source_ids=ds.source, target_ids=ds.target,\n",
        "    criterion=configs['loss_func'],\n",
        "    params=configs,\n",
        "    device=device,\n",
        "    max_length=ds.maxlen,\n",
        "    #n_sample=0,\n",
        "    teacher_forcing_ratio=configs['teacher_forcing_ratio'],\n",
        ")\n",
        "\n",
        "plt.plot(losses) \n",
        "\n",
        "_ds = terao_se_ds\n",
        "inputs = [v['ひら'] for k, v in _ds.data_dict.items()]\n",
        "counter = 0\n",
        "for i, inp in enumerate(inputs):\n",
        "    tgt = ds.target_ids2tkn(_ds.__getitem__(i)[-1])\n",
        "    out = eval_input_seq2seq(encoder=encoder2, decoder=decoder2, ds=ds, inp_wrd=inp, isPrint=False)\n",
        "    yesno = out[0] == tgt\n",
        "    if yesno:\n",
        "        color = 'blue'\n",
        "        counter += 1\n",
        "    else:\n",
        "        color = 'red'\n",
        "    if not yesno:\n",
        "        print(f'{i:3d}: {inp}->/{\"\".join(ph for ph in out[0][:-1])}/',\n",
        "              f'{colored(yesno, color,attrs=[\"bold\"])}',\n",
        "              f' tgt:{\"\".join(ph for ph in tgt[:-1])}')\n",
        "\n",
        "p = counter/_ds.data_dict.__len__()\n",
        "        \n",
        "print(f'counter:{counter}/{_ds.data_dict.__len__()} = {p * 100:6.2f}')    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outwrd, l = eval_input_seq2seq(encoder=encoder2, decoder=decoder2, ds=ds, isPrint=False)\n",
        "print(\" \".join(p for p in outwrd[:-1]), np.exp(np.array(l)))"
      ],
      "metadata": {
        "id": "GfZ3Hd8-0MBp"
      },
      "id": "GfZ3Hd8-0MBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "42a25353-6f0e-4cd7-90e8-abe31e60302d",
      "metadata": {
        "id": "42a25353-6f0e-4cd7-90e8-abe31e60302d"
      },
      "source": [
        "\n",
        "フルの微調整の場合\n",
        "```\n",
        "  1: けが->/keka/ False  tgt:kage\n",
        "  8: こと->/koko/ False  tgt:toko\n",
        " 20: はまなこ->/chaNanako/ False  tgt:hanamako\n",
        " 21: こっきょう->/koqko:/ False  tgt:kyoqko:\n",
        " 30: のーとるだむ->/no:rutodamu/ False  tgt:no:tomudaru\n",
        " 37: こうしょきょうふしょう->/ko:shoko:fusho:/ False  tgt:kyo:shoko:fusho:\n",
        " 42: かんとくさんにん->/kaNtokukaNniN/ False  tgt:saNtokukaNniN\n",
        " 46: ななねんめ->/nanameNne/ False  tgt:shichimeNne\n",
        " 61: はいるあて->/karuhate/ False  tgt:airuhate\n",
        " 64: あんぜんうんてん->/aNzeNaNteN/ False  tgt:uNzeNaNteN\n",
        " 65: けいひん->/keikiN/ False  tgt:heikiN\n",
        " 85: かさま->/kakama/ False  tgt:sakama\n",
        " 90: かっぷ->/kyaqku/ False  tgt:paqku\n",
        "103: こと->/koko/ False  tgt:toko\n",
        "128: かってしったる->/kaqtekaqtaru/ False  tgt:shiqtekaqtaru\n",
        "140: たどって->/tadaq/ False  tgt:todaq\n",
        "counter:128/144 =  88.89\n",
        "```\n",
        "\n",
        "gru_flg = True の場合，すなわち attn_flg はフリーズされる場合\n",
        "\n",
        "```\n",
        " 12: あがつま->/agamama/ False  tgt:agamatsu\n",
        " 15: とつぎさき->/tutogisaki/ False  tgt:tsutogisaki\n",
        " 19: うらない->/urarai/ False  tgt:unarai\n",
        " 20: はまなこ->/chanamako/ False  tgt:hanamako\n",
        " 29: まほめっと->/mameNoqto/ False  tgt:mamehoqto\n",
        " 31: のーとるだむ->/no:tomudaru/ False  tgt:no:rutodamu\n",
        " 36: ほっとちょこ->/choqtochoko/ False  tgt:choqtohoko\n",
        " 38: さようはんさよう->/zayo:saNsayo:/ False  tgt:hayo:saNsayo:\n",
        " 41: かんこうきょうかい->/kaNko:ko:kai/ False  tgt:kaNkyo:ko:kai\n",
        " 42: かんとくさんにん->/kaNtokukaNniN/ False  tgt:saNtokukaNniN\n",
        " 45: さいもんとがーふぁんくる->/gaimoNtosa:furoNu/ False  tgt:gaimoNtosa:faNkuru\n",
        " 59: あけわたしました->/aakeatashimashita/ False  tgt:wakeatashimashita\n",
        " 60: たてのかいてん->/tatenotaiteN/ False  tgt:katenotaiteN\n",
        " 62: びじん->/jijiN/ False  tgt:jibiN\n",
        " 63: ほっとちょこれーと->/choqtochokore:to/ False  tgt:choqtohokore:to\n",
        " 64: あんぜんうんてん->/aNzeNaNteN/ False  tgt:uNzeNaNteN\n",
        " 77: みとめてもらう->/mitomo/ False  tgt:mitemo\n",
        " 80: くうこう->/ko:ko:/ False  tgt:ko:ku:\n",
        " 85: かさま->/kakama/ False  tgt:sakama\n",
        " 86: おおわらわ->/o:wara/ False  tgt:o:rawa\n",
        " 88: Eかっぷ->/mypaqku/ False  tgt:<UNK>paqku\n",
        "105: ばななわにえん->/bananabanieN/ False  tgt:wananabanieN\n",
        "118: うらわ->/uwaka/ False  tgt:uwara\n",
        "119: はをかって->/aaohaqte/ False  tgt:kaohaqte\n",
        "126: せんきょけっか->/seNkyoseqka/ False  tgt:keNkyoseqka\n",
        "130: さいたはな->/kaitasana/ False  tgt:haitasana\n",
        "132: うけとめて->/ututomere/ False  tgt:utoke\n",
        "140: たどって->/tadaq/ False  tgt:todaq\n",
        "141: たのしませて->/tanoe:ashi/ False  tgt:tanomashi\n",
        "counter:115/144 =  79.86\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}