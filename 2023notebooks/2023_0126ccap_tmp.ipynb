{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkQNh++z4BrgGBIFpcEzxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0126ccap_tmp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## はじめに\n",
        "\n",
        "符号化器-復号化器モデルは，[seq2seq](https://arxiv.org/abs/1409.3215) と呼ばれるモデルでもある。\n",
        "邦訳すれば，系列-2-系列 モデルなのだが，今回のプロジェクトでは，意味表象が，系列ではない。\n",
        "そのため，seq2seq という名称よりも，より一般化した，符号化器-復号化器 (enc-dec model) モデルとしたい。\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/master/assets/2014Sutskever_S22_Fig1.svg\" width=\"66%\">\n",
        "<br/>    \n",
        "From Sutskever 2014, Figure 1.\n",
        "</center>\n",
        "\n",
        "上図は，seq2seq モデルの概略図である。\n",
        "符号化器と呼ばれる部分は，トークン `<EOS>` が入力された時点までである。\n",
        "それ以降は，復号化器となる。\n",
        "符号化器と復号化器とで，一時刻前の中間層の状態が共有されていることがポイントである。\n",
        "seq2seq は翻訳モデルであり，符号化器と復号化器とで，言語モデルの扱う言語が異なっている。\n",
        "具体的には，フランス語と英語である。\n",
        "\n",
        "\n",
        "オリジナルの，三角モデルにおける o2p については，三層のニューラルネットワークとみなしうる。\n",
        "このため，o2p の中間層は，識別性能を向上する役割と，モダリティ間の結合という２つの異なる役割を担っていたとみなすことができる。\n",
        "理論的には，両者を分離する必要も，統合する必要もない，どちらにしても積極的な理由は存在しないと思われる。\n",
        "駄菓子菓子，計算論的な役割においては，異なるモダリティ間の通信を媒介する役割と，入力モダリティにおける表象を確立するという意味合いを分離すると，役割分担が明確になるのであろうということである。\n",
        "\n",
        "---\n",
        "\n",
        "* 一文字の orth2phon を担保したいために，全角の数字，アルファベット，ひらがな，計 109 文字をデータ先頭に追加した。\n",
        "* Fushimi1999 (Psyc. Rev.) の語彙リストを fushimi1999_list として収録\n",
        "* Fushimi1999_list の扱いに伴い訓練語彙数を 10K から 20K に増加\n",
        "* 学習率 lr は 0.001 だと収束しない。0.0001 であれば良好であり，訓練損失 0.01 程度，訓練精度 0.987 程度までに至る。\n",
        "* ただし，一文字データセット onechar_dataset では lr=0.001 の方が収束が早い。\n",
        "これは，データセットサイズが 20K と 0.1K と 20 倍の差があるためであろう。\n",
        "* 近藤先生が，GPU 上で実行してくださった訓練済モデルのファイル名が `decoder256new.pt` と `encoder256new.pt` である。\n",
        "これは，中間層ユニット数が 256 である orth2phon モデルの訓練済モデルである。\n",
        "* `_train()` 関数内で，正解判定をする際に，GPU から CPU へ転送しなければいけないことを忘れていたので修正した。\n",
        "具体的には， `detach()` と `numpy()` の間に `cpu()` を挿入した。2 箇所\n",
        "```python\n",
        "    ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().cpu().numpy()[0])\n",
        "```\n",
        "* 近藤先生の GPU で訓練済モデルを CPU 環境で実行する必要がある場合，変更して読み込む必要がある\n",
        "\n",
        "```python\n",
        "encoder_pretrained_fname = 'encoder256new.pt'\n",
        "decoder_pretrained_fname = 'decoder256new.pt'\n",
        "if os.path.exists(encoder_pretrained_fname):\n",
        "    encoder = torch.load(encoder_pretrained_fname, map_location=torch.device(device))\n",
        "    \n",
        "if os.path.exists(decoder_pretrained_fname):\n",
        "    decoder = torch.load(decoder_pretrained_fname, map_location=torch.device(device))\n",
        "```\n",
        "\n",
        "近藤先生の実験によれば，結果は以下の通りである(そうだ)。\n",
        "\n",
        "正答率\n",
        "\n",
        "|   | 条件 | 記述         | 正解率 | \n",
        "|:----|:-----|:------------|:------|\n",
        "|WORD |   HF |1:consistent |　18/20\n",
        "|WORD |   HF |2:typical    |   HF___inconsist  16/20|\n",
        "|WORD |   HF |3:atypical   |   HF___atypical_  8/20 |\n",
        "|WORD |   LF |1:consistent |   LF___consist__  14/20|\n",
        "|WORD |   LF |2:typical    |   LF___inconsist  9/20|\n",
        "|WORD |   LF |3:atypical   |   LF___atypical_  3/20|\n",
        "\n",
        "* 伏見らではでなかったatypical効果だけでなく，\n",
        "　consistent-typicalの差もある程度ある気がします\n",
        " また，LFでも効果ありであり，かつ，頻度効果もあり\n",
        "* **今回，L(legitimate alternative reading of components） マークを付けてみました**\n",
        "  Lm, Lnは，モーラ間違い，一文字間違いと混合\n",
        "\n",
        "\n",
        "アクセプト率\n",
        "\n",
        "|     | 条件 | 記述         | 正解率 | \n",
        "|:----|:----|:------------|:------|\n",
        "|非単語| HF  | 1:consistent|HFNW_consist__  17/20|\n",
        "|非単語| HF  | 2:typical   |HFNW_inconsist　　17/20|\n",
        "|非単語| HF  | 3:ambiguous |HFNW_ambiguous  13/20|\n",
        "|非単語| LF  | 1:consistent|LFNW_consist__  15/20|\n",
        "|非単語| LF  | 2:typical   |LFNW_inconsist  13/20|\n",
        "|非単語| LF  | 3:ambiguous |LFNW_ambiguous  7/20|\n",
        "\n",
        "* かなり読めますね．アクセプトは，どんな読みでもいいので読めそうな読み方ならOKにしています．\n",
        "　単語の L と同じになります．\n",
        "* **結構驚きは，非単語のときに連濁や促音化ができているところ**\n"
      ],
      "metadata": {
        "id": "J9uL3QXaXM_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2viQ_2wmXFvC"
      },
      "outputs": [],
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "#IPython.display.Image(url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\")\n",
        "#IPython.display.Image(url=\"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\")\n",
        "\n",
        "import os\n",
        "lum_img_fname = 'lum@pc.webp'\n",
        "if not os.path.exists(lum_img_fname):\n",
        "    !wget \"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\"\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "x = plt.imread('lum@pc.webp')\n",
        "plt.figure(figsize=(5,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 結果の描画"
      ],
      "metadata": {
        "id": "BclRT8bWXoQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "#import matplotlib    \n",
        "#matplotlib.rcParams['text.usetex'] = True    \n",
        "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
        "\n",
        "fig.suptitle('Fushimi+1999 単語リストの検証 (o2p, hid256)')\n",
        "ax[0].plot((18/20,16/20, 8/20), marker=\"v\", color=\"green\", label=\"高頻度\")\n",
        "ax[0].plot((14/20, 9/20, 3/20), marker=\"^\", color=\"blue\", label=\"低頻度\")\n",
        "ax[0].set_xlim(-0.5,2.5)\n",
        "ax[0].set_ylim(0,1)\n",
        "ax[0].set_xticks(ticks=range(3))\n",
        "ax[0].set_xticklabels(labels=['一貫','非一貫','例外'])\n",
        "ax[0].legend()\n",
        "ax[0].set_title('単語')\n",
        "ax[0].set_ylabel('正解率')\n",
        "\n",
        "ax[1].plot((17/20,17/20,13/20), marker=\"v\", color=\"green\", label=\"高頻度\")\n",
        "ax[1].plot((15/20,13/20, 7/20), marker=\"^\", color=\"blue\", label=\"低頻度\")\n",
        "ax[1].set_xlim(-0.5,2.5)\n",
        "ax[1].set_ylim(0,1)\n",
        "ax[1].set_xticks(ticks=range(3))\n",
        "ax[1].set_xticklabels(labels=['一貫','非一貫','例外'])\n",
        "ax[1].set_title('非単語')\n",
        "ax[1].legend()\n",
        "fig.savefig('2023_0123LAM_o2p_hid256_fushimi1999.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u0osMgeYXpWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 準備作業\n",
        "\n",
        "## 1.1 ライブラリのインポート"
      ],
      "metadata": {
        "id": "_jsDg4iAXt2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "from IPython import get_ipython\n",
        "import os\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "if isColab:\n",
        "    # `import bit` する前に termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==2.0 2>&1  \n",
        "    import termcolor    \n",
        "\n",
        "    # !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    # !git clone https://github.com/ShinAsakawa/bit.git 2>&1\n",
        "\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で MeCab を動作させるために，C コンパイラを起動して，MeCab の構築を行う\n",
        "    # そのため時間がかかる。\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    wakati = MeCab.Tagger('-Owakati').parse\n",
        "    yomi = MeCab.Tagger('-Oyomi').parse\n",
        "    \n",
        "else:\n",
        "    from ccap.mecab_settings import yomi\n",
        "    from ccap.mecab_settings import wakati\n",
        "\n",
        "# if isColab:\n",
        "#     !pip install jupyter_contrib_nbextensions 2>&1 \n",
        "#     !jupyter nbextension enable codefolding/main 2>&1"
      ],
      "metadata": {
        "id": "vfTOaL1eXq2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 パラメータ設定\n",
        "\n",
        "語彙数を 10K 語から 20K 語に倍増しているのは，Fushimi1999 の語彙リストの未知語が存在したためである。"
      ],
      "metadata": {
        "id": "slhJq-aSX0S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    # psylex71utf8.txt.gz, ntt_psylex.py, fushimi1999.py, triangle2_utils.py, 2023_0126triangle2.pt,\n",
        "    from google.colab import files\n",
        "    _ = files.upload()\n"
      ],
      "metadata": {
        "id": "Hd60CssLXvhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    !mkdir ccap\n",
        "    !mv psylex71utf8.txt.gz ccap"
      ],
      "metadata": {
        "id": "tmAAUVy-ZcrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from triangle2_utils import *\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "X = torch.load('2023_0126triangle2.pt', map_location=torch.device(device))\n",
        "encoder = X['encoder']\n",
        "decoder = X['decoder']\n",
        "params  = X['params']\n",
        "\n",
        "# モデルの概要を印字\n",
        "print(f'encoder:{encoder}')\n",
        "print(f'decoder:{decoder}')\n",
        "#print(f'params:{params}')\n",
        "for k, v in params.items():\n",
        "    print(f'{k}:{colored(v,\"red\",attrs=[\"bold\"])}')\n",
        "\n",
        "params['loss_func'] = torch.nn.NLLLoss()    "
      ],
      "metadata": {
        "id": "drCNxHxmYHil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# シミュレーションに必要なパラメータの設定\n",
        "try:\n",
        "    params\n",
        "except:\n",
        "    params = {\n",
        "        'traindata_size':  20000,   # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "        #'traindata_size': 301612,  # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "        'epochs': 30,               # 学習のためのエポック数\n",
        "        #'hidden_size': 256,          # 中間層のニューロン数\n",
        "        'hidden_size': 64,         # 中間層のニューロン数\n",
        "        'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "        # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "        'source': 'orth',          # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "        'target': 'orth',          # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "        #'target': 'mora_p_r',     # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "        # 'orth': 書記素, \n",
        "        # 'phon': 音韻, \n",
        "        # 'mora': モーラ\n",
        "        # 'mora_p': モーラを silius による音分解\n",
        "        # 'mora_p_r': モーラの silius 音分解の逆\n",
        "        'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "        #'pretrained': True,          # True であれば訓練済ファイルを読み込む\n",
        "        #'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "        # 学習済のモデルパラメータを保存するファイル名\n",
        "        #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "        #'path_saved': '2022_0829lam_p2p_hid24_vocab10k.pt',\n",
        "        'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "        # 結果の散布図を保存するファイル名    \n",
        "        'path_graph': '2023_0115lam_p2o_hid32_vocabntt_freq20k.pdf',\n",
        "        'path_graph': False,                     # 保存しない場合\n",
        "\n",
        "        'lr': 1e-4,                     # 学習率\n",
        "        'dropout_p': 0.0,                 # ドロップアウト率\n",
        "        'teacher_forcing_ratio': 0.5,     # 教師強制を行う確率\n",
        "        'optim_func': torch.optim.Adam,   # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "        'loss_func' :torch.nn.NLLLoss(),  # 負の対数尤度損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}"
      ],
      "metadata": {
        "id": "Jtm-Xv3KYZy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fushimi1999 import fushimi1999\n",
        "from fushimi1999 import _fushimi1999_list\n",
        "fushimi1999_list = _fushimi1999_list()"
      ],
      "metadata": {
        "id": "Fom1DczGYpzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import ntt_psylex\n",
        "\n",
        "_vocab = ntt_psylex.psylex71_dataset(\n",
        "    traindata_size=params['traindata_size'],\n",
        "    w2v=None,\n",
        "    yomi=yomi,\n",
        "    stop_list=fushimi1999_list,\n",
        "    source=params['source'],\n",
        "    target=params['target'],\n",
        ")\n",
        "\n",
        "top_n = 300\n",
        "print(f'語彙先頭の項目 {top_n} を印字')\n",
        "for i, wrd in enumerate(_vocab.word_list[:top_n]):\n",
        "    _end = \" \" if (i+1) % 10 != 0 else \"\\n\"\n",
        "    print((i+1, wrd), end=_end)"
      ],
      "metadata": {
        "id": "Brj4JseTY63v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from triangle2_utils import convert_ids2tensor    \n",
        "from triangle2_utils import calc_accuracy    \n",
        "from triangle2_utils import asMinutes\n",
        "from triangle2_utils import timeSince\n",
        "from triangle2_utils import check_vals_performance\n",
        "from triangle2_utils import evaluate\n",
        "from triangle2_utils import _train\n",
        "from triangle2_utils import _fit\n",
        "#from triangle2_utils import evaluate\n",
        "from triangle2_utils import Onechar_dataset"
      ],
      "metadata": {
        "id": "I-_PlPrCY_f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(\n",
        "    _dataset,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    max_length=None,\n",
        "    source_vocab=None,\n",
        "    target_vocab=None,\n",
        "    source_ids=None,\n",
        "    target_ids=None,\n",
        "    isPrint=False):\n",
        "\n",
        "    ok_count = 0\n",
        "    for i in range(_dataset.__len__()):\n",
        "        _input_ids, _target_ids = _dataset.__getitem__(i)\n",
        "        _output_words, _output_ids, _attentions = evaluate(\n",
        "            encoder=encoder,\n",
        "            decoder=decoder,\n",
        "            input_ids=_input_ids,\n",
        "            max_length=max_length,\n",
        "            source_vocab=source_vocab,\n",
        "            target_vocab=target_vocab,\n",
        "            source_ids=source_ids,\n",
        "            target_ids=target_ids,\n",
        "        )\n",
        "        ok_count += 1 if _target_ids == _output_ids else 0\n",
        "        if (_target_ids != _output_ids) and (isPrint):\n",
        "            print(i, _target_ids == _output_ids, _output_words, _input_ids, _target_ids)\n",
        "\n",
        "    return ok_count/_dataset.__len__()"
      ],
      "metadata": {
        "id": "wWY7zIQ-ZA9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onechar_dataset = Onechar_dataset(\n",
        "    source=params['source'], \n",
        "    target=params['target'],\n",
        "    yomi=yomi,\n",
        "    _vocab=_vocab)"
      ],
      "metadata": {
        "id": "J7-lO1qpZ5Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    losses\n",
        "except:\n",
        "    losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=10,\n",
        "               #epochs=params['epochs'], \n",
        "               max_length=_vocab.source_maxlen,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=_vocab.source_vocab,\n",
        "               target_vocab=_vocab.target_vocab,\n",
        "               source_ids=_vocab.source_ids,\n",
        "               target_ids=_vocab.target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               #train_dataset=train_dataset,\n",
        "               train_dataset=onechar_dataset,\n",
        "               #lr=params['lr'],\n",
        "               lr=0.001,\n",
        "               val_dataset=None,\n",
        "               #val_dataset=X_vals,\n",
        "              )"
      ],
      "metadata": {
        "id": "dh0GnceQZ-69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "WyvB7uznZ_O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 3000\n",
        "_orth_ids = _vocab.__getitem__(N)[0]\n",
        "_phon_ids = _vocab.__getitem__(N)[1]\n",
        "_orth = _vocab.orth_ids2tkn(_orth_ids)\n",
        "_phon = _vocab.phon_ids2tkn(_phon_ids)\n",
        "print(_orth, _phon)\n",
        "# print(_vocab.orth_ids2tkn(_vocab.__getitem__(N)[0]))\n",
        "# print(_vocab.phon_ids2tkn(_vocab.__getitem__(N)[1]))"
      ],
      "metadata": {
        "id": "PQd2rz67abqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_fushimi1999_list(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           is_print:bool=False,\n",
        "                          )->str:\n",
        "\n",
        "    ret_msg = \"\"\n",
        "    counter = 1\n",
        "    for key, val in fushimi1999.items():\n",
        "        key_old = \"\"\n",
        "        if key != key_old:\n",
        "            key_old = key\n",
        "            ret_msg += f'{key}:'\n",
        "            if is_print:\n",
        "                print(colored(f'{key}:', 'green', attrs=['bold']), end=\" \")\n",
        "        \n",
        "        n_ok, n_all = 0, 0\n",
        "        msg = \"\"\n",
        "        for wrd in val:\n",
        "            _orth = _vocab.orth_tkn2ids(wrd) + [_vocab.orth_vocab.index('<EOW>')]\n",
        "            ans=evaluate(encoder,\n",
        "                         decoder,\n",
        "                         _orth,\n",
        "                         _vocab.source_maxlen,\n",
        "                         _vocab.source_vocab,\n",
        "                         _vocab.target_vocab,\n",
        "                         _vocab.source_ids,\n",
        "                         _vocab.target_ids)\n",
        "            \n",
        "            res = \"\".join(p for p in ans[0][:-1])  # モデルからの戻り値を再構成\n",
        "            if res == wrd:\n",
        "                n_ok += 1\n",
        "            n_all += 1\n",
        "\n",
        "            counter =  1 if (counter % 10) == 0 else (counter + 1)\n",
        "            _end = \"\\n\" if counter==1 else \", \"\n",
        "            # print(f'{wrd}',\n",
        "            #       colored(f'/{res}/','grey', attrs=['bold']), \n",
        "            #       end=_end)\n",
        "            msg += f\"{wrd}->/{res}/{_end}\"\n",
        "            \n",
        "        ret_msg += f'{n_ok/n_all * 100:5.2f}%\\n{msg}'\n",
        "        if is_print:\n",
        "            print(f'{n_ok/n_all * 100:5.2f}%\\n{msg}')\n",
        "            \n",
        "    return ret_msg\n",
        "            \n",
        "print(check_fushimi1999_list())"
      ],
      "metadata": {
        "id": "e1Qz7FsHadzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P  = int(_vocab.__len__() * 0.9)\n",
        "_P = _vocab.__len__() - P\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset=_vocab,\n",
        "                                                           lengths=(P, _P),\n",
        "                                                           generator=torch.Generator().manual_seed(params['random_seed']))\n"
      ],
      "metadata": {
        "id": "QWpxpMnyafT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    losses\n",
        "except:\n",
        "    losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               #epochs=10,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.source_maxlen,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=_vocab.source_vocab,\n",
        "               target_vocab=_vocab.target_vocab,\n",
        "               source_ids=_vocab.source_ids,\n",
        "               target_ids=_vocab.target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=train_dataset,\n",
        "               #train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               #lr=0.001,\n",
        "               val_dataset={'val': val_dataset},\n",
        "               #val_dataset=X_vals,\n",
        "              )"
      ],
      "metadata": {
        "id": "ozeN3vDwaiJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({'encoder':encoder, 'decoder':decoder, 'params':params, 'losses':losses}, '2023_0126triangle2.pt')\n",
        "if isColab:\n",
        "    files.download('2023_0126triangle2.pt')"
      ],
      "metadata": {
        "id": "7GiBEw9Falmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}