{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0824pytorch_dataset_data_loader_sampler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CNAFLu8hN1o"
      },
      "source": [
        "# PyTorch `Dataset`, `DataLoader`, `Sampler`, `Transforms` の使い方 <!-- # Working with Data: `Dataset`, `DataLoader`, `Sampler`, and `Transforms` -->\n",
        "\n",
        "これらの基本的な概念により，大規模なデータを簡単に扱うことができる。\n",
        "<!-- These basic concepts make it easy to work with large data. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN1vjd2thN1p"
      },
      "source": [
        "## 必要となるライブラリ，補助関数，ユーティリティ等の輸入\n",
        "<!-- ## Init, helpers, utils, ... -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "o_xC8a0KhN1p"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qe-gWg4FhN1q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PsOSKb_NhN1q"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.core.debugger import set_trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oGEE18AhN1q"
      },
      "source": [
        "# `Dataset`\n",
        "\n",
        "データセットを作るのは簡単な方法を示す。\n",
        "PyTorch には\n",
        "あらかじめ [データセット](https://pytorch.org/docs/stable/torchvision/datasets.html) が定義されている。\n",
        "以下に例を示す：\n",
        "\n",
        "<!-- It's easy to create your `Dataset`,\n",
        "but PyTorch comes with some\n",
        "[build-in datasets](https://pytorch.org/docs/stable/torchvision/datasets.html):\n",
        "-->\n",
        "\n",
        "- MNIST\n",
        "- Fashion-MNIST\n",
        "- KMNIST\n",
        "- EMNIST\n",
        "- FakeData\n",
        "- COCO\n",
        "  - Captions\n",
        "  - Detection\n",
        "- LSUN\n",
        "- ImageFolder\n",
        "- DatasetFolder\n",
        "- Imagenet-12\n",
        "- CIFAR\n",
        "- STL10\n",
        "- SVHN\n",
        "- PhotoTour\n",
        "- SBU\n",
        "- Flickr\n",
        "- VOC\n",
        "- Cityscapes\n",
        "\n",
        "`Dataset` はサンプルの数に関する情報を与え (`__len__` を実装)，与えられたインデックスのサンプルを与える (`__getitem__`) を実装する必要がある。\n",
        "これはデータを扱うためのシンプルで良い抽象化となっている。\n",
        "\n",
        "<!--`Dataset` gives you information about the number of samples (implement `__len__`) and gives you the sample at a given index (implement `__getitem__`.\n",
        "It's a nice and simple abstraction to work with data.-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_YFozjADhN1q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYXS6du7hN1q"
      },
      "source": [
        "```python\n",
        "class Dataset(object):\n",
        "    def __getitem__(self, index):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return ConcatDataset([self, other])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_39iSJNhN1q"
      },
      "source": [
        "`ImageFolder` データセットは非常に便利で，フォルダレイアウトの通常の規則に従っている：<!-- The `ImageFolder` dataset is quite useful and follows the usual conventions for folder layouts: -->\n",
        "\n",
        "```\n",
        "root/dog/xxx.png\n",
        "root/dog/xxy.png\n",
        "root/dog/xxz.png\n",
        "\n",
        "root/cat/123.png\n",
        "root/cat/nsdf3.png\n",
        "root/cat/asd932_.png\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk9VkVV2hN1q"
      },
      "source": [
        "## 例 <!--Example-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hU8gMY75hN1q"
      },
      "outputs": [],
      "source": [
        "# %load my_datasets.py\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "from torchvision.datasets.folder import ImageFolder, default_loader\n",
        "from torchvision.datasets.utils import download_url, check_integrity\n",
        "\n",
        "################################################################################\n",
        "# PyTorch\n",
        "class DogsCatsDataset(ImageFolder):\n",
        "    \"\"\"\n",
        "    The 'Dogs and Cats' dataset from kaggle.\n",
        "\n",
        "    https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/\n",
        "\n",
        "    Args:\n",
        "        root: the location where to store the dataset\n",
        "        suffix: path to the train/valid/sample dataset. See folder structure.\n",
        "        transform (callable, optional): A function/transform that takes in\n",
        "            an PIL image and returns a transformed version.\n",
        "            E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that\n",
        "            takes in the target and transforms it.\n",
        "        loader: A function to load an image given its path.\n",
        "        download: if ``True``, download the data.\n",
        "\n",
        "\n",
        "    The folder structure of the dataset is as follows::\n",
        "\n",
        "        └── dogscats\n",
        "            ├── sample\n",
        "            │   ├── train\n",
        "            │   │   ├── cats\n",
        "            │   │   └── dogs\n",
        "            │   └── valid\n",
        "            │       ├── cats\n",
        "            │       └── dogs\n",
        "            ├── train\n",
        "            │   ├── cats\n",
        "            │   └── dogs\n",
        "            └── valid\n",
        "                ├── cats\n",
        "                └── dogs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    url = 'https://files.fast.ai/data/examples/dogscats.tgz'\n",
        "    filename = \"dogscats.tgz\"\n",
        "    checksum = 'ad2c4e646241a6dc06aedb4b59ef7687'\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        suffix: str,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        loader=default_loader,\n",
        "        download=False,\n",
        "    ):\n",
        "        self.root = os.path.expanduser(root)\n",
        "\n",
        "        if download:\n",
        "            self._download()\n",
        "            self._extract()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\n",
        "                \"Dataset not found or corrupted. \"\n",
        "                \"You can use download=True to download it\"\n",
        "            )\n",
        "\n",
        "        path = os.path.join(self.root, \"dogscats\", suffix)\n",
        "        print(f\"Loading data from {path}.\")\n",
        "        assert os.path.isdir(path), f\"'{suffix}' is not valid.\"\n",
        "\n",
        "        super().__init__(path, transform, target_transform, loader)\n",
        "\n",
        "    def _download(self):\n",
        "        if self._check_integrity():\n",
        "            print(\"Dataset already downloaded and verified.\")\n",
        "            return\n",
        "\n",
        "        root = self.root\n",
        "        print(\"Downloading dataset... (this might take a while)\")\n",
        "        download_url(self.url, root, self.filename, self.checksum)\n",
        "\n",
        "    def _extract(self):\n",
        "        path_to_tgz = os.path.join(self.root, self.filename)\n",
        "\n",
        "        # open file\n",
        "        file = tarfile.open(path_to_tgz)\n",
        "\n",
        "        # extracting file\n",
        "        file.extractall(self.root)\n",
        "        file.close()\n",
        "        #path_to_zip = os.path.join(self.root, self.filename)\n",
        "        #with zipfile.ZipFile(path_to_zip, \"r\") as zip_ref:\n",
        "        #    zip_ref.extractall(self.root)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        path_to_zip = os.path.join(self.root, self.filename)\n",
        "        return check_integrity(path_to_zip, self.checksum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "EiIySkiAhN1r"
      },
      "outputs": [],
      "source": [
        "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install tree"
      ],
      "metadata": {
        "id": "PstG93uzlJKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "fCCnH2_ShN1r"
      },
      "outputs": [],
      "source": [
        "!tree -d ../data/raw/dogscats/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "UIqD-iUlhN1r"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "cn-_cN7jhN1s"
      },
      "outputs": [],
      "source": [
        "# the __len__ method\n",
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "tkCWDtcqhN1s"
      },
      "outputs": [],
      "source": [
        "# the __getitem__ method\n",
        "train_ds[0]\n",
        "#print(len(train_ds[0]))  # 2\n",
        "#print(train_ds[0])  # (PIL.Image.Image mode=RGB, 0)\n",
        "print(train_ds[0][0].size)  # (499,375)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "AWtsRn59hN1s"
      },
      "outputs": [],
      "source": [
        "train_ds[15][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcJUEuDShN1s",
        "outputId": "03b235e6-eb7f-4eed-ea0c-6c8c4776f86a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_ds[14][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R2yVqoQhN1s"
      },
      "source": [
        "オプションとして，便利な関数や属性を提供するデータセットもある．\n",
        "これはインターフェイスによって強制されるものではない．それに頼ってはいけない．\n",
        "<!-- Optionally, some datasets offer convenience functions and attributes.\n",
        "This is not enforced by the interface! Don't rely on it! -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "YCTcpZ16hN1s"
      },
      "outputs": [],
      "source": [
        "train_ds.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Hiuz_PhYhN1s"
      },
      "outputs": [],
      "source": [
        "train_ds.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "px242KShhN1s"
      },
      "outputs": [],
      "source": [
        "train_ds.imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "aHfDrxO7hN1s"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9vUJD6_vhN1s"
      },
      "outputs": [],
      "source": [
        "for img, label_id in random.sample(list(train_ds), 4):\n",
        "    print(label_id, train_ds.classes[label_id])\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YE_nCNmhN1s"
      },
      "source": [
        "# `torchvision.transforms`\n",
        "\n",
        "合成，連鎖などの操作可能な一般的な画像変換について [torchvision の transform 参照](https://pytorch.org/vision/stable/transforms.html)\n",
        "\n",
        "<!-- (https://pytorch.org/docs/stable/torchvision/transforms.html)。 -->\n",
        "<!-- Common image transformation that can be composed/chained [[docs]](https://pytorch.org/docs/stable/torchvision/transforms.html). -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "c8O4uHKLhN1s"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ChJc6BhuhN1s"
      },
      "outputs": [],
      "source": [
        "_image_size = 224\n",
        "_mean = [0.485, 0.456, 0.406]\n",
        "_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    transforms.RandomCrop(_image_size),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.ColorJitter(.3, .3, .3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])\n",
        "\n",
        "trans(train_ds[13][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4xgQ4NghN1s"
      },
      "source": [
        "## `torchvision.transforms.functional`\n",
        "\n",
        "<blockquote>\n",
        "\n",
        "`Funcitional transforms` では，transform パイプラインを細かく制御することができる。\n",
        "上記の transform とは対照的に，functional transform はパラメータに乱数生成器を含まない。\n",
        "つまり，すべてのパラメータを指定/生成する必要がある。\n",
        "だが，functional transform を再利用することができる。\n",
        "たとえば，以下のように複数の画像に関数変換を適用することができる：\n",
        "<!-- Functional transforms give you fine-grained control of the transformation pipeline.\n",
        "As opposed to the transformations above, functional transforms don’t contain a random number generator for their parameters.\n",
        "That means you have to specify/generate all parameters, but you can reuse the functional transform.\n",
        "For example, you can apply a functional transform to multiple images like this: -->\n",
        "\n",
        "https://pytorch.org/vision/stable/transforms.html\n",
        "</blockquote>\n",
        "\n",
        "```python\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "\n",
        "def my_segmentation_transforms(image, segmentation):\n",
        "    if random.random() > 5:\n",
        "        angle = random.randint(-30, 30)\n",
        "        image = TF.rotate(image, angle)\n",
        "        segmentation = TF.rotate(segmentation, angle)\n",
        "    # more transforms ...\n",
        "    return image, segmentation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH3oflXQhN1t"
      },
      "source": [
        "Ref:\n",
        "- https://pytorch.org/vision/stable/transforms.html\n",
        "- https://pytorch.org/vision/stalbe/transforms.html#functional-transforms\n",
        "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "- https://github.com/mdbloice/Augmentor\n",
        "- https://github.com/aleju/imgaug\n",
        "\n",
        "<!--\n",
        "- https://pytorch.org/docs/stable/torchvision/transforms.htm\n",
        "- https://pytorch.org/docs/stable/torchvision/transforms.html#functional-transforms\n",
        "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "- https://github.com/mdbloice/Augmentor\n",
        "- https://github.com/aleju/imgaug -->\n",
        "\n",
        "Shout-out:\n",
        "- Hig performance image augmentation with pillow-simd [[github]](https://github.com/uploadcare/pillow-simd) [[benchmark]](http://python-pillow.org/pillow-perf/)\n",
        "- Improving Deep Learning Performance with AutoAugment [[blog]](https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html) [[paper]](https://arxiv.org/abs/1805.09501) [[pytorch implementation]](https://github.com/DeepVoltaire/AutoAugment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55bx_wZShN1t"
      },
      "source": [
        "# `Dataloader`\n",
        "\n",
        "`DataLoader` クラスは，データセットのバッチ化ローディングをマルチプロセシングと様々なサンプリング手法で提供している。\n",
        "公式ドキュメントは\n",
        "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "<!-- The `DataLoader` class offers batch loading of datasets with multi-processing and different sample strategies [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).-->\n",
        "\n",
        "プロトタイプは以下のようになる： <!-- The signature looks something like this: -->\n",
        "\n",
        "```python\n",
        "DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    sampler=None,\n",
        "    batch_sampler=None,\n",
        "    num_workers=0,\n",
        "    collate_fn=default_collate,\n",
        "    pin_memory=False,\n",
        "    drop_last=False,\n",
        "    timeout=0,\n",
        "    worker_init_fn=None\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4QndeNGPhN1t"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfh4__CzhN1t",
        "outputId": "7876f6a7-aae9-43e8-e1c0-ae2f8083d20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from ../data/raw/dogscats/sample/train.\n"
          ]
        }
      ],
      "source": [
        "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", transform=trans)\n",
        "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
        "#train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4mbBNsO1hN1t"
      },
      "outputs": [],
      "source": [
        "train_iter = iter(train_dl)\n",
        "X, y = next(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APvu9LsAhN1t",
        "outputId": "9650bb04-f1ae-4d6c-9635-0c9723671334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: torch.Size([2, 3, 224, 224])\n",
            "y: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSysRYeHhN1t"
      },
      "source": [
        "`trans` を渡したが，これは pillow 画像ではなく `torch.Tensor` を返す。\n",
        "DataLoader はテンソル，数値，辞書，リストを想定している。\n",
        "<!-- Note that I passed `trans`, which returns `torch.Tensor`, not pillow images.\n",
        "DataLoader expects tensors, numbers, dicts or lists. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvZ_rKz0hN1t",
        "outputId": "9c290bc6-7543-4ffa-9e39-cfeb6ffebc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from ../data/raw/dogscats/sample/train.\n",
            "ERROR\n",
            "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
          ]
        }
      ],
      "source": [
        "_train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", transform=None)\n",
        "_train_dl = DataLoader(_train_ds, batch_size=2, shuffle=True)\n",
        "\n",
        "try:\n",
        "    for batch in _train_dl:\n",
        "        pass\n",
        "except TypeError as e:\n",
        "    print(\"ERROR\")\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0zKEMLShN1t"
      },
      "source": [
        "## `collate_fn`\n",
        "\n",
        "`DataLoader` の `collate_fn` 引数を使用すると，単一のデータポイントをバッチにまとめる方法をカスタマイズできる。\n",
        "`collate_fn` はデータポイントのリスト (`dataset.__getitem__` が返すもの) を取得する単純な callable である。\n",
        "<!-- The `collate_fn` argument of `DataLoader` allows you to customize how single datapoints are put together into a batch.\n",
        "`collate_fn` is a simple callable that gets a list of datapoints (i.e. what `dataset.__getitem__` returns). -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VypMasqUhN1t"
      },
      "source": [
        "カスタム`collate_fn`の例\n",
        "([こちら](https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278/3)から引用)：\n",
        "\n",
        "<!-- Example of a custom `collate_fn`\n",
        "(taken from [here](https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278/3)): -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "S9joUpGUhN1t"
      },
      "outputs": [],
      "source": [
        "def my_collate_fn(list_of_x_y):\n",
        "    data = [item[0] for item in list_of_x_y]\n",
        "    target = [item[1] for item in list_of_x_y]\n",
        "    target = torch.LongTensor(target)\n",
        "    return [data, target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbuOSKTlhN1t"
      },
      "source": [
        "# `Sampler`\n",
        "\n",
        "`Sampler` はデータセット[[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.sampler.Sampler)からサンプリングする方法を定義する。\n",
        "\n",
        "<!-- `Sampler` define **how** to sample from the dataset [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.sampler.Sampler). -->\n",
        "\n",
        "例:\n",
        "- `SequentialSampler`\n",
        "- `RandomSamples`\n",
        "- `SubsetSampler`\n",
        "- `WeightedRandomSampler`\n",
        "\n",
        "`__iter__` を実装するだけで，データセットのインデックスを繰り返し処理することができる。\n",
        "<!-- Write your own by simply implementing `__iter__` to iterate over the indices of the dataset. -->\n",
        "\n",
        "```python\n",
        "class Sampler(object):\n",
        "    def __init__(self, data_source):\n",
        "        pass\n",
        "\n",
        "    def __iter__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OueURAZ3hN1t"
      },
      "source": [
        "# まとめ <!-- # Recap-->\n",
        "\n",
        "- `Dataset`：データポイントを1つ取得する\n",
        "- `transforms`: 組み合わせ可能な変換\n",
        "- `DataLoader`: 1 つのデータポイントをバッチにまとめる\n",
        "- `Sampler`：データセットからサンプリングする方法を提供\n",
        "\n",
        "簡潔で拡張可能なインターフェースである\n",
        "\n",
        "<!-- - `Dataset`: get one datapoint\n",
        "- `transforms`: composable transformations\n",
        "- `DataLoader`: combine single datapoints into batches (plus multi processing and more)\n",
        "- `Sampler`: **how** to sample from a dataset\n",
        "\n",
        "**Simple but extensible interfaces** -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMqHtp79hN1t"
      },
      "source": [
        "# 演習 <!--Exercise-->\n",
        "\n",
        "- `DogsCatsDataset` を拡張して，データセットのサイズ，つまりサンプルの数を指定できるようにせよ。\n",
        "- より小さなデータセットを作成するために  `Subset` [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) を試せ。\n",
        "- データセットのサイズ (0 から1 の間) を指定することができる `SubsetFraction` を作成せよ。\n",
        "- `DogsCatsDataset` 用のカスタム collate 関数を書いて，自己符号化器の設定で使用するのに適切なデータセットにせよ。\n",
        "\n",
        "\n",
        "<!-- Go out and play:\n",
        "\n",
        "- Maybe extend the `DogsCatsDataset` such that you can specify the size of dataset, i.e. the number of samples.\n",
        "- Maybe try the `Subset` [[docs]](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) to create smaller datasets.\n",
        "- Maybe create `SubsetFraction` where you can specify the size of the dataset (between 0. and 1.).\n",
        "- Maybe write a custom collate function for the `DogsCatsDataset` that turns it into a dataset appropriate to use in an autoencoder settings. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PgjRC987hN1t"
      },
      "outputs": [],
      "source": [
        "def autoencoder_collate_fn(list_of_x_y):\n",
        "    # TODO implement me\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "FCsRuAsIhN1u"
      },
      "outputs": [],
      "source": [
        "class MyDataSet(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO implement me\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO implement me\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO implement me\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obWLcrbDrg2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}