{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN0Ebn8RLDlqrp1Ia+p/pw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0113lam_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w5JxNk5Fq3E"
      },
      "outputs": [],
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "#IPython.display.Image(url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\")\n",
        "IPython.display.Image(url=\"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 準備作業\n"
      ],
      "metadata": {
        "id": "WURvZt39Lxm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.1 ライブラリのインポート\n",
        "\n",
        "1.   直下セルは，mecab をコンパイルするので時間がかかるので注意\n",
        "\n"
      ],
      "metadata": {
        "id": "vtmclGaRLyyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    wakati = MeCab.Tagger('-Owakati').parse\n",
        "    yomi = MeCab.Tagger('-Oyomi').parse\n",
        "else:\n",
        "    from ccap.mecab_settings import yomi\n",
        "    from ccap.mecab_settings import wakati\n",
        "\n",
        "# 自作ライブラリ LAM の読み込み\n",
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    !git clone https://github.com/ShinAsakawa/lam.git"
      ],
      "metadata": {
        "id": "4AKzWYhyFzNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Colab 上で実行する場合，必要なファイルのアップロード"
      ],
      "metadata": {
        "id": "3Uo56ZcOGFrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # upload `pslex71utf8.txt`, NTT 日本語の語彙特性 頻度データ\n",
        "# # upload `lam/2022_0508SALA_TLPA.json` SALA と TLPA のデータが必要になるかもしれない。\n",
        "# if isColab:\n",
        "#     from google.colab import files\n",
        "#     uploaded = files.upload()"
      ],
      "metadata": {
        "id": "b2HdzvD9F_Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 パラメータ設定"
      ],
      "metadata": {
        "id": "F6zaoXdEGPK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import lam\n",
        "device = lam.device  # CPU or GPU の選択\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "params = {\n",
        "    'traindata_size':  20000,   # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    #'traindata_size': 301612,  # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    'epochs': 20,               # 学習のためのエポック数\n",
        "    'hidden_size': 128,         # 中間層のニューロン数\n",
        "    'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "    # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "    'source': 'orth',          # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    'target': 'phon',         # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    #'target': 'mora_p_r',      # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    # 'orthography': 書記素, \n",
        "    # 'phonology': 音韻, \n",
        "    # 'mora': モーラ\n",
        "    # 'mora_p': モーラを silius による音分解\n",
        "    # 'mora_p_r': モーラの silius 音分解の逆\n",
        "    'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "    #'pretrained': True,          # True であれば訓練済ファイルを読み込む\n",
        "    #'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "    #'path_saved': '2022_0829lam_p2p_hid24_vocab10k.pt',\n",
        "    'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "    # 結果の散布図を保存するファイル名    \n",
        "    #'path_graph': '2022_0829lam_p2p_hid24_vocab10k.pdf',\n",
        "    'path_graph': False,                     # 保存しない場合\n",
        "\n",
        "    'lr': 0.0001,                              # 学習率\n",
        "    'dropout_p': 0.0,                         # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,             # 教師強制を行う確率\n",
        "    'optim_func': torch.optim.Adam,           # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :torch.nn.CrossEntropyLoss(), # 交差エントロピー損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}"
      ],
      "metadata": {
        "id": "wNfdyAqrGP6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 データセットの設定"
      ],
      "metadata": {
        "id": "u_ZJ76frGpe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_vocab = lam.VOCAB(traindata_size=params['traindata_size'], \n",
        "                   w2v=None, \n",
        "                   yomi=yomi) \n",
        "\n",
        "source = params['source']\n",
        "target = params['target']\n",
        "\n",
        "# _max_len はアテンション機構のデコーダで必要になるため，全条件で最長の長さを指定する必要がある\n",
        "_max_len = _vocab.max_ortho_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_phone_length else _vocab.max_phone_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_length else _vocab.max_mora_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_p_length else _vocab.max_mora_p_length\n",
        "_vocab.max_length = _max_len + 1\n",
        "print(colored(f'_vocab.max_length: {_vocab.max_length}', 'blue', attrs=['bold']))\n",
        "\n",
        "# ソース，すなわち encoder 側の，項目番号，項目 ID，decoder 側の項目，項目 ID を設定\n",
        "source_vocab, source_ids, target_vocab, target_ids = lam.get_soure_and_target_from_params(\n",
        "    params=None,\n",
        "    _vocab=_vocab,\n",
        "    source=source,\n",
        "    target=target,\n",
        "    is_print=True)\n",
        "\n",
        "print(colored(f'source:{source}','blue', attrs=['bold']), f'{source_vocab}')\n",
        "print(colored(f'target:{target}','cyan', attrs=['bold']), f'{target_vocab}')\n",
        "print(colored(f'source_ids:{source_ids}','blue', attrs=['bold']), f'{source_ids}')\n",
        "print(colored(f'target_ids:{target_ids}','cyan', attrs=['bold']), f'{target_ids}')\n",
        "\n",
        "# 検証データとして，TLPA と SALA のデータを用いる\n",
        "tlpa1, tlpa2, tlpa3, tlpa4, sala_r29, sala_r30, sala_r31 = lam.read_json_tlpa1234_sala_r29_30_31(\n",
        "    json_fname='lam/2022_0508SALA_TLPA.json')\n",
        "\n",
        "_dataset = {}\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']\n",
        "for data in _data_names:\n",
        "    _dataset[data] = {'rawdata':eval(data),\n",
        "                      'pdata': lam.make_vocab_dataset(eval(data),vocab=_vocab)}\n",
        "\n",
        "# 以下は後から付け足したので，コードが汚くなっている。\n",
        "# 時間ができたらコードの整理をすること\n",
        "X_vals = lam.make_X_vals(_dataset=_dataset,\n",
        "                         source_vocab=source_vocab,\n",
        "                         target_vocab=target_vocab,\n",
        "                         source_ids=source_ids,\n",
        "                         target_ids=target_ids\n",
        "                        )"
      ],
      "metadata": {
        "id": "m3N6-wUoGRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_wordlist = [v['orig'] for k, v in _vocab.train_data.items()]\n",
        "print(len(train_wordlist))"
      ],
      "metadata": {
        "id": "lXta-tEBGs60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 任意の単語 orthography を変換するための関数"
      ],
      "metadata": {
        "id": "L-1QLzhrGxfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_ids_from_orth(orth_wrd:str='てれび',\n",
        "                       __vocab:lam.lam.VOCAB=_vocab):\n",
        "    _yomi, _phon, _phon_r, _orth, _orth_r, _mora, _mora_r = __vocab.get7lists_from_orth(orth=orth_wrd)\n",
        "    phon_ids, phon_ids_r, orth_ids, orth_ids_r, mora_ids, mora_ids_r = __vocab.get6ids(yomi=_yomi, _phon=_phon, _orth=_orth)\n",
        "    \n",
        "    return {'_yomi':_yomi,\n",
        "            '_phon':_phon,\n",
        "            '_phon_r':_phon_r,\n",
        "            '_orth':_orth,\n",
        "            '_orth_r':_orth_r,\n",
        "            '_mora':_mora,\n",
        "            '_mora_r':_mora_r,\n",
        "            'phon_ids':phon_ids,\n",
        "            'phon_ids_r':phon_ids_r,\n",
        "            'orth_ids':orth_ids,\n",
        "            'orth_ids_r':orth_ids_r,\n",
        "            'mora_ids':mora_ids,\n",
        "            'mora_ids_r':mora_ids_r,\n",
        "           }\n",
        "    \n",
        "print(_get_ids_from_orth())\n",
        "\n",
        "\n",
        "def orth_ids2tkn(ids:list):\n",
        "    return [_vocab.ortho_vocab[idx] for idx in ids]\n",
        "\n",
        "def orth_tkn2ids(tkn:list):\n",
        "    return [_vocab.ortho_vocab.index(_tkn) if _tkn in _vocab.ortho_vocab else _vocab.ortho_vocab.index('<UNK>') for _tkn in tkn]\n",
        "\n",
        "def mora_p_ids2tkn(ids:list):\n",
        "    return [_vocab.mora_p_vocab[idx] for idx in ids]\n",
        "\n",
        "def mora_p_tkn2ids(tkn:list):\n",
        "    return [_vocab.mora_p_vocab.index(_tkn) if _tkn in _vocab.mora_p_vocab else _vocab.mora_p_vocab('<UNK>') for _tkn in tkn]\n",
        "\n",
        "def mora_ids2tkn(ids:list):\n",
        "    return [_vocab.mora_vocab[idx] for idx in ids]\n",
        "\n",
        "def mora_tkn2ids(tkn:list):\n",
        "    return [_vocab.mora_vocab.index(_tkn) if _tkn in _vocab.mora_vocab else _vocab.mora_vocab('<UNK>') for _tkn in tkn]\n",
        "    #return [_vocab.mora_vocab.index(_tkn) for _tkn in tkn]\n",
        "\n",
        "\n",
        "_ids = [111, 298]\n",
        "print(orth_ids2tkn(_ids))\n",
        "print(orth_tkn2ids(orth_ids2tkn(_ids)))\n",
        "\n",
        "print(orth_tkn2ids('新しい'))\n",
        "print(orth_tkn2ids('神経心理学'))\n",
        "print(orth_ids2tkn(orth_tkn2ids('神経心理学')))\n",
        "print(mora_p_ids2tkn([17,19,11,4,32,17]))\n",
        "print(mora_p_tkn2ids(mora_p_ids2tkn([17,19,11,4,32,17])))\n",
        "print(mora_ids2tkn([37,139,31,7]))\n",
        "print(mora_tkn2ids(mora_ids2tkn([37,139,31,7])))"
      ],
      "metadata": {
        "id": "KPsp7Xd4Gx3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SALA and TLPA dataset"
      ],
      "metadata": {
        "id": "u7M0qKRVG2nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 検証データとして，TLPA と SALA のデータを用いる\n",
        "tlpa1, tlpa2, tlpa3, tlpa4, sala_r29, sala_r30, sala_r31 = lam.read_json_tlpa1234_sala_r29_30_31(\n",
        "    json_fname='lam/2022_0508SALA_TLPA.json')\n",
        "\n",
        "_dataset = {}\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']\n",
        "for data in _data_names:\n",
        "    _dataset[data] = {'rawdata':eval(data),\n",
        "                      'pdata': lam.make_vocab_dataset(eval(data), vocab=_vocab)}\n",
        "\n",
        "# 以下は後から付け足したので，コードが汚くなっている。\n",
        "# 時間ができたらコードの整理をすること\n",
        "# X_vals = lam.make_X_vals(_dataset=_dataset,\n",
        "#                          source_vocab=source_vocab,\n",
        "#                          target_vocab=target_vocab,\n",
        "#                          source_ids=source_ids,\n",
        "#                          target_ids=target_ids)\n",
        "\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']    \n",
        "for data in _data_names:\n",
        "    print(colored(data, 'blue', attrs=['bold']), eval(data))"
      ],
      "metadata": {
        "id": "ay7zOCqQG26m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wCHf_X31G_Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fushimi1999 データセット"
      ],
      "metadata": {
        "id": "d4Hpf_VFG-Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fushimi1999 = {\n",
        "    'HF___consist__': ['戦争', '倉庫', '医学', '注意', '記念', '番号', '料理', '完全', '開始', '印刷',\n",
        "                       '連続', '予約', '多少', '教員', '当局', '材料', '夕刊', '労働', '運送', '電池' ], # consistent, 'high-frequency words\n",
        "    'HF___inconsist': ['反対', '失敗', '作品', '指定', '実験', '決定', '独占', '独身', '固定', '食品',\n",
        "                       '表明', '安定', '各種', '役所', '海岸', '決算', '地帯', '道路', '安打', '楽団' ], # inconsistent, 'high-frequency words\n",
        "    'HF___atypical_': ['仲間', '夫婦', '人間', '神経', '相手', '反発', '化粧', '建物', '彼女', '毛糸', \n",
        "                       '場合', '台風', '夜間', '人形', '東西', '地元', '松原', '競馬', '大幅', '貸家' ], # inconsistent atypical, 'high-frequency words\n",
        "    'LF___consist__': ['集計', '観察', '予告', '動脈', '理学', '信任', '任務', '返信', '医局', '低温', \n",
        "                       '区別', '永続', '持続', '試練', '満開', '軍備', '製材', '銀貨', '急送', '改選' ], # consistent, 'low-frequecy words\n",
        "    'LF___inconsist': ['表紙', '指針', '熱帯', '作詞', '決着', '食費', '古代', '地形', '役場', '品種', \n",
        "                       '祝福', '金銭', '根底', '接種', '経由', '郷土', '街路', '宿直', '曲折', '越境' ], # inconsistent, 'low-frequency words\n",
        "    'LF___atypical_': ['強引', '寿命', '豆腐', '出前', '歌声', '近道', '間口', '風物', '面影', '眼鏡', \n",
        "                       '居所', '献立', '小雨', '毛皮', '鳥居', '仲買', '頭取', '極上', '奉行', '夢路' ], # inconsistent atypical, 'low-frequncy words\n",
        "    'HFNW_consist__': ['集学', '信別', '製信', '運学', '番送', '電続', '完意', '軍開', '動選', '当働', \n",
        "                       '予続', '倉理', '予少', '教池', '理任', '銀務', '連料', '開員', '注全', '記争' ], # consistent, 'high-character-frequency nonwords\n",
        "    'HFNW_inconsist': ['作明', '風行', '失定', '指団', '決所', '各算', '海身', '東発', '楽験', '作代',\n",
        "                       '反原', '独対', '歌上', '反定', '独定', '場家', '安種', '経着', '決土', '松合' ], # inconsistent biased, 'high-character-frequency nonwords\n",
        "    'HFNW_ambiguous': ['表品', '実定', '人風', '神間', '相経', '人元', '小引', '指場', '毛所', '台手',\n",
        "                       '間物', '道品', '出取', '建馬', '大婦', '地打', '化間', '面口', '金由', '彼間' ], # inconsistent ambigous, 'high-character-frequency nonwords\n",
        "    'LFNW_consist__': ['急材', '戦刊', '返計', '印念', '低局', '労号', '満送', '永告', '試脈', '観備',\n",
        "                       '材約', '夕局', '医庫', '任続', '医貨', '改練', '区温', '多始', '材刷', '持察' ], # consistent, 'low-character-frequency nonwords\n",
        "    'LFNW_inconsist': ['食占', '表底', '宿帯', '決帯', '古費', '安敗', '役針', '近命', '眼道', '豆立',\n",
        "                       '街直', '固路', '郷種', '品路', '曲銭', '献居', '奉買', '根境', '役岸', '祝折' ], # inconsistent biased, 'low-character-frequency nonwords\n",
        "    'LFNW_ambiguous': ['食形', '接紙', '競物', '地詞', '強腐', '頭路', '毛西', '夜糸', '仲影', '熱福',\n",
        "                       '寿前', '鳥雨', '地粧', '越種', '仲女', '極鏡', '夢皮', '居声', '貸形', '夫幅' ], # inconsistent ambigous, 'low-character-frequency nonwords\n",
        "}\n",
        "\n",
        "for k, v in fushimi1999.items():\n",
        "    print(colored(k, 'blue', attrs=['bold']), v)\n",
        "\n",
        "fushimi1999_list = []\n",
        "for k, v in fushimi1999.items():\n",
        "    for _v in v:\n",
        "        fushimi1999_list.append(_v)\n",
        "\n",
        "train_wordlist = [v['orig'] for k, v in _vocab.train_data.items()]\n",
        "\n",
        "for i, wrd in enumerate(fushimi1999_list):\n",
        "    if wrd in train_wordlist:\n",
        "        idx = train_wordlist.index(wrd)\n",
        "        print(f'{i:3d} {wrd}:{idx:5d}')\n",
        "        #print(i, wrd, idx, _vocab.train_data[idx])        "
      ],
      "metadata": {
        "id": "0SW8VElBHATs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, w in enumerate(fushimi1999_list):\n",
        "    ids = orth_tkn2ids(w)\n",
        "    tnk = orth_ids2tkn(ids)\n",
        "    if i > 125:\n",
        "        print(i, w, ids, tnk)\n",
        "        o = _get_ids_from_orth(orth_wrd=w)\n",
        "        print(colored((i,w),'blue',attrs=['bold']), o)"
      ],
      "metadata": {
        "id": "t0FDRk9UHJaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テストのための一文字の書記素データセットの作成"
      ],
      "metadata": {
        "id": "8dF3M3soHPHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#source\n",
        "# _src = 'orth' if source == 'orthography' else source\n",
        "# _tgt = 'orth' if target == 'orthography' else target\n",
        "\n",
        "# _src = 'mora' if source == 'mora_p' else source\n",
        "# _tgt = 'mora' if target == 'mora_p' else source\n",
        "\n",
        "_src, _tgt = source+'_ids', target+'_ids'\n",
        "print(_src,_tgt)\n",
        "\n",
        "_get_ids_from_orth('あい')\n",
        "#_get_ids_from_orth('あ')"
      ],
      "metadata": {
        "id": "Knqi9HshMx7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_chars0 = '０１２３４５６７８９ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "one_chars1 = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわをん'\n",
        "one_chars2 = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヲン'\n",
        "one_chars = one_chars0 + one_chars1 + one_chars2\n",
        "for ch in one_chars:\n",
        "    tmp = _get_ids_from_orth(ch)\n",
        "    __src, __tgt, __yomi = tmp[_src], tmp[_tgt], tmp['_yomi']\n",
        "    print(colored(ch, 'blue', attrs=['bold']), f'__src:{__src}, __tgt:{__tgt}, __yomi:{__yomi}')"
      ],
      "metadata": {
        "id": "ukgmbcx_HOlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Onechar_dataset(torch.utils.data.Dataset): #_vocab.train_data):\n",
        "    def __init__(self,\n",
        "                 source:str='orthography',\n",
        "                 target:str='mora_p',                \n",
        "                ):\n",
        "        super().__init__()\n",
        "\n",
        "        _src = 'orth' if source == 'orthography' else source\n",
        "        _tgt = 'orth' if target == 'orthography' else target\n",
        "\n",
        "        _src = 'mora' if _src == 'mora_p' else _src\n",
        "        _tgt = 'mora' if _tgt == 'mora_p' else _tgt\n",
        "        _src, _tgt = _src+'_ids', _tgt+'_ids'\n",
        "        \n",
        "        one_chars0 = '０１２３４５６７８９ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "        one_chars1 = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわをん'\n",
        "        one_chars2 = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヲン'\n",
        "        \n",
        "        all_chars = one_chars0 + one_chars1 + one_chars2\n",
        "        self.all_chars = all_chars\n",
        "        data_dict = {}\n",
        "        for i, ch in enumerate(all_chars):\n",
        "            tmp = _get_ids_from_orth(ch)\n",
        "            __src, __tgt, __yomi = tmp[_src], tmp[_tgt], tmp['_yomi']\n",
        "            data_dict[i] = {'yomi':__yomi,\n",
        "                            'src':__src,\n",
        "                            'tgt':__tgt,\n",
        "                           }\n",
        "            #print(colored(ch, 'blue', attrs=['bold']), f'__src:{__src}, __tgt:{__tgt}, __yomi:{__yomi}')\n",
        "        self.data_dict = data_dict\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return len(self.data_dict)\n",
        "    \n",
        "    def __getitem__(self,\n",
        "                    x:int):\n",
        "        _data = self.data_dict[x]\n",
        "        return _data['src'], _data['tgt']\n",
        "        \n",
        "onechar_dataset = Onechar_dataset(source=source,\n",
        "                                  target=target\n",
        "                                 )\n",
        "print(onechar_dataset.__len__())\n",
        "print(onechar_dataset.__getitem__(0))"
      ],
      "metadata": {
        "id": "4IjAfPoGMRZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. モデルの定義"
      ],
      "metadata": {
        "id": "dU-jsTFXNUWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 自作ライブラリ LAM の読み込み\n",
        "import lam \n",
        "\n",
        "from lam import EncoderRNN\n",
        "from lam import AttnDecoderRNN\n",
        "from lam import calc_accuracy\n",
        "\n",
        "if (params['pretrained']) and (params['path_saved'] != False) and os.path.exists(params['path_saved']):\n",
        "    \"\"\"セーブした学習済のモデルがあれば読み込む\"\"\"\n",
        "    \n",
        "    checkpoint = torch.load(params['path_saved'])\n",
        "    encoder = EncoderRNN(len(source_vocab), params['hidden_size']).to(device)\n",
        "    decoder = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                             n_out=len(target_vocab), \n",
        "                             dropout_p=params['dropout_p'],\n",
        "                             max_length=_vocab.max_length).to(device)\n",
        "    encoder.load_state_dict(checkpoint['encoder'])\n",
        "    decoder.load_state_dict(checkpoint['decoder'])\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    #losses = []\n",
        "\n",
        "    print(colored(f\"セーブした学習済のモデル {params['path_saved']} があるので読み込みました\",\n",
        "          color='blue', attrs=['bold']))\n",
        "\n",
        "else:\n",
        "    encoder = EncoderRNN(len(_vocab.ortho_vocab), \n",
        "                         params['hidden_size']).to(device)\n",
        "    decoder = AttnDecoderRNN(n_hid=params['hidden_size'], \n",
        "                             n_out=len(target_vocab), \n",
        "                             dropout_p=params['dropout_p'],\n",
        "                             max_length=_vocab.max_length\n",
        "                            ).to(device)\n",
        "\n",
        "# モデルの概要を印字\n",
        "print(f'encoder:{encoder}')\n",
        "print(f'decoder:{decoder}')\n",
        "        \n",
        "for test_name, val_dataset in X_vals.items():\n",
        "    acc = calc_accuracy(_dataset=val_dataset,\n",
        "                        encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        #decoder=decoder2,\n",
        "                        max_length=_vocab.max_length,\n",
        "                        source_vocab=source_vocab,\n",
        "                        target_vocab=target_vocab,\n",
        "                        source_ids=source_ids,\n",
        "                        target_ids=target_ids,\n",
        "                       )\n",
        "    print(colored(f'{test_name} の精度:{acc:.3f}','blue', attrs=['bold']))\n",
        "\n",
        "\n",
        "# params の印刷\n",
        "print(colored(params,'blue',attrs=['bold']))    "
      ],
      "metadata": {
        "id": "T0kDC3_nNR4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def asMinutes(s:int)->str:\n",
        "    \"\"\"時間変数を見やすいように，分と秒に変換して返す\"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{int(m):2d}分 {int(s):2d}秒'\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since:time.time,\n",
        "            percent:time.time)->str:\n",
        "    \"\"\"開始時刻 since と，現在の処理が全処理中に示す割合 percent を与えて，経過時間と残り時間を計算して表示する\"\"\"\n",
        "    now = time.time()  #現在時刻を取得\n",
        "    s = now - since    # 開始時刻から現在までの経過時間を計算\n",
        "    #s = since - now\n",
        "    es = s / (percent) # 経過時間を現在までの処理割合で割って終了予想時間を計算\n",
        "    rs = es - s        # 終了予想時刻から経過した時間を引いて残り時間を計算\n",
        "\n",
        "    return f'経過時間:{asMinutes(s)} (残り時間 {asMinutes(rs)})'\n",
        "\n",
        "def evaluate(encoder:torch.nn.Module,\n",
        "             decoder:torch.nn.Module,\n",
        "             input_ids:list=None,\n",
        "             max_length:int=1,\n",
        "             source_vocab:list=None,\n",
        "             target_vocab:list=None,\n",
        "             source_ids:list=None,\n",
        "             target_ids:list=None,\n",
        "            )->(list,torch.LongTensor):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        input_tensor = convert_ids2tensor(input_ids)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.n_hid, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[source_vocab.index('<SOW>')]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words, decoded_ids = [], []  # decoded_ids を追加\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs, device=device)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            decoded_ids.append(int(topi.squeeze().detach())) # decoded_ids に追加\n",
        "            if topi.item() == target_vocab.index('<EOW>'):\n",
        "                decoded_words.append('<EOW>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(target_vocab[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoded_ids, decoder_attentions[:di + 1]  # decoded_ids を返すように変更\n",
        "        #return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "\n",
        "def check_vals_performance(encoder=None, decoder=None,\n",
        "                           _dataset=None,\n",
        "                           max_length=0,\n",
        "                           source_vocab=None,\n",
        "                           target_vocab=None,\n",
        "                           source_ids=None,\n",
        "                           target_ids=None,\n",
        "                           ):\n",
        "    if _dataset == None or encoder == None or decoder == None or max_length == 0 or source_vocab == None:\n",
        "        return\n",
        "    print('検証データ:',end=\"\")\n",
        "    for _x in _dataset:\n",
        "        ok_count = 0\n",
        "        for i in range(_dataset[_x].__len__()):\n",
        "            _input_ids, _target_ids = _dataset[_x].__getitem__(i)\n",
        "            _output_words, _output_ids, _attentions = evaluate(encoder, decoder, _input_ids,\n",
        "                                                               max_length,\n",
        "                                                               source_vocab=source_vocab,\n",
        "                                                               target_vocab=target_vocab,\n",
        "                                                               source_ids=source_ids,\n",
        "                                                               target_ids=target_ids,\n",
        "                                                               )\n",
        "            ok_count += 1 if _target_ids == _output_ids else 0\n",
        "        print(f'{_x}:{ok_count/_dataset[_x].__len__():.3f},',end=\"\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def convert_ids2tensor(sentence_ids:list, \n",
        "                       device:torch.device=torch.device(\"cuda:0\" if torch.cuda.is_available () else \"cpu\")):\n",
        "    \n",
        "    \"\"\"数値 ID リストをテンソルに変換\n",
        "    例えば，[0,1,2] -> tensor([[0],[1],[2]])\n",
        "    \"\"\"\n",
        "    return torch.tensor(sentence_ids, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def _train(input_tensor:torch.Tensor=None, \n",
        "           target_tensor:torch.Tensor=None,\n",
        "           encoder:torch.nn.Module=None, \n",
        "           decoder:torch.nn.Module=None,\n",
        "           encoder_optimizer:torch.optim=None, \n",
        "           decoder_optimizer:torch.optim=None,\n",
        "           criterion:torch.nn.modules.loss=torch.nn.modules.loss.CrossEntropyLoss,\n",
        "           max_length:int=1,\n",
        "           target_vocab:list=None,\n",
        "           teacher_forcing_ratio:float=0.,\n",
        "           device:torch.device=None)->float:\n",
        "    encoder_hidden = encoder.initHidden() # 符号化器の中間層を初期化\n",
        "    encoder_optimizer.zero_grad()         # 符号化器の最適化関数の初期化\n",
        "    decoder_optimizer.zero_grad()         # 復号化器の最適化関数の初期化\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.n_hid, device=device)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[target_vocab.index('<SOW>')]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    ok_flag = True\n",
        "    # 教師強制をするか否かを確率的に決める\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    if use_teacher_forcing: # 教師強制する場合 Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs,device=device)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().numpy()[0])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else: # 教師強制しない場合 Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs,device=device)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().numpy()[0])\n",
        "            if decoder_input.item() == target_vocab.index('<EOW>'):\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length, ok_flag\n",
        "\n",
        "\n",
        "def _fit(encoder:torch.nn.Module, \n",
        "         decoder:torch.nn.Module,\n",
        "         epochs:int=1,\n",
        "         lr:float=0.0001,\n",
        "         n_sample:int=3,\n",
        "         teacher_forcing_ratio=False,\n",
        "         train_dataset:torch.utils.data.Dataset=None,\n",
        "         val_dataset:dict=None,\n",
        "         source_vocab:list=None,\n",
        "         target_vocab:list=None,\n",
        "         source_ids:str=None,\n",
        "         target_ids:list=None,\n",
        "         params:dict=None,\n",
        "         max_length:int=1,\n",
        "         device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "        )->list:\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    encoder_optimizer = params['optim_func'](encoder.parameters(), lr=lr)\n",
        "    decoder_optimizer = params['optim_func'](decoder.parameters(), lr=lr)\n",
        "    criterion = params['loss_func']\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        ok_count = 0\n",
        "        \n",
        "        #エポックごとに学習順をシャッフルする\n",
        "        learning_order = np.random.permutation(train_dataset.__len__())\n",
        "        \n",
        "        for i in range(train_dataset.__len__()):\n",
        "            x = learning_order[i]   # ランダムにデータを取り出す\n",
        "            input_ids, target_ids = train_dataset.__getitem__(x)\n",
        "            input_tensor = convert_ids2tensor(input_ids)\n",
        "            target_tensor = convert_ids2tensor(target_ids)\n",
        "\n",
        "            #訓練の実施\n",
        "            loss, ok_flag = _train(input_tensor=input_tensor, \n",
        "                                   target_tensor=target_tensor,\n",
        "                                   encoder=encoder, \n",
        "                                   decoder=decoder,\n",
        "                                   encoder_optimizer=encoder_optimizer, \n",
        "                                   decoder_optimizer=decoder_optimizer,\n",
        "                                   criterion=criterion,\n",
        "                                   max_length=max_length,\n",
        "                                   target_vocab=target_vocab,\n",
        "                                   teacher_forcing_ratio=teacher_forcing_ratio,\n",
        "                                   device=device)\n",
        "            epoch_loss += loss\n",
        "            ok_count += 1 if ok_flag else 0\n",
        "\n",
        "\n",
        "        losses.append(epoch_loss/train_dataset.__len__())\n",
        "        print(colored(f'エポック:{epoch:2d} 損失:{epoch_loss/train_dataset.__len__():.2f}', 'blue', attrs=['bold']),\n",
        "              colored(f'{timeSince(start_time, (epoch+1) * train_dataset.__len__()/(epochs * train_dataset.__len__()))}',\n",
        "                      'cyan', attrs=['bold']),\n",
        "              colored(f'訓練データの精度:{ok_count/train_dataset.__len__():.3f}', 'blue', attrs=['bold']))\n",
        "\n",
        "        check_vals_performance(_dataset=val_dataset,\n",
        "                               encoder=encoder,\n",
        "                               decoder=decoder,\n",
        "                               max_length=max_length,\n",
        "                               source_vocab=source_vocab,\n",
        "                               target_vocab=target_vocab,\n",
        "                               source_ids=source_ids,\n",
        "                               target_ids=target_ids)\n",
        "        if n_sample > 0:\n",
        "            evaluateRandomly(encoder, decoder, n=n_sample)\n",
        "\n",
        "    return losses\n"
      ],
      "metadata": {
        "id": "UDckNJ5bNWZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               val_dataset=X_vals,\n",
        "              )"
      ],
      "metadata": {
        "id": "53ndp0FZNZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               val_dataset=X_vals,\n",
        "              )"
      ],
      "metadata": {
        "id": "JrnaIeVuObnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データセットと検証データセットを作成\n",
        "train_dataset = lam.Train_dataset(data=_vocab.train_data,\n",
        "                                  source_vocab=source_vocab, \n",
        "                                  target_vocab=target_vocab,\n",
        "                                  source_ids=source_ids,   # おそらくこの 2 行を入れないといけなかった\n",
        "                                  target_ids=target_ids)  # そうでなければ，デフォルトの `mora_p_r` になってしまう\n",
        "\n",
        "P  = int(train_dataset.__len__() * 0.9)\n",
        "_P = train_dataset.__len__() - P\n",
        "_train_dataset, val_dataset = torch.utils.data.random_split(dataset=train_dataset,\n",
        "                                                           lengths=(P, _P),\n",
        "                                                           generator=torch.Generator().manual_seed(42),\n",
        "                                                          )\n",
        "\n",
        "# val_dataset = lam.Val_dataset(data=_dataset['sala_r29']['pdata'],\n",
        "#                               source_vocab=source_vocab, \n",
        "#                               target_vocab=target_vocab,\n",
        "#                               source_ids=source_ids,\n",
        "#                               target_ids=target_ids)\n",
        "                \n",
        "# 訓練データセットと検証データセットを作成\n",
        "print(f'len(train_dataset):{len(train_dataset)}',\n",
        "      f'len(val_dataset):{len(val_dataset)}')      "
      ],
      "metadata": {
        "id": "aUQVn0ebNdB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=train_dataset,\n",
        "               #train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               val_dataset=X_vals,\n",
        "              )"
      ],
      "metadata": {
        "id": "Gj979sVeNpho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}