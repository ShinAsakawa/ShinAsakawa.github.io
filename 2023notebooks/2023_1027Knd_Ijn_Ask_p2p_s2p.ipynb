{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOHGrbrJ/0vll22DVXuviaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_1027Knd_Ijn_Ask_p2p_s2p.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* date: 2023_1027\n",
        "* author: 浅川伸一\n",
        "* filename: 2023_1027Knd_Ijn_Ask_s2p_ps2.ipynb\n",
        "\n",
        "# 符号化器‐復号化器 (encoder-decoder a.k.a seq2seq) モデルによる，単語復唱，単語産出，および単語理解処理過程の実装\n",
        "\n",
        "\n",
        "see 2004Harm&Seidenberg: Computing the Meanings of Words in Reading: Cooperative Division of Labor Between Visual and Phonological Processes.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4c.svg\"><br/>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4d.svg\"><br/>\n",
        "<!-- <img src=\"2004Harm_Seidenberg_fig4c.svg\"><br/>-->\n",
        "<!-- <img src=\"2004Harm_Seidenberg_fig4d.svg\"><br/> -->\n",
        "`2004Harm&Seidenberg2004`, Figure 4 c, and d\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "Kf7kkO_J9SBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TksY9DHT9KF0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# このセルは MeCab のコンパイルに時間を要するため，実行終了まで 15 分程度かかります。\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ローカルと colab との相違を吸収するために必要となるライブラリをインストール\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "if isColab:\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "from termcolor import colored\n",
        "\n",
        "# MeCab, fugashi, ipadic のインストール\n",
        "if isColab:\n",
        "    !apt install aptitude swig > /dev/null 2>&1\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null 2>&1\n",
        "    !pip install mecab-python3==0.7 > /dev/null 2>&1\n",
        "    !pip install --upgrade ipadic > /dev/null 2>&1\n",
        "    !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null 2>&1\n",
        "    !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null 2>&1\n",
        "\n",
        "    import subprocess\n",
        "    cmd='echo `mecab-config --dicdir`\\\"/mecab-ipadic-neologd\\\"'\n",
        "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                                     shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "    !pip install 'fugashi[unidic]' > /dev/null 2>&1\n",
        "    !python -m unidic download > /dev/null 2>&1\n",
        "    !pip install ipadic > /dev/null 2>&1\n",
        "    !pip install 'konoha[mecab]'\n",
        "\n",
        "\n",
        "try:\n",
        "    import ccap\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    import ccap\n",
        "\n",
        "try:\n",
        "    import RAM\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "    import RAM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 意味表現として word2vec による意味埋め込みベクトルを使う"
      ],
      "metadata": {
        "id": "JXPQkatyZJt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# word2vec を読み込む おそらく 1, 2 分かかる\n",
        "from ccap import ccap_w2v\n",
        "w2v = ccap_w2v().w2v\n",
        "#w2v = ccap_w2v(isColab=False).w2v\n",
        "\n",
        "# MeCab による yomi を輸入\n",
        "from ccap.mecab_settings import yomi"
      ],
      "metadata": {
        "id": "K0RS20Nt9LjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット Psylex71_Dataset の読み込み"
      ],
      "metadata": {
        "id": "CL4kFcgLZOqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from kunrei import kunrei\n",
        "except ImportError:\n",
        "    !wget https://shinasakawa.github.io/2023notebooks/kunrei.py -O kunrei.py\n",
        "    from kunrei import kunrei\n",
        "\n",
        "# データセットとしての Psylex71_Dataset の読み込み\n",
        "from RAM import Psylex71_Dataset\n",
        "\n",
        "psylex71_ds = Psylex71_Dataset(max_words=30000)\n",
        "print(f'psylex71_ds の単語数:{psylex71_ds.__len__()}')"
      ],
      "metadata": {
        "id": "N8X6SPD39e0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットのヒストグラム描画"
      ],
      "metadata": {
        "id": "VGuBaR7SZf2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from RAM import draw_word_char_histgram\n",
        "\n",
        "draw_word_char_histgram(_dict=psylex71_ds.data_dict, key='phon', title='音韻', figsize2=(8,3))"
      ],
      "metadata": {
        "id": "8Hq3NRhY-DJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## psylex71_ds データをすべて word2vec の埋め込みベクトル行列を得る"
      ],
      "metadata": {
        "id": "qwu-YKHcZnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# psylex71_ds データをすべて word2vec の埋め込みベクトル行列を得る\n",
        "_f = [dct['orth'] for dct in psylex71_ds.data_dict.values()]\n",
        "\n",
        "# gensim() の `vectors_for_all()` 関数を使えば，望む語彙からなる word2vec 単語埋め込みモデルを作成できる\n",
        "w2v_psylex71 = w2v.vectors_for_all(_f)\n",
        "\n",
        "# NaN データが入っている可能性がるので変換\n",
        "w2v_psylex71.vectors = np.nan_to_num(w2v_psylex71.vectors)\n",
        "print(f'w2v_psylex71.vectors.shape:{w2v_psylex71.vectors.shape}')"
      ],
      "metadata": {
        "id": "ZSczeFBoZkAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## psylex71 データセット中の単語における w2v を表示してテストする"
      ],
      "metadata": {
        "id": "DVUBqUP9ZreZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from tqdm.notebook import tqdm\n",
        "Emb = w2v_psylex71.vectors\n",
        "\n",
        "Wrd = input('単語を入力してください:')\n",
        "color = 'blue'\n",
        "while (Wrd != \"\"):\n",
        "    if Wrd in w2v_psylex71:\n",
        "        Idx = w2v_psylex71.key_to_index[Wrd]\n",
        "        print(f'入力単語 Wrd:{colored(Wrd, color, attrs=[\"bold\"])},',\n",
        "              f'対応する単語番号 Idx:{colored(Idx, color, attrs=[\"bold\"])},',\n",
        "              f'w2v_psylex71.get_index({Wrd}):{colored(w2v_psylex71.get_index(Wrd), color, attrs=[\"bold\"])}')\n",
        "    else:\n",
        "        print(colored(f'{Wrd} という単語はありません。','red', attrs=['bold']))\n",
        "    Wrd = input('単語を入力してください (終了するには改行のみを入力):')"
      ],
      "metadata": {
        "id": "khZ0sADeZtPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch 用のデータセット定義"
      ],
      "metadata": {
        "id": "hu823wYUZ2DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import gensim\n",
        "\n",
        "class psylex71_w2v_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 direction='s2p',  # ['s2p', 'p2s']\n",
        "                 #source='seme',    # エンコーダ用 入力データ, ['orth', seme', 'phon'] のいずれか一つ\n",
        "                 #target='phon',    # デコーダ用 出力データ ,  ['orth', seme', 'phon'] のいずれか一つ\n",
        "                 w2v:gensim.models.keyedvectors.KeyedVectors=w2v_psylex71,\n",
        "                 old_ds:RAM.dataset.Psylex71_Dataset=psylex71_ds,\n",
        "                 mecab_yomi=yomi,\n",
        "                ):\n",
        "        self.direction = 's2p' if direction == 's2p' else direction\n",
        "        self.w2v = w2v\n",
        "        self.old_ds = old_ds\n",
        "        self.mecab_yomi = yomi\n",
        "\n",
        "        _wrds = []\n",
        "        for idx in range(len(w2v)):\n",
        "            _wrds.append(w2v.index_to_key[idx])\n",
        "        self.words = _wrds\n",
        "        self.W = w2v.vectors\n",
        "\n",
        "        # 訓令式に従った日本語ローマ字表記 `kurei.py` 参照\n",
        "        self.phoneme = ['<PAD>', '<SOW>', '<EOW>', '<UNK>', # 特殊トークン，純に，埋め草，語頭，語末，未知\n",
        "                        'a', 'i', 'u', 'e', 'o',            # 母音\n",
        "                        'a:', 'i:', 'u:', 'e:', 'o:',       # 長母音\n",
        "                        'N', 'Q',                           # 撥音，拗音\n",
        "                        'b', 'by', 'ch', 'd', 'dy', 'f', 'g', 'gy', 'h', 'hy', # 子音\n",
        "                        'j', 'k', 'ky', 'm', 'my', 'n', 'ny',  'p', 'py', 'r', # 子音\n",
        "                        'ry', 's', 'sy', 't', 'ty', 'w', 'y', 'z', 'zy']       # 子音\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx:int,\n",
        "                    direction:str=None):\n",
        "        wrd = self.words[idx]\n",
        "        if direction == None:\n",
        "            direction = self.direction\n",
        "        if direction == 'p2s':\n",
        "            X = torch.LongTensor(self.wrd2phon_ids(wrd))\n",
        "            y = torch.tensor(self.w2v.get_vector(idx))\n",
        "        else:\n",
        "            y = torch.LongTensor(self.wrd2phon_ids(wrd))\n",
        "            X = torch.tensor(self.w2v.get_vector(idx))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.w2v)\n",
        "\n",
        "    def getitem(self,\n",
        "                idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        _yomi = self.wrd2yomi(wrd)\n",
        "        _yomi = kunrei(_yomi).split(' ')\n",
        "        ids = [self.phoneme.index(idx) for idx in _yomi]\n",
        "        return wrd, _yomi, ids\n",
        "\n",
        "    def wrd2phon_ids(self, wrd:str)->list:\n",
        "        _yomi = self.wrd2yomi(wrd)\n",
        "        _yomi = kunrei(_yomi).split(' ')\n",
        "        ids = [self.phoneme.index(idx) for idx in _yomi]\n",
        "        ids = [self.phoneme.index('<SOW>')] + ids + [self.phoneme.index('<EOW>')]\n",
        "        return ids #, _yomi\n",
        "\n",
        "    def get_wrdidx_from_word(self, wrd:str):\n",
        "        if wrd in self.words:\n",
        "            wrd_idx = self.w2v.get_index(wrd)\n",
        "        return wrd_idx\n",
        "\n",
        "    def wrd2emb(self, wrd:str)->np.ndarray:\n",
        "        if wrd in self.words:\n",
        "            return self.w2v.get_vector(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def wrd2wrd_idx(self, wrd:str)->int:\n",
        "        if wrd in self.words:\n",
        "            return self.words.index(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def wrd_idx2wrd(self, idx:int)->str:\n",
        "        if 0 <= idx and idx < len(self.words):\n",
        "            return self.words[idx]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def wrd2onehot(self, wrd:str)->np.ndarray:\n",
        "        ret = np.zeros((self.W.shape[0],), dtype=np.int32)\n",
        "        if wrd in self.words:\n",
        "            ret[self.w2v.get_index(wrd)] = 1\n",
        "            return ret\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def phon_ids2phn(self, ids:list):\n",
        "        return \"\".join([self.phoneme[idx] for idx in ids])\n",
        "\n",
        "    def wrd2yomi(self, wrd:str)->list:\n",
        "        if wrd in self.words:\n",
        "            _yomi = self.old_ds.orth2info_dict[wrd]['ヨミ']\n",
        "        else:\n",
        "            _yomi = self.mecab_yomi(wrd).strip().split()[0]\n",
        "        return _yomi\n",
        "\n",
        "    def wrd2info(self, wrd:str)->dict:\n",
        "        if wrd in self.words:\n",
        "            return self.old_ds.orth2info_dict[wrd]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "_psylex71_ds = psylex71_w2v_Dataset()\n",
        "\n",
        "# 以下確認作業\n",
        "N = np.random.randint(_psylex71_ds.__len__())\n",
        "wrd = _psylex71_ds.wrd_idx2wrd(N)\n",
        "print(f'_Wrd:{wrd}\\n',\n",
        "      f'_psylex71_ds.wrd2phon_ids({wrd}):{_psylex71_ds.wrd2phon_ids(wrd)}\\n',\n",
        "      f'_psylex71_ds.phon_ids2phn(_psylex71_ds.wrd2phon_ids({wrd})):{_psylex71_ds.phon_ids2phn(_psylex71_ds.wrd2phon_ids(wrd))}\\n',\n",
        "      f'_psylex71_ds.wrd2yomi({wrd}): {_psylex71_ds.wrd2yomi(wrd)}\\n',\n",
        "      f'_psylex71_ds.wrd2wrd_idx({wrd}): {_psylex71_ds.wrd2wrd_idx(wrd)}\\n',\n",
        "      f'_psylex71_ds.wrd2info({wrd}): {_psylex71_ds.wrd2info(wrd)}')"
      ],
      "metadata": {
        "id": "OUYVavq8Z3Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader の設定"
      ],
      "metadata": {
        "id": "WzD4qUKwZ8sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "    images, targets= list(zip(*batch))\n",
        "    xs = list(images)\n",
        "    ys = list(targets)\n",
        "    return xs, ys\n",
        "\n",
        "batch_size = 1024\n",
        "dataloader = DataLoader(_psylex71_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        collate_fn=my_collate_fn)"
      ],
      "metadata": {
        "id": "YqVwmYUKZ_lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 復唱モデル\n",
        "\n",
        "<p style=\"font-family:serif;font-size:14pt;color:purple;font-weight:900\">\n",
        "\n",
        "PyTorch RNN モデルの実装に対する注意メモ\n",
        "    \n",
        "* Encoder 側のデータと Decoder 側のデータそれぞれに対して Padding の処理を行う。\n",
        "* Encoder 側のデータには Padding 値として `0` で埋める。\n",
        "* Decoder 側のデータをモデルの forward で使う場合には、Padding 値は `0` を埋める。\n",
        "* ただし，Decoder 側のデータを教師データとして使う場合には，Padding 値には -1 を用いて，埋めることに注意。\n",
        "* `nn.Embedding()` のオプションに `padding_idx=O` を付け，`CrosEntropyLoss` のオプションに `ignore_index=-1` を付ける。\n",
        "\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "0RRrL4PZaIVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 モデルの定義"
      ],
      "metadata": {
        "id": "NKFH1V7NOkCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class EncDec_w_Att(nn.Module):\n",
        "    \"\"\" 注意つき符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        #print(f'c_t.size():{c_t.size()}, dec_out.size():{dec_out.size()}')\n",
        "        #print(f'dec_out_.size():{dec_out.size()}')\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "n_hid = 64\n",
        "n_layers = 1\n",
        "bidirectional=True\n",
        "# 直下行で，enc_vocab_size と dec_vocab_size を phoneme にしているので，音韻複勝課題に相当する\n",
        "enc_dec = EncDec_w_Att(enc_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                       dec_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                       n_layers=n_layers,\n",
        "                       bidirectional=bidirectional,\n",
        "                       n_hid=n_hid).to(device)\n",
        "print(enc_dec.eval())"
      ],
      "metadata": {
        "id": "ZBet5d87aM0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 訓練の実施"
      ],
      "metadata": {
        "id": "3wg61KvMagRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "n_hid = 64\n",
        "n_layers = 1\n",
        "epochs = 10\n",
        "bidirectional=True\n",
        "model = EncDec_w_Att(enc_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                     dec_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                     n_layers=n_layers,\n",
        "                     bidirectional=bidirectional,\n",
        "                     n_hid=n_hid).to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "model.train()\n",
        "interval = int(_psylex71_ds.__len__()/batch_size) >> 2\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for x, y in dataloader:\n",
        "        enc_inp = pad_sequence(y, batch_first=True).to(device)\n",
        "        #enc_inp = pad_sequence(y, batch_first=True).to(device)[:,:-1]\n",
        "        #enc_inp = pad_sequence(y, batch_first=True).to(device)[:,1:]\n",
        "\n",
        "        dec_inp = pad_sequence(y, batch_first=True).to(device)[:,:]\n",
        "        #dec_inp = pad_sequence(y, batch_first=True).to(device)[:,:-1]\n",
        "        #dec_inp = pad_sequence(y, batch_first=True).to(device)[:,1:]\n",
        "\n",
        "        tch = pad_sequence(y, batch_first=True, padding_value=-1.0).to(device)\n",
        "        #tch = tch[:,1:]\n",
        "\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/len(x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(x):.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()\n",
        "\n",
        "#outfile = \"attnmt2-\" + str(epoch) + \".model\"\n",
        "#torch.save(net.state_dict(),outfile)"
      ],
      "metadata": {
        "id": "iVc-Hlkpaisi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 学習結果の検証"
      ],
      "metadata": {
        "id": "8voQ8m1aO5V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "errors = []\n",
        "isPrint = False\n",
        "for N in tqdm(range(_psylex71_ds.__len__())):\n",
        "    x =_psylex71_ds.__getitem__(N)[1].to(device)\n",
        "    y = model(x[1:].unsqueeze(0), x[:-1].unsqueeze(0)).to('cpu')\n",
        "    y_ids = np.argmax(y.squeeze(0).detach().numpy(), axis=1)[1:]\n",
        "    y_phon = _psylex71_ds.phon_ids2phn(y_ids)\n",
        "    grand_truth = _psylex71_ds.getitem(N)\n",
        "\n",
        "    n_correct = np.array((y_ids == grand_truth[2]).sum())\n",
        "    isOK = n_correct == len(grand_truth[2])\n",
        "\n",
        "\n",
        "    color = 'grey' if isOK else 'red'\n",
        "    if not isOK:\n",
        "        errors.append((N,y_ids))\n",
        "        if isPrint:\n",
        "            print(colored((f'IDX:{N:5d}',\n",
        "                           f'単語:{grand_truth[0]}',\n",
        "                           f'出力:{y_phon}',\n",
        "                           f'出力ID:{y_ids}',\n",
        "                           f'{grand_truth[2]}'), color, attrs=['bold']))\n",
        "\n",
        "\n",
        "cr = len(errors) / _psylex71_ds.__len__()\n",
        "print(f'総エラー数:{len(errors)}',\n",
        "      f'正解率:{(1.-cr)*100:.3f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "SyHYiBkdO859"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 産出モデル\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jdRrg59amxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 モデルの定義"
      ],
      "metadata": {
        "id": "bsm_xR_GPAZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class EncDec_s2p(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sem_dim:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False,\n",
        "                ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 単語の意味ベクトル a.k.a 埋め込み表現 を decoder の中間層に接続するための変換層\n",
        "        # 別解としては，入力層に接続する方法があるが，それはまた別実装にする\n",
        "        self.enc_transform_layer = nn.Linear(in_features=sem_dim,\n",
        "                                             out_features=n_hid)\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.enc_transform_layer(enc_inp)\n",
        "        hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        return self.out_layer(dec_out)\n",
        "\n",
        "n_hid = 64\n",
        "n_layers = 1\n",
        "bidirectional=False\n",
        "# 直下行で，enc_vocab_size と dec_vocab_size を phoneme にしているので，音韻複勝課題に相当する\n",
        "enc_dec = EncDec_s2p(sem_dim=_psylex71_ds.w2v.vector_size,\n",
        "                     dec_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                     n_layers=n_layers,\n",
        "                     bidirectional=bidirectional,\n",
        "                     n_hid=n_hid).to(device)\n",
        "enc_dec.eval()"
      ],
      "metadata": {
        "id": "naU-W9KuaqKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 訓練の実施"
      ],
      "metadata": {
        "id": "BhHtxVeXa2kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "n_hid = 64\n",
        "n_layers = 1\n",
        "epochs = 10\n",
        "bidirectional=False\n",
        "model = EncDec_s2p(sem_dim=_psylex71_ds.w2v.vector_size,\n",
        "                   dec_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "model.train()\n",
        "interval = int(_psylex71_ds.__len__()/batch_size) >> 2\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for x, y in dataloader:\n",
        "        #enc_inp = torch.from_numpy(np.array(x)).to(device).unsqueeze(0)\n",
        "        enc_inp= torch.tensor([_x.detach().numpy() for _x in x]).to(device)\n",
        "\n",
        "        dec_inp = pad_sequence(y, batch_first=True).to(device)\n",
        "        #dec_inp = pad_sequence(y, batch_first=True).to(device)[:,1:]\n",
        "        tch = pad_sequence(y, batch_first=True, padding_value=-1.0).to(device)\n",
        "        #tch = tch[:,1:]\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/len(x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(x):.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tlvDjxjeP9DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "n_hid = 64\n",
        "#n_hid = 32\n",
        "n_layers = 1\n",
        "epochs = 10\n",
        "bidirectional=False\n",
        "model = EncDec_s2p(sem_dim=_psylex71_ds.w2v.vector_size,\n",
        "                   dec_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "model.train()\n",
        "interval = int(_psylex71_ds.__len__()/batch_size) >> 2\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for x, y in dataloader:\n",
        "        print(type(x), len(x))\n",
        "        sys.exit()\n",
        "        enc_inp = torch.from_numpy(np.array(x)).float().to(device).unsqueeze(0)\n",
        "        #enc_inp = torch.from_numpy(np.array(x)).to(device).unsqueeze(0)\n",
        "        dec_inp = pad_sequence(y, batch_first=True).to(device)[:,1:]\n",
        "        tch = pad_sequence(y, batch_first=True, padding_value=-1.0).to(device)\n",
        "        tch = tch[:,1:]\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/len(x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(x):.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()\n",
        "\n",
        "#outfile = \"attnmt2-\" + str(epoch) + \".model\"\n",
        "#torch.save(net.state_dict(),outfile)"
      ],
      "metadata": {
        "id": "Z-Gys8WXa6mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 学習結果の評価"
      ],
      "metadata": {
        "id": "Z2eFYp2Na-dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "model.eval()\n",
        "for N in range(_psylex71_ds.__len__()):\n",
        "#for N in np.random.permutation(_psylex71_ds.__len__())[:100]:\n",
        "    x, y = _psylex71_ds.__getitem__(N)\n",
        "    enc_inp = torch.from_numpy(np.array(x)).to(device).unsqueeze(0)\n",
        "    enc_emb = model.enc_transform_layer(enc_inp)\n",
        "    hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "    dec_inp = y\n",
        "    dec_emb = model.decoder_emb(dec_inp)\n",
        "    dec_out, (hny, cny) = model.decoder(dec_emb,(hnx, cnx))\n",
        "    dec_out = model.out_layer(dec_out)\n",
        "    y_ids = np.argmax(dec_out.detach().numpy(),axis=1)\n",
        "\n",
        "    n_correct = np.array((y_ids[1:-1] == _psylex71_ds.getitem(N)[2]).sum())\n",
        "    isOK = n_correct == len(_psylex71_ds.getitem(N)[2])\n",
        "    color = 'grey' if isOK else 'red'\n",
        "\n",
        "    if not isOK:\n",
        "        errors.append((N,y_ids))\n",
        "        print(colored((f'{N:05d}', #y_ids,\n",
        "                       \"\".join(p for p in _psylex71_ds.phon_ids2phn(y_ids[1:-1]))),color,attrs=[\"bold\"]), end=\" \")\n",
        "        print(_psylex71_ds.getitem(N))\n",
        "\n",
        "cr = len(errors) / _psylex71_ds.__len__()\n",
        "print(f'総エラー数:{len(errors)}',\n",
        "      f'正解率:{(1.-cr)*100:.3f}')\n"
      ],
      "metadata": {
        "id": "27BxVraEbB77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 理解モデル"
      ],
      "metadata": {
        "id": "QbW93Mx6PTBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 モデルの定義\n"
      ],
      "metadata": {
        "id": "9ysMJyaEPYyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class EncDec_p2s(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sem_dim:int,\n",
        "                 enc_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.out_layer = nn.Linear(in_features=n_hid * bi_fact,\n",
        "                                   out_features=sem_dim)\n",
        "\n",
        "    def forward(self, enc_inp):\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "        dec_out = self.out_layer(hnx)\n",
        "        return dec_out\n",
        "\n",
        "n_hid = 64\n",
        "n_layers = 1\n",
        "bidirectional=False\n",
        "enc_dec = EncDec_p2s(sem_dim=_psylex71_ds.w2v.vector_size,\n",
        "                     enc_vocab_size=len(_psylex71_ds.phoneme),\n",
        "                     n_layers=n_layers,\n",
        "                     bidirectional=bidirectional,\n",
        "                     n_hid=n_hid).to(device)\n",
        "enc_dec.eval()"
      ],
      "metadata": {
        "id": "JXPyhTQLPV4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYRZVZSIPd1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}