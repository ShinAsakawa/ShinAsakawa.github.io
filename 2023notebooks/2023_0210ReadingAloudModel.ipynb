{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0210ReadingAloudModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad8bcd9-b0eb-41a3-a524-238a9efe519b",
      "metadata": {
        "id": "dad8bcd9-b0eb-41a3-a524-238a9efe519b"
      },
      "source": [
        "# 単語の処理と文脈および意味表現プロジェクト 資料\n",
        "\n",
        "- Project for Word processings, context, and semantic representation (WordProc&Con_Sem)\n",
        "- date: 2023_0210\n",
        "- author: 浅川伸一 <asakawa@ieee.org>\n",
        "\n",
        "- `git` コマンドを使ってソースコードをローカルディスクに保存するなどしてください。\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/ShinAsakawa/RAM.git\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70f64e0-0bd0-4386-a09f-f68092bd4183",
      "metadata": {
        "id": "f70f64e0-0bd0-4386-a09f-f68092bd4183"
      },
      "source": [
        "## おあそび RAM (abbriviated for Reading Aloud Model) の描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89e5453-1f6c-4587-a74e-2fd1c0481ac2",
      "metadata": {
        "id": "d89e5453-1f6c-4587-a74e-2fd1c0481ac2"
      },
      "outputs": [],
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "#lams_url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\"\n",
        "#lams_url=\"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\"\n",
        "#IPython.display.Image(url=lams_url)\n",
        "\n",
        "import os\n",
        "lum_img_fname = 'lum@pc.webp'\n",
        "if not os.path.exists(lum_img_fname):\n",
        "    !wget \"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\"\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "x = plt.imread('lum@pc.webp')\n",
        "plt.figure(figsize=(4,7))\n",
        "plt.axis('off')\n",
        "plt.imshow(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c8f5f9-526e-4b5f-85e0-84d60baa9fc9",
      "metadata": {
        "id": "e9c8f5f9-526e-4b5f-85e0-84d60baa9fc9",
        "tags": []
      },
      "source": [
        "### 0.0.1 RNN, LSTM, GRU に関して\n",
        "<!--\n",
        "次のサンプルコードを参照\n",
        "\n",
        "```python\n",
        "_gru = nn.GRU(input_size=3, hidden_size=2, num_layers=1, batch_first=False)\n",
        "#_gru(input=torch.tensor([1,2,3]), h0=torch.tensor([4,5]))\n",
        "#help(nn.GRU)\n",
        "\n",
        "seq_len, n_seq, n_inp, n_hid, n_layers = 5, 3, 10, 8, 2\n",
        "seq_len, n_seq, n_inp, n_hid, n_layers = 1, 3, 5, 7, 2\n",
        "\n",
        "inp_sf = torch.randn(seq_len, n_seq, n_inp)     # sequence first (=time) first\n",
        "inp_bf = torch.randn(n_seq, seq_len, n_inp)     # batch (=sentences order) first\n",
        "hid0   = torch.randn(n_layers, n_seq, n_hid)\n",
        "cel0   = torch.randn(n_layers, n_seq, n_hid)\n",
        "\n",
        "model0 = nn.GRU(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=False)\n",
        "model1 = nn.GRU(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=True)\n",
        "model2 = nn.RNN(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=False)\n",
        "model3 = nn.RNN(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=True)\n",
        "model4 = nn.LSTM(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=False)\n",
        "model5 = nn.LSTM(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=True)\n",
        "model6 = nn.LSTM(input_size=n_inp, hidden_size=n_hid, num_layers=n_layers, batch_first=False)\n",
        "\n",
        "output0, hn = model0(inp_sf, hid0)\n",
        "print(f'output0.size():{output0.size()}', f'hn.size():{hn.size()}')\n",
        "\n",
        "output1, hn = model1(inp_bf, hid0)\n",
        "print(f'output1.size():{output1.size()}', f'hn.size():{hn.size()}')\n",
        "\n",
        "output2, hn = model2(inp_sf, hid0)\n",
        "print(f'output2.size():{output2.size()}', f'hn.size():{hn.size()}')\n",
        "\n",
        "output3, hn = model3(inp_bf, hid0)\n",
        "print(f'output3.size():{output3.size()}', f'hn.size():{hn.size()}')\n",
        "\n",
        "output4, (hn, cn) = model4(inp_sf, (hid0, cel0))\n",
        "print(f'output4.size():{output4.size()}', f'hn.size():{hn.size()}')\n",
        "\n",
        "output5, (hn, cn) = model5(inp_bf, (hid0, cel0))\n",
        "print(f'output5.size():{output5.size()}', f'hn.size():{hn.size()}')\n",
        "```\n",
        "\n",
        "出力は以下の通り\n",
        "\n",
        "```bash\n",
        "output0.size():torch.Size([1, 3, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "output1.size():torch.Size([3, 1, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "output2.size():torch.Size([1, 3, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "output3.size():torch.Size([3, 1, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "output4.size():torch.Size([1, 3, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "output5.size():torch.Size([3, 1, 7]) hn.size():torch.Size([2, 3, 7])\n",
        "``` -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709323c2-a834-4770-a63a-340d98064c66",
      "metadata": {
        "id": "709323c2-a834-4770-a63a-340d98064c66"
      },
      "source": [
        "## 0.1 2023_0120 の議論\n",
        "\n",
        "符号化器-復号化器モデルは，[seq2seq](https://arxiv.org/abs/1409.3215) と呼ばれるモデルでもある。\n",
        "邦訳すれば，系列-2-系列 モデルなのだが，今回のプロジェクトでは，意味表象が，系列ではない。\n",
        "そのため，seq2seq という名称よりも，より一般化した，符号化器-復号化器 (enc-dec model) モデルとしたい。\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/master/assets/2014Sutskever_S22_Fig1.svg\" width=\"66%\">\n",
        "<br/>    \n",
        "From Sutskever 2014, Figure 1.\n",
        "</center>\n",
        "\n",
        "上図は，seq2seq モデルの概略図である。\n",
        "符号化器と呼ばれる部分は，トークン `<EOS>` が入力された時点までである。\n",
        "それ以降は，復号化器となる。\n",
        "符号化器と復号化器とで，一時刻前の中間層の状態が共有されていることがポイントである。\n",
        "seq2seq は翻訳モデルであり，符号化器と復号化器とで，言語モデルの扱う言語が異なっている。\n",
        "具体的には，フランス語と英語である。\n",
        "\n",
        "\n",
        "オリジナルの，三角モデルにおける o2p については，三層のニューラルネットワークとみなしうる。\n",
        "このため，o2p の中間層は，識別性能を向上する役割と，モダリティ間の結合という２つの異なる役割を担っていたとみなすことができる。\n",
        "理論的には，両者を分離する必要も，統合する必要もない，どちらにしても積極的な理由は存在しないと思われる。\n",
        "駄菓子菓子，計算論的な役割においては，異なるモダリティ間の通信を媒介する役割と，入力モダリティにおける表象を確立するという意味合いを分離すると，役割分担が明確になるのであろうということである。\n",
        "\n",
        "---\n",
        "\n",
        "* 一文字の orth2phon を担保したいために，全角の数字，アルファベット，ひらがな，計 109 文字をデータ先頭に追加した。\n",
        "* Fushimi1999 (Psyc. Rev.) の語彙リストを fushimi1999_list として収録\n",
        "* Fushimi1999_list の扱いに伴い訓練語彙数を 10K から 20K に増加\n",
        "* 学習率 lr は 0.001 だと収束しない。0.0001 であれば良好であり，訓練損失 0.01 程度，訓練精度 0.987 程度までに至る。\n",
        "* ただし，一文字データセット onechar_dataset では lr=0.001 の方が収束が早い。\n",
        "これは，データセットサイズが 20K と 0.1K と 20 倍の差があるためであろう。\n",
        "* 近藤先生が，GPU 上で実行してくださった訓練済モデルのファイル名が `decoder256new.pt` と `encoder256new.pt` である。\n",
        "これは，中間層ユニット数が 256 である orth2phon モデルの訓練済モデルである。\n",
        "* `_train()` 関数内で，正解判定をする際に，GPU から CPU へ転送しなければいけないことを忘れていたので修正した。\n",
        "具体的には， `detach()` と `numpy()` の間に `cpu()` を挿入した。2 箇所\n",
        "```python\n",
        "    ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().cpu().numpy()[0])\n",
        "```\n",
        "* 近藤先生の GPU で訓練済モデルを CPU 環境で実行する必要がある場合，変更して読み込む必要がある\n",
        "\n",
        "```python\n",
        "encoder_pretrained_fname = 'encoder256new.pt'\n",
        "decoder_pretrained_fname = 'decoder256new.pt'\n",
        "if os.path.exists(encoder_pretrained_fname):\n",
        "    encoder = torch.load(encoder_pretrained_fname, _location=torch.device(device))map\n",
        "    \n",
        "if os.path.exists(decoder_pretrained_fname):\n",
        "    decoder = torch.load(decoder_pretrained_fname, map_location=torch.device(device))\n",
        "```\n",
        "\n",
        "近藤先生の実験によれば，結果は以下の通りである(そうだ)。\n",
        "\n",
        "正答率\n",
        "\n",
        "|   | 条件 | 記述         | 正解率 | \n",
        "|:----|:-----|:------------|:------|\n",
        "|WORD |   HF |1:consistent |　18/20\n",
        "|WORD |   HF |2:typical    |   HF___inconsist  16/20|\n",
        "|WORD |   HF |3:atypical   |   HF___atypical_  8/20 |\n",
        "|WORD |   LF |1:consistent |   LF___consist__  14/20|\n",
        "|WORD |   LF |2:typical    |   LF___inconsist  9/20|\n",
        "|WORD |   LF |3:atypical   |   LF___atypical_  3/20|\n",
        "\n",
        "* 伏見らではでなかったatypical効果だけでなく，\n",
        "　consistent-typicalの差もある程度ある気がします\n",
        " また，LFでも効果ありであり，かつ，頻度効果もあり\n",
        "* **今回，L(legitimate alternative reading of components） マークを付けてみました**\n",
        "  Lm, Lnは，モーラ間違い，一文字間違いと混合\n",
        "\n",
        "アクセプト率\n",
        "\n",
        "|     | 条件 | 記述         | 正解率 | \n",
        "|:----|:----|:------------|:------|\n",
        "|非単語| HF  | 1:consistent|HFNW_consist__  17/20|\n",
        "|非単語| HF  | 2:typical   |HFNW_inconsist　　17/20|\n",
        "|非単語| HF  | 3:ambiguous |HFNW_ambiguous  13/20|\n",
        "|非単語| LF  | 1:consistent|LFNW_consist__  15/20|\n",
        "|非単語| LF  | 2:typical   |LFNW_inconsist  13/20|\n",
        "|非単語| LF  | 3:ambiguous |LFNW_ambiguous  7/20|\n",
        "\n",
        "* かなり読めますね．アクセプトは，どんな読みでもいいので読めそうな読み方ならOKにしています．\n",
        "　単語の L と同じになります．\n",
        "* **結構驚きは，非単語のときに連濁や促音化ができているところ**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652daee2-4886-4b33-a2fd-eff242a27a75",
      "metadata": {
        "id": "652daee2-4886-4b33-a2fd-eff242a27a75"
      },
      "source": [
        "## 0.2 近藤先生からいただいた結果の描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1546adb-c63a-4421-b7ed-4458668bdbc0",
      "metadata": {
        "id": "d1546adb-c63a-4421-b7ed-4458668bdbc0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "#import matplotlib    \n",
        "#matplotlib.rcParams['text.usetex'] = True    \n",
        "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
        "\n",
        "fig.suptitle('Fushimi+1999 単語リストの検証 (o2p, hid256)')\n",
        "ax[0].plot((18/20,16/20, 8/20), marker=\"v\", color=\"green\", label=\"高頻度\")\n",
        "ax[0].plot((14/20, 9/20, 3/20), marker=\"^\", color=\"blue\", label=\"低頻度\")\n",
        "ax[0].set_xlim(-0.5,2.5)\n",
        "ax[0].set_ylim(0,1)\n",
        "ax[0].set_xticks(ticks=range(3))\n",
        "ax[0].set_xticklabels(labels=['一貫','非一貫','例外'])\n",
        "ax[0].legend()\n",
        "ax[0].set_title('単語')\n",
        "ax[0].set_ylabel('正解率')\n",
        "\n",
        "ax[1].plot((17/20,17/20,13/20), marker=\"v\", color=\"green\", label=\"高頻度\")\n",
        "ax[1].plot((15/20,13/20, 7/20), marker=\"^\", color=\"blue\", label=\"低頻度\")\n",
        "ax[1].set_xlim(-0.5,2.5)\n",
        "ax[1].set_ylim(0,1)\n",
        "ax[1].set_xticks(ticks=range(3))\n",
        "ax[1].set_xticklabels(labels=['一貫','非一貫','例外'])\n",
        "ax[1].set_title('非単語')\n",
        "ax[1].legend()\n",
        "fig.savefig('2023_0123LAM_o2p_hid256_fushimi1999.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a331efbe-bf75-48c2-8566-98181ce13cd0",
      "metadata": {
        "id": "a331efbe-bf75-48c2-8566-98181ce13cd0"
      },
      "source": [
        "# 1. 必要となるライブラリのインストール\n",
        "\n",
        "注意: Colab 上で実行する場合，Google Drive への接続許可を求めるポップアップウィンドウが開くので，許可する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b7f33b-fe8a-4638-86ab-186da6be99dc",
      "metadata": {
        "id": "80b7f33b-fe8a-4638-86ab-186da6be99dc"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "if isColab:\n",
        "\n",
        "    # termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    import termcolor    \n",
        "\n",
        "    # 結果を保存するために Google Drive をマウントする\n",
        "    import google.colab\n",
        "    google.colab.drive.mount('/content/drive/')\n",
        "    \n",
        "    # GPU 情報を表示\n",
        "    !nvidia-smi -L\n",
        "\n",
        "    #!pip install ipynbname --upgrade > /dev/null\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で MeCab を動作させるために，C コンパイラを起動して，MeCab の構築を行う\n",
        "    # そのため時間がかかる。\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    mecab_wakati = MeCab.Tagger('-Owakati').parse\n",
        "    mecab_yomi = MeCab.Tagger('-Oyomi').parse\n",
        "    \n",
        "else:\n",
        "    from ccap.mecab_settings import yomi as mecab_yomi\n",
        "    from ccap.mecab_settings import wakati as mecab_wakati\n",
        "\n",
        "\n",
        "# ここから下は，コード実行に関するバージョン情報などの情報源の取得と表示\n",
        "from termcolor import colored\n",
        "\n",
        "import platform\n",
        "HOSTNAME = platform.node().split('.')[0]\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname\n",
        "    import ipynbname\n",
        "FILEPATH = str(ipynbname.path()).replace(HOME+'/','')\n",
        "\n",
        "import pwd\n",
        "USER=pwd.getpwuid(os.geteuid())[0]\n",
        "\n",
        "from datetime import date\n",
        "TODAY=date.today()\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "\n",
        "color = 'green'\n",
        "print('日付:',colored(f'{TODAY}', color=color, attrs=['bold']))\n",
        "print('HOSTNAME:',colored(f'{HOSTNAME}', color=color, attrs=['bold']))\n",
        "print('ユーザ名:',colored(f'{USER}', color=color, attrs=['bold']))\n",
        "print('HOME:',colored(f'{HOME}', color=color,attrs=['bold']))\n",
        "print('ファイル名:',colored(f'{FILEPATH}', color=color, attrs=['bold']))\n",
        "print('torch.__version__:',colored(f'{TORCH_VERSION}', color=color, attrs=['bold']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e975d51d-a302-4cf5-9f9b-bad8e5be2e70",
      "metadata": {
        "id": "e975d51d-a302-4cf5-9f9b-bad8e5be2e70"
      },
      "source": [
        "# 2. パラメータ設定\n",
        "\n",
        "語彙数を 10K 語から 20K 語に倍増しているのは，Fushimi1999 の語彙リストの未知語が存在したためである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b81c818d-400e-494f-b608-29bec77136db",
      "metadata": {
        "id": "b81c818d-400e-494f-b608-29bec77136db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29986ffd-4382-406c-f1f0-116041917bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traindata_size:\u001b[1m\u001b[32m20000\u001b[0m\n",
            "epochs:\u001b[1m\u001b[32m30\u001b[0m\n",
            "hidden_size:\u001b[1m\u001b[32m256\u001b[0m\n",
            "random_seed:\u001b[1m\u001b[32m42\u001b[0m\n",
            "source:\u001b[1m\u001b[32morth\u001b[0m\n",
            "target:\u001b[1m\u001b[32mphon\u001b[0m\n",
            "pretrained:\u001b[1m\u001b[32mFalse\u001b[0m\n",
            "path_saved:\u001b[1m\u001b[32m2023_0201triangle2023_o2p_hid256.pt\u001b[0m\n",
            "lr:\u001b[1m\u001b[32m0.0001\u001b[0m\n",
            "dropout_p:\u001b[1m\u001b[32m0.0\u001b[0m\n",
            "teacher_forcing_ratio:\u001b[1m\u001b[32m0.5\u001b[0m\n",
            "optim_func:\u001b[1m\u001b[32m<class 'torch.optim.adam.Adam'>\u001b[0m\n",
            "loss_func:\u001b[1m\u001b[32mNLLLoss()\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "params = {\n",
        "    'traindata_size':  20000,   # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    'epochs': 30,               # 学習のためのエポック数\n",
        "    \n",
        "    'hidden_size': 256,          # 中間層のニューロン数\n",
        "    #'hidden_size': 128,         # 中間層のニューロン数\n",
        "    \n",
        "    'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "    # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "    'source': 'orth',          # ['orth', 'phon']\n",
        "    'target': 'phon',          # ['orth', 'phon']\n",
        "\n",
        "    'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "    #'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "    'path_saved': '2023_0201triangle2023_o2p_hid256.pt',\n",
        "    #'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "    'lr': 1e-4,                     # 学習率\n",
        "    'dropout_p': 0.0,                 # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,     # 教師強制を行う確率\n",
        "    'optim_func': torch.optim.Adam,   # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :torch.nn.NLLLoss(),  # 負の対数尤度損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}\n",
        "\n",
        "color = 'green'\n",
        "for k, v in params.items():\n",
        "    print(f'{k}:{colored(v, color=color, attrs=[\"bold\"])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9a22d7-2787-4bbe-8f29-62d4b9d0a2d4",
      "metadata": {
        "id": "7d9a22d7-2787-4bbe-8f29-62d4b9d0a2d4"
      },
      "source": [
        "# 3. ライブラリの輸入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a43ab530-40aa-47bd-aed5-d8c752504bf2",
      "metadata": {
        "id": "a43ab530-40aa-47bd-aed5-d8c752504bf2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f91e49b-4a70-4cdf-93fb-6dfa645f07e3",
      "metadata": {
        "id": "7f91e49b-4a70-4cdf-93fb-6dfa645f07e3"
      },
      "source": [
        "# 4. データ作成"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe06677-84b5-4ccd-a342-23d032eb4a76",
      "metadata": {
        "id": "ffe06677-84b5-4ccd-a342-23d032eb4a76"
      },
      "source": [
        "## 4.1. psylex71_dataset と vdrj_dataset の定義\n",
        "\n",
        "* Psylex71 は「NTT 日本語の語彙特性」頻度表であり，著作権上の問題があるため配布不可\n",
        "* vdrj は松下言語学習ラボ，[日本語を読むための語彙データベース（研究用）](http://www17408ui.sakura.ne.jp/tatsum/database.html#vdrj) を加工して作成したデータである\n",
        "\n",
        "RAM ディレクトリ直下に，`psylex71_data.gz`, `vdrj_data.gz` がある。\n",
        "これらは，`RAM/make_psylex71_dict.py`, `RAM/make_vdrj_dict.py` を実行して作成されたデータファイルである。\n",
        "ここでは，これらのデータファイルが作成済と仮定している。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf RAM"
      ],
      "metadata": {
        "id": "sJ2s3vcphGTn"
      },
      "id": "sJ2s3vcphGTn",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c22875cb-5470-4207-8f3b-eb018c9bb049",
      "metadata": {
        "id": "c22875cb-5470-4207-8f3b-eb018c9bb049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc331c73-d37e-4f30-a341-5e506df49758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAM'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 31 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), 14.31 MiB | 7.74 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git \n",
        "\n",
        "from RAM import convert_ids2tensor    \n",
        "from RAM import calc_accuracy    \n",
        "from RAM import asMinutes\n",
        "from RAM import timeSince\n",
        "from RAM import check_vals_performance\n",
        "from RAM import evaluate\n",
        "#from RAM import draw_word_char_histgram\n",
        "from RAM.utils import _train\n",
        "from RAM.utils import _fit\n",
        "# #from RAM import evaluate\n",
        "#from RAM import Onechar_dataset\n",
        "from RAM.dataset import OneChar_Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45426160-d7f2-4ec0-bb6f-383a43e5f852",
      "metadata": {
        "id": "45426160-d7f2-4ec0-bb6f-383a43e5f852"
      },
      "source": [
        "## 4.2. Fushimi, Ijuin, and Patterson(1999) データの読み込み\n",
        "\n",
        "- Fushimi1999 データは検証データとして用いるため，最初に読み込む"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a12107-082a-4f03-827e-6ee598d6434e",
      "metadata": {
        "id": "e0a12107-082a-4f03-827e-6ee598d6434e"
      },
      "outputs": [],
      "source": [
        "from RAM.fushimi1999 import _fushimi1999_list\n",
        "from RAM.fushimi1999 import fushimi1999_dict\n",
        "fushimi1999_list = _fushimi1999_list()\n",
        "for k, v in fushimi1999_dict.items():\n",
        "    print(k,v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "78af5167-c210-4c78-ac02-2f9066fa4385",
      "metadata": {
        "id": "78af5167-c210-4c78-ac02-2f9066fa4385"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import gzip\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from RAM.dataset import Psylex71_Dataset\n",
        "from RAM.dataset import VDRJ_Dataset\n",
        "\n",
        "psylex71_dataset = Psylex71_Dataset(source=params['source'], target=params['target'])\n",
        "vdrj_dataset = VDRJ_Dataset(source=params['source'], target=params['target'])\n",
        "\n",
        "ds = psylex71_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1633cfb0-cb09-4729-98b8-4794b6a7e69c",
      "metadata": {
        "id": "1633cfb0-cb09-4729-98b8-4794b6a7e69c"
      },
      "source": [
        "## 4.3 定義したデータセット psylex71 と vdrj を宣言"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f36ea0-bc02-41a6-9f0c-b6c5e78872eb",
      "metadata": {
        "id": "d3f36ea0-bc02-41a6-9f0c-b6c5e78872eb"
      },
      "source": [
        "### 4.3.1 確認作業"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bf9857-3907-4681-91e6-f3f2494dcbf6",
      "metadata": {
        "id": "f8bf9857-3907-4681-91e6-f3f2494dcbf6"
      },
      "outputs": [],
      "source": [
        "wrd = '蕎麦'\n",
        "N = 1999\n",
        "for ds in [psylex71_dataset, vdrj_dataset]:\n",
        "    #print(str(ds))\n",
        "    #print(ds.data_dict[N])\n",
        "    inp_ids, tgt_ids = ds.__getitem__(N)\n",
        "    print(ds.source_ids2tkn(inp_ids), ds.target_ids2tkn(tgt_ids))\n",
        "    #print(ds.orth2info_dict[wrd])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f96499-79fc-4aef-b9f7-8cc32f1cfa47",
      "metadata": {
        "id": "a8f96499-79fc-4aef-b9f7-8cc32f1cfa47"
      },
      "source": [
        "## 4.4 データセットの頻度情報の視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520f4b35-8847-459b-bb7b-462028f29f55",
      "metadata": {
        "id": "520f4b35-8847-459b-bb7b-462028f29f55"
      },
      "outputs": [],
      "source": [
        "from RAM.utils import draw_word_char_histgram\n",
        "ds = psylex71_dataset\n",
        "draw_word_char_histgram(_dict=ds.data_dict, key='phon', title='psylex71 phon', figsize2=(8,3))\n",
        "draw_word_char_histgram(_dict=ds.data_dict, key='orth', title='psylex71 orth', figsize2=(8,3))\n",
        "\n",
        "ds = vdrj_dataset\n",
        "draw_word_char_histgram(_dict=ds.data_dict, key='phon', title='vdrj phon', figsize2=(8,3))\n",
        "draw_word_char_histgram(_dict=ds.data_dict, key='orth', title='vdrj orth', figsize2=(8,3))\n",
        "\n",
        "ds = psylex71_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "916c4061-7601-40a4-81e5-ceb0f2008e0f",
      "metadata": {
        "id": "916c4061-7601-40a4-81e5-ceb0f2008e0f"
      },
      "source": [
        "# 5. 一文字データセットによる予備検証"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30742b47-f5de-43e3-907d-14c472071189",
      "metadata": {
        "id": "30742b47-f5de-43e3-907d-14c472071189"
      },
      "source": [
        "## 5.1. 自作ライブラリ triangle2023 のインポート"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ac2cc9-a3b7-4283-8f8f-cafcca89a7fe",
      "metadata": {
        "id": "d8ac2cc9-a3b7-4283-8f8f-cafcca89a7fe"
      },
      "source": [
        "## 5.2 一文字データセットの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f9def0-02f7-4881-8e89-b46994866f73",
      "metadata": {
        "id": "15f9def0-02f7-4881-8e89-b46994866f73"
      },
      "outputs": [],
      "source": [
        "from RAM.dataset import OneChar_Dataset\n",
        "onechar_dataset = OneChar_Dataset(\n",
        "    source=params['source'], \n",
        "    target=params['target'])\n",
        "#onechar_dataset.data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ccea0b2-b696-468b-986b-83695e976be5",
      "metadata": {
        "id": "6ccea0b2-b696-468b-986b-83695e976be5"
      },
      "outputs": [],
      "source": [
        "#params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38640e7-ac8b-4853-a7fe-56a0c40ac49d",
      "metadata": {
        "id": "c38640e7-ac8b-4853-a7fe-56a0c40ac49d"
      },
      "outputs": [],
      "source": [
        "print(onechar_dataset.source_list)\n",
        "print(onechar_dataset.target_list)\n",
        "print(onechar_dataset.data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8854e61c-6227-499c-8360-67a03042e833",
      "metadata": {
        "id": "8854e61c-6227-499c-8360-67a03042e833"
      },
      "outputs": [],
      "source": [
        "draw_word_char_histgram(_dict=onechar_dataset.data_dict, key='orth', figsize2=(6,4))\n",
        "draw_word_char_histgram(_dict=onechar_dataset.data_dict, key='phon', figsize2=(6,3))\n",
        "#print(onechar_dataset.data_dict[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60732484-0602-424a-a46b-eb80020631ee",
      "metadata": {
        "id": "60732484-0602-424a-a46b-eb80020631ee"
      },
      "source": [
        "## 5.3. 符号化器-復号化器モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c49dee-62dd-4878-a344-5af888a51758",
      "metadata": {
        "id": "44c49dee-62dd-4878-a344-5af888a51758"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from RAM.model import EncoderRNN\n",
        "from RAM.model import AttnDecoderRNN\n",
        "from RAM import train_one_seq2seq\n",
        "from RAM import train_epochs\n",
        "\n",
        "ds = psylex71_dataset\n",
        "\n",
        "encoder = EncoderRNN(\n",
        "    n_inp=len(onechar_dataset.source_list),                # 符号化器への入力データ次元数の特徴数 (語彙数): int\n",
        "    n_hid=params['hidden_size']).to(device)   # 符号化器の中間層数，埋め込みベクトルとして復号化器へ渡される次元数: int\n",
        "                                              # 復号化器の出力層素子数は，入力層と同一であるので指定しない\n",
        "\n",
        "decoder = AttnDecoderRNN(\n",
        "    n_hid=params['hidden_size'],               # 復号化器の中間層次元数: int\n",
        "    n_out=len(onechar_dataset.target_list),                 # 復号化器の出力層次元数，入力層の次元と等しいので入力層次元を指定せず: int\n",
        "    dropout_p=params['dropout_p'],\n",
        "    max_length=ds.target_maxlen).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f619ce62-0439-4d58-a5c4-27cda091c7af",
      "metadata": {
        "id": "f619ce62-0439-4d58-a5c4-27cda091c7af"
      },
      "source": [
        "## 5.4. 訓練用最適化関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190de6de-c301-4024-910c-06639570a070",
      "metadata": {
        "id": "190de6de-c301-4024-910c-06639570a070"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    econder_optimizer\n",
        "except:\n",
        "    encoder_optimizer = params['optim_func'](encoder.parameters(), lr=params['lr'])\n",
        "    \n",
        "try:\n",
        "    decoder_optimizer\n",
        "except:\n",
        "    decoder_optimizer = params['optim_func'](decoder.parameters(), lr=params['lr'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2c156c-90ff-4d58-bcef-fd538d813502",
      "metadata": {
        "tags": [],
        "id": "3b2c156c-90ff-4d58-bcef-fd538d813502"
      },
      "source": [
        "## 5.5. 一文字データセットを用いた訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ad0849-0519-4974-aec3-abdf1bcc6500",
      "metadata": {
        "id": "e8ad0849-0519-4974-aec3-abdf1bcc6500"
      },
      "outputs": [],
      "source": [
        "# 新たな訓練を実行する場合には，損失関数を消去する必要があります\n",
        "#del losses\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7049eee-c266-4bb7-b279-bc7d02fbdac1",
      "metadata": {
        "id": "f7049eee-c266-4bb7-b279-bc7d02fbdac1"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    losses\n",
        "except:\n",
        "    losses = []\n",
        "\n",
        "losses += train_epochs( \n",
        "    #epochs=200,\n",
        "    #epochs=params['epochs'], \n",
        "    epochs=30,\n",
        "    \n",
        "    #lr=params['lr'],\n",
        "    lr=0.001,\n",
        "\n",
        "    encoder=encoder, decoder=decoder,  \n",
        "    encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
        "    source_vocab=ds.source_list, target_vocab=ds.target_list,\n",
        "    source_ids=ds.source, target_ids=ds.target,\n",
        "    params=params,\n",
        "    \n",
        "    device=device,\n",
        "    max_length=ds.target_maxlen,\n",
        "    n_sample=0,\n",
        "    teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "    \n",
        "    #train_dataset=train_dataset,\n",
        "    train_dataset=onechar_dataset,\n",
        "    \n",
        "    #val_dataset=X_vals,\n",
        "    val_dataset=None,\n",
        "    #val_dataset={'val':onechar_dataset},\n",
        ")\n",
        "\n",
        "try:\n",
        "    plt\n",
        "except:\n",
        "    import matplotlib.pyplot as plt\n",
        "plt.plot(losses)    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009e4077-4b51-4a69-8c4e-20bdea420326",
      "metadata": {
        "tags": [],
        "id": "009e4077-4b51-4a69-8c4e-20bdea420326"
      },
      "source": [
        "## 2.3 Fushimi1999 データによる検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3571bca9-8ee2-4f50-b703-fd559e7a923a",
      "metadata": {
        "id": "3571bca9-8ee2-4f50-b703-fd559e7a923a"
      },
      "outputs": [],
      "source": [
        "def check_fushimi1999_list(encoder=encoder,\n",
        "                           decoder=decoder,\n",
        "                           is_print:bool=False,\n",
        "                          )->str:\n",
        "\n",
        "    ret_msg = \"\"\n",
        "    counter = 1\n",
        "    for key, val in fushimi1999_dict.items():\n",
        "        key_old = \"\"\n",
        "        if key != key_old:\n",
        "            key_old = key\n",
        "            ret_msg += f'{key}:'\n",
        "            if is_print:\n",
        "                print(colored(f'{key}:', 'green', attrs=['bold']), end=\" \")\n",
        "        \n",
        "        n_ok, n_all = 0, 0\n",
        "        msg = \"\"\n",
        "        for wrd in val:\n",
        "            _src_ids = psylex71_dataset.source_tkn2ids(wrd) + [psylex71_dataset.source_list.index('<EOW>')]\n",
        "            ans=evaluate(encoder=encoder, decoder=decoder,\n",
        "                         input_ids=_src_ids,\n",
        "                         max_length= psylex71_dataset.target_maxlen,\n",
        "                         source_vocab=psylex71_dataset.source_list, \n",
        "                         target_vocab=psylex71_dataset.target_list,\n",
        "                         device=device)\n",
        "            \n",
        "            res = \"\".join(p for p in ans[0][:-1])  # モデルからの戻り値を再構成\n",
        "            if res == wrd:\n",
        "                n_ok += 1\n",
        "                n_all += 1\n",
        "\n",
        "            counter =  1 if (counter % 10) == 0 else (counter + 1)\n",
        "            _end = \"\\n\" if counter==1 else \", \"\n",
        "            msg += f\"{wrd}->/{res}/{_end}\"\n",
        "        \n",
        "        if n_all != 0:\n",
        "            ret_msg += f'{n_ok/n_all * 100:5.2f}%\\n{msg}'\n",
        "        else:\n",
        "            ret_msg += f'{0:5.2f}%\\n{msg}'\n",
        "        if is_print:\n",
        "            print(f'{n_ok/n_all * 100:5.2f}%\\n{msg}')\n",
        "            \n",
        "    return ret_msg\n",
        "            \n",
        "print(check_fushimi1999_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5737ca38-ca3c-4671-a054-b888e79872c8",
      "metadata": {
        "id": "5737ca38-ca3c-4671-a054-b888e79872c8"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from triangle2023.model import EncoderRNN\n",
        "from triangle2023.model import AttnDecoderRNN\n",
        "\n",
        "encoder = EncoderRNN(\n",
        "    n_inp=len(psylex71_dataset.source_list),         # 符号化器への入力データ次元数の特徴数 (語彙数): int\n",
        "    n_hid=params['hidden_size']).to(device)   # 符号化器の中間層数，埋め込みベクトルとして復号化器へ渡される次元数: int\n",
        "                                              # 復号化器の出力層素子数は，入力層と同一であるので指定しない\n",
        "\n",
        "decoder = AttnDecoderRNN(\n",
        "    n_hid=params['hidden_size'],               # 復号化器の中間層次元数: int\n",
        "    n_out=len(psylex71_dataset.target_list),          # 復号化器の出力層次元数，入力層の次元と等しいので入力層次元を指定せず: int\n",
        "    dropout_p=params['dropout_p'],\n",
        "    max_length=psylex71_dataset.target_maxlen).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5969cfd-a59b-427b-b7c4-30a2a834075b",
      "metadata": {
        "id": "a5969cfd-a59b-427b-b7c4-30a2a834075b"
      },
      "source": [
        "# 6. 全データを用いた訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2813a8de-845f-42a0-a9b7-e62384a1dde9",
      "metadata": {
        "id": "2813a8de-845f-42a0-a9b7-e62384a1dde9"
      },
      "source": [
        "## 6.1. 全データを訓練データと検証データに分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69af6fee-70bc-43f3-8493-a3a169289463",
      "metadata": {
        "id": "69af6fee-70bc-43f3-8493-a3a169289463"
      },
      "outputs": [],
      "source": [
        "P  = int(psylex71_dataset.__len__() * 0.9)\n",
        "_P = psylex71_dataset.__len__() - P\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    dataset=psylex71_dataset,\n",
        "    lengths=(P, _P),\n",
        "    generator=torch.Generator().manual_seed(params['random_seed']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab81501f-13e4-499b-b899-585a75210b13",
      "metadata": {
        "id": "ab81501f-13e4-499b-b899-585a75210b13"
      },
      "source": [
        "## 6.2. 訓練の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8ba195-1a12-46f4-9a1b-71881fe071d1",
      "metadata": {
        "id": "6c8ba195-1a12-46f4-9a1b-71881fe071d1"
      },
      "outputs": [],
      "source": [
        "del losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a0c169-7886-4d96-a6a5-86c116fce5ba",
      "metadata": {
        "id": "36a0c169-7886-4d96-a6a5-86c116fce5ba"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    losses\n",
        "except:\n",
        "    losses = []\n",
        "losses += train_epochs(\n",
        "    epochs=5,\n",
        "    lr=params['lr'],\n",
        "    #lr=0.001,\n",
        "    \n",
        "    encoder=encoder, decoder=decoder, \n",
        "    encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
        "    source_vocab=psylex71_dataset.source_list, target_vocab=psylex71_dataset.target_list,\n",
        "    source_ids=psylex71_dataset.source, target_ids=psylex71_dataset.target,\n",
        "    params=params,\n",
        "    device=device,\n",
        "    max_length=psylex71_dataset.target_maxlen,\n",
        "    n_sample=0,\n",
        "    teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset={'val': val_dataset},\n",
        ")\n",
        "\n",
        "try:\n",
        "    plt\n",
        "except:\n",
        "    import matplotlib.pyplot as plt\n",
        "plt.plot(losses)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48304666-7b38-44b1-9dd1-e545da5cc052",
      "metadata": {
        "id": "48304666-7b38-44b1-9dd1-e545da5cc052"
      },
      "outputs": [],
      "source": [
        "pt_fname = '2023_0210fname.pt'\n",
        "torch.save({'encoder':encoder.state_dict(), 'decoder':decoder.state_dict(),\n",
        "            'encoder_optimizer': encoder_optimizer.state_dict(), 'decoder_optimizer': decoder_optimizer.state_dict(),\n",
        "            'params': params, 'data': psylex71_dataset.data_dict}, \n",
        "           pt_fname)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}