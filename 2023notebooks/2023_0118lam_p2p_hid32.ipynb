{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0118lam_p2p_hid32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe44f14f-5c81-4890-9e43-1e44d926bdfd",
      "metadata": {
        "id": "fe44f14f-5c81-4890-9e43-1e44d926bdfd"
      },
      "source": [
        "---\n",
        "date: 2023_0116\n",
        "fname: 2022_0115lam_p2o.ipynb\n",
        "---\n",
        "\n",
        "* 2023_0116 関係者にわかりやうように，コメントを多用して，問題点を共有するように務めること\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5421bf8-348e-4fd6-a718-737ef24c90f5",
      "metadata": {
        "tags": [],
        "id": "a5421bf8-348e-4fd6-a718-737ef24c90f5"
      },
      "outputs": [],
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "#IPython.display.Image(url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\")\n",
        "#IPython.display.Image(url=\"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\")\n",
        "\n",
        "import os\n",
        "lum_img_fname = 'lum@pc.webp'\n",
        "if not os.path.exists(lum_img_fname):\n",
        "    !wget \"https://uy-allstars.com/_assets/images/pages/char/detail/webp/lum@pc.webp\"\n",
        "import matplotlib.pyplot as plt\n",
        "x = plt.imread(lum_img_fname)\n",
        "plt.figure(figsize=(5,8))\n",
        "plt.axis('off') #=None\n",
        "plt.imshow(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0feaa46-c1fb-401c-ad97-dcf9bd613ed1",
      "metadata": {
        "id": "b0feaa46-c1fb-401c-ad97-dcf9bd613ed1"
      },
      "source": [
        "# 1 準備作業"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3d0402-3b6c-4850-ad80-20521d88fe1b",
      "metadata": {
        "id": "1f3d0402-3b6c-4850-ad80-20521d88fe1b"
      },
      "source": [
        "## 1.1 ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a253b9a-40f0-4cde-9af0-f35ebbc90ab9",
      "metadata": {
        "id": "8a253b9a-40f0-4cde-9af0-f35ebbc90ab9"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    !git clone https://github.com/ShinAsakawa/bit.git 2>&1\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で MeCab を動作させるために，C コンパイラを起動して，MeCab の構築を行う\n",
        "    # そのため時間がかかる。\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    wakati = MeCab.Tagger('-Owakati').parse\n",
        "    yomi = MeCab.Tagger('-Oyomi').parse\n",
        "    \n",
        "else:\n",
        "    from ccap.mecab_settings import yomi\n",
        "    from ccap.mecab_settings import wakati\n",
        "\n",
        "# 自作ライブラリ LAM の読み込み\n",
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    !git clone https://github.com/ShinAsakawa/lam.git\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で termcolor の色制御が動作しないので，バージョンを下げる必要がある\n",
        "    !pip install --upgrade termcolor==2.0 2>&1\n",
        "    \n",
        "    !pip install jupyter_contrib_nbextensions 2>&1 \n",
        "    !jupyter nbextension enable codefolding/main 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f4d784-d3be-41ef-8583-e5c66148a64f",
      "metadata": {
        "id": "e4f4d784-d3be-41ef-8583-e5c66148a64f"
      },
      "source": [
        "## 1.2 パラメータ設定\n",
        "\n",
        "語彙数を 10K 語から 20K 語に倍増しているのは，Fushimi1999 の語彙リストの未知語が存在したためである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dabe3e47-b0b4-4a03-b8fb-9b36ff95bbdc",
      "metadata": {
        "id": "dabe3e47-b0b4-4a03-b8fb-9b36ff95bbdc"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import lam\n",
        "#device = lam.device  # CPU or GPU の選択\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "params = {\n",
        "    'traindata_size':  20000,   # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    #'traindata_size': 301612,  # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    'epochs': 30,               # 学習のためのエポック数\n",
        "    'hidden_size': 64,          # 中間層のニューロン数\n",
        "    #'hidden_size': 128,         # 中間層のニューロン数\n",
        "    'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "    # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "    'source': 'phon',          # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    'target': 'phon',          # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    #'target': 'mora_p_r',     # ['orth', 'phon', 'mora', 'mora_p', 'mora_p_r']\n",
        "    # 'orth': 書記素, \n",
        "    # 'phon': 音韻, \n",
        "    # 'mora': モーラ\n",
        "    # 'mora_p': モーラを silius による音分解\n",
        "    # 'mora_p_r': モーラの silius 音分解の逆\n",
        "    'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "    #'pretrained': True,          # True であれば訓練済ファイルを読み込む\n",
        "    #'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    'path_saved': '2023_0120lam_o2p_hid64_nttfreq20k.pt', \n",
        "    #'path_saved': '2022_0829lam_p2p_hid24_vocab10k.pt',\n",
        "    #'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "    # 結果の散布図を保存するファイル名    \n",
        "    'path_graph': '2023_0120lam_p2p_hid64_nttfreq20k.pdf',\n",
        "    #'path_graph': False,                     # 保存しない場合\n",
        "\n",
        "    'lr': 0.001,                              # 学習率\n",
        "    'dropout_p': 0.0,                         # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,             # 教師強制を行う確率\n",
        "    'optim_func': torch.optim.Adam,           # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :torch.nn.CrossEntropyLoss(), # 交差エントロピー損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}\n",
        "\n",
        "source = params['source']\n",
        "target = params['target']\n",
        "_src, _tgt = source+'_ids', target+'_ids'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3b25f30f-504c-4707-bf8b-f9bece933ed6",
      "metadata": {
        "id": "3b25f30f-504c-4707-bf8b-f9bece933ed6"
      },
      "outputs": [],
      "source": [
        "def get_soure_and_target_from_params(\n",
        "    params=None,\n",
        "    _vocab=None,\n",
        "    source=None,\n",
        "    target=None,\n",
        "    is_print:bool=True):\n",
        "\n",
        "    if source == 'orth':\n",
        "        source_vocab = _vocab.orth_vocab\n",
        "        source_ids = 'orth_ids'\n",
        "    elif source == 'phon':\n",
        "        source_vocab = _vocab.phon_vocab\n",
        "        source_ids = 'phon_ids'\n",
        "    elif source == 'mora':\n",
        "        source_vocab = _vocab.mora_vocab\n",
        "        source_ids = 'mora_ids'\n",
        "    elif source == 'mora_p':\n",
        "        source_vocab = _vocab.mora_p_vocab\n",
        "        source_ids = 'mora_p_ids'\n",
        "    elif source == 'mora_p_r':\n",
        "        source_vocab = _vocab.mora_p_vocab\n",
        "        source_ids = 'mora_p_ids_r'\n",
        "\n",
        "    if target == 'orth':\n",
        "        target_vocab = _vocab.orth_vocab\n",
        "        target_ids = 'orth_ids'\n",
        "    elif target == 'phon':\n",
        "        target_vocab = _vocab.phon_vocab\n",
        "        target_ids = 'phon_ids'\n",
        "    elif target == 'mora':\n",
        "        target_vocab = _vocab.mora_vocab\n",
        "        target_ids = 'mora_ids'\n",
        "    elif target == 'mora_p':\n",
        "        target_vocab = _vocab.mora_p_vocab\n",
        "        target_ids = 'mora_p_ids'\n",
        "    elif target == 'mora_p_r':\n",
        "        target_vocab = _vocab.mora_p_vocab\n",
        "        target_ids = 'mora_p_ids_r'\n",
        "\n",
        "    if is_print:\n",
        "        print(colored(f'source:{source}','blue', attrs=['bold']), f'{source_vocab}')\n",
        "        print(colored(f'target:{target}','cyan', attrs=['bold']), f'{target_vocab}')\n",
        "        print(colored(f'source_ids:{source_ids}','blue', attrs=['bold']), f'{source_ids}')\n",
        "        print(colored(f'target_ids:{target_ids}','cyan', attrs=['bold']), f'{target_ids}')\n",
        "\n",
        "    return source_vocab, source_ids, target_vocab, target_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b28896b3-272d-461a-a40f-c2fb565caa15",
      "metadata": {
        "id": "b28896b3-272d-461a-a40f-c2fb565caa15"
      },
      "source": [
        "## 1.3 Fushimi1999 データセット"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc9a8c62-c0e5-43a7-b8ef-c7db98cb0870",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc9a8c62-c0e5-43a7-b8ef-c7db98cb0870",
        "outputId": "3c5ee21d-8cda-4627-a2c3-fdf95d1bf48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF___consist__ ['戦争', '倉庫', '医学', '注意', '記念', '番号', '料理', '完全', '開始', '印刷', '連続', '予約', '多少', '教員', '当局', '材料', '夕刊', '労働', '運送', '電池']\n",
            "HF___inconsist ['反対', '失敗', '作品', '指定', '実験', '決定', '独占', '独身', '固定', '食品', '表明', '安定', '各種', '役所', '海岸', '決算', '地帯', '道路', '安打', '楽団']\n",
            "HF___atypical_ ['仲間', '夫婦', '人間', '神経', '相手', '反発', '化粧', '建物', '彼女', '毛糸', '場合', '台風', '夜間', '人形', '東西', '地元', '松原', '競馬', '大幅', '貸家']\n",
            "LF___consist__ ['集計', '観察', '予告', '動脈', '理学', '信任', '任務', '返信', '医局', '低温', '区別', '永続', '持続', '試練', '満開', '軍備', '製材', '銀貨', '急送', '改選']\n",
            "LF___inconsist ['表紙', '指針', '熱帯', '作詞', '決着', '食費', '古代', '地形', '役場', '品種', '祝福', '金銭', '根底', '接種', '経由', '郷土', '街路', '宿直', '曲折', '越境']\n",
            "LF___atypical_ ['強引', '寿命', '豆腐', '出前', '歌声', '近道', '間口', '風物', '面影', '眼鏡', '居所', '献立', '小雨', '毛皮', '鳥居', '仲買', '頭取', '極上', '奉行', '夢路']\n",
            "HFNW_consist__ ['集学', '信別', '製信', '運学', '番送', '電続', '完意', '軍開', '動選', '当働', '予続', '倉理', '予少', '教池', '理任', '銀務', '連料', '開員', '注全', '記争']\n",
            "HFNW_inconsist ['作明', '風行', '失定', '指団', '決所', '各算', '海身', '東発', '楽験', '作代', '反原', '独対', '歌上', '反定', '独定', '場家', '安種', '経着', '決土', '松合']\n",
            "HFNW_ambiguous ['表品', '実定', '人風', '神間', '相経', '人元', '小引', '指場', '毛所', '台手', '間物', '道品', '出取', '建馬', '大婦', '地打', '化間', '面口', '金由', '彼間']\n",
            "LFNW_consist__ ['急材', '戦刊', '返計', '印念', '低局', '労号', '満送', '永告', '試脈', '観備', '材約', '夕局', '医庫', '任続', '医貨', '改練', '区温', '多始', '材刷', '持察']\n",
            "LFNW_inconsist ['食占', '表底', '宿帯', '決帯', '古費', '安敗', '役針', '近命', '眼道', '豆立', '街直', '固路', '郷種', '品路', '曲銭', '献居', '奉買', '根境', '役岸', '祝折']\n",
            "LFNW_ambiguous ['食形', '接紙', '競物', '地詞', '強腐', '頭路', '毛西', '夜糸', '仲影', '熱福', '寿前', '鳥雨', '地粧', '越種', '仲女', '極鏡', '夢皮', '居声', '貸形', '夫幅']\n",
            "fushimi1999_list:['戦争', '倉庫', '医学', '注意', '記念', '番号', '料理', '完全', '開始', '印刷', '連続', '予約', '多少', '教員', '当局', '材料', '夕刊', '労働', '運送', '電池', '反対', '失敗', '作品', '指定', '実験', '決定', '独占', '独身', '固定', '食品', '表明', '安定', '各種', '役所', '海岸', '決算', '地帯', '道路', '安打', '楽団', '仲間', '夫婦', '人間', '神経', '相手', '反発', '化粧', '建物', '彼女', '毛糸', '場合', '台風', '夜間', '人形', '東西', '地元', '松原', '競馬', '大幅', '貸家', '集計', '観察', '予告', '動脈', '理学', '信任', '任務', '返信', '医局', '低温', '区別', '永続', '持続', '試練', '満開', '軍備', '製材', '銀貨', '急送', '改選', '表紙', '指針', '熱帯', '作詞', '決着', '食費', '古代', '地形', '役場', '品種', '祝福', '金銭', '根底', '接種', '経由', '郷土', '街路', '宿直', '曲折', '越境', '強引', '寿命', '豆腐', '出前', '歌声', '近道', '間口', '風物', '面影', '眼鏡', '居所', '献立', '小雨', '毛皮', '鳥居', '仲買', '頭取', '極上', '奉行', '夢路', '集学', '信別', '製信', '運学', '番送', '電続', '完意', '軍開', '動選', '当働', '予続', '倉理', '予少', '教池', '理任', '銀務', '連料', '開員', '注全', '記争', '作明', '風行', '失定', '指団', '決所', '各算', '海身', '東発', '楽験', '作代', '反原', '独対', '歌上', '反定', '独定', '場家', '安種', '経着', '決土', '松合', '表品', '実定', '人風', '神間', '相経', '人元', '小引', '指場', '毛所', '台手', '間物', '道品', '出取', '建馬', '大婦', '地打', '化間', '面口', '金由', '彼間', '急材', '戦刊', '返計', '印念', '低局', '労号', '満送', '永告', '試脈', '観備', '材約', '夕局', '医庫', '任続', '医貨', '改練', '区温', '多始', '材刷', '持察', '食占', '表底', '宿帯', '決帯', '古費', '安敗', '役針', '近命', '眼道', '豆立', '街直', '固路', '郷種', '品路', '曲銭', '献居', '奉買', '根境', '役岸', '祝折', '食形', '接紙', '競物', '地詞', '強腐', '頭路', '毛西', '夜糸', '仲影', '熱福', '寿前', '鳥雨', '地粧', '越種', '仲女', '極鏡', '夢皮', '居声', '貸形', '夫幅']\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "import sys\n",
        "\n",
        "verbose = False\n",
        "\n",
        "fushimi1999 = {\n",
        "    'HF___consist__': ['戦争', '倉庫', '医学', '注意', '記念', '番号', '料理', '完全', '開始', '印刷',\n",
        "                       '連続', '予約', '多少', '教員', '当局', '材料', '夕刊', '労働', '運送', '電池' ], # consistent, 'high-frequency words\n",
        "    'HF___inconsist': ['反対', '失敗', '作品', '指定', '実験', '決定', '独占', '独身', '固定', '食品',\n",
        "                       '表明', '安定', '各種', '役所', '海岸', '決算', '地帯', '道路', '安打', '楽団' ], # inconsistent, 'high-frequency words\n",
        "    'HF___atypical_': ['仲間', '夫婦', '人間', '神経', '相手', '反発', '化粧', '建物', '彼女', '毛糸', \n",
        "                       '場合', '台風', '夜間', '人形', '東西', '地元', '松原', '競馬', '大幅', '貸家' ], # inconsistent atypical, 'high-frequency words\n",
        "    'LF___consist__': ['集計', '観察', '予告', '動脈', '理学', '信任', '任務', '返信', '医局', '低温', \n",
        "                       '区別', '永続', '持続', '試練', '満開', '軍備', '製材', '銀貨', '急送', '改選' ], # consistent, 'low-frequecy words\n",
        "    'LF___inconsist': ['表紙', '指針', '熱帯', '作詞', '決着', '食費', '古代', '地形', '役場', '品種', \n",
        "                       '祝福', '金銭', '根底', '接種', '経由', '郷土', '街路', '宿直', '曲折', '越境' ], # inconsistent, 'low-frequency words\n",
        "    'LF___atypical_': ['強引', '寿命', '豆腐', '出前', '歌声', '近道', '間口', '風物', '面影', '眼鏡', \n",
        "                       '居所', '献立', '小雨', '毛皮', '鳥居', '仲買', '頭取', '極上', '奉行', '夢路' ], # inconsistent atypical, 'low-frequncy words\n",
        "    'HFNW_consist__': ['集学', '信別', '製信', '運学', '番送', '電続', '完意', '軍開', '動選', '当働', \n",
        "                       '予続', '倉理', '予少', '教池', '理任', '銀務', '連料', '開員', '注全', '記争' ], # consistent, 'high-character-frequency nonwords\n",
        "    'HFNW_inconsist': ['作明', '風行', '失定', '指団', '決所', '各算', '海身', '東発', '楽験', '作代',\n",
        "                       '反原', '独対', '歌上', '反定', '独定', '場家', '安種', '経着', '決土', '松合' ], # inconsistent biased, 'high-character-frequency nonwords\n",
        "    'HFNW_ambiguous': ['表品', '実定', '人風', '神間', '相経', '人元', '小引', '指場', '毛所', '台手',\n",
        "                       '間物', '道品', '出取', '建馬', '大婦', '地打', '化間', '面口', '金由', '彼間' ], # inconsistent ambigous, 'high-character-frequency nonwords\n",
        "    'LFNW_consist__': ['急材', '戦刊', '返計', '印念', '低局', '労号', '満送', '永告', '試脈', '観備',\n",
        "                       '材約', '夕局', '医庫', '任続', '医貨', '改練', '区温', '多始', '材刷', '持察' ], # consistent, 'low-character-frequency nonwords\n",
        "    'LFNW_inconsist': ['食占', '表底', '宿帯', '決帯', '古費', '安敗', '役針', '近命', '眼道', '豆立',\n",
        "                       '街直', '固路', '郷種', '品路', '曲銭', '献居', '奉買', '根境', '役岸', '祝折' ], # inconsistent biased, 'low-character-frequency nonwords\n",
        "    'LFNW_ambiguous': ['食形', '接紙', '競物', '地詞', '強腐', '頭路', '毛西', '夜糸', '仲影', '熱福',\n",
        "                       '寿前', '鳥雨', '地粧', '越種', '仲女', '極鏡', '夢皮', '居声', '貸形', '夫幅' ], # inconsistent ambigous, 'low-character-frequency nonwords\n",
        "}\n",
        "\n",
        "\n",
        "for k, v in fushimi1999.items():\n",
        "    # 上のデータを表示\n",
        "    print(colored(k, 'blue', attrs=['bold']), v)\n",
        "\n",
        "fushimi1999_list = [] # 上のデータをリスト化\n",
        "for k, v in fushimi1999.items():\n",
        "    for _v in v:\n",
        "        fushimi1999_list.append(_v)\n",
        "\n",
        "if verbose:\n",
        "    print(colored('# Fushimi1999 データから，訓練データに含まれているデータを表示する', 'blue', attrs=['bold']))\n",
        "    for i, wrd in enumerate(fushimi1999_list):\n",
        "        \n",
        "        if wrd in train_wordlist:\n",
        "            color = 'blue'\n",
        "            idx = train_wordlist.index(wrd)\n",
        "        else:\n",
        "            color = 'red'\n",
        "            idx = -1\n",
        "        print(colored((f'{i:3d} wrd:{wrd},idx:{idx:5d}',\n",
        "              f'orth_tkn2ids:{orth_tkn2ids(wrd)}', #o[_tgt]\n",
        "                 ),color=color, attrs=['bold']))\n",
        "\n",
        "print(f'fushimi1999_list:{fushimi1999_list}')        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51477356-7417-4bb5-a781-5fcdf7642a65",
      "metadata": {
        "id": "51477356-7417-4bb5-a781-5fcdf7642a65"
      },
      "source": [
        "## 1.3 データセットの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f554c353-e510-4b34-9729-be7ca73f8b22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638,
          "referenced_widgets": [
            "faae3833805a4c2eb8a9a4875310304e",
            "df811b1221e74407b207ea6d9b054719",
            "741ec590492a476a9bfcef1902292bfc",
            "015225773d244c738b3cd1c7a7de9d37",
            "819bd5348be047b4a3106c900f176eb9",
            "8e105bcab860474bb5edda04f8f1ea12",
            "8d29306283c94a42815afaa4bb7e6d1b",
            "eab0db49331f410e9951c8241f16db8b",
            "01582af0b90c4ff3b2187c61ba22a282",
            "2a88e96e47c44f08980116694689847b",
            "80409008ae4e419cabe0df1032fcd98f"
          ]
        },
        "id": "f554c353-e510-4b34-9729-be7ca73f8b22",
        "outputId": "3b07b8c4-d2dc-45a1-b07a-7ed4fc503523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# NTT日本語語彙特性 (天野，近藤; 1999, 三省堂)より頻度情報を取得\n",
            "# 訓練に用いる単語の選定 20000 語\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faae3833805a4c2eb8a9a4875310304e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "語彙先頭の項目 300 を印字\n",
            "(1, 'あ') (2, 'い') (3, 'う') (4, 'え') (5, 'お') (6, 'か') (7, 'が') (8, 'き') (9, 'ぎ') (10, 'く')\n",
            "(11, 'ぐ') (12, 'け') (13, 'げ') (14, 'こ') (15, 'ご') (16, 'さ') (17, 'ざ') (18, 'し') (19, 'じ') (20, 'す')\n",
            "(21, 'ず') (22, 'せ') (23, 'ぜ') (24, 'そ') (25, 'ぞ') (26, 'た') (27, 'だ') (28, 'ち') (29, 'ぢ') (30, 'つ')\n",
            "(31, 'づ') (32, 'て') (33, 'で') (34, 'と') (35, 'ど') (36, 'な') (37, 'に') (38, 'ぬ') (39, 'ね') (40, 'の')\n",
            "(41, 'は') (42, 'ば') (43, 'ぱ') (44, 'ひ') (45, 'び') (46, 'ぴ') (47, 'ふ') (48, 'ぶ') (49, 'ぷ') (50, 'へ')\n",
            "(51, 'べ') (52, 'ぺ') (53, 'ほ') (54, 'ぼ') (55, 'ぽ') (56, 'ま') (57, 'み') (58, 'む') (59, 'め') (60, 'も')\n",
            "(61, 'や') (62, 'ゆ') (63, 'よ') (64, 'ら') (65, 'り') (66, 'る') (67, 'れ') (68, 'ろ') (69, 'わ') (70, 'ゐ')\n",
            "(71, 'ゑ') (72, 'を') (73, 'ん') (74, 'Ａ') (75, 'Ｂ') (76, 'Ｃ') (77, 'Ｄ') (78, 'Ｅ') (79, 'Ｆ') (80, 'Ｇ')\n",
            "(81, 'Ｈ') (82, 'Ｉ') (83, 'Ｊ') (84, 'Ｋ') (85, 'Ｌ') (86, 'Ｍ') (87, 'Ｎ') (88, 'Ｏ') (89, 'Ｐ') (90, 'Ｑ')\n",
            "(91, 'Ｒ') (92, 'Ｓ') (93, 'Ｔ') (94, 'Ｕ') (95, 'Ｖ') (96, 'Ｗ') (97, 'Ｘ') (98, 'Ｙ') (99, 'Ｚ') (100, '０')\n",
            "(101, '１') (102, '２') (103, '３') (104, '４') (105, '５') (106, '６') (107, '７') (108, '８') (109, '９') (110, 'っ')\n",
            "(111, 'ている') (112, 'から') (113, 'れる') (114, 'する') (115, 'こと') (116, 'など') (117, '日') (118, 'なる') (119, 'ない') (120, 'ある')\n",
            "(121, 'いう') (122, '年') (123, '日本') (124, 'この') (125, 'ため') (126, '円') (127, '人') (128, 'られる') (129, 'まで') (130, 'さん')\n",
            "(131, 'ます') (132, 'として') (133, 'である') (134, 'その') (135, '氏') (136, '問題') (137, 'てくる') (138, 'かっ') (139, 'という') (140, '約')\n",
            "(141, 'できる') (142, 'です') (143, 'について') (144, 'でも') (145, 'ようだ') (146, 'もの') (147, 'だけ') (148, '万') (149, 'これ') (150, '同')\n",
            "(151, '東京') (152, '米国') (153, '政府') (154, '首相') (155, 'ては') (156, 'たい') (157, '時') (158, 'しかし') (159, '側') (160, 'ても')\n",
            "(161, '出る') (162, '者') (163, '後') (164, 'たち') (165, 'せる') (166, 'いる') (167, '思う') (168, '分') (169, 'よる') (170, 'それ')\n",
            "(171, 'つく') (172, 'による') (173, '見る') (174, '中') (175, '大統領') (176, 'みる') (177, '受ける') (178, '私') (179, '昨年') (180, '企業')\n",
            "(181, '求める') (182, '回') (183, 'ておる') (184, '内') (185, '考える') (186, '的だ') (187, '関係') (188, '開く') (189, '示す') (190, 'べきだ')\n",
            "(191, '億') (192, '中国') (193, '二') (194, '経済') (195, '多い') (196, 'ので') (197, '党') (198, '歳') (199, '事件') (200, 'また')\n",
            "(201, '国') (202, '会社') (203, 'とは') (204, '前') (205, '入る') (206, '会') (207, '午前') (208, '言う') (209, 'より') (210, '出す')\n",
            "(211, '発表') (212, '第') (213, 'よう') (214, 'でいる') (215, '話') (216, '強い') (217, 'たり') (218, 'ていく') (219, '自民党') (220, '自分')\n",
            "(221, '持つ') (222, '化する') (223, '調査') (224, '代表') (225, '新') (226, '会長') (227, 'だろう') (228, '間') (229, '決める') (230, '三')\n",
            "(231, '述べる') (232, '年度') (233, '女性') (234, 'ソ連') (235, '参加') (236, '改革') (237, '続く') (238, '国民') (239, 'かける') (240, '元')\n",
            "(241, '会議') (242, '東京都') (243, 'そうだ') (244, '計画') (245, '予定') (246, 'いく') (247, '全国') (248, 'ながら') (249, '政治') (250, '今年')\n",
            "(251, '社長') (252, '一') (253, '使う') (254, '午後') (255, '時代') (256, '認める') (257, 'に対する') (258, '政権') (259, '政策') (260, 'に対し')\n",
            "(261, '五') (262, '協力') (263, '声') (264, '中心') (265, '地域') (266, 'とる') (267, '明らかだ') (268, '選挙') (269, '社') (270, 'メートル')\n",
            "(271, '世界') (272, '委員長') (273, '方針') (274, '初めて') (275, '進める') (276, '各') (277, '大きい') (278, 'のに') (279, 'いい') (280, '行く')\n",
            "(281, 'てしまう') (282, 'ところ') (283, 'だが') (284, '検討') (285, '目') (286, '制度') (287, '社会') (288, '派') (289, '情報') (290, 'になる')\n",
            "(291, '国会') (292, '高い') (293, '必要') (294, '対策') (295, 'とする') (296, '韓国') (297, '委員会') (298, '長') (299, '議員') (300, 'ドル')\n"
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm  #jupyter で実行時\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import gzip\n",
        "import jaconv\n",
        "\n",
        "class VOCAB():\n",
        "    '''\n",
        "    訓練データとしては，NTT 日本語語彙特性 (天野，近藤, 1999, 三省堂) の頻度データ，実際のファイル名としては `pslex71.txt` から頻度データを読み込んで，高頻度語を訓練データとする。\n",
        "    ただし，検証データに含まれる単語は訓練データとして用いない。\n",
        "\n",
        "    検証データとして，以下のいずれかを考える\n",
        "    1. TLPA (藤田 他, 2000, 「失語症語彙検査」の開発，音声言語医学 42, 179-202)\n",
        "    2. SALA 上智大学失語症語彙検査\n",
        "\n",
        "    このオブジェクトクラスでは，\n",
        "    `phon_vocab`, `orth_vocab`, `ntt_freq`, に加えて，単語の読みについて ntt_orth2hira によって読みを得ることにした。\n",
        "\n",
        "    * `train_data`, `test_data` という辞書が本体である。\n",
        "    各辞書の項目には，さらに\n",
        "    `Vocab_ja.test_data[0].keys() = dict_keys(['orig', 'orth', 'phon', 'orth_ids', 'phon_ids', 'semem'])`\n",
        "\n",
        "    各モダリティ共通トークンとして以下を設定した\n",
        "    * <PAD>: 埋め草トークン\n",
        "    * <EQW>: 単語終端トークン\n",
        "    * <SOW>: 単語始端トークン\n",
        "    * <UNK>: 未定義トークン\n",
        "\n",
        "    このクラスで定義されるデータは 2 つの辞書である。すなわち 1. train_data, 2. tlpa_data である。\n",
        "    各辞書は，次のような辞書項目を持つ。\n",
        "    ```\n",
        "    {0: {'orig': 'バス',\n",
        "    'yomi': 'ばす',\n",
        "    'orth': ['バ', 'ス'],\n",
        "    'orth_ids': [695, 514],\n",
        "    'orth_r': ['ス', 'バ'],\n",
        "    'orth_ids_r': ['ス', 'バ'],\n",
        "    'phon': ['b', 'a', 's', 'u'],\n",
        "    'phon_ids': [23, 7, 19, 12],\n",
        "    'phon_r': ['u', 's', 'a', 'b'],\n",
        "    'phon_ids_r': [12, 19, 7, 23],\n",
        "    'mora': ['ば', 'す'],\n",
        "    'mora_r': ['す', 'ば'],\n",
        "    'mora_ids': [87, 47],\n",
        "    'mora_p': ['b', 'a', 's', 'u'],\n",
        "    'mora_p_r': ['s', 'u', 'b', 'a'],\n",
        "    'mora_p_ids': [6, 5, 31, 35],\n",
        "    'mora_p_ids_r': [31, 35, 6, 5]},\n",
        "    ```\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                 traindata_size = 10000,  # デフォルト語彙数\n",
        "                 w2v=None,                # word2vec (gensim)\n",
        "                 yomi=None,               # MeCab を用いた `読み` の取得のため`\n",
        "                 ps71_fname:str=None,     # NTT 日本語語彙特性の頻度データファイル名\n",
        "                 stop_list:list=[],       # ストップ単語リスト：訓練データから排除する単語リスト\n",
        "                 #test_name='TLPA',  # or 'SALA',\n",
        "                ):\n",
        "\n",
        "        if yomi != None:\n",
        "            self.yomi = yomi\n",
        "        else:\n",
        "            #from mecab_settings import yomi\n",
        "            from ccap.mecab_settings import yomi\n",
        "            self.yomi = yomi\n",
        "\n",
        "        # 訓練語彙数の上限 `training_size` を設定\n",
        "        self.traindata_size = traindata_size\n",
        "\n",
        "        # `self.moraWakachi()` で用いる正規表現のあつまり 各条件を正規表現で表す\n",
        "        self.c1 = '[うくすつぬふむゆるぐずづぶぷゔ][ぁぃぇぉ]' #ウ段＋「ァ/ィ/ェ/ォ」\n",
        "        self.c2 = '[いきしちにひみりぎじぢびぴ][ゃゅぇょ]' #イ段（「イ」を除く）＋「ャ/ュ/ェ/ョ」\n",
        "        self.c3 = '[てで][ぃゅ]' #「テ/デ」＋「ャ/ィ/ュ/ョ」\n",
        "        self.c4 = '[ぁ-ゔー]' #カタカナ１文字（長音含む）\n",
        "        self.c5 = '[ふ][ゅ]'\n",
        "        ## self.c1 = '[ウクスツヌフムユルグズヅブプヴ][ァィェォ]' #ウ段＋「ァ/ィ/ェ/ォ」\n",
        "        ## self.c2 = '[イキシチニヒミリギジヂビピ][ャュェョ]' #イ段（「イ」を除く）＋「ャ/ュ/ェ/ョ」\n",
        "        ## self.c3 = '[テデ][ィュ]' #「テ/デ」＋「ャ/ィ/ュ/ョ」\n",
        "        ## self.c4 = '[ァ-ヴー]' #カタカナ１文字（長音含む）\n",
        "        ##cond = '('+c1+'|'+c2+'|'+c3+'|'+c4+')'\n",
        "        self.cond = '('+self.c5+'|'+self.c1+'|'+self.c2+'|'+self.c3+'|'+self.c4+')'\n",
        "        self.re_mora = re.compile(self.cond)\n",
        "        ## 以上 `self.moraWakachi()` で用いる正規表現の定義\n",
        "\n",
        "        self.orth_vocab, self.orth_freq = ['<PAD>', '<EOW>','<SOW>','<UNK>'], {}\n",
        "        self.phon_vocab, self.phone_freq = ['<PAD>', '<EOW>','<SOW>','<UNK>'], {}\n",
        "        self.phon_vocab = ['<PAD>', '<EOW>', '<SOW>', '<UNK>',\\\n",
        "                           'N', 'a', 'a:', 'e', 'e:', 'i', 'i:', 'i::', 'o', 'o:', 'o::', 'u', 'u:', \\\n",
        "                           'b', 'by', 'ch', 'd', 'dy', 'f', 'g', 'gy', 'h', 'hy', 'j', 'k', 'ky', \\\n",
        "                           'm', 'my', 'n', 'ny', 'p', 'py', 'q', 'r', 'ry', 's', 'sh', 't', 'ts', 'w', 'y', 'z']\n",
        "        self.mora_vocab = ['<PAD>', '<EOW>', '<SOW>', '<UNK>',\\\n",
        "                           'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', \\\n",
        "                           'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', \\\n",
        "                           'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', \\\n",
        "                           'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', \\\n",
        "                           'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', \\\n",
        "                           'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', \\\n",
        "                           'マ', 'ミ', 'ム', 'メ', 'モ', \\\n",
        "                           'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', \\\n",
        "                           'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ー'] \n",
        "        \n",
        "        # 全モーラリストを `mora_vocab` として登録\n",
        "        self.mora_vocab=[\n",
        "            '<PAD>', '<EOW>', '<SOW>', '<UNK>',\n",
        "            'ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'うぃ', 'うぇ', 'うぉ', 'ぇ', 'え', 'お',\n",
        "            'か', 'が', 'き', 'きゃ', 'きゅ', 'きょ', 'ぎ', 'ぎゃ', 'ぎゅ', 'ぎょ', 'く', 'くぁ', 'くぉ', 'ぐ', 'ぐぁ', 'け', 'げ', 'こ', 'ご',\n",
        "            'さ', 'ざ', 'し', 'しぇ', 'しゃ', 'しゅ', 'しょ', 'じ', 'じぇ', 'じゃ', 'じゅ', 'じょ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ',\n",
        "            'た', 'だ', 'ち', 'ちぇ', 'ちゃ', 'ちゅ', 'ちょ', 'ぢ', 'ぢゃ', 'ぢょ', 'っ', 'つ', 'つぁ', 'つぃ', 'つぇ', 'つぉ', 'づ', 'て',\n",
        "            'てぃ', 'で', 'でぃ', 'でゅ', 'と', 'ど',\n",
        "            'な', 'に', 'にぇ', 'にゃ', 'にゅ', 'にょ', 'ぬ', 'ね', 'の',\n",
        "            'は', 'ば', 'ぱ', 'ひ', 'ひゃ', 'ひゅ', 'ひょ', 'び', 'びゃ', 'びゅ', 'びょ', 'ぴ', 'ぴゃ', 'ぴゅ', 'ぴょ',\n",
        "            'ふ', 'ふぁ', 'ふぃ', 'ふぇ', 'ふぉ', 'ふゅ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ',\n",
        "            'ま', 'み', 'みゃ', 'みゅ', 'みょ', 'む', 'め', 'も',\n",
        "            'や', 'ゆ', 'よ', 'ら', 'り', 'りゃ', 'りゅ', 'りょ', 'る', 'れ', 'ろ', 'ゎ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', 'ー',\n",
        "            # 2022_1017 added\n",
        "            'ずぃ', 'ぶぇ', 'ぶぃ', 'ぶぁ', 'ゅ', 'ぶぉ', 'いぇ', 'ぉ', 'くぃ', 'ひぇ', 'くぇ', 'ぢゅ', 'りぇ',\n",
        "        ]\n",
        "        \n",
        "        # モーラに用いる音を表すリストを `mora_p_vocab` として登録\n",
        "        self.mora_p_vocab = ['<PAD>', '<EOW>', '<SOW>', '<UNK>',  \\\n",
        "        'N', 'a', 'b', 'by', 'ch', 'd', 'dy', 'e', 'f', 'g', 'gy', 'h', 'hy', 'i', 'j', 'k', 'ky', \\\n",
        "        'm', 'my', 'n', 'ny', 'o', 'p', 'py', 'q', 'r', 'ry', 's', 'sh', 't', 'ts', 'u', 'w', 'y', 'z']\n",
        "\n",
        "        # 母音を表す音から ひらがな への変換表を表す辞書を `vow2hira` として登録\n",
        "        self.vow2hira = {'a':'あ', 'i':'い', 'u':'う', 'e':'え', 'o':'お', 'N':'ん'}\n",
        "\n",
        "        self.mora_freq = {'<PAD>':0, '<EOW>':0, '<SOW>':0, '<UNK>':0}\n",
        "        self.mora_p = {}\n",
        "\n",
        "        # NTT 日本語語彙特性データから，`self.train_data` を作成\n",
        "        self.ntt_freq, self.ntt_orth2hira = self.make_ntt_freq_data(ps71_fname=ps71_fname)\n",
        "        self.ntt_freq_vocab = self.set_train_vocab()\n",
        "        self.train_data, self.excluded_data = {}, []\n",
        "        max_orth_length, max_phon_length, max_mora_length, max_mora_p_length = 0, 0, 0, 0\n",
        "        self.train_vocab = []\n",
        "        \n",
        "        num = '０１２３４５６７８９'\n",
        "        alpha = 'ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'   # ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "        hira = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわゐゑをん'\n",
        "        kata = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヰヱヲン'\n",
        "        onechars = hira+alpha+num # +kata\n",
        "        for i, orth in enumerate(onechars):\n",
        "            \n",
        "            if not orth in self.train_vocab:\n",
        "                self.train_vocab.append(orth)\n",
        "            _yomi = yomi(orth).strip()\n",
        "            hira = jaconv.kata2hira(_yomi)\n",
        "            phon_juli = jaconv.hiragana2julius(hira).split(' ')\n",
        "                \n",
        "            # 書記素 ID リスト `orth_ids` に書記素を登録\n",
        "            for o in orth:\n",
        "                if not o in self.orth_vocab:\n",
        "                    self.orth_vocab.append(o)\n",
        "            orth_ids = [self.orth_vocab.index(o) for o in orth]\n",
        "            phon_ids = [self.phon_vocab.index(p) if p in self.phon_vocab else self.phon_vocab.index('<UNK>') for p in phon_juli]\n",
        "            \n",
        "            self.train_data[i] = {\n",
        "                'orig':orth,\n",
        "                'orth':orth,\n",
        "                'yomi':_yomi,\n",
        "                'phon':phon_juli,\n",
        "                'phon_ids': phon_ids,\n",
        "                'orth_ids': orth_ids\n",
        "            }\n",
        "\n",
        "\n",
        "        for orth in tqdm(self.ntt_freq_vocab):\n",
        "            if orth in stop_list:       # stop list に登録されていたらスキップ\n",
        "                continue\n",
        "                \n",
        "            if orth in self.train_vocab: # すでに登録されている単語であればスキップ\n",
        "                continue\n",
        "            else:\n",
        "                self.train_vocab.append(orth)\n",
        "                \n",
        "            n_i = len(self.train_data)\n",
        "\n",
        "            # 書記素 `orth` から 読みリスト，音韻表現リスト，音韻表現反転リスト，\n",
        "            # 書記表現リスト，書記表現反転リスト，モーラ表現リスト，モーラ表現反転リスト の 7 つのリストを得る\n",
        "            _yomi, _phon, _phon_r, _orth, _orth_r, _mora, _mora_r = self.get7lists_from_orth(orth_wrd=orth)\n",
        "\n",
        "            # 音韻語彙リスト `self.phon_vocab` に音韻が存在していれば True そうでなければ False というリストを作成し，\n",
        "            # そのリスト無いに False があれば，排除リスト `self.excluded_data` に登録する\n",
        "            #if False in [True if p in self.phon_vocab else False for p in _phon]:\n",
        "            #    self.excluded_data.append(orth)\n",
        "            #    continue\n",
        "\n",
        "            phon_ids, phon_ids_r, orth_ids, orth_ids_r, mora_ids, mora_ids_r = self.get6ids(_phon, _orth, _yomi)\n",
        "            _yomi, _mora1, _mora1_r, _mora, _mora_ids, _mora_p, _mora_p_r, _mora_p_ids, _mora_p_ids_r, _juls = self.yomi2mora_transform(_yomi)\n",
        "            self.train_data[n_i] = {'orig': orth, 'yomi': _yomi,\n",
        "                                    'orth':_orth, 'orth_ids': orth_ids, 'orth_r': _orth_r, 'orth_ids_r': orth_ids_r,\n",
        "                                    'phon':_phon, 'phon_ids': phon_ids, 'phon_r': _phon_r, 'phon_ids_r': phon_ids_r,\n",
        "                                    'mora': _mora1, 'mora_r': _mora1_r, 'mora_ids': _mora_ids, 'mora_p': _mora_p,\n",
        "                                    'mora_p_r': _mora_p_r, 'mora_p_ids': _mora_p_ids, 'mora_p_ids_r': _mora_p_ids_r,\n",
        "                                   }\n",
        "            len_orth, len_phon, len_mora, len_mora_p = len(_orth), len(_phon), len(_mora), len(_mora_p)\n",
        "            max_orth_length = len_orth if len_orth > max_orth_length else max_orth_length\n",
        "            max_phon_length = len_phon if len_phon > max_phon_length else max_phon_length\n",
        "            max_mora_length = len_mora if len_mora > max_mora_length else max_mora_length\n",
        "            max_mora_p_length = len_mora_p if len_mora_p > max_mora_p_length else max_mora_p_length\n",
        "            \n",
        "            if len(self.train_data) >= self.traindata_size: # 上限値に達したら終了する\n",
        "                #self.train_vocab = [self.train_data[x]['orig'] for x in self.train_data.keys()]\n",
        "                break\n",
        "\n",
        "        self.max_orth_length = max_orth_length\n",
        "        self.max_phon_length = max_phon_length\n",
        "        self.max_mora_length = max_mora_length\n",
        "        self.max_mora_p_length = max_mora_p_length\n",
        "        \n",
        "\n",
        "\n",
        "    def yomi2mora_transform(self, yomi):\n",
        "        \"\"\"ひらがな表記された引数 `yomi` から，日本語の 拍(モーラ)  関係のデータを作成する\n",
        "        引数:\n",
        "        yomi:str ひらがな表記された単語 UTF-8 で符号化されていることを仮定している\n",
        "\n",
        "        戻り値:\n",
        "        yomi:str 入力された引数\n",
        "        _mora1:list[str] `_mora` に含まれる長音 `ー` を直前の母音で置き換えた，モーラ単位の分かち書きされた文字列のリスト\n",
        "        _mora1_r:list[str] `_mora1` を反転させた文字列リスト\n",
        "        _mora:list[str] `self.moraWakatchi()` によってモーラ単位で分かち書きされた文字列のリスト\n",
        "        _mora_ids:list[int] `_mora` を対応するモーラ ID で置き換えた整数値からなるリスト\n",
        "        _mora_p:list[str] `_mora` を silius によって音に変換した文字列リスト\n",
        "        _mora_p_r:list[str] `_mora_p` の反転リスト\n",
        "        _mora_p_ids:list[int] `mora_p` の各要素を対応する 音 ID に変換した数値からなるリスト\n",
        "        _mora_p_ids_r:list[int] `mora_p_ids` の各音を反転させた数値からなるリスト\n",
        "        _juls:list[str]: `yomi` を julius 変換した音素からなるリスト\n",
        "        \"\"\"\n",
        "        _mora = self.moraWakachi(yomi) # 一旦モーラ単位の分かち書きを実行して `_mora` に格納\n",
        "\n",
        "        # 単語をモーラ反転した場合に長音「ー」の音が問題となるので，長音「ー」を母音で置き換えるためのプレースホルダとして. `_mora` を用いる\n",
        "        _mora1 = _mora.copy()\n",
        "\n",
        "        # その他のプレースホルダの初期化，モーラ，モーラ毎 ID, モーラ音素，モーラの音素の ID， モーラ音素の反転，モーラ音素の反転 ID リスト\n",
        "        mora_ids, mora_p, mora_p_ids, mora_p_r, _mora_p_ids_r = [], [], [], [], []\n",
        "        _m0 = 'ー' # 長音記号\n",
        "\n",
        "        for i, _m in enumerate(_mora): # 各モーラ単位の処理と登録\n",
        "\n",
        "            __m = _m0 if _m == 'ー' else _m               # 長音だったら，前音の母音を __m とし，それ以外は自分自身を __m に代入\n",
        "            _mora1[i] = __m                               # 長音を変換した結果を格納\n",
        "            mora_ids.append(self.mora_vocab.index(__m))  # モーラを ID 番号に変換\n",
        "            mora_p += jaconv.hiragana2julius(__m).split()\n",
        "            #_mora_p += self.mora2jul[__m]                 # モーラを音素に変換して `_mora_p` に格納\n",
        "\n",
        "            # 変換した音素を音素 ID に変換して，`_mora_p_ids` に格納\n",
        "            #for _p in jaconv.hiragana2julius(_m).split():\n",
        "            #    idx = self.phon_vocab.index(_p)\n",
        "            #    mora_p_ids.append(idx)\n",
        "            #mora_p_ids = [self.phon_vocab.index(_p) for _p in jaconv.hiragana2julius(__m).split()]\n",
        "            #_mora_p_ids += [self.mora_p_vocab.index(_p) for _p in self.mora2jul[__m]]\n",
        "\n",
        "            if not _m in self.mora_freq: # モーラの頻度表を集計\n",
        "                self.mora_freq[__m] = 1\n",
        "            else:\n",
        "                self.mora_freq[__m] +=1\n",
        "\n",
        "            if self.hira2julius(__m)[-1] in self.vow2hira:      # 直前のモーラの最終音素が母音であれば\n",
        "                _m0 = self.vow2hira[self.hira2julius(__m)[-1]]  # 直前の母音を代入しておく。この処理が 2022_0311 でのポイントであった\n",
        "                \n",
        "        mora_p_ids = [self.phon_vocab.index(_p) for _p in mora_p]\n",
        "\n",
        "        # モーラ分かち書きした単語 _mora1 の反転を作成し `_mora1_r` に格納\n",
        "        _mora1_r = [m for m in _mora1[::-1]]\n",
        "        mora_p_r = []\n",
        "        for _m in _mora1_r:                   # 反転した各モーラについて\n",
        "            # モーラ単位で julius 変換して音素とし `_mora_p_r` に格納\n",
        "            for _jul in jaconv.hiragana2julius(_m).split():\n",
        "                mora_p_r.append(_jul)\n",
        "            #_mora_p_r += self.mora2jul[_m]\n",
        "\n",
        "            # mora_p_r に格納した音素を音素 ID に変換し mora_p_ids に格納\n",
        "            #mora_p_ids += [self.mora_p_vocab.index(_p) for _p in self.mora2jul[_m]]\n",
        "            \n",
        "        mora_p_ids_r = [self.phon_vocab.index(_m) for _m in mora_p_r]\n",
        "        _juls = self.hira2julius(yomi)\n",
        "\n",
        "        return yomi, _mora1, _mora1_r, _mora, mora_ids, mora_p, mora_p_r, mora_p_ids, mora_p_ids_r, _juls\n",
        "\n",
        "    def orth2orth_ids(self, \n",
        "                      orth:str):\n",
        "        orth_ids = [self.orth_vocab.index(ch) if ch in self.orth_vocab else self.orth_vocab.index('<UNK>') for ch in orth]\n",
        "        return orth_ids\n",
        "\n",
        "    def phon2phon_ids(self, \n",
        "                      phon:list):\n",
        "        phon_ids = [self.phon_vocab.index(ph) if ph in self.phon_vocab else self.phon_vocab.index('<UNK>') for ph in phon]\n",
        "        return phon_ids\n",
        "    \n",
        "    def yomi2phon_ids(self,\n",
        "                      yomi:str):\n",
        "        phon_ids = []\n",
        "        for _jul in self.hira2julius(yomi):\n",
        "            if _jul in self.phon_vocab:\n",
        "                ph = self.phon_vocab.index(_jul)\n",
        "            else:\n",
        "                ph = self.phon_vocab.index('<UNK>')\n",
        "            phon_ids.append(ph)\n",
        "        return phon_ids\n",
        "    \n",
        "    \n",
        "    def orth_ids2tkn(self, ids:list):\n",
        "        return [self.orth_vocab[idx] for idx in ids]\n",
        "\n",
        "    def orth_tkn2ids(self, tkn:list):\n",
        "        return [self.orth_vocab.index(_tkn) if _tkn in self.orth_vocab else self.orth_vocab.index('<UNK>') for _tkn in tkn]\n",
        "\n",
        "    def mora_p_ids2tkn(self, ids:list):\n",
        "        return [self.mora_p_vocab[idx] for idx in ids]\n",
        "\n",
        "    def mora_p_tkn2ids(self, tkn:list):\n",
        "        return [self.mora_p_vocab.index(_tkn) if _tkn in self.mora_p_vocab else self.mora_p_vocab('<UNK>') for _tkn in tkn]\n",
        "\n",
        "    def mora_ids2tkn(self, ids:list):\n",
        "        return [self.mora_vocab[idx] for idx in ids]\n",
        "\n",
        "    def mora_tkn2ids(self, tkn:list):\n",
        "        return [self.mora_vocab.index(_tkn) if _tkn in self.mora_vocab else self.mora_vocab('<UNK>') for _tkn in tkn]\n",
        "\n",
        "    def phon_ids2tkn(self, ids:list):\n",
        "        return [self.phon_vocab[idx] for idx in ids]\n",
        "\n",
        "    def phon_tkn2ids(self, tkn:list):\n",
        "        return [self.phon_vocab.index(_tkn) if _tkn in self.phon_vocab else self.phon_vocab.index('<UNK>') for _tkn in tkn]\n",
        "\n",
        "    def get6ids(self, _phon, _orth, yomi):\n",
        "\n",
        "        # 音韻 ID リスト `phon_ids` に音素を登録する\n",
        "        phon_ids = [self.phon_vocab.index(p) if p in self.phon_vocab else self.phon_vocab.index('<UNK>') for p in _phon]\n",
        "\n",
        "        # 直上の音韻 ID リストの逆転を作成\n",
        "        phon_ids_r = [p_id for p_id in phon_ids[::-1]]\n",
        "\n",
        "        # 書記素 ID リスト `orth_ids` に書記素を登録\n",
        "        for o in _orth:\n",
        "            if not o in self.orth_vocab:\n",
        "                self.orth_vocab.append(o)\n",
        "        orth_ids = [self.orth_vocab.index(o) for o in _orth]\n",
        "\n",
        "        # 直上の書記素 ID リストの逆転を作成\n",
        "        orth_ids_r = [o_id for o_id in orth_ids[::-1]]\n",
        "        #orth_ids_r = [o_id for o_id in _orth[::-1]]\n",
        "\n",
        "        mora_ids = []\n",
        "        for _p in self.hira2julius(yomi):\n",
        "            mora_ids.append(self.phon_vocab.index(_p) if _p in self.phon_vocab else self.phon_vocab.index('<UNK>'))\n",
        "\n",
        "        mora_ids_r = [m_id for m_id in mora_ids]\n",
        "        return phon_ids, phon_ids_r, orth_ids, orth_ids_r, mora_ids, mora_ids_r\n",
        "\n",
        "\n",
        "    def moraWakachi(self, hira_text):\n",
        "        \"\"\" ひらがなをモーラ単位で分かち書きする\n",
        "        https://qiita.com/shimajiroxyz/items/a133d990df2bc3affc12\"\"\"\n",
        "\n",
        "        return self.re_mora.findall(hira_text)\n",
        "\n",
        "\n",
        "    def _kana_moraWakachi(kan_text):\n",
        "        self.cond = '('+self.c1+'|'+self.c2+'|'+self.c3+'|'+self.c4+')'\n",
        "        self.re_mora = re.compile(self.cond)\n",
        "\n",
        "        return re_mora.findall(kana_text)\n",
        "\n",
        "    \n",
        "    def get7lists_from_orth(self, orth_wrd):\n",
        "        \"\"\"書記素 `orth` から 読みリスト，音韻表現リスト，音韻表現反転リスト，\n",
        "        書記表現リスト，書記表現反転リスト，モーラ表現リスト，モーラ表現反転リスト の 7 つのリストを得る\"\"\"\n",
        "\n",
        "        # 単語の表層形を，読みに変換して `_yomi` に格納\n",
        "        # ntt_orth2hira という命名はおかしかったから修正 2022_0309\n",
        "        if orth_wrd in self.ntt_orth2hira:\n",
        "            _yomi = self.ntt_orth2hira[orth_wrd]\n",
        "        else:\n",
        "            _yomi = jaconv.kata2hira(self.yomi(orth_wrd).strip())\n",
        "\n",
        "        # `_yomi` を julius 表記に変換して `_phon` に代入\n",
        "        _phon = self.hira2julius(_yomi)# .split(' ')\n",
        "\n",
        "        # 直上の `_phon` の逆転を作成して `_phone_r` に代入\n",
        "        _phon_r = [_p_id for _p_id in _phon[::-1]]\n",
        "\n",
        "        # 書記素をリストに変換\n",
        "        _orth = [c for c in orth_wrd]\n",
        "\n",
        "        # 直上の `_orth` の逆転を作成して `_orth_r` に代入\n",
        "        _orth_r = [c for c in _orth[::-1]]\n",
        "\n",
        "        #_mora = self.moraWakachi(jaconv.hira2kata(_yomi))\n",
        "        _mora = self.moraWakachi(_yomi)\n",
        "        for _m in _mora:\n",
        "            if not _m in self.mora_vocab:\n",
        "                self.mora_vocab.append(_m)\n",
        "            for _j in self.hira2julius(_m):\n",
        "                if not _j in self.mora_p:\n",
        "                    self.mora_p[_j] = 1\n",
        "                else:\n",
        "                    self.mora_p[_j] += 1\n",
        "        _mora_r = [_m for _m in _mora[::-1]]\n",
        "        return _yomi, _phon, _phon_r, _orth, _orth_r, _mora, _mora_r\n",
        "\n",
        "\n",
        "    def hira2julius(self, text:str)->str:\n",
        "        \"\"\"`jaconv.hiragana2julius()` では未対応の表記を扱う\"\"\"\n",
        "        text = text.replace('ゔぁ', ' b a')\n",
        "        text = text.replace('ゔぃ', ' b i')\n",
        "        text = text.replace('ゔぇ', ' b e')\n",
        "        text = text.replace('ゔぉ', ' b o')\n",
        "        text = text.replace('ゔゅ', ' by u')\n",
        "\n",
        "        #text = text.replace('ぅ゛', ' b u')\n",
        "        text = jaconv.hiragana2julius(text).split()\n",
        "        return text\n",
        "\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return len(self.train_data)\n",
        "\n",
        "    \n",
        "    def __call__(self, x:int)->dict:\n",
        "        return self.train_data[x]\n",
        "\n",
        "    \n",
        "    def __getitem__(self, x:int)->dict:\n",
        "        return self.train_data[x]\n",
        "\n",
        "    \n",
        "    def set_train_vocab(self):\n",
        "    #def set_train_vocab_minus_test_vocab(self):\n",
        "        \"\"\"JISX2008-1990 コードから記号とみなしうるコードを集めて ja_symbols とする\n",
        "        記号だけから構成されている word2vec の項目は排除するため\n",
        "        \"\"\"\n",
        "        self.ja_symbols = '、。，．・：；？！゛゜´\\' #+ \\'｀¨＾‾＿ヽヾゝゞ〃仝々〆〇ー—‐／＼〜‖｜…‥‘’“”（）〔〕［］｛｝〈〉《》「」『』【】＋−±×÷＝≠＜＞≦≧∞∴♂♀°′″℃¥＄¢£％＃＆＊＠§☆★○●◎◇◆□■△▲▽▼※〒→←↑↓〓∈∋⊆⊇⊂⊃∪∩∧∨¬⇒⇔∀∃∠⊥⌒∂∇≡≒≪≫√∽∝∵∫∬Å‰♯♭♪†‡¶◯#ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "        #self.ja_symbols_normalized = jaconv.normalize(self.ja_symbols)\n",
        "\n",
        "        print(f'# 訓練に用いる単語の選定 {self.traindata_size} 語')\n",
        "        vocab = []; i=0\n",
        "        while i<len(self.ntt_freq):\n",
        "            word = self.ntt_freq[i]\n",
        "            if word == '\\u3000': # NTT 日本語の語彙特性で，これだけ変なので特別扱い\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # 良い回避策が見つからないので，以下の行の変換だけ特別扱いしている\n",
        "            word = jaconv.normalize(word).replace('・','').replace('ヴ','ブ')\n",
        "\n",
        "            if (not word in self.ja_symbols) and (not word.isascii()): # and (word in self.w2v):\n",
        "                \n",
        "                if not word in vocab:\n",
        "                    vocab.append(word)\n",
        "                    if len(vocab) >= self.traindata_size:\n",
        "                        return vocab\n",
        "            i += 1\n",
        "        return vocab\n",
        "\n",
        "\n",
        "    def make_ntt_freq_data(self,\n",
        "                           ps71_fname:str=None):\n",
        "\n",
        "        print('# NTT日本語語彙特性 (天野，近藤; 1999, 三省堂)より頻度情報を取得')\n",
        "\n",
        "        if ps71_fname == None:\n",
        "            #データファイルの保存してあるディレクトリの指定\n",
        "            ntt_dir = 'ccap'\n",
        "            psy71_fname = 'psylex71utf8.txt'  # ファイル名\n",
        "            psy71_fname = 'psylex71utf8.txt.gz'  # ファイル名\n",
        "            #with gzip.open(os.path.join(ntt_dir,psy71_fname), 'r') as f:\n",
        "            with gzip.open(os.path.join(ntt_dir,psy71_fname), 'rt', encoding='utf-8') as f:\n",
        "                ntt71raw = f.readlines()\n",
        "        else:\n",
        "            with open(ps71_fname, 'r') as f:\n",
        "                ntt71raw = f.readlines()\n",
        "\n",
        "        tmp = [line.split(' ')[:6] for line in ntt71raw]\n",
        "        tmp2 = [[int(line[0]),line[2],line[4],int(line[5]), line[3]] for line in tmp]\n",
        "        #単語ID(0), 単語，品詞，頻度 だけ取り出す\n",
        "\n",
        "        ntt_freq = {x[0]-1:{'単語':jaconv.normalize(x[1]),\n",
        "                            '品詞':x[2],\n",
        "                            '頻度':x[3],\n",
        "                            'よみ':jaconv.kata2hira(jaconv.normalize(x[4]))\n",
        "                            } for x in tmp2}\n",
        "        #ntt_freq = {x[0]-1:{'単語':x[1],'品詞':x[2],'頻度':x[3], 'よみ':x[4]} for x in tmp2}\n",
        "        ntt_orth2hira = {ntt_freq[x]['単語']:ntt_freq[x]['よみ'] for x in ntt_freq}\n",
        "        #print(f'#登録総単語数: {len(ntt_freq)}')\n",
        "\n",
        "        Freq = np.zeros((len(ntt_freq)), dtype=np.uint)  #ソートに使用する numpy 配列\n",
        "        for i, x in enumerate(ntt_freq):\n",
        "            Freq[i] = ntt_freq[i]['頻度']\n",
        "\n",
        "        Freq_sorted = np.argsort(Freq)[::-1]  #頻度降順に並べ替え\n",
        "\n",
        "        # self.ntt_freq には頻度順に単語が並んでいる\n",
        "        return [ntt_freq[x]['単語']for x in Freq_sorted], ntt_orth2hira\n",
        "\n",
        "_vocab = VOCAB(\n",
        "    traindata_size=params['traindata_size'],     \n",
        "    w2v=None, \n",
        "    yomi=yomi,\n",
        "    stop_list=fushimi1999_list) \n",
        "\n",
        "train_wordlist = [v['orig'] for k, v in _vocab.train_data.items()]\n",
        "\n",
        "top_n = 300\n",
        "print(f'語彙先頭の項目 {top_n} を印字')\n",
        "for i, wrd in enumerate(train_wordlist[:top_n]):\n",
        "    _end = \" \" if (i+1) % 10 != 0 else \"\\n\"\n",
        "    print((i+1, wrd), end=_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "80742a4a-dd62-4f9f-b1ac-5283589983de",
      "metadata": {
        "id": "80742a4a-dd62-4f9f-b1ac-5283589983de"
      },
      "outputs": [],
      "source": [
        "class Train_dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data:VOCAB=None,\n",
        "                 source_vocab:list=None,\n",
        "                 target_vocab:list=None,\n",
        "                 source_ids:str=None,\n",
        "                 target_ids:str=None,\n",
        "                ):\n",
        "\n",
        "        if data == None:\n",
        "            self.data = VOCAB()\n",
        "        else:\n",
        "            self.data = data\n",
        "        self.order = {i:self.data[x] for i, x in enumerate(self.data)}\n",
        "\n",
        "        self.source_ids = source_ids\n",
        "        self.target_ids = target_ids\n",
        "        self.source_vocab = source_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, x:int):\n",
        "        return self.order[x][self.source_ids] + [self.source_vocab.index('<EOW>')], self.order[x][self.target_ids] + [self.target_vocab.index('<EOW>')]\n",
        "\n",
        "    def convert_source_ids_to_tokens(self, ids:list):\n",
        "        return [self.source_vocab[idx] for idx in ids]\n",
        "\n",
        "    def convert_target_ids_to_tokens(self, ids:list):\n",
        "        return [self.target_vocab[idx] for idx in ids]\n",
        "\n",
        "\n",
        "class Val_dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"同じく検証データセットの定義\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                data:dict=None,\n",
        "                source_vocab:list=None,\n",
        "                target_vocab:list=None,\n",
        "                source_ids:str=None,\n",
        "                target_ids:str=None,\n",
        "                ):\n",
        "\n",
        "        if 'pdata' in str(data.keys()):\n",
        "            self.data = data['pdata']\n",
        "        else:\n",
        "            self.data = data\n",
        "\n",
        "        self.order = {i:self.data[x] for i, x in enumerate(self.data)}\n",
        "\n",
        "        self.target_ids = target_ids\n",
        "        self.source_ids = source_ids\n",
        "\n",
        "        self.source_vocab = source_vocab if source_vocab != None else VOCAB().mora_p_vocab\n",
        "        self.target_vocab = target_vocab if target_vocab != None else VOCAB().mora_p_vocab\n",
        "\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, x:int):\n",
        "        return self.order[x][self.source_ids] + [self.source_vocab.index('<EOW>')], self.order[x][self.target_ids] + [self.target_vocab.index('<EOW>')]\n",
        "\n",
        "    def convert_source_ids_to_tokens(self, ids:list):\n",
        "        return [self.source_vocab[idx] for idx in ids]\n",
        "\n",
        "    def convert_target_ids_to_tokens(self, ids:list):\n",
        "        return [self.target_vocab[idx] for idx in ids]\n",
        "\n",
        "def make_X_vals(_dataset=None,\n",
        "                source_vocab=None,\n",
        "                target_vocab=None,\n",
        "                source_ids=None,\n",
        "                target_ids=None,\n",
        "                ):\n",
        "\n",
        "    if _dataset == None:\n",
        "        print('_dataset must be set')\n",
        "        sys.exit()\n",
        "\n",
        "    sala_r29val = Val_dataset(\n",
        "        data=_dataset['sala_r29'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    sala_r30val = Val_dataset(\n",
        "        data=_dataset['sala_r30'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    sala_r31val = Val_dataset(\n",
        "        data=_dataset['sala_r31'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    tlpa2val    = Val_dataset(\n",
        "        data=_dataset['tlpa2'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    tlpa3val    = Val_dataset(\n",
        "        data=_dataset['tlpa3'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    tlpa4val    = Val_dataset(\n",
        "        data=_dataset['tlpa4'],\n",
        "        source_vocab=source_vocab,\n",
        "        target_vocab=target_vocab,\n",
        "        source_ids=source_ids,\n",
        "        target_ids=target_ids)\n",
        "\n",
        "    X_vals = { \n",
        "        'sala_r29val': sala_r29val,\n",
        "        'sala_r30val': sala_r30val,\n",
        "        'sala_r31val': sala_r31val,\n",
        "        'tlpa2val': tlpa2val, \n",
        "        'tlpa3val': tlpa3val, \n",
        "        'tlpa4val': tlpa4val}\n",
        "\n",
        "    return X_vals\n",
        "\n",
        "\n",
        "def make_vocab_dataset(_dict:dict, vocab:VOCAB=None)->dict:\n",
        "    \"\"\"上記 VOCAB を用いた下請け関数\n",
        "    読み，音韻，モーラなどの情報を作成してデータセットといしての体裁を整える\"\"\"\n",
        "    \n",
        "    _data = {}\n",
        "    if vocab == None:\n",
        "        vocab = VOCAB()\n",
        "    x = [x[0] for x in _dict.values()]\n",
        "    for _x in x:\n",
        "        i = len(_data)  # 連番の番号を得る\n",
        "        orth = vocab.ntt_orth2hira[_x] if _x in vocab.ntt_orth2hira else _x\n",
        "        _yomi, _phon, _phon_r, _orth, _orth_r, _mora, _mora_r = vocab.get7lists_from_orth(orth)\n",
        "        phon_ids, phon_ids_r, orth_ids, orth_ids_r, mora_ids, mora_ids_r = vocab.get6ids(_phon, _orth, _yomi)\n",
        "        _yomi, _mora1, _mora1_r, _mora, _mora_ids, _mora_p, _mora_p_r, _mora_p_ids, _mora_p_ids_r, _juls = vocab.yomi2mora_transform(_yomi)\n",
        "        _data[i] = {'orig': orth, \n",
        "                    'yomi': _yomi, \n",
        "                    'orth':_orth, 'orth_ids': orth_ids, 'orth_r': _orth_r, 'orth_ids_r': orth_ids_r,\n",
        "                    'phon':_phon, 'phon_ids': phon_ids, 'phon_r': _phon_r, 'phon_ids_r': phon_ids_r,\n",
        "                    'mora': _mora1, 'mora_r': _mora1_r, 'mora_ids': _mora_ids, 'mora_p': _mora_p,\n",
        "                    'mora_p_r': _mora_p_r, 'mora_p_ids': _mora_p_ids, 'mora_p_ids_r': _mora_p_ids_r, }\n",
        "    return _data    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e3240c3-173b-40aa-ab44-03f94ed6eafd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e3240c3-173b-40aa-ab44-03f94ed6eafd",
        "outputId": "710791fe-8096-4099-c45f-f4fd43b4d9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_vocab.max_length: 34\n",
            "source:phon ['<EOW>', '<PAD>', '<SOW>', '<UNK>', 'N', 'a', 'a:', 'b', 'by', 'ch', 'd', 'dy', 'e', 'e:', 'f', 'g', 'gy', 'h', 'hy', 'i', 'i:', 'i::', 'j', 'k', 'ky', 'm', 'my', 'n', 'ny', 'o', 'o:', 'o::', 'p', 'py', 'q', 'r', 'ry', 's', 'sh', 't', 'ts', 'u', 'u:', 'w', 'y', 'z']\n",
            "target:phon ['<EOW>', '<PAD>', '<SOW>', '<UNK>', 'N', 'a', 'a:', 'b', 'by', 'ch', 'd', 'dy', 'e', 'e:', 'f', 'g', 'gy', 'h', 'hy', 'i', 'i:', 'i::', 'j', 'k', 'ky', 'm', 'my', 'n', 'ny', 'o', 'o:', 'o::', 'p', 'py', 'q', 'r', 'ry', 's', 'sh', 't', 'ts', 'u', 'u:', 'w', 'y', 'z']\n"
          ]
        }
      ],
      "source": [
        "# _max_len はアテンション機構のデコーダで必要になるため，全条件で最長の長さを指定する必要がある\n",
        "_max_len = _vocab.max_orth_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_phon_length else _vocab.max_phon_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_length else _vocab.max_mora_length\n",
        "_max_len = _max_len if _max_len > _vocab.max_mora_p_length else _vocab.max_mora_p_length\n",
        "_vocab.max_length = _max_len + 1\n",
        "print(colored(f'_vocab.max_length: {_vocab.max_length}', 'blue', attrs=['bold']))\n",
        "\n",
        "# ソース，すなわち encoder 側の，項目番号，項目 ID，decoder 側の項目，項目 ID を設定\n",
        "source_vocab, source_ids, target_vocab, target_ids = get_soure_and_target_from_params(\n",
        "    #params=None,\n",
        "    _vocab=_vocab,\n",
        "    source=source,\n",
        "    target=target,\n",
        "    is_print=False)\n",
        "    #is_print=True)\n",
        "\n",
        "print(colored(f'source:{source}','blue', attrs=['bold']), f'{sorted(source_vocab)}')\n",
        "print(colored(f'target:{target}','cyan', attrs=['bold']), f'{sorted(target_vocab)}')\n",
        "#print(colored(f'source_ids:{source_ids}','blue', attrs=['bold']), f'{sorted(source_ids)}')\n",
        "#print(colored(f'target_ids:{target_ids}','cyan', attrs=['bold']), f'{sorted(target_ids)}')\n",
        "\n",
        "\n",
        "# 検証データとして，TLPA と SALA のデータを用いる\n",
        "tlpa1, tlpa2, tlpa3, tlpa4, sala_r29, sala_r30, sala_r31 = lam.read_json_tlpa1234_sala_r29_30_31(\n",
        "    json_fname='lam/2022_0508SALA_TLPA.json')\n",
        "\n",
        "_dataset = {}\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']\n",
        "for data in _data_names:\n",
        "    _dataset[data] = {'rawdata':eval(data),\n",
        "                      'pdata': make_vocab_dataset(eval(data),vocab=_vocab)}\n",
        "\n",
        "# 以下は後から付け足したので，コードが汚くなっている。\n",
        "# 時間ができたらコードの整理をすること\n",
        "X_vals = make_X_vals(_dataset=_dataset,\n",
        "                         source_vocab=source_vocab,\n",
        "                         target_vocab=target_vocab,\n",
        "                         source_ids=source_ids,\n",
        "                         target_ids=target_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "07b46391-3fdd-4395-b482-a656871fcabb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07b46391-3fdd-4395-b482-a656871fcabb",
        "outputId": "23252a12-778c-4dc9-b70e-f12936cdeb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['屏風', 'ふしぎ', '役柄', 'はんらん', 'しゅん', 'アジア開発銀行', '白保', '起債', '掘り出す', '熊野', '三角形', '各所', '必勝', '法的地位', '弘子', 'カモ', '小物', '驚異的だ', '軽量化', '全銀協', '百姓', '秘書課', 'たいして', '社共', '鹿川', '熟年', '古文書', '残せる', '青果', '日本原子力研究所', '歌える', '贈呈', '時局', '八幡', '雨期', '計器', 'てはならぬ', '和光', '追い求める', '抵当権', '物心', 'げだ', '突き出す', '石川島播磨重工業', '公報', 'サムファン', 'まえる', '神道', 'モンテネグロ', '入り交じる', '鶴男', '文化財保護', '核抑止', '電信', 'カントリークラブ', '三世', '八戸', 'ケガ', '順一', '私物', '植田', 'つのらす', '連邦捜査局', '性教育', '初等', '総動員', 'ひと足', 'じん臓', 'ペーパー', '司法修習生', '懲戒免職', 'ビッグスリー', '大観', '広田', '延長戦', '漏えい', '扇動', '信頼醸成措置', 'バカンス', '拡大解釈', '生い立ち', '明け方', '制憲', '初心', '明白', '三兆', '投資銀行', '凝固', '逝去', '二番手', '蚊', 'ブット', '出先', '花形', '寝かせる', '秀明', '一万四千', '取りやめ', '末尾', '媒介']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'orig': '租税',\n",
              " 'yomi': 'そぜい',\n",
              " 'orth': ['租', '税'],\n",
              " 'orth_ids': [2226, 599],\n",
              " 'orth_r': ['税', '租'],\n",
              " 'orth_ids_r': [599, 2226],\n",
              " 'phon': ['s', 'o', 'z', 'e', 'i'],\n",
              " 'phon_ids': [39, 12, 45, 7, 9],\n",
              " 'phon_r': ['i', 'e', 'z', 'o', 's'],\n",
              " 'phon_ids_r': [9, 7, 45, 12, 39],\n",
              " 'mora': ['そ', 'ぜ', 'い'],\n",
              " 'mora_r': ['い', 'ぜ', 'そ'],\n",
              " 'mora_ids': [51, 50, 7],\n",
              " 'mora_p': ['s', 'o', 'z', 'e', 'i'],\n",
              " 'mora_p_r': ['i', 'z', 'e', 's', 'o'],\n",
              " 'mora_p_ids': [39, 12, 45, 7, 9],\n",
              " 'mora_p_ids_r': [9, 45, 7, 39, 12]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#print(train_wordlist)\n",
        "word = '神経心理学'\n",
        "#print(_vocab.orth2phon(word))\n",
        "#print(_vocab.orth2mora(word))\n",
        "#print(_vocab.orth2yomi(word))\n",
        "\n",
        "print(_vocab.train_vocab[-100:])\n",
        "_vocab.train_data[_vocab.train_vocab.index('租税')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547224b1-ab27-45f4-a954-6200e8384205",
      "metadata": {
        "id": "547224b1-ab27-45f4-a954-6200e8384205"
      },
      "outputs": [],
      "source": [
        "_vocab2 = VOCAB(traindata_size=params['traindata_size'],     \n",
        "               w2v=None, \n",
        "               yomi=yomi,\n",
        "               #stop_list=fushimi1999_list\n",
        "              ) \n",
        "\n",
        "for i, wrd in enumerate(fushimi1999_list):\n",
        "    if wrd in _vocab.train_vocab:\n",
        "        print(wrd)\n",
        "    if wrd in _vocab2.train_vocab:\n",
        "        color = 'red'\n",
        "    else:\n",
        "        color = 'blue'\n",
        "        \n",
        "    _end = '\\n' if (i+1) % 10 == 0 else ' '\n",
        "    print(colored((f'{i+1:3d}',wrd), color=color, attrs=['bold']), end=_end)\n",
        "\n",
        "print('赤字は訓練データに存在，青字は存在せず')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f963b1f3-fa00-437a-bb94-43fe07f919a5",
      "metadata": {
        "id": "f963b1f3-fa00-437a-bb94-43fe07f919a5"
      },
      "outputs": [],
      "source": [
        "for i, wrd in enumerate(fushimi1999_list):\n",
        "    _end = \"\\n\" if (i+1) % 10 == 0 else ' '\n",
        "    print(f'{i+1:3d}: {wrd}', end=\" \") #\n",
        "    for ch in wrd:\n",
        "        print(f'({ch}:{_vocab.orth_vocab.index(ch):4d})', end=\" \")\n",
        "    if (i+1) % 5 == 0:\n",
        "        print()\n",
        "    else:\n",
        "        print(' ', end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268bbc63-3443-45a6-9a54-5b467d366c1c",
      "metadata": {
        "id": "268bbc63-3443-45a6-9a54-5b467d366c1c"
      },
      "source": [
        "### 1.3.1 任意の単語 orthography を変換するための関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "163ea3bd-3b3b-4ccc-9326-e5d14c45e346",
      "metadata": {
        "id": "163ea3bd-3b3b-4ccc-9326-e5d14c45e346"
      },
      "outputs": [],
      "source": [
        "import jaconv\n",
        "\n",
        "verbose=True\n",
        "\n",
        "def _get_ids_from_orth(orth_wrd:str='てれび',\n",
        "                       _vocab=_vocab):\n",
        "    \n",
        "    digit_alpha = '０１２３４５６７８９ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "    hira = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわゐゑをん'\n",
        "    kata = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヰヱヲン'\n",
        "    onechars = digit_alpha+hira+kata\n",
        "\n",
        "    if orth_wrd in onechars:\n",
        "        _yomi = yomi(orth_wrd).strip()\n",
        "        hira = jaconv.kata2hira(_yomi)\n",
        "        phon_juli = jaconv.hiragana2julius(hira).split(' ')\n",
        "        phon_ids = phon_tkn2ids(phon_juli)\n",
        "        orth_ids = orth_tkn2ids(orth_wrd)\n",
        "        out = {'_yomi':_yomi,\n",
        "               '_phon':phon_juli,\n",
        "               'phon_ids':phon_ids,\n",
        "               'orth_ids':orth_ids}\n",
        "        return out\n",
        "\n",
        "    _yomi, _phon, _phon_r, _orth, _orth_r, _mora, _mora_r = _vocab.get7lists_from_orth(orth_wrd=orth_wrd)\n",
        "    phon_ids, phon_ids_r, orth_ids, orth_ids_r, mora_ids, mora_ids_r = _vocab.get6ids(yomi=_yomi, \n",
        "                                                                                      _phon=_phon, \n",
        "                                                                                      _orth=_orth)\n",
        "    \n",
        "    return {'_yomi':_yomi,\n",
        "            '_phon':_phon,\n",
        "            '_phon_r':_phon_r,\n",
        "            '_orth':_orth,\n",
        "            '_orth_r':_orth_r,\n",
        "            '_mora':_mora,\n",
        "            '_mora_r':_mora_r,\n",
        "            'phon_ids':phon_ids,\n",
        "            'phon_ids_r':phon_ids_r,\n",
        "            'orth_ids':orth_ids,\n",
        "            'orth_ids_r':orth_ids_r,\n",
        "            'mora_ids':mora_ids,\n",
        "            'mora_ids_r':mora_ids_r,\n",
        "           }\n",
        "\n",
        "print(_get_ids_from_orth()) if verbose else None\n",
        "\n",
        "\n",
        "if verbose:\n",
        "    _ids = [111, 298]\n",
        "    print(_vocab.orth_ids2tkn(_ids))\n",
        "    print(_vocab.orth_tkn2ids(_vocab.orth_ids2tkn(_ids)))\n",
        "\n",
        "    print(_vocab.orth_tkn2ids('新しい'))\n",
        "    print(_vocab.orth_tkn2ids('神経心理学'))\n",
        "    print(_vocab.orth_ids2tkn(_vocab.orth_tkn2ids('神経心理学')))\n",
        "    print(_vocab.mora_p_ids2tkn([17,19,11,4,32,17]))\n",
        "    print(_vocab.mora_p_tkn2ids(_vocab.mora_p_ids2tkn([17,19,11,4,32,17])))\n",
        "    print(_vocab.mora_ids2tkn([37,139,31,7]))\n",
        "    print(_vocab.mora_tkn2ids(_vocab.mora_ids2tkn([37,139,31,7])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c4db7e5-2eb2-4b42-8c1f-44062edd94e5",
      "metadata": {
        "id": "2c4db7e5-2eb2-4b42-8c1f-44062edd94e5"
      },
      "source": [
        "### 1.3.2 SALA and TLPA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5ddba0-87b3-497d-9d55-b2220e5ce89d",
      "metadata": {
        "id": "ed5ddba0-87b3-497d-9d55-b2220e5ce89d"
      },
      "outputs": [],
      "source": [
        "# 検証データとして，TLPA と SALA のデータを用いる\n",
        "tlpa1, tlpa2, tlpa3, tlpa4, sala_r29, sala_r30, sala_r31 = lam.read_json_tlpa1234_sala_r29_30_31(\n",
        "    json_fname='lam/2022_0508SALA_TLPA.json')\n",
        "\n",
        "_dataset = {}\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']\n",
        "for data in _data_names:\n",
        "    _dataset[data] = {'rawdata':eval(data),\n",
        "                      'pdata': make_vocab_dataset(eval(data), vocab=_vocab)}\n",
        "\n",
        "# 以下は後から付け足したので，コードが汚くなっている。\n",
        "# 時間ができたらコードの整理をすること\n",
        "X_vals = make_X_vals(_dataset=_dataset,\n",
        "                         source_vocab=source_vocab,\n",
        "                         target_vocab=target_vocab,\n",
        "                         source_ids=source_ids,\n",
        "                         target_ids=target_ids)\n",
        "\n",
        "_data_names = ['tlpa2', 'tlpa3', 'tlpa4', 'sala_r29', 'sala_r30', 'sala_r31']    \n",
        "for data in _data_names:\n",
        "    print(colored(data, 'blue', attrs=['bold']), eval(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779fdadf-f21e-4eb7-bd60-d884e2c0414c",
      "metadata": {
        "id": "779fdadf-f21e-4eb7-bd60-d884e2c0414c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "verbose = True\n",
        "_src, _tgt = source+'_ids', target+'_ids'\n",
        "\n",
        "if verbose:\n",
        "    for i, w in enumerate(fushimi1999_list):\n",
        "        ids = _vocab.orth_tkn2ids(w)\n",
        "        tnk = _vocab.orth_ids2tkn(ids)\n",
        "        if i >= 0:\n",
        "            o = _get_ids_from_orth(orth_wrd=w)\n",
        "            print(colored((f\"{i:3d}\",w),'blue',attrs=['bold']), \n",
        "                  f\"_src:{o[_src]}\", \n",
        "                  f\"_tgt:{o[_tgt]}\")\n",
        "        #os.system(f\"say {w} --voice kyoko\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90ef0ddf-344f-4930-ad08-9234e37fe444",
      "metadata": {
        "id": "90ef0ddf-344f-4930-ad08-9234e37fe444"
      },
      "source": [
        "### 1.3.3 一文字データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b697c72-a2b1-4632-a72b-e20e5ed4cc40",
      "metadata": {
        "id": "5b697c72-a2b1-4632-a72b-e20e5ed4cc40"
      },
      "outputs": [],
      "source": [
        "class Onechar_dataset(torch.utils.data.Dataset): #_vocab.train_data):\n",
        "    def __init__(self,\n",
        "                 source:str='orth',\n",
        "                 target:str='mora_p',\n",
        "                 source_vocab=source_vocab,\n",
        "                 target_vocab=target_vocab,\n",
        "                ):\n",
        "        super().__init__()\n",
        "\n",
        "        _src = source\n",
        "        _tgt = target\n",
        "\n",
        "        _src = 'mora' if _src == 'mora_p' else _src\n",
        "        _tgt = 'mora' if _tgt == 'mora_p' else _tgt\n",
        "        _src, _tgt = _src+'_ids', _tgt+'_ids'\n",
        "        \n",
        "        digit_alpha = '０１２３４５６７８９ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ' # ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "        hira = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわゐゑをん'\n",
        "        kata = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヰヱヲン'\n",
        "        onechars = digit_alpha+hira #+kata\n",
        "        \n",
        "        data_dict = {}\n",
        "        for i, orth in enumerate(onechars):\n",
        "            _yomi = yomi(orth).strip()\n",
        "            hira = jaconv.kata2hira(_yomi)\n",
        "            phon_juli = jaconv.hiragana2julius(hira).split(' ')\n",
        "            phon_ids = _vocab.phon_tkn2ids(phon_juli)\n",
        "            orth_ids = _vocab.orth_tkn2ids(orth)\n",
        "            \n",
        "            _data = {'_yomi':_yomi,\n",
        "                     'phon':phon_juli,\n",
        "                     'phon_ids':phon_ids,\n",
        "                     'orth':orth,\n",
        "                     'orth_ids':orth_ids}\n",
        "            __src, __tgt = _data[_src], _data[_tgt]\n",
        "            data_dict[i] = {'yomi':_yomi,\n",
        "                            'orth':orth,\n",
        "                            'src':__src,\n",
        "                            'tgt':__tgt,\n",
        "                            '_phon':phon_juli,\n",
        "                            'phon_ids':phon_ids,\n",
        "                            'orth_ids':orth_ids}\n",
        "\n",
        "        self.source_vocab = source_vocab if source_vocab != None else VOCAB().mora_p_vocab\n",
        "        self.target_vocab = target_vocab if target_vocab != None else VOCAB().mora_p_vocab\n",
        "            \n",
        "            \n",
        "        self.data_dict = data_dict\n",
        "\n",
        "    def __len__(self)->int:\n",
        "        return len(self.data_dict)\n",
        "    \n",
        "    def __getitem__(self,\n",
        "                    x:int):\n",
        "        _data = self.data_dict[x]\n",
        "        return _data['src']+[self.source_vocab.index('<EOW>')], _data['tgt']+[self.target_vocab.index('<EOW>')]\n",
        "    \n",
        "#    def __getitem__(self, x:int):\n",
        "#        return self.order[x][self.source_ids] + [self.source_vocab.index('<EOW>')], self.order[x][self.target_ids] + [self.target_vocab.index('<EOW>')]\n",
        "    \n",
        "        \n",
        "onechar_dataset = Onechar_dataset(source=source, target=target)\n",
        "# print(onechar_dataset.__len__())\n",
        "# print(onechar_dataset.__getitem__(0))\n",
        "\n",
        "for i in range(onechar_dataset.__len__()):\n",
        "    inp, tch = onechar_dataset.__getitem__(i)\n",
        "    print(f'{i:3d}', \n",
        "          f'orth:{onechar_dataset.data_dict[i][\"orth\"]}', \n",
        "          f'inp:{inp}, tch:{tch}', \n",
        "          f\"{colored(onechar_dataset.data_dict[i]['yomi'],'blue',attrs=['bold'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20d6978d-c5d0-4940-ab8a-201fb26eaba6",
      "metadata": {
        "id": "20d6978d-c5d0-4940-ab8a-201fb26eaba6"
      },
      "source": [
        "# 2. モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af63e834-7d77-46c5-aca7-6d449a016021",
      "metadata": {
        "id": "af63e834-7d77-46c5-aca7-6d449a016021"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 自作ライブラリ LAM の読み込み\n",
        "#import lam \n",
        "#from lam import EncoderRNN\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"RNNによる符号化器\"\"\"\n",
        "    def __init__(self,\n",
        "            n_inp:int=0,\n",
        "            n_hid:int=0):\n",
        "            #device=device):\n",
        "        super().__init__()\n",
        "        self.n_hid = n_hid if n_hid != 0 else 8\n",
        "        self.n_inp = n_inp if n_inp != 0 else 8\n",
        "\n",
        "        self.embedding = nn.Embedding(n_inp, n_hid)\n",
        "        self.gru = nn.GRU(n_hid, n_hid)\n",
        "\n",
        "    def forward(self,\n",
        "                inp:int=0,\n",
        "                hid:int=0,\n",
        "                device=device\n",
        "               ):\n",
        "        embedded = self.embedding(inp).view(1, 1, -1)\n",
        "        out = embedded\n",
        "        out, hid = self.gru(out, hid)\n",
        "        return out, hid\n",
        "\n",
        "    def initHidden(self)->torch.Tensor:\n",
        "        return torch.zeros(1, 1, self.n_hid, device=device)\n",
        "\n",
        "\n",
        "#from lam import AttnDecoderRNN\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    \"\"\"注意付き復号化器の定義\"\"\"\n",
        "    def __init__(self, \n",
        "                 n_hid:int=0, \n",
        "                 n_out:int=0, \n",
        "                 dropout_p:float=0.0, \n",
        "                 max_length:int=0):\n",
        "        super().__init__()\n",
        "        self.n_hid = n_hid\n",
        "        self.n_out = n_out\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.n_out, self.n_hid)\n",
        "        self.attn = nn.Linear(self.n_hid * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.n_hid * 2, self.n_hid)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.n_hid, self.n_hid)\n",
        "        self.out = nn.Linear(self.n_hid, self.n_out)\n",
        "\n",
        "    def forward(self, \n",
        "                inp:int=0, \n",
        "                hid:int=0, \n",
        "                encoder_outputs:torch.Tensor=None, \n",
        "                device=device):\n",
        "        embedded = self.embedding(inp).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hid[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        out = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        out = self.attn_combine(out).unsqueeze(0)\n",
        "\n",
        "        out = F.relu(out)\n",
        "        out, hid = self.gru(out, hid)\n",
        "\n",
        "        out = F.log_softmax(self.out(out[0]), dim=1)\n",
        "        return out, hid, attn_weights\n",
        "\n",
        "    def initHidden(self)->torch.Tensor:\n",
        "        return torch.zeros(1, 1, self.n_hid, device=device)\n",
        "\n",
        "    \n",
        "def convert_ids2tensor(\n",
        "    sentence_ids:list, \n",
        "    device:torch.device=torch.device(\"cuda:0\" if torch.cuda.is_available () else \"cpu\")):\n",
        "    \n",
        "    \"\"\"数値 ID リストをテンソルに変換\n",
        "    例えば，[0,1,2] -> tensor([[0],[1],[2]])\n",
        "    \"\"\"\n",
        "    return torch.tensor(sentence_ids, dtype=torch.long, device=device).view(-1, 1)\n",
        "    \n",
        "    \n",
        "def evaluate(encoder:nn.Module,\n",
        "             decoder:nn.Module,\n",
        "             input_ids,\n",
        "             max_length,\n",
        "             source_vocab,\n",
        "             target_vocab,\n",
        "             source_ids,\n",
        "             target_ids,\n",
        "            )->(list,torch.LongTensor):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = convert_ids2tensor(input_ids)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.n_hid, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[source_vocab.index('<SOW>')]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words, decoded_ids = [], []  # decoded_ids を追加\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs, device=device)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            decoded_ids.append(int(topi.squeeze().detach())) # decoded_ids に追加\n",
        "            if topi.item() == target_vocab.index('<EOW>'):\n",
        "                decoded_words.append('<EOW>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(target_vocab[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoded_ids, decoder_attentions[:di + 1]  # decoded_ids を返すように変更\n",
        "        #return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "    \n",
        "#from lam import calc_accuracy\n",
        "def calc_accuracy(\n",
        "    _dataset,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    max_length=None,\n",
        "    source_vocab=None,\n",
        "    target_vocab=None,\n",
        "    source_ids=None,\n",
        "    target_ids=None,\n",
        "    isPrint=False):\n",
        "\n",
        "    ok_count = 0\n",
        "    for i in range(_dataset.__len__()):\n",
        "        _input_ids, _target_ids = _dataset.__getitem__(i)\n",
        "        _output_words, _output_ids, _attentions = evaluate(\n",
        "            encoder=encoder,\n",
        "            decoder=decoder,\n",
        "            input_ids=_input_ids,\n",
        "            max_length=max_length,\n",
        "            source_vocab=source_vocab,\n",
        "            target_vocab=target_vocab,\n",
        "            source_ids=source_ids,\n",
        "            target_ids=target_ids,\n",
        "        )\n",
        "        ok_count += 1 if _target_ids == _output_ids else 0\n",
        "        if (_target_ids != _output_ids) and (isPrint):\n",
        "            print(i, _target_ids == _output_ids, _output_words, _input_ids, _target_ids)\n",
        "\n",
        "    return ok_count/_dataset.__len__()\n",
        "\n",
        "\n",
        "encoder = EncoderRNN(\n",
        "    len(source_vocab), \n",
        "    params['hidden_size']).to(device)\n",
        "\n",
        "decoder = AttnDecoderRNN(\n",
        "    n_hid=params['hidden_size'], \n",
        "    n_out=len(target_vocab), \n",
        "    dropout_p=params['dropout_p'],\n",
        "    max_length=_vocab.max_length).to(device)\n",
        "    \n",
        "if (params['pretrained']) and (params['path_saved'] != False) and os.path.exists(params['path_saved']):\n",
        "    \"\"\"セーブした学習済のモデルがあれば読み込む\"\"\"\n",
        "    \n",
        "    checkpoint = torch.load(params['path_saved'])\n",
        "    encoder.load_state_dict(checkpoint['encoder'])\n",
        "    decoder.load_state_dict(checkpoint['decoder'])\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    print(colored(f\"セーブした学習済のモデル {params['path_saved']} があるので読み込みました\",\n",
        "          color='blue', attrs=['bold']))\n",
        "\n",
        "    \n",
        "# モデルの概要を印字\n",
        "print(f'encoder:{encoder}')\n",
        "print(f'decoder:{decoder}')\n",
        "        \n",
        "for test_name, val_dataset in X_vals.items():\n",
        "    acc = calc_accuracy(_dataset=val_dataset,\n",
        "                        encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=_vocab.max_length,\n",
        "                        source_vocab=source_vocab,\n",
        "                        target_vocab=target_vocab,\n",
        "                        source_ids=source_ids,\n",
        "                        target_ids=target_ids)\n",
        "    print(colored(f'{test_name} の精度:{acc:.3f}','blue', attrs=['bold']))\n",
        "\n",
        "\n",
        "# params の印刷\n",
        "print(colored(params,'blue',attrs=['bold']))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b57dfd26-c1f3-4932-8795-07c7efab84b3",
      "metadata": {
        "id": "b57dfd26-c1f3-4932-8795-07c7efab84b3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def asMinutes(s:int)->str:\n",
        "    \"\"\"時間変数を見やすいように，分と秒に変換して返す\"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{int(m):2d}分 {int(s):2d}秒'\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since:time.time,\n",
        "            percent:time.time)->str:\n",
        "    \"\"\"開始時刻 since と，現在の処理が全処理中に示す割合 percent を与えて，経過時間と残り時間を計算して表示する\"\"\"\n",
        "    now = time.time()  #現在時刻を取得\n",
        "    s = now - since    # 開始時刻から現在までの経過時間を計算\n",
        "    #s = since - now\n",
        "    es = s / (percent) # 経過時間を現在までの処理割合で割って終了予想時間を計算\n",
        "    rs = es - s        # 終了予想時刻から経過した時間を引いて残り時間を計算\n",
        "\n",
        "    return f'経過時間:{asMinutes(s)} (残り時間 {asMinutes(rs)})'\n",
        "\n",
        "\n",
        "def check_vals_performance(encoder=None, \n",
        "                           decoder=None,\n",
        "                           _dataset=None,\n",
        "                           max_length=0,\n",
        "                           source_vocab=None, \n",
        "                           target_vocab=None,\n",
        "                           source_ids=None, \n",
        "                           target_ids=None):\n",
        "\n",
        "    if _dataset == None or encoder == None or decoder == None or max_length == 0 or source_vocab == None:\n",
        "        return\n",
        "    print('検証データ:',end=\"\")\n",
        "    for _x in _dataset:\n",
        "        ok_count = 0\n",
        "        for i in range(_dataset[_x].__len__()):\n",
        "            _input_ids, _target_ids = _dataset[_x].__getitem__(i)\n",
        "            _output_words, _output_ids, _attentions = evaluate(encoder, \n",
        "                                                               decoder, \n",
        "                                                               _input_ids,\n",
        "                                                               max_length,\n",
        "                                                               source_vocab=source_vocab, \n",
        "                                                               target_vocab=target_vocab,\n",
        "                                                               source_ids=source_ids, \n",
        "                                                               target_ids=target_ids)\n",
        "            ok_count += 1 if _target_ids == _output_ids else 0\n",
        "        print(f'{_x}:{ok_count/_dataset[_x].__len__():.3f},',end=\"\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def _train(input_tensor:torch.Tensor=None, \n",
        "           target_tensor:torch.Tensor=None,\n",
        "           encoder:torch.nn.Module=None, \n",
        "           decoder:torch.nn.Module=None,\n",
        "           encoder_optimizer:torch.optim=None, \n",
        "           decoder_optimizer:torch.optim=None,\n",
        "           criterion:torch.nn.modules.loss=torch.nn.modules.loss.CrossEntropyLoss,\n",
        "           max_length:int=_vocab.max_length,\n",
        "           target_vocab:list=None,\n",
        "           teacher_forcing_ratio:float=0.,\n",
        "           device:torch.device=device)->float:\n",
        "    \n",
        "    \"\"\"inpute_tensor (torch.Tensor() に変換済の入力系列) を 1 つ受け取って，\n",
        "    encoder と decoder の訓練を行う\n",
        "    \"\"\"\n",
        "    \n",
        "    encoder_hidden = encoder.initHidden() # 符号化器の中間層を初期化\n",
        "    encoder_optimizer.zero_grad()         # 符号化器の最適化関数の初期化\n",
        "    decoder_optimizer.zero_grad()         # 復号化器の最適化関数の初期化\n",
        "\n",
        "    input_length = input_tensor.size(0)   # 0 次元目が系列であることを仮定\n",
        "    target_length = target_tensor.size(0)\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.n_hid, device=device)\n",
        "    \n",
        "    loss = 0.  # 損失関数値\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            inp=input_tensor[ei], \n",
        "            hid=encoder_hidden, \n",
        "            device=device)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[target_vocab.index('<SOW>')]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    ok_flag = True\n",
        "    # 教師強制をするか否かを確率的に決める\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    \n",
        "    if use_teacher_forcing: # 教師強制する場合 Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
        "                                                                        decoder_hidden, \n",
        "                                                                        encoder_outputs,\n",
        "                                                                        device=device)\n",
        "            decoder_input = target_tensor[di]      # 教師強制 する\n",
        "            \n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().numpy()[0])\n",
        "            if decoder_input.item() == target_vocab.index('<EOW>'):\n",
        "                break\n",
        "\n",
        "    else: # 教師強制しない場合 Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
        "                                                                        decoder_hidden, \n",
        "                                                                        encoder_outputs,\n",
        "                                                                        device=device)\n",
        "            topv, topi = decoder_output.topk(1)     # 教師強制しない\n",
        "            decoder_input = topi.squeeze().detach() \n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            ok_flag = (ok_flag) and (decoder_output.argmax() == target_tensor[di].detach().numpy()[0])\n",
        "            if decoder_input.item() == target_vocab.index('<EOW>'):\n",
        "                break\n",
        "\n",
        "    loss.backward()           # 誤差逆伝播\n",
        "    encoder_optimizer.step()  # encoder の学習\n",
        "    decoder_optimizer.step()  # decoder の学習\n",
        "    return loss.item() / target_length, ok_flag\n",
        "\n",
        "\n",
        "def _fit(encoder:torch.nn.Module, \n",
        "         decoder:torch.nn.Module,\n",
        "         epochs:int=1,\n",
        "         lr:float=0.0001,\n",
        "         n_sample:int=3,\n",
        "         teacher_forcing_ratio=False,\n",
        "         train_dataset:torch.utils.data.Dataset=None,\n",
        "         val_dataset:dict=None,\n",
        "         source_vocab:list=None,\n",
        "         target_vocab:list=None,\n",
        "         source_ids:str=None,\n",
        "         target_ids:list=None,\n",
        "         params:dict=None,\n",
        "         max_length:int=1,\n",
        "         device=device,\n",
        "        )->list:\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    encoder_optimizer = params['optim_func'](encoder.parameters(), lr=lr)\n",
        "    decoder_optimizer = params['optim_func'](decoder.parameters(), lr=lr)\n",
        "    criterion = params['loss_func']\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        ok_count = 0\n",
        "        \n",
        "        #エポックごとに学習順をシャッフルする\n",
        "        learning_order = np.random.permutation(train_dataset.__len__())\n",
        "        \n",
        "        for i in range(train_dataset.__len__()):\n",
        "            x = learning_order[i]   # ランダムにデータを取り出す\n",
        "            input_ids, target_ids = train_dataset.__getitem__(x)\n",
        "            input_tensor = convert_ids2tensor(input_ids)\n",
        "            target_tensor = convert_ids2tensor(target_ids)\n",
        "\n",
        "            #訓練の実施\n",
        "            loss, ok_flag = _train(input_tensor=input_tensor, \n",
        "                                   target_tensor=target_tensor,\n",
        "                                   encoder=encoder, \n",
        "                                   decoder=decoder,\n",
        "                                   encoder_optimizer=encoder_optimizer, \n",
        "                                   decoder_optimizer=decoder_optimizer,\n",
        "                                   criterion=criterion,\n",
        "                                   max_length=max_length,\n",
        "                                   target_vocab=target_vocab,\n",
        "                                   teacher_forcing_ratio=teacher_forcing_ratio,\n",
        "                                   device=device)\n",
        "            epoch_loss += loss\n",
        "            ok_count += 1 if ok_flag else 0\n",
        "\n",
        "\n",
        "        losses.append(epoch_loss/train_dataset.__len__())\n",
        "        print(colored(f'エポック:{epoch:2d} 損失:{epoch_loss/train_dataset.__len__():.2f}', 'blue', attrs=['bold']),\n",
        "              colored(f'{timeSince(start_time, (epoch+1) * train_dataset.__len__()/(epochs * train_dataset.__len__()))}',\n",
        "                      'cyan', attrs=['bold']),\n",
        "              colored(f'訓練データの精度:{ok_count/train_dataset.__len__():.3f}', 'blue', attrs=['bold']))\n",
        "\n",
        "        check_vals_performance(_dataset=val_dataset,\n",
        "                               encoder=encoder,\n",
        "                               decoder=decoder,\n",
        "                               max_length=max_length,\n",
        "                               source_vocab=source_vocab,\n",
        "                               target_vocab=target_vocab,\n",
        "                               source_ids=source_ids,\n",
        "                               target_ids=target_ids)\n",
        "        if n_sample > 0:\n",
        "            evaluateRandomly(encoder, decoder, n=n_sample)\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bcd7303-b9bc-45d5-8a91-e25255424a60",
      "metadata": {
        "id": "0bcd7303-b9bc-45d5-8a91-e25255424a60"
      },
      "source": [
        "# 訓練データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2695c73e-2d02-4925-b83e-6721be11ccc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2695c73e-2d02-4925-b83e-6721be11ccc4",
        "outputId": "9617931f-23c3-4495-e8db-dbd58ab5cc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(_train_dataset):17953 len(_val_dataset):1995\n"
          ]
        }
      ],
      "source": [
        "# 訓練データセットと検証データセットを作成\n",
        "train_dataset = Train_dataset(data=_vocab.train_data,\n",
        "                              source_vocab=source_vocab, \n",
        "                              target_vocab=target_vocab,\n",
        "                              source_ids=source_ids,   # おそらくこの 2 行を入れないといけなかった\n",
        "                              target_ids=target_ids)  # そうでなければ，デフォルトの `mora_p_r` になってしまう\n",
        "\n",
        "P  = int(train_dataset.__len__() * 0.9)\n",
        "_P = train_dataset.__len__() - P\n",
        "_train_dataset, _val_dataset = torch.utils.data.random_split(dataset=train_dataset,\n",
        "                                                            lengths=(P, _P),\n",
        "                                                            generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "                \n",
        "# 訓練データセットと検証データセットを作成\n",
        "print(f'len(_train_dataset):{len(_train_dataset)}',\n",
        "      f'len(_val_dataset):{len(_val_dataset)}')      "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1721275d-decb-458a-876e-53de187acbb6",
      "metadata": {
        "id": "1721275d-decb-458a-876e-53de187acbb6"
      },
      "source": [
        "# 一文字データの学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec070c18-fa39-4f31-9f18-c9aea679492f",
      "metadata": {
        "id": "ec070c18-fa39-4f31-9f18-c9aea679492f"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=20,\n",
        "               #epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               #train_dataset=train_dataset,\n",
        "               train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               val_dataset=None,\n",
        "               #val_dataset=X_vals,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "82d9caa7-891c-405f-9519-2b0f31c5cf74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82d9caa7-891c-405f-9519-2b0f31c5cf74",
        "outputId": "a762633f-2f79-4e19-9476-d767916c4c36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttnDecoderRNN(\n",
              "  (embedding): Embedding(46, 64)\n",
              "  (attn): Linear(in_features=128, out_features=34, bias=True)\n",
              "  (attn_combine): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (dropout): Dropout(p=0.0, inplace=False)\n",
              "  (gru): GRU(64, 64)\n",
              "  (out): Linear(in_features=64, out_features=46, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "if len(params['path_saved']) > 0:\n",
        "    if os.path.exists(params['path_saved']) == True:\n",
        "        print(params['path_saved'])\n",
        "    else:\n",
        "        torch.save({'encoder':encoder,\n",
        "                    'decoder':decoder},\n",
        "                   params['path_saved'])\n",
        "\n",
        "        \n",
        "encoder2 = EncoderRNN(\n",
        "    len(source_vocab), \n",
        "    params['hidden_size']).to(device)\n",
        "\n",
        "\n",
        "decoder2 = AttnDecoderRNN(\n",
        "    n_hid=params['hidden_size'], \n",
        "    n_out=len(target_vocab), \n",
        "    dropout_p=params['dropout_p'],\n",
        "    max_length=_vocab.max_length).to(device)\n",
        "\n",
        "\n",
        "_X_ = torch.load(params['path_saved'])\n",
        "encoder2.load_state_dict = _X_['encoder']\n",
        "decoder2 = _X_['decoder']\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d54d85c9-da86-42da-a028-41687b6fbfaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54d85c9-da86-42da-a028-41687b6fbfaa",
        "outputId": "1238fa10-c42f-40a6-be8a-43267261b782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids:[45, 7, 37, 12, 1] _vocab.phon_ids2tkn(input_ids):['z', 'e', 'r', 'o', '<EOW>'] num:0\n"
          ]
        }
      ],
      "source": [
        "print(f'input_ids:{input_ids}', \n",
        "      f'_vocab.phon_ids2tkn(input_ids):{_vocab.phon_ids2tkn(input_ids)}', \n",
        "      f'num:{num}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5693370c-872c-4f28-819b-a977f514fbb3",
      "metadata": {
        "id": "5693370c-872c-4f28-819b-a977f514fbb3"
      },
      "source": [
        "# 本来のデータセットの学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c21182-3bdb-4f90-9fb9-1d883857d572",
      "metadata": {
        "id": "19c21182-3bdb-4f90-9fb9-1d883857d572"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               #epochs=1,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=_train_dataset,\n",
        "               #train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               #val_dataset=None,\n",
        "               val_dataset=X_vals,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5377d6b-24c9-479b-9b06-c69a66777f5d",
      "metadata": {
        "id": "b5377d6b-24c9-479b-9b06-c69a66777f5d"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               #epochs=1,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=_train_dataset,\n",
        "               #train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               #val_dataset=None,\n",
        "               val_dataset=_val_dataset,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558809fe-ea1b-4cc0-b42d-d1eb086e37c8",
      "metadata": {
        "id": "558809fe-ea1b-4cc0-b42d-d1eb086e37c8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()\n",
        "\n",
        "#torch.save(encoder, '2023_0115lam_p2o_encoder.pt')\n",
        "#torch.save(decoder, '2023_0115lam_p2o_decoder.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0634d7c5-0f67-4798-8449-11f987d52f97",
      "metadata": {
        "id": "0634d7c5-0f67-4798-8449-11f987d52f97"
      },
      "outputs": [],
      "source": [
        "losses += _fit(encoder=encoder, \n",
        "               decoder=decoder, \n",
        "               device=device,\n",
        "               epochs=params['epochs'], \n",
        "               max_length=_vocab.max_length,\n",
        "               n_sample=0,\n",
        "               params=params,\n",
        "               source_vocab=source_vocab,\n",
        "               target_vocab=target_vocab,\n",
        "               source_ids=source_ids,\n",
        "               target_ids=target_ids,\n",
        "               teacher_forcing_ratio=params['teacher_forcing_ratio'],\n",
        "               train_dataset=train_dataset,\n",
        "               #train_dataset=onechar_dataset,\n",
        "               lr=params['lr'],\n",
        "               val_dataset=X_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c6f146-b472-4b93-8ff9-70f505f2bd87",
      "metadata": {
        "id": "57c6f146-b472-4b93-8ff9-70f505f2bd87"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "faae3833805a4c2eb8a9a4875310304e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df811b1221e74407b207ea6d9b054719",
              "IPY_MODEL_741ec590492a476a9bfcef1902292bfc",
              "IPY_MODEL_015225773d244c738b3cd1c7a7de9d37"
            ],
            "layout": "IPY_MODEL_819bd5348be047b4a3106c900f176eb9"
          }
        },
        "df811b1221e74407b207ea6d9b054719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e105bcab860474bb5edda04f8f1ea12",
            "placeholder": "​",
            "style": "IPY_MODEL_8d29306283c94a42815afaa4bb7e6d1b",
            "value": "100%"
          }
        },
        "741ec590492a476a9bfcef1902292bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab0db49331f410e9951c8241f16db8b",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01582af0b90c4ff3b2187c61ba22a282",
            "value": 20000
          }
        },
        "015225773d244c738b3cd1c7a7de9d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a88e96e47c44f08980116694689847b",
            "placeholder": "​",
            "style": "IPY_MODEL_80409008ae4e419cabe0df1032fcd98f",
            "value": " 20000/20000 [00:30&lt;00:00, 389.66it/s]"
          }
        },
        "819bd5348be047b4a3106c900f176eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e105bcab860474bb5edda04f8f1ea12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d29306283c94a42815afaa4bb7e6d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eab0db49331f410e9951c8241f16db8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01582af0b90c4ff3b2187c61ba22a282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a88e96e47c44f08980116694689847b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80409008ae4e419cabe0df1032fcd98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}