{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_0215RAM_from_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4481f606-e903-48d7-b887-8b65f6e4b4ae",
      "metadata": {
        "id": "4481f606-e903-48d7-b887-8b65f6e4b4ae"
      },
      "source": [
        "# 1. P2P の簡単なデモ\n",
        "\n",
        "<!-- 注意: Colab 上で実行する場合，Google Drive への接続許可を求めるポップアップウィンドウが開くので，許可する必要があります。 -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6755db74-bfd8-404c-8750-45815b019a07",
      "metadata": {
        "id": "6755db74-bfd8-404c-8750-45815b019a07"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import gzip\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv\n",
        "    \n",
        "\n",
        "if isColab:\n",
        "\n",
        "    # termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    import termcolor    \n",
        "\n",
        "    # 結果を保存するために Google Drive をマウントする\n",
        "    # import google.colab\n",
        "    # google.colab.drive.mount('/content/drive/')\n",
        "    \n",
        "    # GPU 情報を表示\n",
        "    !nvidia-smi -L\n",
        "\n",
        "    #!pip install ipynbname --upgrade > /dev/null\n",
        "\n",
        "    !pip install japanize_matplotlib\n",
        "\n",
        "if isColab:\n",
        "    # colab 上で MeCab を動作させるために，C コンパイラを起動して，MeCab の構築を行う\n",
        "    # そのため時間がかかる。\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install jaconv\n",
        "    \n",
        "    import MeCab\n",
        "    mecab_wakati = MeCab.Tagger('-Owakati').parse\n",
        "    mecab_yomi = MeCab.Tagger('-Oyomi').parse\n",
        "    \n",
        "else:\n",
        "    from ccap.mecab_settings import yomi as mecab_yomi\n",
        "    from ccap.mecab_settings import wakati as mecab_wakati\n",
        "\n",
        "\n",
        "# ここから下は，コード実行に関するバージョン情報などの情報源の取得と表示\n",
        "from termcolor import colored\n",
        "\n",
        "import platform\n",
        "HOSTNAME = platform.node().split('.')[0]\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname\n",
        "    import ipynbname\n",
        "FILEPATH = str(ipynbname.path()).replace(HOME+'/','')\n",
        "\n",
        "import pwd\n",
        "USER=pwd.getpwuid(os.geteuid())[0]\n",
        "\n",
        "from datetime import date\n",
        "TODAY=date.today()\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "\n",
        "color = 'green'\n",
        "print('日付:',colored(f'{TODAY}', color=color, attrs=['bold']))\n",
        "print('HOSTNAME:',colored(f'{HOSTNAME}', color=color, attrs=['bold']))\n",
        "print('ユーザ名:',colored(f'{USER}', color=color, attrs=['bold']))\n",
        "print('HOME:',colored(f'{HOME}', color=color,attrs=['bold']))\n",
        "print('ファイル名:',colored(f'{FILEPATH}', color=color, attrs=['bold']))\n",
        "print('torch.__version__:',colored(f'{TORCH_VERSION}', color=color, attrs=['bold']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a325d690-f68f-449a-8f7e-993c060aeeca",
      "metadata": {
        "id": "a325d690-f68f-449a-8f7e-993c060aeeca"
      },
      "outputs": [],
      "source": [
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6df23cdd-a607-44c7-859d-36b5fb574909",
      "metadata": {
        "id": "6df23cdd-a607-44c7-859d-36b5fb574909"
      },
      "outputs": [],
      "source": [
        "# シミュレーションに必要なパラメータの設定ユーティリティ\n",
        "from RAM import set_params_from_file\n",
        "from RAM import set_params_from_config\n",
        "\n",
        "# json file から読み込むか\n",
        "json_fname = 'params_test2.json'\n",
        "\n",
        "# そうでなければ，以下のパラメータを設定して実行\n",
        "configs = {\n",
        "    'dataset_name'  : 'vdrj',   # ['pyslex71', 'vdrj', 'onechar', 'fushimi1999']\n",
        "    #'dataset_name'  : 'fushimi1999',   # ['pyslex71', 'vdrj', 'onechar', 'fushimi1999']\n",
        "    #'dataset_name'   : 'onechar',\n",
        "    'traindata_size':  10000,    # 訓練データ (語彙) 数，\n",
        "    #'traindata_size':  2000,   # 訓練データ (語彙) 数，\n",
        "    'traindata_ratio': 0.9,     # 訓練データと検証データを分割する比率。ただし onechar データセットでは無効\n",
        "    #'traindata_ratio': 1.0,     # 訓練データと検証データを分割する比率。ただし onechar データセットでは無効\n",
        "    #'stop_list': fushimi1999_wordlist,\n",
        "    'stop_list': None,\n",
        "    'epochs': 5,               # 学習のためのエポック数\n",
        "    \n",
        "    # 以下 `source` と `rget` を定義することで，別の課題を実行可能\n",
        "    'source': 'phon',          # ['orth', 'phon']\n",
        "    'target': 'phon',          # ['orth', 'phon']\n",
        "\n",
        "    #'hidden_size': 256,        # 中間層のニューロン数\n",
        "    #'hidden_size': 128,\n",
        "    'hidden_size': 64,\n",
        "\n",
        "    #'lr' : 0.0001,\n",
        "    #'lr': 1e-4,                       # 学習率\n",
        "    'lr': 1e-3,                       # 学習率\n",
        "    'dropout_p': 0.0,                 # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,     # 教師強制を行う確率\n",
        "    'optim_func': \"torch.optim.Adam\",   # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :\"torch.nn.NLLLoss\",  # 負の対数尤度損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "    #'loss_func' :torch.nn.NLLLoss(),\n",
        "\n",
        "    'random_seed': 42,          # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "    'pretrained': False,       # True であれば訓練済ファイルを読み込む\n",
        "    #'isTrain'   : True,       # True であれば学習する\n",
        "    \n",
        "    'verbose'   : False,\n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "    #'path_saved': '2023_0220vdrj_2k_p2p.pt',\n",
        "    'path_saved': False,                      # 保存しない場合\n",
        "}\n",
        "\n",
        "\n",
        "#params, encoder, decoder, ds, train_dataset, val_dataset, \\\n",
        "#encoder_optimizer, decoder_optimizer, N_train, N_val = set_params_from_file(\n",
        "#     json_fname=json_fname, device=device)\n",
        "# params, encoder, decoder, ds, train_dataset, val_dataset, \\\n",
        "# encoder_optimizer, decoder_optimizer, N_train, N_val = set_params_from_file(params=configs, device=device)\n",
        "\n",
        "X = set_params_from_config(configs=configs, device=device)\n",
        "params = X['params']\n",
        "encoder = X['encoder']\n",
        "decoder = X['decoder']\n",
        "ds = X['dataset']\n",
        "train_dataset = X['train_dataset']\n",
        "#val_dataset = {'val':X['val_dataset']}\n",
        "val_dataset = X['val_dataset']\n",
        "encoder_optimizer = X['encoder_optimizer']\n",
        "decoder_optimizer = X['decoder_optimizer']\n",
        "N_train = X['N_train']\n",
        "N_val   = X['N_val']\n",
        "\n",
        "configs['max_length'] = ds.maxlen\n",
        "configs['source_vocab'], configs['target_vocab'] = ds.source_list, ds.target_list\n",
        "configs['encoder'], configs['decoder'] = encoder, decoder\n",
        "configs['encoder_optimizer'], configs['decoder_optimizer'] = encoder_optimizer, decoder_optimizer\n",
        "configs['N_train'], configs['N_val'] = N_train, N_val\n",
        "configs['train_dataset'], configs['val_dataset'] = train_dataset, val_dataset\n",
        "configs['device'] = device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5226042-93d4-405b-ac15-bb122610dfa0",
      "metadata": {
        "id": "a5226042-93d4-405b-ac15-bb122610dfa0"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "from RAM import train_epochs_with_config\n",
        "\n",
        "perfs = train_epochs_with_config(configs=configs, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41a05fe-6dd9-4414-bdf4-bfd4ae00e1d3",
      "metadata": {
        "id": "a41a05fe-6dd9-4414-bdf4-bfd4ae00e1d3"
      },
      "outputs": [],
      "source": [
        "plt.plot(perfs['losses'])\n",
        "plt.show()\n",
        "\n",
        "#plt.yticks(np.arange(0, 1, step=0.2))\n",
        "plt.xticks(np.arange(0, len(perfs['train_accuracy']), step=1))\n",
        "plt.plot(perfs['train_accuracy'], label='訓練データ')\n",
        "plt.plot(perfs['val_accuracy'], label='検証データ')\n",
        "plt.legend(loc=\"upper left\")\n",
        "#plt.ylim(0,1.75)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64aaeeb3-34de-4597-8976-1708de555e8d",
      "metadata": {
        "id": "64aaeeb3-34de-4597-8976-1708de555e8d"
      },
      "outputs": [],
      "source": [
        "from RAM import eval_input_seq2seq\n",
        "_ = eval_input_seq2seq(encoder=encoder, decoder=decoder, ds=ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7c9b61-f0a7-4a9d-b291-e8e838ed381c",
      "metadata": {
        "id": "ff7c9b61-f0a7-4a9d-b291-e8e838ed381c"
      },
      "outputs": [],
      "source": [
        "from RAM import SALA_Dataset\n",
        "sala_r31 = SALA_Dataset(task=\"sala_r29\")\n",
        "sala_r31_words = [v['orth'] for k, v in sala_r31.data_dict.items()]\n",
        "for wrd in sala_r31_words:\n",
        "    _phon = jaconv.hiragana2julius(wrd).split()\n",
        "    print(wrd, eval_input_seq2seq(encoder=encoder, decoder=decoder, ds=ds, inp_wrd=_phon, isPrint=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbERZ_uTu0AV"
      },
      "id": "DbERZ_uTu0AV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}