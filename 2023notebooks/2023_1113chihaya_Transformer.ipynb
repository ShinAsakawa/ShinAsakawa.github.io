{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4nH5s6hIRoXVtjnTiAIuZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2023notebooks/2023_1113chihaya_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 百人一首の上の句とエンコーダによって符号化し，下の句をデコーダで生成する自作 Transformer モデル\n",
        "\n",
        "* date: 2023_0225\n",
        "* author: 浅川伸一\n",
        "* bibliography: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n"
      ],
      "metadata": {
        "id": "PqRn9GSrNKKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備 必要なライブラリの輸入と諸元の表示"
      ],
      "metadata": {
        "id": "fur4cMuzNxWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxaEpeycIiGL"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "if isColab:\n",
        "\n",
        "    # GPU 情報を表示\n",
        "    !nvidia-smi -L\n",
        "\n",
        "    # `import bit` する前に termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    import termcolor\n",
        "\n",
        "    !pip install jaconv\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "\n",
        "import platform\n",
        "HOSTNAME = platform.node().split('.')[0]\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname\n",
        "    import ipynbname\n",
        "FILEPATH = str(ipynbname.path()).replace(HOME+'/','')\n",
        "\n",
        "import pwd\n",
        "USER=pwd.getpwuid(os.geteuid())[0]\n",
        "\n",
        "from datetime import date\n",
        "TODAY=date.today()\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "color = 'green'\n",
        "print('日付:',colored(f'{TODAY}', color=color, attrs=['bold']))\n",
        "print('HOSTNAME:',colored(f'{HOSTNAME}', color=color, attrs=['bold']))\n",
        "print('ユーザ名:',colored(f'{USER}', color=color, attrs=['bold']))\n",
        "print('HOME:',colored(f'{HOME}', color=color,attrs=['bold']))\n",
        "print('ファイル名:',colored(f'{FILEPATH}', color=color, attrs=['bold']))\n",
        "print('torch.__version__:',colored(f'{TORCH_VERSION}', color=color, attrs=['bold']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 百人一首データのダウンロード"
      ],
      "metadata": {
        "id": "dMe3zwsUN4bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import json\n",
        "chihaya_fname = 'chihaya.json'\n",
        "\n",
        "if os.path.exists(chihaya_fname):\n",
        "    # カレントディレクトリに 'chihaya.json' があれば，その情報を読み込む\n",
        "    with open(chihaya_fname, 'r') as fp:\n",
        "        chihaya = OrderedDict(json.load(fp))\n",
        "else:\n",
        "    # カレントディレクトリに 'chihaya.json' がなければ，ダウンロード\n",
        "    import requests\n",
        "    url = 'http://www.diana.dti.ne.jp/~fujikura/List/List.html'\n",
        "    page = requests.get(url)  # url から内容を取得\n",
        "\n",
        "    from bs4 import BeautifulSoup\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    # print(soup.prettify()) 確認のため表示\n",
        "    body = list(soup.children)[0]\n",
        "\n",
        "    chihaya = OrderedDict()\n",
        "    i = 1\n",
        "    m = []\n",
        "    # 最初と最後は百人一首の歌と無関係なため [1:-1] で除外\n",
        "    for p in body.getText().split()[1:-1]:\n",
        "        mod = i % 7\n",
        "\n",
        "        if mod == 0:\n",
        "            chihaya[N] = m\n",
        "            print(chihaya[N])\n",
        "            m = []\n",
        "        elif mod == 1:\n",
        "            N = int(p)\n",
        "        elif mod > 2:\n",
        "            m.append(p)\n",
        "        i += 1\n",
        "\n",
        "    # 後日のために，'chihaya.json' を書き出す\n",
        "    if not os.path.exists(chihaya_fname):\n",
        "        with open(chihaya_fname, 'w') as fp:\n",
        "            json.dump(chihaya, fp, ensure_ascii=False, indent=4)\n",
        "\n",
        "chihaya_chrs = OrderedDict()\n",
        "for k, v in chihaya.items():\n",
        "\n",
        "    # v[0]:漢字上の句，v[1]:漢字下の句，v[2]:ひらがな上の句，v[3]:ひらがな下の句\n",
        "    for ku in [v[2], v[3]]:\n",
        "        for ch in ku:\n",
        "            if not ch in chihaya_chrs:\n",
        "                chihaya_chrs[ch] = 1\n",
        "            else:\n",
        "                chihaya_chrs[ch] += 1\n",
        "\n",
        "chihaya_tokens = sorted(chihaya_chrs.keys())\n",
        "for tkn in reversed(['<PAD>','<SOS>','<EOS>','<UNK>']):\n",
        "    chihaya_tokens.insert(0, tkn)\n",
        "\n",
        "_chihaya = OrderedDict()\n",
        "for k, v in chihaya.items():\n",
        "    _chihaya[int(k)] = v\n",
        "chihaya = _chihaya\n",
        "\n",
        "idx2tkn = dict(enumerate(chihaya_tokens))  # トークン ID 番号から文字を返す辞書\n",
        "\n",
        "# 文字からトークン ID を返す辞書\n",
        "def tkn2idx(tkn:list, tokens=chihaya_tokens):\n",
        "    ret = []\n",
        "    for _tkn in tkn:\n",
        "        #print(f'_tkn:{_tkn}')\n",
        "        if not _tkn in tokens:\n",
        "            ret.append(tokens.index('<UNK>'))\n",
        "        else:\n",
        "            ret.append(tokens.index(_tkn))\n",
        "    return ret\n",
        "\n",
        "print(f'idx2tkn:{idx2tkn}')\n",
        "for tkn in chihaya_tokens:\n",
        "    print(f'({tkn},{tkn2idx([tkn])})', end=\" \")"
      ],
      "metadata": {
        "id": "PYGm0FDmLZza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自作 Transformer の輸入"
      ],
      "metadata": {
        "id": "d90lx6KbOBpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from RAM import Transformer\n",
        "model = Transformer(src_vocab_size=len(idx2tkn),\n",
        "                    tgt_vocab_size=len(idx2tkn),\n",
        "                    model_dim=32,\n",
        "                    num_heads=4,\n",
        "                    num_layers=1,\n",
        "                    max_seq_length=22,\n",
        "                    dropout=0.,\n",
        "                    ff_dim=32).to(device)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "72VSUMlvInPc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 乱数の種の設定"
      ],
      "metadata": {
        "id": "zyr8HI5FOHCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数のシードを設定\n",
        "import random\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "Mdu-P4xoLfVL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練"
      ],
      "metadata": {
        "id": "3DyvHqUJOXc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 交差エントロピーによる損失関数\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "# [Adam](https://arxiv.org/abs/1412.6980) による最適化関数の定義\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "epochs = 6\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()  # 訓練モードに設定\n",
        "    losses = []\n",
        "    epoch_loss, n_corrects = 0, 0\n",
        "    Ns = np.random.permutation(len(chihaya))\n",
        "    for i in Ns:\n",
        "        kami, simo = chihaya[i+1][2], chihaya[i+1][3]\n",
        "        optimizer.zero_grad()\n",
        "        kami_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(kami)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "        simo_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "        tch_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).to(device)\n",
        "        out = model(kami_, simo_).to(device) # 出力を得る\n",
        "\n",
        "        loss = criterion(out[0], tch_)       # 損失値の計算\n",
        "        loss.backward()                      # 誤差逆伝播\n",
        "        optimizer.step()                     # 誤差に基づき学習ステップ実行\n",
        "        epoch_loss += loss.item()            # 損失値総和\n",
        "\n",
        "    model.eval()  # 評価モードに設定\n",
        "    for i in range(len(chihaya)):\n",
        "        kami, simo = chihaya[i+1][2], chihaya[i+1][3]\n",
        "        kami_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(kami)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "        simo_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "        out = model(kami_, simo_).detach().numpy()[0]\n",
        "        _out = np.argmax(out, axis=-1)\n",
        "\n",
        "        out_str = \"\".join([idx2tkn[idx] for idx in _out[1:-1]])  # 出力文字列の作成\n",
        "        yesno = out_str == simo                                  # 正誤判断\n",
        "        if yesno:\n",
        "            n_corrects += 1                                      # 正答数の計測\n",
        "        if yesno == False:                                       # 不正解の場合結果の表示\n",
        "            print(f'{i+1:4d} ', end=\"\")\n",
        "            for i, c0 in enumerate(out_str):\n",
        "                if i < len(simo):\n",
        "                    color = 'blue' if c0 == simo[i] else 'red'\n",
        "                    print(colored(c0, color=color, attrs=['bold']), end=\"\")\n",
        "            print(f', 正解(下句):{simo}',\n",
        "                  f', 入力(上句):{kami}')\n",
        "\n",
        "    # エポック毎の結果表示\n",
        "    print(f'エポック:{epoch+1}',\n",
        "          f'損失:{epoch_loss/len(chihaya):.5f}',\n",
        "          f'正解率: {((n_corrects / len(chihaya)))*100:7.3f}%'),"
      ],
      "metadata": {
        "id": "AZTIsEIOLhUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "count = {}\n",
        "for k, v in chihaya.items():\n",
        "    kami, shimo = v[2], v[3]\n",
        "    for ch in kami+shimo:\n",
        "        #print(ch, end=\" \")\n",
        "        if ch in count:\n",
        "            count[ch] += 1\n",
        "        else:\n",
        "            count[ch] = 1\n",
        "count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "plt.figure(figsize=(14,4))\n",
        "N = np.array([x[1] for x in count.items()]).sum()\n",
        "plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "plt.title('百人一首の文字頻度')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8MtKUOGTOTbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}