{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMeTNzvii/HUGJ8ir1NGoYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1029bit_letter_cancellation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BIT 文字抹消課題\n",
        "* filename: 2022_1029bit_letter_cancellation.ipynb\n",
        "* date: 2022_1029\n",
        "* author: 浅川伸一\n"
      ],
      "metadata": {
        "id": "6ZBaSLGWWPv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxpUjw9QWNzv"
      },
      "outputs": [],
      "source": [
        "# このセルは 2 回実行しないといけないかも知れません\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "    import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    # 2022_0916 現在 PIL のバージョンが古く truetype フォント\n",
        "    # の表示に不具合が出るためバージョン 9.2.0 以上に更新する\n",
        "    !pip install --upgrade Pillow\n",
        "\n",
        "import torch\n",
        "import PIL\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 刺激の作成\n",
        "## 1.1 画面分割の定義と対応するフォントの設定\n",
        "\n",
        "* font が 14 種類あって，そのサイズが 5 種類だから，フォントは全部で 70 種類存在する。\n",
        "* 色は 9 種類\n",
        "* 記号は 49 種類ある\n",
        "* 色 X 記号 X フォントの種類 =  9 X 49 X 14 = 6174\n",
        "* したがって，一つの位置に 6174 だけ刺激が存在する。\n",
        "* そうすると全ての位置に刺激が 6174 だけ存在するので，刺激情報 `stims` は `stims[split_{split}] ^[len(pos)]` だけだから\n",
        "\n",
        "\n",
        "画面の分割によって，フォントサイズが異なるため，事前に登録しておく"
      ],
      "metadata": {
        "id": "opNK1JRaWXtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from PIL import ImageFont\n",
        "\n",
        "noto_font_dir = 'fonts'\n",
        "notofonts_fnames = glob(os.path.join(noto_font_dir,'*otf'))\n",
        "notofonts = {fname.split('/')[-1].split('.')[0]:{'fname':fname} for fname in notofonts_fnames}\n",
        "for fontname in notofonts.keys():\n",
        "    notofonts[fontname]['data'] = ImageFont.truetype(notofonts[fontname]['fname'])\n",
        "#notofonts;\n",
        "symbols = bit.BIT(fontdata=notofonts).symbols     # 文字の登録\n",
        "#print(symbols);"
      ],
      "metadata": {
        "id": "Kescvx1PWm8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from PIL_util import colornames # 色名を定義\n",
        "# `brown` を削除した\n",
        "colornames = ['black', 'blue', 'cyan', 'green', 'magenta', 'orange', 'purple', 'red', 'yellow'] \n",
        "\n",
        "# フォント名の取得\n",
        "fontnames = bit.get_notojp_fonts(verbose=False).keys()\n",
        "\n",
        "class _params:\n",
        "    def __init__(self,\n",
        "                 splits:list=[2,3,4,5,6],\n",
        "                 symbols:list=['<background>', '<line>', '★', \n",
        "                               'あ', 'い', 'う', 'え', 'お', \n",
        "                               'か', 'き', 'く', 'け', 'こ', \n",
        "                               'さ', 'し', 'す', 'せ', 'そ', \n",
        "                               'た', 'ち', 'つ', 'て', 'と', \n",
        "                               'な', 'に', 'ぬ', 'ね', 'の', \n",
        "                               'は', 'ひ', 'ふ', 'へ', 'ほ', \n",
        "                               'ま', 'み', 'む', 'め', 'も', \n",
        "                               'や', 'ゆ', 'よ', \n",
        "                               'ら', 'り', 'る', 'れ', 'ろ', \n",
        "                               'わ', 'を', 'ん'],\n",
        "                 colornames:list=['black', 'blue', 'cyan', \n",
        "                                  'green', 'magenta', 'orange', \n",
        "                                  'purple', 'red', 'yellow'],\n",
        "                 fontnames:list=fontnames,\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.splits     = splits\n",
        "        self.symbols    = symbols\n",
        "        self.colornames = colornames\n",
        "        self.fontnames  = fontnames\n",
        "\n",
        "        \n",
        "params = _params() \n",
        "#params = _params(splits=[1,3])\n",
        "# for x in dir(params):\n",
        "#     if not str(x).startswith('_'):\n",
        "#         print(f'{x}:{eval(x)}')\n",
        "splits = params.splits\n",
        "print(splits)\n",
        "        \n",
        "        "
      ],
      "metadata": {
        "id": "UIY6wmdnWXBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ShinAsakawa.github.io/2022notebooks/PIL_util.py -O PIL_util.py\n",
        "!wget https://ShinAsakawa.github.io/2022notebooks/bit_utils.py -O bit_utils.py"
      ],
      "metadata": {
        "id": "sIy8eA4SYdcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splits = [2,3,4,5,6]    # 画面の分割数\n",
        "# #splits = [1, 3]            # 画面の分割数\n",
        "from PIL_util import make_a_canvas as make_canvas  # PIL による画像とキャンバスの作成\n",
        "from PIL_util import make_div_areas                # 領域を縦横に分割\n",
        "\n",
        "# フォントサイズの計算\n",
        "fontsizes = {}\n",
        "#for split in params.splits: # 各条件ごと\n",
        "for split in splits: # 各条件ごと\n",
        "    areas = make_div_areas(div=split)  # 分割された領域\n",
        "    fontsize = int((areas[0][3]) / 8 * 6) # 領域の大きさからフォントサイズを計算\n",
        "    #fontsize = int((areas[0][3])/8 * 7) # 領域の大きさからフォントサイズを計算\n",
        "    fontsizes[split] = {'split':split,\n",
        "                        'size':fontsize}\n",
        "\n",
        "fonts_info = {}      # フォント情報の登録\n",
        "for key, fontsize in fontsizes.items():\n",
        "    _fonts = bit.get_notojp_fonts(fontsize=fontsize['size'], verbose=False)\n",
        "    for fontname, font in _fonts.items():\n",
        "        font_entry = f\"{fontsize['size']}_{fontname}\"\n",
        "        fonts_info[font_entry] = font\n",
        "\n",
        "print(f'fontsizes:{fontsizes}')\n",
        "print(f'len(symbols):{len(symbols)} symbols:{symbols}')\n",
        "print(f'len(colornames):{len(colornames)} colornames:{colornames}')\n",
        "print(f'len(fonts_info):{len(fonts_info)}')\n",
        "print(f'fontnames:{fontnames}')\n",
        "\n",
        "print(f'総刺激:{len(colornames) * len(symbols) * len(fontnames)} 種')"
      ],
      "metadata": {
        "id": "2kXG0wYMWSQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 刺激作成条件に基づく刺激の作成"
      ],
      "metadata": {
        "id": "AVN7b_vUZ9pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データセット，テストデータセットの作成\n",
        "# 色 と フォント と 記号 との直交で全ての刺激を作成\n",
        "# フォントサイズは，画面分割数に依存するため，各刺激画像で異なるが，それ以外の情報である，色，記号，および，フォントは\n",
        "# 直交するので全組合わせを作成しておく。\n",
        "# これを _stimset とする\n",
        "_stimset = [] \n",
        "for font in fontnames:\n",
        "    for color in colornames:\n",
        "        for symbol in symbols:\n",
        "            _stimset.append((symbol, color, font))\n",
        "print(f'len(_stimset):{len(_stimset)}')\n",
        "\n",
        "# 直上で作成した _stimset を並べ替えて，刺激画像上の各位置に描画する刺激を配置する。\n",
        "# $\\text{各位置}^{len(_stimset)}$ だけ，可能性があるが，数が多くなりすぎる\n",
        "# そこで，_stimset を乱数を使って並べ替え，画像の各位置に現れる刺激として採用することにした。\n",
        "# これにより，各画面分割数 `splits` を条件として，この条件毎に `len(_stimset)` 数だけの刺激画像が存在することとした。\n",
        "stims = {f'split_{split}':{} for split in splits}\n",
        "for split in splits:        # 全分割数ごとに\n",
        "    positions = split ** 2  # 画面上の領域の個数。左上は 0 番で右下が positions-1 番\n",
        "    for pos in range(positions):\n",
        "        # 刺激画面上の各位置には _stimset を並べ替えた順番で個々の刺激が並ぶことになる。\n",
        "        stims[f'split_{split}'][pos] = np.random.permutation(_stimset).tolist()\n",
        "\n",
        "stims_info = []\n",
        "for split in splits:\n",
        "    positions = split ** 2  # 画面上の領域の個数。左上は 0 番で右下が positions-1 番\n",
        "    for i in range(len(_stimset)):\n",
        "        _tmp = []\n",
        "        for pos in range(positions):\n",
        "            _tmp.append((pos,stims[f'split_{split}'][pos][i])) \n",
        "        stims_info.append({'split':split, 'stim':_tmp})\n",
        "\n",
        "print(f'len(stims_info:{len(stims_info)}')\n",
        "print(f'stims_info[0]:{stims_info[0]}')"
      ],
      "metadata": {
        "id": "8gHfvV00aAfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pt_get_original_img(stiminfo:dict=None,\n",
        "                        img:PIL.Image=None,\n",
        "                        symbols:list=bit.BIT(fontdata=notofonts).symbols,\n",
        "                        verbose:bool=False):\n",
        "    if img == None:\n",
        "        img, canvas = make_canvas()\n",
        "    else:\n",
        "        canvas = PIL.ImageDraw.Draw(img)\n",
        "\n",
        "    split = stiminfo['split']\n",
        "    bboxes = []\n",
        "    labels = []\n",
        "    areas = make_div_areas(div=split)\n",
        "    \n",
        "    for stim in stiminfo['stim']:\n",
        "        pos = stim[0]\n",
        "        area = areas[pos]\n",
        "\n",
        "        symbol  = stim[1][0]\n",
        "        \n",
        "        label   = symbols.index(symbol)\n",
        "        labels.append(label)\n",
        "        \n",
        "        color    = stim[1][1]\n",
        "        fontname = stim[1][2]\n",
        "        fontsize = fontsizes[split]['size']\n",
        "        font = fonts_info[f'{fontsize}_{fontname}']\n",
        "\n",
        "        if symbol == '<line>' or symbol == '<background>':\n",
        "            #print(symbol, color, fontname, area, fontsize, fontname, type(font))\n",
        "            ;\n",
        "        else:\n",
        "            offset_x = ((area[2] - area[0]) - fontsize) >> 1\n",
        "            offset_y = (area[3] - area[1] - fontsize) >> 1\n",
        "            xy = (area[0]+offset_x, area[1]+offset_y)\n",
        "            canvas.text(xy=xy,\n",
        "                        text=symbol,\n",
        "                        fill=color,\n",
        "                        font=font,\n",
        "                        anchor='lt')\n",
        "            bbox = canvas.textbbox(xy=xy,\n",
        "                                   text=symbol,\n",
        "                                   font=font,\n",
        "                                   anchor='lt',\n",
        "                                   stroke_width=4)\n",
        "            bboxes.append(bbox)\n",
        "            if verbose:\n",
        "                canvas.rectangle(xy=bbox, fill=None, outline='red', width=2)\n",
        "\n",
        "    # ここから下は PyTorch 用変換\n",
        "    pt_img = torch.Tensor(np.array(img)).permute(2,0,1)\n",
        "    pt_labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        \n",
        "    # convert boxes into a torch.Tensor\n",
        "    pt_bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n",
        "\n",
        "    # getting the areas of the boxes\n",
        "    pt_area = (pt_bboxes[:, 3] - pt_bboxes[:, 1]) * (pt_bboxes[:, 2] - pt_bboxes[:, 0])\n",
        "    pt_iscrowd = torch.zeros((pt_bboxes.shape[0],), dtype=torch.int64)\n",
        "\n",
        "    pt_target = {}\n",
        "    #pt_target[\"img\"]     = pt_img\n",
        "    pt_target[\"boxes\"]   = pt_bboxes\n",
        "    pt_target[\"labels\"]  = pt_labels\n",
        "    pt_target[\"area\"]    = pt_area\n",
        "    pt_target[\"iscrowd\"] = pt_iscrowd\n",
        "                \n",
        "    return img, bboxes, pt_target"
      ],
      "metadata": {
        "id": "UlSbSLLTaA1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 PyTorch 用データセットの作成"
      ],
      "metadata": {
        "id": "VRf2qqe3aUPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BIT_LineCancellation_dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"留意事項\n",
        "    1. データセットはタプルを返す。1 つ目の要素は画像の形状，2 つ目の要素は辞書である。\n",
        "    2. 画像はデータセット定義時に指定したサイズでカラーモードは RGB\n",
        "    3. 画像には 4 つのバウンディングボックスがあり，これはボックス内の 4 つのリストとラベルの長さから明らかである。\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 stim_info:list=stims_info,\n",
        "                 symbols:list = bit.BIT(fontdata=notofonts).symbols):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.symbols = symbols\n",
        "        self.stim_info = stims_info\n",
        "        \n",
        "    def __get_original_img(self,\n",
        "                           index:int):\n",
        "        stiminfo = self.stim_info[index]\n",
        "        img, bboxes, pt_target = pt_get_original_img(stiminfo)\n",
        "        return img\n",
        "        \n",
        "    def __getitem__(self, \n",
        "                    index:int):\n",
        "        stiminfo = self.stim_info[index]\n",
        "        _img, bboxes, pt_target = pt_get_original_img(stiminfo)\n",
        "        img = torch.Tensor(np.array(_img)/255.).permute(2,0,1)\n",
        "        pt_target['image_id'] = torch.tensor([index])\n",
        "\n",
        "        return img, pt_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.stim_info)\n",
        "\n",
        "bit_dataset = BIT_LineCancellation_dataset()\n",
        "\n",
        "# 以下検証用\n",
        "print(f'bit_dataset.__len__():{bit_dataset.__len__()}')\n",
        "N = np.random.choice(bit_dataset.__len__())\n",
        "img, labels = bit_dataset.__getitem__(N)\n",
        "\n",
        "print(f'N:{N}')\n",
        "print(f'labels:{labels}')\n",
        "print([(_label, symbols[_label]) for _label in labels['labels']])\n",
        "\n",
        "#_img = img.detach().numpy().transpose(1,2,0).clip(0,1)\n",
        "#plt.subplot(1,2,1);plt.imshow(_img);plt.title('データ')\n",
        "#plt.subplot(1,2,2);plt.imshow(pt_get_original_img(stims_info[N])[0]);plt.title('オリジナル')"
      ],
      "metadata": {
        "id": "_2STThdaaDcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 データセットを分割して，訓練データとテストデータを作成"
      ],
      "metadata": {
        "id": "hm0b9Bv0bIay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットを分割して，訓練データとテストデータを作成\n",
        "N = bit_dataset.__len__()\n",
        "N_train = int((N / 10) * 9)\n",
        "N_test = N - N_train\n",
        "print(f'N_train:{N_train}, N_test:{N_test}')\n",
        "seed=42\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(bit_dataset, \n",
        "                                                            [N_train, N_test], \n",
        "                                                            generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "2Yjz3VaOaV6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 データローダの作成"
      ],
      "metadata": {
        "id": "FzqPGbwGbNi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダの作成\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# 学習・検証用データローダの定義\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=128, \n",
        "    shuffle=True, \n",
        "    num_workers=0,\n",
        "    collate_fn=collate_fn)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=128, \n",
        "    shuffle=False, \n",
        "    num_workers=0,\n",
        "    collate_fn=collate_fn)\n",
        "\n",
        "print(f'len(train_dataset):{len(train_dataset)}, len(test_dataset):{len(test_dataset)}')"
      ],
      "metadata": {
        "id": "MoQ626OmbKUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. モデルの定義と頭部の付け替え"
      ],
      "metadata": {
        "id": "Kt4as745bTzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの定義と頭部の付け替え\n",
        "import torch\n",
        "import torchvision \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "#_bit = bit.BIT()\n",
        "\n",
        "def get_object_detection_model(\n",
        "    num_classes:int=1024)->torch.nn.Module:\n",
        "\n",
        "    # MS-COCO で事前に学習させたモデルを読み込み\n",
        "    # https://arxiv.org/abs/1506.01497\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    #model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.DEFAULT')\n",
        "    \n",
        "    # 分類器の入力特徴数の取得\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    print(f'変換前 model.roi_heads:{model.roi_heads}')\n",
        "\n",
        "    # 事前学習済頭部を新しいものに置き換え\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
        "    print(f'変換後 model.roi_heads:{model.roi_heads}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# 上で定義した自作ヘルパ関数を使ってモデルを宣言\n",
        "num_classes = len(symbols)\n",
        "model = get_object_detection_model(num_classes)\n",
        "model.roi_heads"
      ],
      "metadata": {
        "id": "iyChtTi6bPQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 事前訓練済パラメータの読み込み"
      ],
      "metadata": {
        "id": "XXXZc1kBbsU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# データの ID を入れて，データを入手\n",
        "download = drive.CreateFile({'id': '1nRM2YzkRakEExDoc42_Mtnrbw8pxRhb8'})\n",
        "# https://drive.google.com/file/d/1nRM2YzkRakEExDoc42_Mtnrbw8pxRhb8/view?usp=sharing\n",
        "download.GetContentFile('2022_1109letter_cancellation_0.pt')\n"
      ],
      "metadata": {
        "id": "kQh48s6Cbziu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練済モデルがあれば読み込む\n",
        "import os\n",
        "#fname_model_trained = '2022_0620fine_tuned_bit_line_bisection.cpt'\n",
        "#if os.path.exists(fname_model_trained):\n",
        "#    XXX = torch.load(fname_model_trained)['model']\n",
        "\n",
        "#fname_model_trained = '2022_1026line_cancellation_19.pt'\n",
        "#fname_model_trained = '2022_1102letter_cancellation_2.pt'\n",
        "fname_model_trained = '2022_1109letter_cancellation_0.pt'\n",
        "if os.path.exists(fname_model_trained):\n",
        "    XXX = torch.load(fname_model_trained)\n",
        "\n",
        "model.load_state_dict(XXX)"
      ],
      "metadata": {
        "id": "NCE_beoHbWl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bit_utils import torch_to_pil\n",
        "from bit_utils import plot_img_bbox\n",
        "from bit_utils import apply_nms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "UwSTIp4ke5Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 予測\n"
      ],
      "metadata": {
        "id": "mAQYYTJIgo3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = np.random.choice(test_dataset.__len__())\n",
        "img, target = test_dataset.__getitem__(num)\n",
        "img_orig = img.detach().numpy().transpose(1,2,0).clip(0,1)\n",
        "\n",
        "model.eval()  # モデルを eval() モードに設定する。学習しないように\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])[0]\n",
        "    \n",
        "plot_img_bbox(img_orig,\n",
        "              target, \n",
        "              title=\"グランドトルース\",\n",
        "              figsize=(3,3))\n",
        "\n",
        "nms_prediction = apply_nms(prediction, iou_thresh=0.01)\n",
        "plot_img_bbox(img.numpy().transpose(1,2,0), # .clip(0,1),\n",
        "              nms_prediction, \n",
        "              title=\"モデル予測\",\n",
        "              figsize=(3,3))"
      ],
      "metadata": {
        "id": "rKE8VO-lgQCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in nms_prediction.keys():\n",
        "    print(k, type(nms_prediction[k]))\n",
        "for i, box in enumerate(nms_prediction['boxes']):\n",
        "    print(i, box.size(), type(box))"
      ],
      "metadata": {
        "id": "MG-AbblFgRdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(dir(nms_prediction))\n",
        "c = nms_prediction.copy()\n",
        "#help(nms_prediction)\n",
        "\n",
        "_c = {'boxes':None, 'labels':None, 'scores':None}\n",
        "for k in nms_prediction.keys():\n",
        "    for box in nms_prediction['boxes']:\n",
        "        left, top, right, bottom = box\n",
        "        center = (left + right) / 2\n",
        "        #print(left,top,right,bottom)"
      ],
      "metadata": {
        "id": "Qd0yPGrfja66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-Ls2mxwkcC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}