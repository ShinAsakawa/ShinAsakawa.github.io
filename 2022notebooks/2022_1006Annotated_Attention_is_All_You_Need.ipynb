{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1006Annotated_Attention_is_All_You_Need.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wArePITKUgQG"
      },
      "source": [
        "# トランスフォーマー注釈\n",
        "\n",
        "- [オリジナルブログ The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
        "- [オリジナル Colab code](https://drive.google.com/file/d/1xQXSv6mtAOLXxEMi8RvaW8TW-7bvYBDF/view)\n",
        "- [オリジナルブログの新バージョン](https://nlp.seas.harvard.edu/annotated-transformer/)\n",
        "- [新バージョンの GitHub リポジトリ](https://nlp.seas.harvard.edu/annotated-transformer/)\n",
        "\n",
        "- このファイル <https://drive.google.com/open?id=1naZHpTLgfLd54RcY4yi0WyQYoKf1yBBo>\n",
        "\n",
        "- [他の実装も参照](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html)\n",
        "\n",
        "<center>\n",
        "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_0_0.png\" width=\"49%\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWEk4ttUgQH"
      },
      "source": [
        "私は教える際，機械学習の最近の動向を理解する方法として，実装を重視しています。\n",
        "この投稿は， この目標に沿って自分を誠実に保つための試みです。\n",
        "NIPS 2017 で発表された最近の [Attention is All You Need](https://arxiv.org/abs/1706.03762) 論文は， 機械翻訳や 潜在的に自然言語処理 全般の新しい手法として， 瞬く間にインパクトのある論文となりました。\n",
        "この論文は非常にわかりやすく書かれていますが， これまでの常識では， 正しく実装するのはかなり難しいとされてきました。\n",
        "\n",
        "> この投稿では， 論文の最初から最後までを追い， 各構成要素をコードで実装してみました。\n",
        "(元の論文から若干の順序変更やスキップをしています)。\n",
        "この文書自体が作業用のノートであり， 完全に使用可能で効率的な実装であるべきです。\n",
        "[PyTorch](http://pytorch.org/) と [torchtext](https://github.com/pytorch/text) をインストールする必要があります。\n",
        "完全なコードは [github](https://github.com/harvardnlp/annotated-transformer) にあります。\n",
        "> - Alexander \"Sasha\" Rush ([@harvardnlp](https://twitter.com/harvardnlp))\n",
        "\n",
        "\n",
        "`Attention is All You Need` の Transformer は，昨年から多くの人の心をとらえている。\n",
        "翻訳品質の大幅な向上に加え，他の多くの NLP 課題に新しいアーキテクチャを提供している。\n",
        "この論文自体は非常にわかりやすく書かれていますが，正しく実装するのはかなり難しいというのがこれまでの常識であった。\n",
        "<!-- The Transformer from “Attention is All You Need” has been on a lot of people’s minds over the last year. \n",
        "Besides producing major improvements in translation quality, it provides a new architecture for many other NLP tasks. \n",
        "The paper itself is very clearly written, but the conventional wisdom has been that it is quite difficult to implement correctly.\n",
        "-->\n",
        "\n",
        "この投稿では，この論文の「注釈付き」バージョンを，一行ごとの実装という形で紹介する。\n",
        "元論文からいくつかの節を並べ替えたり削除したりし，全体的にコメントを追加している。\n",
        "この文書自体はワーキングノートであり，完全に使用可能な実装である。\n",
        "合計で 400 行のライブラリコードがあり，4 つの GPU で 1 秒間に 27,000 トークンを処理することができる。\n",
        "<!-- In this post I present an “annotated” version of the paper in the form of a line-by-line implementation. \n",
        "I have reordered and deleted some sections from the original paper and added comments throughout. \n",
        "This document itself is a working notebook, and should be a completely usable implementation. \n",
        "In total there are 400 lines of library code which can process 27,000 tokens per second on 4 GPUs.\n",
        "-->\n",
        "\n",
        "Alexander Rush (@harvardnlp or srush@seas.harvard.edu), with help from Vincent Nguyen and Guillaume Klein\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EAsw9f9pzu5"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaYyfFUqUnGY"
      },
      "outputs": [],
      "source": [
        "# if isColab:\n",
        "#     !pip install --upgrade pytorch torchtext numpy matplotlib spacy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4LTc4HW7UgQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9933bce2-90cf-4a29-a724-bdcb4d3b356c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting japanize_matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from japanize_matplotlib) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->japanize_matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->japanize_matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120275 sha256=aefa5402337dca041d77cfaa020a4ea1ef7a017080f26d205cc87e907dff833a\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/97/6b/e9e0cde099cc40f972b8dd23367308f7705ae06cd6d4714658\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n"
          ]
        }
      ],
      "source": [
        "# 標準的な PyTorch 関連ライブラリの輸入\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy\n",
        "from torch.autograd import Variable\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esxhOQubUgQL"
      },
      "source": [
        "# 1. 背景"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M-PiEMOUgQM"
      },
      "source": [
        "[Extended Neural GPU](https://arxiv.org/abs/1511.08228), [ByteNet](https://arxiv.org/abs/1610.10099), [ConvS2S](https://arxiv.org/abs/1705.03122) などのモデルでは，基本的な構成要素として畳み込みニューラルネットワークが用いられており，すべての入出力位置について隠れた表現を並列に計算している。\n",
        "これらのモデルでは， 任意の 2 つの入出力位置からの信号を関連付けるために必要な演算の数は，位置間の距離に応じて ConvS2S では線形に，ByteNet では対数的に増加する。\n",
        "このため，離れた位置間の依存関係を学習することが難しくなる。\n",
        "トランスフォーマーでは，注目度の高い位置を平均化することで実効的な解像度が低下するが，これは以下の多頭注意機構によって相殺され，一定の演算数に抑えられる。\n",
        "\n",
        "自己注意 (イントラ注意と呼ばれることもある) は 1 つの配列の異なる位置を関連づけて，その配列の表現を計算するための注意機構である。\n",
        "自己注意は，読解，抽象的な要約，テキストの含意，課題に依存しない文の表現の学習など，さまざまな課題で利用されています。\n",
        "エンド=2=エンド (煩雑な前処理や後処理が不要) の メモリネットワークは，配列に沿った再帰ではなく，再帰的な注意機構に基づいており，簡易な言語の質問応答や言語モデルの課題で優れた性能を発揮することが示されている。\n",
        "\n",
        "しかし，我々の知る限り，トランスフォーマーは，配列を揃えた RNN や畳み込みを使用せずに，自己注意に完全に依存して入力と出力の表現を計算する初めての伝達モデル (transduction model) である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84vTAA5TUgQM"
      },
      "source": [
        "# 2. モデル構成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBOvyU9BUgQN"
      },
      "source": [
        "ほとんどの競合するニューラルネットワーク トランスファーモデルは， 符号化器-復号化器構造を持っています[(Bahdanau2014)](https://arxiv.org/abs/1409.0473)\n",
        "<!-- (cho2014learning,bahdanau2014neural,sutskever14)。 -->\n",
        "ここで，符号化器は， 入力された記号表現の列 $(x_1, ..., x_n)$ を連続表現の列 $\\mathbf{z} = (z_1, ..., z_n)$ にマッピングします。\n",
        "復号化器は $\\mathbf{z}$ が与えられると，1 要素ずつ記号の出力系列 $(y_1,...,y_m)$ を生成します。\n",
        "各ステップにおいて， モデルは自己回帰的に [(Graves2013)](https://arxiv.org/abs/1308.0850) 次の記号を生成する際に， 前に生成された記号を追加入力として消費します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uF9j_Htnpzu7"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"典型的な 符号化器-復号化器 アーキテクチャ 基本モデル\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 encoder:nn.Module, \n",
        "                 decoder:nn.Module, \n",
        "                 src_embed:nn.Module, \n",
        "                 tgt_embed:nn.Module, \n",
        "                 generator:nn.Module):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, \n",
        "                src:torch.Tensor, \n",
        "                tgt:torch.Tensor, \n",
        "                src_mask:torch.Tensor, \n",
        "                tgt_mask:torch.Tensor):\n",
        "        \"\"\"マスク付きの ソース系列 と ターゲット系列を用いて処理\"\"\"\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, \n",
        "                           tgt, tgt_mask)\n",
        "    \n",
        "    def encode(self, \n",
        "               src:torch.Tensor, \n",
        "               src_mask:torch.Tensor):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "    \n",
        "    def decode(self, \n",
        "               memory:torch.Tensor, \n",
        "               src_mask:torch.Tensor, \n",
        "               tgt:torch.Tensor, \n",
        "               tgt_mask:torch.Tensor):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1AC8KeDJUgQO"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder_old(nn.Module):\n",
        "    \"\"\"典型的な 符号化器-復号化器 アーキテクチャ 基本モデル\"\"\"\n",
        "    def __init__(self, \n",
        "                 encoder:nn.Module, \n",
        "                 decoder:nn.Module, \n",
        "                 src_embed:nn.Module, \n",
        "                 tgt_embed:nn.Module, \n",
        "                 generator:nn.Module):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, \n",
        "                src, \n",
        "                tgt, \n",
        "                src_mask, \n",
        "                tgt_mask):\n",
        "        \"\"\"マスク化ソース `src` と目的系列を取り込み処理\"\"\"\n",
        "        memory = self.encoder(self.src_embed(src), src_mask)\n",
        "        output = self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip0EXqvEUgQQ"
      },
      "source": [
        "トランスフォーマーは，この全体的なアーキテクチャに沿って，図 1 の左半分と右半分にそれぞれ示されているように，符号化器と復号化器の両方に，積層自己注意と点毎の完全連結層を使用している。\n",
        "\n",
        "<center>\n",
        "<img src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png\" width=\"19%\"><br/>\n",
        "図 1. \n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euyRXbaMUgQR"
      },
      "source": [
        "## 2.1 符号化器と復号化器の積層\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKvRjPKF53JI"
      },
      "source": [
        "\n",
        "### 2.1.1 符号化器: \n",
        "\n",
        "符号化器は $N=6$ 枚の同じ層の積み重ねで構成される。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6yy7pY85UgQR"
      },
      "outputs": [],
      "source": [
        "def clones(module:nn.Module, N:int=1):\n",
        "    \"\"\"N 個の積層を作成するための関数。完全に同一な (identical) 層を複製\"\"\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "psiq5idJUgQT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"核となる符号化器 は N 層の積層\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 layer:nn.Module, \n",
        "                 N:int=1):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "        \n",
        "    def forward(self, \n",
        "                x:nn.Module, \n",
        "                mask:nn.Module):\n",
        "        \"\"\"入力（とマスク）を各層に順番に通す\"\"\"\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mie9sUeSUgQV"
      },
      "source": [
        "2 つの下位層それぞれの周りに **残差接続** [(He2015,ResNet)](https://arxiv.org/abs/1512.03385) を採用し，その後 **層正規化** [(LeiBa+2016)](https://arxiv.org/abs/1607.06450) を行う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sEz9kLClUgQV"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"層正規化モジュール  (詳細は原著 https://arxiv.org/abs/1607.06450)\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 features:int, \n",
        "                 eps:float=1e-6):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx4On5PCUgQY"
      },
      "source": [
        "つまり，各下位層の出力は `LayerNorm(x + Sublayer(x))` となり，`Sublayer(x)` は下位層自身が実装する関数である。\n",
        "各下位層の出力に **ドロップアウト**[(Srivastava+2014)](https://jmlr.org/papers/v15/srivastava14a.html) を適用してから，下位層の入力に加えて正規化する。 \n",
        "\n",
        "これらの残差接続を容易にするために，モデル内のすべての下位層と埋め込み層は，次元 $d_{\\text{model}}=512$ の出力を生成する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zx9JBwAcUgQY"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"正規化層に後続する残差接続\n",
        "    コードを簡単にするために，ノルムを最後に適用するのではなく，最初に適用することに注意\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 size:int, \n",
        "                 dropout:float):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(features=size)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"\"\"同一形状を維持するため，任意の SubLayer 関数に残差接続を適用\"\"\"\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZduB6mIlUgQa"
      },
      "source": [
        "各層には 2 つの下位層がある。\n",
        "1 つ目は多頭自己注意機構で，2 つ目は簡単な，位置ごと(point-wise) 完全連結フィードフォワードネットワークである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0mEBw9tIUgQb"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"符号化器は自己注意層とフィードフォワード (以下で定義) の 2 つの下位層で構成される\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 size:int, \n",
        "                 self_attn:nn.Module, \n",
        "                 feed_forward:nn.Module, \n",
        "                 dropout:float=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), size)\n",
        "        #self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, \n",
        "                x:nn.Module, \n",
        "                mask:nn.Module):\n",
        "        \"\"\"図 1 左 に従って接続\"\"\"\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHOZnpnBUgQd"
      },
      "source": [
        "### 2.1.2 復号化器:\n",
        "\n",
        "また，復号化器は $N=6$ 個の同一の階層の積み重ねで構成される。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3o_ZB42sUgQd"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"マスク付き復号化器化の一般化 N 層\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 layer:nn.Module, \n",
        "                 N:int=1):\n",
        "        super().__init__()\n",
        "        self.layers = clones(module=layer, N=N)\n",
        "        self.norm = LayerNorm(features=layer.size)\n",
        "        \n",
        "    def forward(self, \n",
        "                x:nn.Module, \n",
        "                memory:torch.Tensor, \n",
        "                src_mask:torch.Tensor, \n",
        "                tgt_mask:torch.Tensor):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOi_W1qaUgQf"
      },
      "source": [
        "各符号化器層の 2 つの下位層に加えて，復号化器は 3 つ目の下位層を挿入し，符号化器の積層の出力に対して多頭注意を行う。\n",
        "符号化器と同様，各下位層の周りに残差接続を採用し，その後，層正規化を行う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kMm6xHWVUgQg"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"復号化器は，`self-attn`, `src-attn`, フィードフォワード (以下で定義）の 3 つの下位層で構成される\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 size, \n",
        "                 self_attn, \n",
        "                 src_attn, \n",
        "                 feed_forward, \n",
        "                 dropout):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        " \n",
        "    def forward(self, \n",
        "                x, \n",
        "                memory, \n",
        "                src_mask:torch.Tensor, \n",
        "                tgt_mask:torch.Tensor):\n",
        "        \"\"\"接続は図 1 右 に従う\"\"\"\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nen9h7wUgQi"
      },
      "source": [
        "また，復号化器積層の自己注意下位層を変更し，位置が後続の位置に注意を向けないようにする。\n",
        "このマスクと，出力埋め込みが 1 位置分の離されていることを組み合わせることで，位置 $i$ の予測は，$i$ よりも小さい位置での既知の出力にのみ依存することが可能となる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RyQKI9AgUgQj"
      },
      "outputs": [],
      "source": [
        "def subsequent_mask(size:int)->torch.Tensor:\n",
        "    \"\"\"後続位置のマスク\"\"\"\n",
        "    \n",
        "    attn_shape = (1, size, size)\n",
        "    \n",
        "    # `np.triu` 上三角行列，k 次の三角行列を得る\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    \n",
        "    return torch.from_numpy(subsequent_mask) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgQMtvM-UgQl"
      },
      "outputs": [],
      "source": [
        "# 注意のマスクは，各目標単語 (行) が見ることを許される位置 (列) を示す。\n",
        "# 単語は訓練中に将来の単語を注目するためにブロックされる。\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(subsequent_mask(20)[0])\n",
        "plt.title('注意の後方マスク')\n",
        "plt.show()\n",
        "print(subsequent_mask(20)[0] * 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3twSbimFUgQq"
      },
      "source": [
        "### 2.1.3 注意: \n",
        "\n",
        "注意関数は，クエリとキーと値の対となる出力に写像する。\n",
        "クエリ，キー，バリュー，の出力はすべてベクトルである。\n",
        "出力は，バリューの加重和として計算され，各バリューに割り当てられた重みは，クエリと対応するキーの互換性関数によって計算される。\n",
        "\n",
        "この特別な注意を「規格化済み内積注意」と呼びことにする。\n",
        "入力は $d_k$ 次元のクエリとキー，$d_v$ 次元のバリューとからなる。\n",
        "クエリとすべてのキーの内積を計算し，それぞれを $\\sqrt{d_k}$ で割り，ソフトマックス関数を適用して値の重みを求める。\n",
        "\n",
        "<center>\n",
        "<img width=\"09%\" src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png\"><br/>\n",
        "</center>\n",
        "\n",
        "実際には，行列 $Q$ にまとめられた一連のクエリに対して同時に注意関数を計算します。\n",
        "キーとバリューも行列 $K$ と $V$ にまとめられる。\n",
        "出力の行列を以下のように計算する:\n",
        "                                                                 \n",
        "$$ \\mathrm{Attention}\\left(Q, K, V\\right) = \\mathrm{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wlZ8zw9PUgQr"
      },
      "outputs": [],
      "source": [
        "def attention(query:torch.Tensor, \n",
        "              key:torch.Tensor, \n",
        "              value:torch.Tensor, \n",
        "              mask:torch.Tensor=None, \n",
        "              dropout:float=0.0)->torch.Tensor:\n",
        "    \"\"\"`規格化内積型注意の計算\"\"\"\n",
        "    \n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    \n",
        "    # 以下で記述するドロップアウト\n",
        "    p_attn = F.dropout(p_attn, p=dropout)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV7cIqbrUgQs"
      },
      "source": [
        "最も一般的に使用される 2 つの注意関数は， Bahdanau の加算型注意 [(Bahdanau2014)](https://arxiv.org/abs/1409.0473)と，Luong の 内積型 (乗算型) 注意である [(Loung+2014)](https://aclanthology.org/D15-1166/)。\n",
        "内積型注意は，$\\displaystyle\\frac{1}{\\sqrt{d_k}}$ という規格化因子を除いて，ここでのアルゴリズムと同じある。\n",
        "加算型注意は，隠れ層が 1 つのフィードフォワードネットワークを使って互換性関数を計算する。\n",
        "この 2 つは理論的な複雑さは類似しているが，内積型注意は，高度に最適化された行列乗算コードを用いて実装できるため，実際にはより高速で，よりスペース効率の高いものとなる。\n",
        "\n",
        "$d_k$ の小さな値では 2 つの機構は同じような性能を発揮するが，$d_k$ が大きな値では規格化なしで加算的注意が内積注意を上回る [(Britz+2017)](https://arxiv.org/abs/1703.03906)。\n",
        "$d_k$ の値が大きくなると，内積の大きさが大きくなり，ソフトマックス関数の勾配が極端に小さくなる領域に押し込まれるのではないかと考えられる (内積が大きくなる理由を説明するために，$q$ と $k$ の成分が平均 $0$, 分散 $1$ の独立した確率変数であると仮定。\n",
        "そうすると，それらの内積である $\\displaystyle q \\cdot k = \\sum_{i=1}^{d_k} q_ik_i$ は 平均 $0$, 分散 $d_k$ となる)。\n",
        "この効果を打ち消すために，内積を $\\displaystyle\\frac{1}{\\sqrt{d_k}}$ で規格化する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiaCxaGGUgQt"
      },
      "source": [
        "### 2.1.4 多頭注意 multi-head attention\n",
        "\n",
        "$d_{\\text{model}}$ 次元のキー，バリュー， クエリで単一の注意関数を実行する代わりに，クエリ，キー，バリューをそれぞれ $d_k$ 次元, $d_k$ 次元, $d_v$ 次元に異なる，学習した線形射影で $h$ 回投影することが有益であることがわかった。\n",
        "\n",
        "これらの射影されたバージョンのクエリ，キー，バリューのそれぞれに対して，注意関数を並行して実行し，$d_v$ 次元の出力値を得る。\n",
        "これらは連結され，再び射影され，最終的な値が得られる。\n",
        "\n",
        "<center>\n",
        "<img width=\"13%\" src=\"http://nlp.seas.harvard.edu/images/the-annotated-transformer_38_0.png\"><br/>\n",
        "    図 2\n",
        "</center>\n",
        "\n",
        "多頭注意では，モデルは異なる位置にある異なる表現下位空間からの情報を共同で注目することができる。\n",
        "単一注意では，平均化がこれを阻害する。\n",
        "\n",
        "$$ \\mathrm{MultiHead}(Q, K, V) = \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O $$\n",
        "\n",
        "ここで，$\\mathrm{head_i}=\\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)$\n",
        "\n",
        "ここで，射影されるのは，パラメータ行列 $W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ と $W^O \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$ である。\n",
        "\n",
        "ここでは $h=8$ 個の並列注意層 (ヘッド) を採用している。\n",
        "それぞれのヘッドには $d_k=d_v=d_{\\text{model}}/h=64$ を使用する。\n",
        "各ヘッドの次元が小さくなったことで，全体の計算コストは，全次元の単一注意の場合と同様になる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_ea0UrEgUgQt"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, \n",
        "                 h:int=8,          # ヘッド数\n",
        "                 d_model:int=512,  # 埋め込み次元\n",
        "                 dropout=0.1       # ドロップアウト率\n",
        "                ):\n",
        "        \"\"\"モデル形状と頭の数を取り込み\"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        assert d_model % h == 0\n",
        "        \n",
        "        # d_v は常に d_k と等しいと仮定\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.p = dropout\n",
        "        self.linears = clones(nn.Linear(\n",
        "            in_features=d_model,\n",
        "            out_features=d_model), 4)\n",
        "        self.attn = None\n",
        "        \n",
        "    def forward(self, \n",
        "                query, \n",
        "                key, \n",
        "                value, \n",
        "                mask=None):\n",
        "        \"\"\"図 2 の実装\"\"\"\n",
        "        \n",
        "        if mask is not None:\n",
        "            # 全 h ヘッドに同一マスクを適用\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "        \n",
        "        # 1) すべての線形投影を一括して行う d_model => h x d_k\n",
        "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "                             for l, x in zip(self.linears, (query, key, value))]\n",
        "        \n",
        "        # 2) バッチ内のすべての投影されたベクトルに注意をかけます。\n",
        "        x, self.attn = attention(query, key, value, mask=mask, dropout=self.p)\n",
        "        \n",
        "        # 3) view  を使って “連結 concat” し 最終的に線形変換を適用する。 \n",
        "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVdpQ_KwUgQv"
      },
      "source": [
        "### 2.1.5 本モデルにおける注意の応用\n",
        "\n",
        "トランスフォーマーは， 多頭注意を 3 つの方法で使用している。\n",
        "\n",
        "\n",
        "1. ｢符号化器-復号化器注意｣層では，クエリは前の復号化層から，メモリのキーとバリューとは符号化器の出力から来る。\n",
        "これにより，復号化器のすべての位置が入力系列のすべての位置に注意することができる。\n",
        "これは [(2016Wu_Google翻訳)](https://arxiv.org/abs/1609.08144) のような seq-2-seq モデルにおける典型的な符号化器・符号化器の注意機構を模倣している。\n",
        "\n",
        "2. 符号化器は自己注意層を含む。自己注意層では，すべてのキー，バリュー，クエリは同じ場所，この場合，符号化器の前の層の出力から来る。\n",
        "符号化器の各位置は，符号化器の前の層のすべての位置に注意することができる。\n",
        "\n",
        "3. 同様に，復号化器の自己注意層は，復号化器内の各位置が，その位置までの復号化器内のすべての位置に注意することを可能にする。\n",
        "自己回帰性を維持するために，復号化器内の左向きの情報フローを防ぐ必要がある。\n",
        "ソフトマックスの入力のうち，不正な接続に対応する全ての値をマスクする (-∞ に設定する) ことにより，規格化内積型注意の内部でこれを実装する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gERLhK-FUgQw"
      },
      "source": [
        "## 2.2 位置毎 (point-wise) 順向ネットワーク\n",
        "\n",
        "注意下位層に加えて，符号化器と復号化器の各層には，完全結合のフィード・フォワード・ネットワークが含まれており，これは各位置に個別かつ同一に適用される。\n",
        "このネットワークは，ReLU 活性化を挟んだ 2 つの線形変換で構成される。\n",
        "\n",
        "$$ \\mathrm{FFN}(x)=\\max(0, xW_1 + b_1) W_2 + b_2 $$                                                                                      \n",
        "\n",
        "線形変換は，異なる位置では同じだが，層ごとに異なるパラメータを使用する。\n",
        "これを別の表現で表すと，カーネルサイズ 1 の 2 つの畳み込みとなる。\n",
        "入出力の次元は $d_{\\text{model}}=512$ であり，内部層の次元は $d_{ff}=2048$ である。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HuDPthO2UgQx"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\"完全結合ネットワーク FFN 式の実装\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 d_model, \n",
        "                 d_ff, \n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "        # Torch linears have a `b` by default. \n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68VLwifsUgQz"
      },
      "source": [
        "## 2.3 埋め込みとソフトマックス\n",
        "\n",
        "他の系列変換モデルと同様に，学習済み埋め込み層を用いて，入力トークンと出力トークンを次元 $d_{\\text{model}}$ のベクトルに変換する。\n",
        "また，復号化器の出力を次のトークンの予測確率に変換するために，通常の学習した線形変換とソフトマックス関数を使用する。\n",
        "我々のモデルでは [(PressWolf2016)](https://arxiv.org/abs/1608.05859) と同様に，2 つの埋め込み層と事前ソフトマックス線形変換の間で同じ重み行列を共有している。\n",
        "埋め込み層では，その重みに $\\sqrt{d_{\\text{model}}}$ を掛ける。\n",
        "\n",
        "<!-- Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension d_model. \n",
        "We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities. \n",
        "In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to (cite). \n",
        "In the embedding layers, we multiply those weights by √d_model. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sl5JzPeGUgQz"
      },
      "outputs": [],
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, \n",
        "                 d_model:int, \n",
        "                 vocab:int):\n",
        "        super().__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_hw5TyCUgQ1"
      },
      "source": [
        "## 2.4 位置符号化器\n",
        "\n",
        "モデルには再帰も畳み込みもないので，モデルが系列の順序を利用するためには，系列内のトークンの相対的または絶対的な位置に関する何らかの情報を注入する必要がある。\n",
        "そのために，符号化器と復号化器の積層の底部にある入力埋め込みに「位置符号化器」を追加する。\n",
        "位置符号化器は埋め込みと同一次元 $d_{\\text{model}}$ であり，2 つの埋め込みの和が取れるようになっている。\n",
        "位置符号化器には学習型と固定型の多くの選択肢がある [(JonasFaceNet2017)](https://arxiv.org/abs/1705.03122)。\n",
        "\n",
        "ここでは，異なる周波数の正弦波(サイン)と 余弦波 (コサイン) 関数を使用している。\n",
        "\n",
        "$$\n",
        "PE_{(\\text{pos},2i)}   = \\sin\\left(\\frac{\\text{pos}}{10000^{\\frac{2i}{d_{\\text{model}}}}}\\right)\\\\\n",
        "PE_{(\\text{pos},2i+1)} = \\cos\\left(\\frac{\\text{pos}}{10000^{\\frac{2i}{d_{\\text{model}}}}}\\right)\n",
        "$$\n",
        "\n",
        "ここで $pos$ は位置，$i$ は次元を表す。\n",
        "つまり，位置情報の各次元は，正弦波に対応している。\n",
        "波長は，$2\\pi$ から $10000\\cdot 2\\pi$ へと幾何学的に変化していく。\n",
        "この関数を選んだのは，任意の固定ズレ $k$ に対して $PE_{\\text{pos}+k}$ は $PE_{\\text{pos}}$ の一次関数として表現できるため，モデルが相対的な位置による注意を容易に学習できるのではないかと考えたからである。\n",
        "\n",
        "さらに，符号化積層と復号化積層の両方で，埋め込みと位置符号化の合計にドロップアウトを適用する。\n",
        "ベースモデルでは $P_{drop}=0.1$ の割合を使用している。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MVsjhp6uUgQ1"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"一符号化器の実装\"\"\"\n",
        "    def __init__(self, \n",
        "                 d_model:int=512, \n",
        "                 dropout:float=0.1, \n",
        "                 max_len=5000):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # 対数空間における位置符号化ベクトルの一度計算しておく\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        \n",
        "        # `register_buffer` パラメータではないがモジュールの状態の一部であるべきテンソルを指定。\n",
        "        # モジュールと同じデバイス上にある必要のあるテンソルに使用される\n",
        "        # `persistent=False` はバッファの状態の辞書に追加しないように PyTorch に指示する (例えばモデルを保存する場合など)。\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMsBRCuLUgQ3"
      },
      "outputs": [],
      "source": [
        "# 位置符号化器では，位置に応じて正弦波が加算される。\n",
        "# 波の周波数とオフセット(ズレ) は，各次元で異なる。\n",
        "plt.figure(figsize=(12, 4))\n",
        "pe = PositionalEncoding(20, 0)\n",
        "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
        "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
        "plt.legend([f\"次元 {p}\" for p in [4,5,6,7]])\n",
        "#plt.legend([\"dim %d\"%p for p in [4,5,6,7]])\n",
        "plt.show()\n",
        "#None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HjtmgH1UgQ5"
      },
      "source": [
        "また，学習した位置符号化 [(JonasFaceNet2017)](https://arxiv.org/abs/1705.03122) を代わりに使う実験も行った。\n",
        "だが，2 つはほぼ同じ結果を得た。\n",
        "正弦波版を選択したのは，学習時に遭遇したものよりも長い系列長にモデルを外挿することができるかもしれないからである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnFnHH9UgQ6"
      },
      "source": [
        "## 2.5 生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "heaKRIaZUgQ6"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"ベースとなる生成関数。(原著論文には記載なし)\"\"\"\n",
        "    def __init__(self, \n",
        "                 d_model:int=512, \n",
        "                 vocab:int=32000):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_features=d_model,\n",
        "                              out_features=vocab)\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        return F.log_softmax(input=self.proj(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3lP9fTUgQ9"
      },
      "source": [
        "## 2.6 完全モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b-LDhRoaUgQ-"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab:int, \n",
        "               tgt_vocab:int, \n",
        "               N:int=6, \n",
        "               d_model:int=512, \n",
        "               d_ff:int=2048,\n",
        "               h:int=8, \n",
        "               dropout:float=0.1):\n",
        "    \"\"\"ハイパーパラメータを指定したモデル構築のヘルパ関数\"\"\"\n",
        "    \n",
        "    c = copy.deepcopy\n",
        "    \n",
        "    attn = MultiHeadedAttention(\n",
        "        h=h, \n",
        "        d_model=d_model, \n",
        "        dropout=dropout)\n",
        "    \n",
        "    ff = PositionwiseFeedForward(\n",
        "        d_model=d_model, \n",
        "        d_ff=d_ff, \n",
        "        dropout=dropout)\n",
        "    \n",
        "    position = PositionalEncoding(\n",
        "        d_model=d_model, \n",
        "        dropout=dropout)\n",
        "    \n",
        "    model = EncoderDecoder(\n",
        "        encoder = Encoder(EncoderLayer(d_model, \n",
        "                                       c(attn), \n",
        "                                       c(ff), \n",
        "                                       dropout), \n",
        "                          N=N),\n",
        "        decoder = Decoder(DecoderLayer(d_model, \n",
        "                                       c(attn), \n",
        "                                       c(attn), \n",
        "                                       c(ff), \n",
        "                                       dropout), \n",
        "                          N=N),\n",
        "        src_embed = nn.Sequential(Embeddings(d_model, \n",
        "                                             src_vocab), \n",
        "                                  c(position)),\n",
        "        tgt_embed = nn.Sequential(Embeddings(d_model, \n",
        "                                             tgt_vocab), \n",
        "                                  c(position)),\n",
        "        generator = Generator(d_model=d_model, vocab=tgt_vocab))\n",
        "    \n",
        "    # 初期化はコード上，重要 (らしい。ブログによると)\n",
        "    # Glorot (ザビエルの初期化) あるいは `fan_avg` でパラメータを初期化\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qP-g4KfhUgQ_"
      },
      "outputs": [],
      "source": [
        "# おもちゃモデルで評価\n",
        "tmp_model = make_model(src_vocab=10, tgt_vocab=10, N=2)\n",
        "tmp_model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuV1e8nEUgRB"
      },
      "source": [
        "# 3. 訓練\n",
        "\n",
        "本節では，我々のモデルの訓練の体制について説明る。\n",
        "\n",
        "ここでは、標準的な符号化器-復号化器モデルを学習するために必要な道具を簡単に解説する。\n",
        "まず，学習用の ソース `src` 文と 目標 `target` 文を保持するバッチオブジェクトを定義し，マスクを作成する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz6n3REAUgRH"
      },
      "source": [
        "## 3.1 学習データとバッチ処理\n",
        "\n",
        "<!-- 約 450 万の文対からなる標準的な WMT 2014 英独データセットで学習を行いました。\n",
        "文は バイトペアエンコーディング cite{DBLP:journals/corr/BritzGLL17} を用いて符号化されており，約 37000 トークンのソース-ターゲット語彙が共有されています。\n",
        "英仏語については，3600 万文からなるかなり大規模な WMT2014 英仏語データセットを使用し，トークンを 32000 語ピースの語彙に分割しました [(cite)](wu2016google)。\n",
        "-->\n",
        "\n",
        "<!-- 文の対は，おおよその配列の長さごとにまとめられました。\n",
        "各学習バッチには，約 25000 個のソーストークンと約 25000 個のターゲットトークンを含む文対のセットが含まれています。 -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xwbbb4UgRK"
      },
      "source": [
        "## 3.2 ハードウェアとスケジュール\n",
        "\n",
        "<!-- 8 台の NVIDIA P100 GPU を搭載した 1 台のマシンでモデルの学習を行いました。\n",
        "本稿で紹介したハイパーパラメータを用いた基本モデルでは，各訓練ステップに約 0.4 秒かかりました。\n",
        "ベースモデルの学習には，合計 100,000 ステップ，12 時間を要しました。\n",
        "ビッグモデルの場合，ステップタイムは 1.0 秒でした。\n",
        "大規模モデルは 300,000 ステップ (3.5 日) の訓練を行いました。 -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPp__T_uUgRK"
      },
      "source": [
        "## 3.3 最適化\n",
        "\n",
        "Adam 最適化 [(kingma2014adam)](https://arxiv.org/abs/1412.6980) を使用し $\\beta_1=0.9$, $\\beta_2=0.98$, $\\epsilon=10^{-9}$ とした。\n",
        "学習の過程で学習率を式にしたがって変化させた。\n",
        "\n",
        "$$\n",
        "\\text{lrate} = d_{\\text{model}}^{-0.5} \\cdot \\min({\\text{step_num}}^{-0.5}, \n",
        "(\\text{step_num} \\cdot {\\text{warmup_steps}}^{-1.5}) $$\n",
        "\n",
        "これは、最初の $\\text{warmup_steps}$ の学習ステップでは学習率を線形に増加させ，その後はステップ数の逆平方根に比例して学習率を減少させることに相当する。\n",
        "ここでは $\\text{warmup_steps}=4000$ とした。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Q5yV0f2QUgRL"
      },
      "outputs": [],
      "source": [
        "# 注: この部分は非常に重要。\n",
        "# モデルが非常に不安定な場合は，このセットアップで訓練する必要がある。\n",
        "class NoamOpt:\n",
        "    \"\"\"rate を実装した最適化関数のラッパー\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 model_size, \n",
        "                 factor, \n",
        "                 warmup, \n",
        "                 optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"\"\"パラメータと rate の更新\"\"\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"\"\"上記 `lrate` の実装\"\"\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup**(-1.5)))\n",
        "        \n",
        "def get_std_opt(model):\n",
        "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
        "            torch.optim.Adam(model.parameters(), \n",
        "                             lr=0, \n",
        "                             betas=(0.9, 0.98), \n",
        "                             eps=1e-9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC2wCVEFUgRO"
      },
      "outputs": [],
      "source": [
        "# ハイパーパラメータ `lrate` の 3 つの設定\n",
        "opts = [NoamOpt(512, 1, 4000, None), \n",
        "        NoamOpt(512, 1, 8000, None),\n",
        "        NoamOpt(256, 1, 4000, None)]\n",
        "plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n",
        "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
        "plt.show()\n",
        "#None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tkzxQYKUgRQ"
      },
      "source": [
        "## 3.4 正則化\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVbTo8qt9Ru0"
      },
      "source": [
        "\n",
        "### 3.4.1 ラベル平滑化\n",
        "\n",
        "学習時には，$\\epsilon_{ls}=0.1$ [(Szegedy2015)](https://arxiv.org/abs/1512.00567) のラベル平滑化を採用した。\n",
        "これは， モデルがより不確かになるように学習するため，パープレキシティ (錯乱度) を悪化させるが，精度と BLEU 得点を向上させる。\n",
        "\n",
        "KL ダイバージェンス損失を用いてラベルの平滑化を行う。\n",
        "ワンホットのターゲット分布ではなく，正解の確信度と残りの平滑化量を語彙全体に分散させた分布を作成。\n",
        "<!-- We implement label smoothing using the KL div loss. \n",
        "Instead of using a one-hot target distribution, we create a distribution that has confidence of the correct word and the rest of the smoothing mass distributed throughout the vocabulary. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IVWDJLXrUgRQ"
      },
      "outputs": [],
      "source": [
        "class LabelSmoothing(nn.Module):\n",
        "    \"Implement label smoothing.\"\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(size_average=False)\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "        \n",
        "    def forward(self, x, target):\n",
        "        assert x.size(1) == self.size\n",
        "        \n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq_1cTzZpzvC"
      },
      "source": [
        "信頼度に応じた質量の単語への分配の例を見ることができる。\n",
        "<!-- Here we can see an example of how the mass is distributed to the words based on confidence. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gXwt5HVUgRT"
      },
      "outputs": [],
      "source": [
        "#Example\n",
        "crit = LabelSmoothing(5, 0, 0.5)\n",
        "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
        "                             [0, 0.2, 0.7, 0.1, 0], \n",
        "                             [0, 0.2, 0.7, 0.1, 0]])\n",
        "v = crit(Variable(predict.log()), \n",
        "         Variable(torch.LongTensor([2, 1, 0])))\n",
        "\n",
        "# 系が期待する目標分布を表示\n",
        "plt.imshow(crit.true_dist)\n",
        "plt.show()\n",
        "#None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHBHTwmjUgRU"
      },
      "outputs": [],
      "source": [
        "# 与えられた選択肢に非常に自信を持った場合\n",
        "# ラベル平滑化はモデルにペナルティを与え始める \n",
        "crit = LabelSmoothing(5, 0, 0.1)\n",
        "#crit = LabelSmoothing(5, 0, 0.2)\n",
        "\n",
        "def loss(x):\n",
        "    d = x + 3 * 1\n",
        "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d], ])\n",
        "    \n",
        "    #print(predict.log())\n",
        "    return crit(Variable(predict.log()),\n",
        "                 Variable(torch.LongTensor([1]))).item() \n",
        "\n",
        "plt.plot(np.arange(1, 100), [loss(x) for x in range(1, 100)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoyfFgLoUgRW"
      },
      "source": [
        "### 3.4.2 メモリ最適化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yVKyONFsUgRW"
      },
      "outputs": [],
      "source": [
        "def loss_backprop(generator, criterion, out, targets, normalize):\n",
        "    \"\"\"\n",
        "    Memory optmization. Compute each timestep separately and sum grads.\n",
        "    \"\"\"\n",
        "    assert out.size(1) == targets.size(1)\n",
        "    total = 0.0\n",
        "    out_grad = []\n",
        "    for i in range(out.size(1)):\n",
        "        out_column = Variable(out[:, i].data, requires_grad=True)\n",
        "        gen = generator(out_column)\n",
        "        loss = criterion(gen, targets[:, i]) / normalize\n",
        "        total += loss.item()\n",
        "        #total += loss.data[0]\n",
        "        loss.backward()\n",
        "        out_grad.append(out_column.grad.data.clone())\n",
        "    out_grad = torch.stack(out_grad, dim=1)\n",
        "    out.backward(gradient=out_grad)\n",
        "    return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LiTlbMq2UgRY"
      },
      "outputs": [],
      "source": [
        "def make_std_mask(src, tgt, pad):\n",
        "    src_mask = (src != pad).unsqueeze(-2)\n",
        "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & Variable(subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "    return src_mask, tgt_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sSF9AaKJUgRZ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_iter, model, criterion, opt, transpose=False):\n",
        "    model.train()\n",
        "    for i, batch in enumerate(train_iter):\n",
        "        src, trg, src_mask, trg_mask = \\\n",
        "            batch.src, batch.trg, batch.src_mask, batch.trg_mask\n",
        "        out = model.forward(src, trg[:, :-1], src_mask, trg_mask[:, :-1, :-1])\n",
        "        loss = loss_backprop(model.generator, criterion, out, trg[:, 1:], batch.ntokens) \n",
        "                        \n",
        "        model_opt.step()\n",
        "        model_opt.optimizer.zero_grad()\n",
        "        if i % 10 == 1:\n",
        "            print(f'{i:5d}, loss:{loss:.3f}, model_opt._rate:{model_opt._rate:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "q4kFYs7nUgRb"
      },
      "outputs": [],
      "source": [
        "def valid_epoch(valid_iter, model, criterion, transpose=False):\n",
        "    model.test()\n",
        "    total = 0\n",
        "    for batch in valid_iter:\n",
        "        src, trg, src_mask, trg_mask = \\\n",
        "            batch.src, batch.trg, batch.src_mask, batch.trg_mask\n",
        "        out = model.forward(src, trg[:, :-1], src_mask, trg_mask[:, :-1, :-1])\n",
        "        loss = loss_backprop(model.generator, criterion, out, trg[:, 1:], batch.ntokens) \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uJo5AZasUgRd"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    \n",
        "    \"\"\"学習時にマスクで一括してデータを保持するためのオブジェクト\"\"\"\n",
        "    def __init__(self, \n",
        "                 src, \n",
        "                 trg, \n",
        "                 src_mask, \n",
        "                 trg_mask, \n",
        "                 ntokens):\n",
        "        self.src = src\n",
        "        self.trg = trg\n",
        "        self.src_mask = src_mask\n",
        "        self.trg_mask = trg_mask\n",
        "        self.ntokens = ntokens\n",
        "    \n",
        "def data_gen(V, batch, nbatches):\n",
        "    for i in range(nbatches):\n",
        "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
        "        src = Variable(data, requires_grad=False)\n",
        "        tgt = Variable(data, requires_grad=False)\n",
        "        src_mask, tgt_mask = make_std_mask(src, tgt, 0)\n",
        "        yield Batch(src, tgt, src_mask, tgt_mask, (tgt[1:] != 0).data.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrpU5b2sUgRe",
        "outputId": "05b4d6c0-3365-4f62-e0af-babfd201aa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1, loss:2.940, model_opt._rate:0.0000\n",
            "   11, loss:2.822, model_opt._rate:0.0000\n",
            "    1, loss:2.534, model_opt._rate:0.0000\n",
            "   11, loss:2.358, model_opt._rate:0.0000\n"
          ]
        }
      ],
      "source": [
        "V = 11\n",
        "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
        "model = make_model(V, V, N=2)\n",
        "model_opt = get_std_opt(model)\n",
        "for epoch in range(2):\n",
        "    train_epoch(data_gen(V, 30, 20), model, criterion, model_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBf8No4ppzvD"
      },
      "source": [
        "## A. 最初の例\n",
        "<!-- ## A. A First Example-->\n",
        "\n",
        "まず，簡単な複写課題を試してみよう。\n",
        "小さな語彙からなるランダムな入力記号の集合が与えられたら，同じ記号を生成して返すことが目標である。\n",
        "<!-- We can begin by trying out a simple copy-task. \n",
        "Given a random set of input symbols from a small vocabulary, the goal is to generate back those same symbols. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PParA0GApzvD"
      },
      "source": [
        "#### A. Batches and Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vYKIBaOipzvD"
      },
      "outputs": [],
      "source": [
        "class _Batch:\n",
        "    \"\"\"学習時にマスクで一括してデータを保持するためのオブジェクト\"\"\"\n",
        "    \n",
        "    def __init__(self, src, trg=None, pad=0):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if trg is not None:\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = \\\n",
        "                self.make_std_mask(self.trg, pad)\n",
        "            self.ntokens = (self.trg_y != pad).data.sum()\n",
        "    \n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & Variable(\n",
        "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "        return tgt_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlY-qZVUpzvD"
      },
      "source": [
        "### A. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "d7vz8uGZpzvD"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def run_epoch(data_iter, \n",
        "              model, \n",
        "              loss_compute)->torch.Tensor:\n",
        "    \"\"\"標準的な訓練とログ関数\"\"\"\n",
        "    \n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        out = model.forward(batch.src, batch.trg, \n",
        "                            batch.src_mask, batch.trg_mask)\n",
        "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        tokens += batch.ntokens\n",
        "        if i % 50 == 1:\n",
        "            elapsed = time.time() - start\n",
        "            print(f\"エポック ステップ: {i:3d} 損失: {loss/batch.ntokens:.3f} トークン数/秒: {tokens/elapsed:.3f}\")\n",
        "            # print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "            #         (i, loss / batch.ntokens, tokens / elapsed))\n",
        "            start = time.time()\n",
        "            tokens = 0\n",
        "    return total_loss / total_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpydXL2upzvE"
      },
      "source": [
        "### A.1 合成データ\n",
        "<!-- ### Synthetic Data -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ii-MGZaNpzvE"
      },
      "outputs": [],
      "source": [
        "def data_gen(V, \n",
        "             batch, \n",
        "             nbatches):\n",
        "    \"\"\"src-tgt 複写課題のためのランダムなデータを生成\"\"\"\n",
        "    \n",
        "    for i in range(nbatches):\n",
        "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
        "        data[:, 0] = 1\n",
        "        src = Variable(data, requires_grad=False)\n",
        "        tgt = Variable(data, requires_grad=False)\n",
        "        yield _Batch(src, tgt, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4rT4-SqpzvE"
      },
      "source": [
        "### A.2 損失の計算\n",
        "<!-- #### Loss Computation -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DIwyY5OopzvE"
      },
      "outputs": [],
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"簡単な損失値の計算と学習関数\"\"\"\n",
        "    \n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "        \n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
        "                              y.contiguous().view(-1)) / norm\n",
        "        loss.backward()\n",
        "        if self.opt is not None:\n",
        "            self.opt.step()\n",
        "            self.opt.optimizer.zero_grad()\n",
        "        return loss.item() * norm\n",
        "        #return loss.data[0] * norm    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI9B0q_DpzvE"
      },
      "source": [
        "### A.3 貪欲復号化\n",
        "<!-- ### A.3 Greedy Decoding -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbC5-SO-pzvE",
        "outputId": "24f3e353-9218-4dd9-ba91-36c8dbc753b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "エポック ステップ:   1 損失: 3.107 トークン数/秒: 473.198\n",
            "エポック ステップ:   1 損失: 1.930 トークン数/秒: 603.217\n",
            "\t\t検証損失: 1.927\n",
            "エポック ステップ:   1 損失: 1.978 トークン数/秒: 490.135\n",
            "エポック ステップ:   1 損失: 1.647 トークン数/秒: 605.666\n",
            "\t\t検証損失: 1.639\n",
            "エポック ステップ:   1 損失: 1.764 トークン数/秒: 481.187\n",
            "エポック ステップ:   1 損失: 1.277 トークン数/秒: 609.721\n",
            "\t\t検証損失: 1.278\n",
            "エポック ステップ:   1 損失: 1.847 トークン数/秒: 476.432\n",
            "エポック ステップ:   1 損失: 1.145 トークン数/秒: 606.831\n",
            "\t\t検証損失: 1.049\n",
            "エポック ステップ:   1 損失: 1.388 トークン数/秒: 483.936\n",
            "エポック ステップ:   1 損失: 0.727 トークン数/秒: 607.359\n",
            "\t\t検証損失: 0.784\n",
            "エポック ステップ:   1 損失: 0.883 トークン数/秒: 492.548\n",
            "エポック ステップ:   1 損失: 0.506 トークン数/秒: 619.217\n",
            "\t\t検証損失: 0.487\n",
            "エポック ステップ:   1 損失: 0.694 トークン数/秒: 505.130\n",
            "エポック ステップ:   1 損失: 0.433 トークン数/秒: 619.672\n",
            "\t\t検証損失: 0.386\n",
            "エポック ステップ:   1 損失: 0.429 トークン数/秒: 506.038\n",
            "エポック ステップ:   1 損失: 0.236 トークン数/秒: 613.529\n",
            "\t\t検証損失: 0.253\n",
            "エポック ステップ:   1 損失: 0.287 トークン数/秒: 507.322\n",
            "エポック ステップ:   1 損失: 0.127 トークン数/秒: 608.473\n",
            "\t\t検証損失: 0.167\n",
            "エポック ステップ:   1 損失: 0.450 トークン数/秒: 495.366\n",
            "エポック ステップ:   1 損失: 0.225 トークン数/秒: 619.490\n",
            "\t\t検証損失: 0.237\n"
          ]
        }
      ],
      "source": [
        "# 簡単な複写課題を訓練する\n",
        "V = 11\n",
        "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
        "model = make_model(src_vocab=V, \n",
        "                   tgt_vocab=V, \n",
        "                   N=2)\n",
        "model_opt = NoamOpt(\n",
        "    model_size = model.src_embed[0].d_model, \n",
        "    factor=1, \n",
        "    warmup=400,\n",
        "    optimizer=torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    run_epoch(data_iter=data_gen(V, 30, 20), \n",
        "              model=model, \n",
        "              loss_compute = SimpleLossCompute(\n",
        "                  generator = model.generator, \n",
        "                  criterion=criterion, \n",
        "                  opt=model_opt))\n",
        "    model.eval()\n",
        "    print('\\t\\t検証損失: %.3f'%run_epoch(data_iter=data_gen(V, 30, 5), \n",
        "                                 model=model,\n",
        "                                 loss_compute=SimpleLossCompute(\n",
        "                                     generator=model.generator, \n",
        "                                     criterion=criterion,\n",
        "                                     opt=None)).detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79toqdvPpzvE"
      },
      "source": [
        "簡単のために貪欲復号化を用いて予測\n",
        "<!-- This code predicts a translation using greedy decoding for simplicity. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A6o77aqpzvE",
        "outputId": "2ee80a94-ad28-453e-8e15-fac6bdd0a23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n"
          ]
        }
      ],
      "source": [
        "def greedy_decode(model:nn.Module, \n",
        "                  src:torch.Tensor, \n",
        "                  src_mask:torch.Tensor, \n",
        "                  max_len:int, \n",
        "                  start_symbol:int):\n",
        "    \n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len-1):\n",
        "        out = model.decode(memory, \n",
        "                           src_mask, \n",
        "                           Variable(ys), \n",
        "                           Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat([ys, \n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "    return ys\n",
        "\n",
        "model.eval()\n",
        "src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) )\n",
        "src_mask = Variable(torch.ones(1, 1, 10) )\n",
        "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S2BcIoOUgRg"
      },
      "source": [
        "# 4. 実際例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP_oq0kLUgRh"
      },
      "outputs": [],
      "source": [
        "# # For data loading.\n",
        "# from torchtext import data, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKynVliVXg6F"
      },
      "outputs": [],
      "source": [
        "# if isColab:\n",
        "#     !pip install torchtext spacy\n",
        "#     !python -m spacy download en\n",
        "#     !python -m spacy download de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4NlcPQ-pzvF"
      },
      "source": [
        "以下は，torchtext が動作しないで fault する。\n",
        "\n",
        "おそらく，allennlp や transformers などが用いられる理由が，このような `torchtext` の不安定さによるのだろう。\n",
        "Huggeingface の transformers は普及しているし，通常の使い方ではこれで十分なように感じられる。\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXtYwdHqUgRj"
      },
      "outputs": [],
      "source": [
        "# Load words from IWSLT\n",
        "\n",
        "#!pip install torchtext spacy\n",
        "#!python -m spacy download en\n",
        "#!python -m spacy download de\n",
        "\n",
        "import spacy\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "import torchtext\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "BLANK_WORD = \"<blank>\"\n",
        "#SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
        "SRC = torchtext.legacy.data.field(tokenize=tokenize_de, \n",
        "                                  lower=True, \n",
        "                                  pad_token=BLANK_WORD,\n",
        "                                  init_token=BOS_WORD, \n",
        "                                  eos_token=EOS_WORD)\n",
        "TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
        "                 eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
        "\n",
        "MAX_LEN = 100\n",
        "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(SRC, TGT), \n",
        "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
        "MIN_FREQ = 1\n",
        "SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
        "TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8MTIJTWUgRl"
      },
      "outputs": [],
      "source": [
        "# Detail. Batching seems to matter quite a bit. \n",
        "# This is temporary code for dynamic batching based on number of tokens.\n",
        "# This code should all go away once things get merged in this library.\n",
        "\n",
        "BATCH_SIZE = 4096\n",
        "global max_src_in_batch, max_tgt_in_batch\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)\n",
        "\n",
        "class MyIterator(data.Iterator):\n",
        "    def create_batches(self):\n",
        "        if self.train:\n",
        "            def pool(d, random_shuffler):\n",
        "                for p in data.batch(d, self.batch_size * 100):\n",
        "                    p_batch = data.batch(\n",
        "                        sorted(p, key=self.sort_key),\n",
        "                        self.batch_size, self.batch_size_fn)\n",
        "                    for b in random_shuffler(list(p_batch)):\n",
        "                        yield b\n",
        "            self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "        else:\n",
        "            self.batches = []\n",
        "            for b in data.batch(self.data(), self.batch_size,\n",
        "                                          self.batch_size_fn):\n",
        "                self.batches.append(sorted(b, key=self.sort_key))\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"Fix order in torchtext to match ours\"\n",
        "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
        "    src_mask, trg_mask = make_std_mask(src, trg, pad_idx)\n",
        "    return Batch(src, trg, src_mask, trg_mask, (trg[1:] != pad_idx).data.sum())\n",
        "\n",
        "train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0,\n",
        "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "                        batch_size_fn=batch_size_fn, train=True)\n",
        "valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0,\n",
        "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "                        batch_size_fn=batch_size_fn, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wamR3SPdUgRo"
      },
      "outputs": [],
      "source": [
        "# Create the model an load it onto our GPU.\n",
        "pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
        "model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
        "model_opt = get_std_opt(model)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SStCCZoiUgRp"
      },
      "outputs": [],
      "source": [
        "\n",
        "criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\n",
        "criterion.cuda()\n",
        "for epoch in range(15):\n",
        "    train_epoch((rebatch(pad_idx, b) for b in train_iter), model, criterion, model_opt)\n",
        "    valid_epoch((rebatch(pad_idx, b) for b in valid_iter), model, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NO9lsw2UgRt"
      },
      "source": [
        "\n",
        "OTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8BVm-hEUgRw"
      },
      "outputs": [],
      "source": [
        "BOS_WORD = '<s>'\n",
        "EOS_WORD = '</s>'\n",
        "BLANK_WORD = \"<blank>\"\n",
        "SRC = data.Field()\n",
        "TGT = data.Field(init_token = BOS_WORD, eos_token = EOS_WORD, pad_token=BLANK_WORD) # only target needs BOS/EOS\n",
        "\n",
        "MAX_LEN = 100\n",
        "train = datasets.TranslationDataset(path=\"/n/home00/srush/Data/baseline-1M_train.tok.shuf\", \n",
        "                                    exts=('.en', '.fr'),\n",
        "                                    fields=(SRC, TGT), \n",
        "                                    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
        "SRC.build_vocab(train.src, max_size=50000)\n",
        "TGT.build_vocab(train.trg, max_size=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFdZyOIzUgRx"
      },
      "outputs": [],
      "source": [
        "pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
        "print(pad_idx)\n",
        "model = make_model(len(SRC.vocab), len(TGT.vocab), pad_idx, N=6)\n",
        "model_opt = get_opt(model)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cinuTkbtUgRz"
      },
      "outputs": [],
      "source": [
        "criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, label_smoothing=0.1)\n",
        "criterion.cuda()\n",
        "for epoch in range(15):\n",
        "    train_epoch(train_iter, model, criterion, model_opt)\n",
        "    valid_epoch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LadFBIEUgR3"
      },
      "outputs": [],
      "source": [
        "print(pad_idx)\n",
        "print(len(SRC.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP_Au0bHUgR7"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"/n/rush_lab/trans_ipython.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqKKIhoOUgR-"
      },
      "outputs": [],
      "source": [
        "#weight = torch.ones(len(TGT.vocab))\n",
        "#weight[pad_idx] = 0\n",
        "#criterion = nn.NLLLoss(size_average=False, weight=weight.cuda())\n",
        "criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, label_smoothing=0.1)\n",
        "criterion.cuda()\n",
        "for epoch in range(15):\n",
        "    train_epoch(train_iter, model, criterion, model_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35JC6i9QUgSB"
      },
      "outputs": [],
      "source": [
        "1 10.825187489390373 6.987712429686844e-07\n",
        "101 9.447168171405792 3.56373333914029e-05\n",
        "201 7.142856806516647 7.057589553983712e-05\n",
        "301 6.237934365868568 0.00010551445768827134\n",
        "401 5.762486848048866 0.00014045301983670557\n",
        "501 5.415792358107865 0.00017539158198513977\n",
        "601 5.081815680023283 0.000210330144133574\n",
        "701 4.788327748770826 0.00024526870628200823\n",
        "801 4.381739928154275 0.0002802072684304424\n",
        "901 4.55433791608084 0.00031514583057887664\n",
        "1001 4.911875109748507 0.0003500843927273108\n",
        "1101 4.0579032292589545 0.0003850229548757451\n",
        "1201 4.2276234351193125 0.0004199615170241793\n",
        "1301 3.932735869428143 0.00045490007917261356\n",
        "1401 3.8179439397063106 0.0004898386413210477\n",
        "1501 3.3608515430241823 0.000524777203469482\n",
        "1601 3.832796103321016 0.0005597157656179162\n",
        "1701 2.907085266895592 0.0005946543277663504\n",
        "1801 3.5280659823838505 0.0006295928899147847\n",
        "1901 2.895841649500653 0.0006645314520632189\n",
        "2001 3.273784235585481 0.000699470014211653\n",
        "2101 3.181488689899197 0.0007344085763600873\n",
        "2201 3.4151616653980454 0.0007693471385085215\n",
        "2301 3.4343731447588652 0.0008042857006569557\n",
        "2401 3.0505455391539726 0.0008392242628053899\n",
        "2501 2.8089329147478566 0.0008741628249538242\n",
        "2601 2.7827929875456903 0.0009091013871022583\n",
        "2701 2.4428516102489084 0.0009440399492506926\n",
        "2801 2.4015486147254705 0.0009789785113991267\n",
        "2901 2.3568112018401735 0.001013917073547561\n",
        "3001 2.6349758653668687 0.0010488556356959952\n",
        "3101 2.5981983028614195 0.0010837941978444295\n",
        "3201 2.666826274838968 0.0011187327599928637\n",
        "3301 3.0092043554177508 0.0011536713221412978\n",
        "3401 2.4580375660589198 0.0011886098842897321\n",
        "3501 2.586465588421561 0.0012235484464381662\n",
        "3601 2.5663993963389657 0.0012584870085866006\n",
        "3701 2.9430236657499336 0.0012934255707350347\n",
        "3801 2.464644919440616 0.001328364132883469\n",
        "3901 2.7124062888276512 0.0013633026950319032\n",
        "4001 2.646443709731102 0.0013971932312809247\n",
        "4101 2.7294750874862075 0.001380057517579748\n",
        "4201 2.1295202329056337 0.0013635372009002666\n",
        "4301 2.596563663915731 0.001347596306985731\n",
        "4401 2.1265982036820787 0.0013322017384983986\n",
        "4501 2.3880532500334084 0.0013173229858148\n",
        "4601 2.6129120760888327 0.0013029318725783852\n",
        "4701 2.2873719420749694 0.001289002331178292\n",
        "4801 2.4949760700110346 0.0012755102040816328\n",
        "4901 2.496607314562425 0.001262433067573089\n",
        "5001 2.1889712483389303 0.0012497500749750088\n",
        "5101 1.8677761815488338 0.0012374418168536253\n",
        "5201 2.2992054556962103 0.0012254901960784316\n",
        "5301 2.664361578106707 0.0012138783159049418\n",
        "5401 2.705850490485318 0.0012025903795063202\n",
        "5501 2.581445264921058 0.0011916115995949978\n",
        "5601 2.2480602325085783 0.0011809281169581616\n",
        "5701 1.9289666265249252 0.0011705269268863989\n",
        "5801 2.4863578918157145 0.0011603958126073107\n",
        "5901 2.632946971571073 0.0011505232849492607\n",
        "6001 2.496141305891797 0.0011408985275576757\n",
        "6101 2.6422974687084206 0.0011315113470699342\n",
        "6201 2.448802186456305 0.0011223521277270118"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}