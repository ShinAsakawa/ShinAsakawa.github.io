{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0627sala_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8086cbc-98d1-4ac8-8442-c3cc22584949",
      "metadata": {
        "id": "e8086cbc-98d1-4ac8-8442-c3cc22584949"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "\n",
        "    import nltk\n",
        "    nltk.download('wordnet')    \n",
        "    nltk.download('omw-1.4')    \n",
        "\n",
        "    import os\n",
        "    if os.path.exists('ccap'):\n",
        "        import shutil\n",
        "        shutil.rmtree('ccap')\n",
        "    !git clone https://github.com/project-ccap/ccap.git\n",
        "\n",
        "   \n",
        "try:    \n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    \n",
        "from ccap import salaDataset\n",
        "sala = salaDataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sala.show_all_images()"
      ],
      "metadata": {
        "id": "ZXVxG9yT0avR"
      },
      "id": "ZXVxG9yT0avR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1541b875-79c5-42aa-9225-a99b92b8b2ee",
      "metadata": {
        "id": "1541b875-79c5-42aa-9225-a99b92b8b2ee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25512a0e-b8d2-4c23-a1c7-278b5333806e",
      "metadata": {
        "id": "25512a0e-b8d2-4c23-a1c7-278b5333806e"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "_image_size = 224\n",
        "_mean = [0.485, 0.456, 0.406]\n",
        "_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "train_trans = transforms.Compose([\n",
        "    transforms.Resize((_image_size,_image_size)),\n",
        "    transforms.RandomAffine(degrees=(-10,+10), scale=(0.8,1.2)),\n",
        "    transforms.ColorJitter(.1, .1, .1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])\n",
        "\n",
        "val_trans = transforms.Compose([\n",
        "    transforms.Resize((_image_size,_image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d04937-069c-4933-9ed0-05ea909773a4",
      "metadata": {
        "id": "99d04937-069c-4933-9ed0-05ea909773a4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a354a9-ec9f-4dc2-aef4-78e83b6b276c",
      "metadata": {
        "id": "b3a354a9-ec9f-4dc2-aef4-78e83b6b276c"
      },
      "outputs": [],
      "source": [
        "sala(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "597dca3b-fbe9-4e12-890a-acde5346e336",
      "metadata": {
        "id": "597dca3b-fbe9-4e12-890a-acde5346e336"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import PIL\n",
        "\n",
        "#from torchvision.datasets.folder import ImageFolder, default_loader\n",
        "#from torchvision.datasets.utils import download_url, check_integrity\n",
        "\n",
        "class SALADataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    SALA の画像データ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sala=salaDataset(),\n",
        "        #root_path:str='./ccap/data',  #/sala_imgs',\n",
        "        transform=train_trans,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        data = {}\n",
        "        for idx in range(sala.__len__()):\n",
        "            img_fname, label = sala(idx)\n",
        "            data[idx] = {'fname': img_fname,\n",
        "                         'label': label,\n",
        "                        }\n",
        "        self.data = data\n",
        "        \n",
        "        self.idx2name = list(data.keys())\n",
        "        self.name2idx = {x:i for i, x in enumerate(self.idx2name)}\n",
        "        self.transform = transform\n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, x):\n",
        "        name = self.idx2name[x]\n",
        "        img_fname = self.data[name]['fname']\n",
        "        img = PIL.Image.open(img_fname)\n",
        "        _img = train_trans(img)\n",
        "        return _img, x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "train_dataset = SALADataset()\n",
        "val_dataset = SALADataset(transform=val_trans)\n",
        "\n",
        "def matplotlib_imshow_pt(img:torch.tensor, \n",
        "                         one_channel:bool=False,\n",
        "                         figsize:tuple=(15,15)):\n",
        "    \"\"\"PyTorch の tensor データを画像として表示する\"\"\"\n",
        "    \n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    img /= 255\n",
        "    npimg = img.numpy().clip(0,1)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "images = []\n",
        "for i in range(32):\n",
        "    for _ in range(8):\n",
        "        images.append(train_dataset.__getitem__(i)[0])\n",
        "        img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "#matplotlib_imshow_pt(img_grid, one_channel=False, figsize=(20,10))\n",
        "plt.figure(figsize=(10,64))\n",
        "plt.imshow(img_grid.numpy().transpose(1,2,0).clip(0,1))\n"
      ],
      "metadata": {
        "id": "K-u_orP1QNb7"
      },
      "id": "K-u_orP1QNb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/vision/stable/auto_examples/plot_visualization_utils.html#sphx-glr-auto-examples-plot-visualization-utils-py\n",
        "\n",
        "N = np.random.choice(train_dataset.__len__())\n",
        "img = train_dataset.__getitem__(N)[0]\n",
        "#_img = img.permute(1,2,0).clone()\n",
        "_img = img.permute(1,2,0).clone().numpy()\n",
        "print(f'_img.shape:{_img.shape}', \n",
        "      f'_img.max():{_img.max():.2f}'\n",
        "      f' _img.min():{ _img.min():.2f}')\n",
        "#_img = torchvision.transforms.functional.to_pil_image(_img)\n",
        "plt.title(str(N))\n",
        "plt.imshow(_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "63Zs3pguQWk6"
      },
      "id": "63Zs3pguQWk6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094eee4a-766e-4e91-8e40-035d3cca9554",
      "metadata": {
        "id": "094eee4a-766e-4e91-8e40-035d3cca9554"
      },
      "outputs": [],
      "source": [
        "train_dataset = SALADataset()\n",
        "val_dataset = SALADataset(transform=val_trans)\n",
        "print(train_dataset.__getitem__(0)[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 128\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")"
      ],
      "metadata": {
        "id": "-iFmYZrXQbMX"
      },
      "id": "-iFmYZrXQbMX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71d9a74-6b4b-4160-a4ef-7dfbfdbbf107",
      "metadata": {
        "id": "f71d9a74-6b4b-4160-a4ef-7dfbfdbbf107"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b4aa51-3343-4137-821c-415e5533e91d",
      "metadata": {
        "id": "b2b4aa51-3343-4137-821c-415e5533e91d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import torchsummary\n",
        "except ImportError:\n",
        "    !pip install torhcsummary\n",
        "\n",
        "# 次行以下のコメントを外すとモデルの構成が表示される\n",
        "# import torchsummary\n",
        "# torchsummary.summary(model, (3, 224, 224), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49308a71-5f75-476c-ba1e-a452927a5dca",
      "metadata": {
        "id": "49308a71-5f75-476c-ba1e-a452927a5dca"
      },
      "outputs": [],
      "source": [
        "# 転移学習に際して，どの層を学習させて，どの層を固定するかによって，性能も学習時間も異なる\n",
        "# 本セルは，そのためのユーティリティ関数\n",
        "def get_trainable(model_params):\n",
        "    return (p for p in model_params if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_frozen(model_params):\n",
        "    return (p for p in model_params if not p.requires_grad)\n",
        "\n",
        "\n",
        "def all_trainable(model_params):\n",
        "    return all(p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def all_frozen(model_params):\n",
        "    return all(not p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def freeze_all(model_params):\n",
        "    for param in model_params:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4b83ac-82ff-4420-bb08-81d2e791b3cb",
      "metadata": {
        "id": "ef4b83ac-82ff-4420-bb08-81d2e791b3cb"
      },
      "outputs": [],
      "source": [
        "# 全結合係数を固定\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# 同じことを関数として実施\n",
        "freeze_all(model.parameters())\n",
        "assert all_frozen(model.parameters())    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed4bd11-58f1-40c8-ac43-0e77faeae9e2",
      "metadata": {
        "id": "2ed4bd11-58f1-40c8-ac43-0e77faeae9e2"
      },
      "outputs": [],
      "source": [
        "#help(transforms.RandomRotation)\n",
        "#help(transforms.RandomAffine)\n",
        "#transforms.RandomAffine(degrees=[-15,-5,5,10], scale=(0.8,1.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f207dce8-a2de-4751-b040-c75edeb3c971",
      "metadata": {
        "id": "f207dce8-a2de-4751-b040-c75edeb3c971"
      },
      "source": [
        "最終直下層を入れ替えて， `requires_grad=True` に設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2232d08f-c4dd-4399-b105-40839ab5f8f3",
      "metadata": {
        "id": "2232d08f-c4dd-4399-b105-40839ab5f8f3"
      },
      "outputs": [],
      "source": [
        "n_classes = train_dataset.__len__()\n",
        "model.fc = nn.Linear(512, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65492cc3-957f-465d-a31e-a2db6695b836",
      "metadata": {
        "id": "65492cc3-957f-465d-a31e-a2db6695b836"
      },
      "outputs": [],
      "source": [
        "def get_model(n_classes=n_classes):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    freeze_all(model.parameters())\n",
        "    model.fc = nn.Linear(512, n_classes)\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33595cd9-d0dd-4244-850f-a327511e0d20",
      "metadata": {
        "id": "33595cd9-d0dd-4244-850f-a327511e0d20"
      },
      "outputs": [],
      "source": [
        "#model;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001e61d2-dbcc-4548-8f3e-ebf73af9671f",
      "metadata": {
        "id": "001e61d2-dbcc-4548-8f3e-ebf73af9671f"
      },
      "outputs": [],
      "source": [
        "# 交差エントロピーを損失関数として用いる\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3ffdeb-d548-4740-9130-e64132eaea25",
      "metadata": {
        "id": "9f3ffdeb-d548-4740-9130-e64132eaea25"
      },
      "outputs": [],
      "source": [
        "# 最適化には Adam を使う\n",
        "optimizer = torch.optim.Adam(\n",
        "    get_trainable(model.parameters()),\n",
        "    lr=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 授業時間に終わるように， N_EPOCHS = の調整が必要。N_EPOCHS=10 程度でも 7 割程度の性能は得られるようだ。\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "N_EPOCHS = 30\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    model.eval()\n",
        "    total_loss, n_correct, n_samples = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_ = model(X)\n",
        "            \n",
        "            _, y_label_ = torch.max(y_, 1)\n",
        "            n_correct += (y_label_ == y).sum().item()\n",
        "            loss = criterion(y_, y)\n",
        "            total_loss += loss.item() * X.shape[0]\n",
        "            n_samples += X.shape[0]\n",
        "\n",
        "    print(f\"エポック {epoch+1:2d}/{N_EPOCHS:2d} \",\n",
        "          f\"検証損失: {total_loss / n_samples:.3f} \",\n",
        "          f\"検証精度: {n_correct / n_samples * 100:.2f}%\", end=\"\\t\")\n",
        "    \n",
        "    model.train()\n",
        "    total_loss, n_correct, n_samples = 0.0, 0, 0\n",
        "    for batch_i, (X, y) in enumerate(train_dl):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_ = model(X)\n",
        "        loss = criterion(y_, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        _, y_label_ = torch.max(y_, 1)\n",
        "        n_correct += (y_label_ == y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "        n_samples += X.shape[0]\n",
        "    \n",
        "    print(f\"訓練損失: {total_loss / n_samples:.3f} \",\n",
        "          f\"訓練精度: {n_correct / n_samples * 100:.2f}%\")\n",
        "    "
      ],
      "metadata": {
        "id": "PdcAZiTJSGA3"
      },
      "id": "PdcAZiTJSGA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_, wrong_ = {}, {}\n",
        "model.eval()\n",
        "for i in range(val_dataset.__len__()):\n",
        "    X, y = val_dataset.__getitem__(i)\n",
        "    #print(X.size())\n",
        "    _y = model(X.unsqueeze(0).to(device))\n",
        "    _, pred = torch.max(_y, 1)\n",
        "\n",
        "    correct = sala(i)[1]\n",
        "    pred_label = sala(int(pred[0].cpu().numpy()))[1]\n",
        "    if correct == pred_label:\n",
        "        correct_[i] = {'正解':sala(i)[1], '予測':sala(int(pred[0].cpu().numpy()))[1]}\n",
        "    else:\n",
        "        wrong_[i] = {'正解':correct,\n",
        "                     '予測':pred_label,\n",
        "                     '予測ID': int(pred[0].cpu().numpy())\n",
        "                    }\n",
        "\n",
        "for k, v in wrong_.items():\n",
        "    print(k,v)\n",
        "    sala.show_an_image(k)\n",
        "    sala.show_an_image(v['予測ID'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C-9NqZNuStvG"
      },
      "id": "C-9NqZNuStvG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習結果を保存\n",
        "torch.save(model,'sala_transfer_learned_from_resnet.pt')\n",
        "\n",
        "if isColab:\n",
        "    # 保存した結果をダウンロード\n",
        "    from google.colab import files\n",
        "    files.download('sala_transfer_learned_from_resnet.pt')"
      ],
      "metadata": {
        "id": "zY2-iQgMmdva"
      },
      "id": "zY2-iQgMmdva",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0627sala_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}