{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0627sala_picture_naming_task_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8086cbc-98d1-4ac8-8442-c3cc22584949",
      "metadata": {
        "id": "e8086cbc-98d1-4ac8-8442-c3cc22584949"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1\n",
        "    import os\n",
        "    import shutil\n",
        "    if os.path.exists('bit'):\n",
        "        shutil.rmtree('bit')\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "if isColab:\n",
        "    import nltk\n",
        "    nltk.download('wordnet')    \n",
        "    nltk.download('omw-1.4')    \n",
        "    import os\n",
        "    if os.path.exists('ccap'):\n",
        "        import shutil\n",
        "        shutil.rmtree('ccap')\n",
        "    !git clone https://github.com/project-ccap/ccap.git\n",
        "\n",
        "try:    \n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    \n",
        "from ccap import salaDataset\n",
        "sala = salaDataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 全 SALA 画像を表示するには，直下行の行頭 # を削除してから実行\n",
        "#sala.show_all_images()"
      ],
      "metadata": {
        "id": "ZXVxG9yT0avR"
      },
      "id": "ZXVxG9yT0avR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1541b875-79c5-42aa-9225-a99b92b8b2ee",
      "metadata": {
        "id": "1541b875-79c5-42aa-9225-a99b92b8b2ee"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "_image_size = 224\n",
        "_mean = [0.485, 0.456, 0.406]\n",
        "_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_trans = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(_image_size),\n",
        "    #transforms.RandomRotation(degrees=(-10,10))\n",
        "    transforms.RandomAffine(degrees=(-15,+15), scale=(0.6,1.4)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(.3, .3, .3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])\n",
        "\n",
        "val_trans = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(_image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(_mean, _std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d04937-069c-4933-9ed0-05ea909773a4",
      "metadata": {
        "id": "99d04937-069c-4933-9ed0-05ea909773a4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "597dca3b-fbe9-4e12-890a-acde5346e336",
      "metadata": {
        "id": "597dca3b-fbe9-4e12-890a-acde5346e336"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import PIL\n",
        "#from torchvision.datasets.folder import ImageFolder, default_loader\n",
        "#from torchvision.datasets.utils import download_url, check_integrity\n",
        "\n",
        "class SALADataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    SALA の画像データ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sala=salaDataset(),\n",
        "        #root_path:str='./ccap/data',  #/sala_imgs',\n",
        "        transform=train_trans,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        data = {}\n",
        "        for idx in range(sala.__len__()):\n",
        "            img_fname, label = sala(idx)\n",
        "            data[idx] = {'fname': img_fname,\n",
        "                         'label': label,\n",
        "                        }\n",
        "        self.data = data\n",
        "        \n",
        "        self.idx2name = list(data.keys())\n",
        "        self.name2idx = {x:i for i, x in enumerate(self.idx2name)}\n",
        "        self.transform = transform\n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, x):\n",
        "        name = self.idx2name[x]\n",
        "        img_fname = self.data[name]['fname']\n",
        "        img = PIL.Image.open(img_fname)\n",
        "        _img = train_trans(img)\n",
        "        return _img, x\n",
        "\n",
        "\n",
        "train_dataset = SALADataset()\n",
        "val_dataset = SALADataset(transform=val_trans)\n",
        "print(train_dataset.__getitem__(0)[0].size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18616340-7f88-4f30-9eb4-a52288dcbd33",
      "metadata": {
        "id": "18616340-7f88-4f30-9eb4-a52288dcbd33"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "val_dl = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/vision/stable/auto_examples/plot_visualization_utils.html#sphx-glr-auto-examples-plot-visualization-utils-py\n",
        "\n",
        "N = np.random.choice(train_dataset.__len__())\n",
        "img = train_dataset.__getitem__(N)[0]\n",
        "_img = img.permute(1,2,0).clone()\n",
        "_img = img.permute(1,2,0).clone().numpy()\n",
        "print(f'_img.shape:{_img.shape}', \n",
        "      f'_img.max():{_img.max():.2f}'\n",
        "      f' _img.min():{ _img.min():.2f}')\n",
        "#_img = torchvision.transforms.functional.to_pil_image(_img)\n",
        "\n",
        "plt.imshow(_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R2QsCFVgDz3n"
      },
      "id": "R2QsCFVgDz3n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b4aa51-3343-4137-821c-415e5533e91d",
      "metadata": {
        "id": "b2b4aa51-3343-4137-821c-415e5533e91d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import torchsummary\n",
        "except ImportError:\n",
        "    !pip install torhcsummary\n",
        "\n",
        "# 次行以下のコメントを外すとモデルの構成が表示される\n",
        "# import torchsummary\n",
        "# torchsummary.summary(model, (3, 224, 224), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49308a71-5f75-476c-ba1e-a452927a5dca",
      "metadata": {
        "id": "49308a71-5f75-476c-ba1e-a452927a5dca"
      },
      "outputs": [],
      "source": [
        "# 転移学習に際して，どの層を学習させて，どの層を固定するかによって，性能も学習時間も異なる\n",
        "# 本セルは，そのためのユーティリティ関数\n",
        "def get_trainable(model_params):\n",
        "    return (p for p in model_params if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_frozen(model_params):\n",
        "    return (p for p in model_params if not p.requires_grad)\n",
        "\n",
        "\n",
        "def all_trainable(model_params):\n",
        "    return all(p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def all_frozen(model_params):\n",
        "    return all(not p.requires_grad for p in model_params)\n",
        "\n",
        "\n",
        "def freeze_all(model_params):\n",
        "    for param in model_params:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f207dce8-a2de-4751-b040-c75edeb3c971",
      "metadata": {
        "id": "f207dce8-a2de-4751-b040-c75edeb3c971"
      },
      "source": [
        "最終直下層を入れ替えて， `requires_grad=True` に設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65492cc3-957f-465d-a31e-a2db6695b836",
      "metadata": {
        "id": "65492cc3-957f-465d-a31e-a2db6695b836"
      },
      "outputs": [],
      "source": [
        "n_classes = sala.__len__()\n",
        "\n",
        "def get_model(n_classes=n_classes):\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    freeze_all(model.parameters())\n",
        "    model.fc = nn.Linear(512, n_classes)\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "model = get_model(n_classes=sala.__len__())\n",
        "\n",
        "# 全結合係数を固定\n",
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False\n",
        "    \n",
        "# 同じことを関数として実施\n",
        "#nfreeze_all(model.parameters())\n",
        "#assert all_frozen(model.parameters())    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33595cd9-d0dd-4244-850f-a327511e0d20",
      "metadata": {
        "id": "33595cd9-d0dd-4244-850f-a327511e0d20"
      },
      "outputs": [],
      "source": [
        "#model;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001e61d2-dbcc-4548-8f3e-ebf73af9671f",
      "metadata": {
        "id": "001e61d2-dbcc-4548-8f3e-ebf73af9671f"
      },
      "outputs": [],
      "source": [
        "# 交差エントロピーを損失関数として用いる\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3ffdeb-d548-4740-9130-e64132eaea25",
      "metadata": {
        "id": "9f3ffdeb-d548-4740-9130-e64132eaea25"
      },
      "outputs": [],
      "source": [
        "# 最適化には Adam を使う\n",
        "optimizer = torch.optim.Adam(\n",
        "    get_trainable(model.parameters()),\n",
        "    lr=0.001,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a00929-033d-4cf8-8201-0263b0c05287",
      "metadata": {
        "id": "11a00929-033d-4cf8-8201-0263b0c05287"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# 授業時間に終わるように， N_EPOCHS = の調整が必要。N_EPOCHS=10 程度でも 7 割程度の性能は得られるようだ。\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "N_EPOCHS = 30\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    total_loss, n_correct, n_samples = 0.0, 0, 0\n",
        "    for batch_i, (X, y) in enumerate(train_dl):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_ = model(X)\n",
        "        loss = criterion(y_, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        _, y_label_ = torch.max(y_, 1)\n",
        "        n_correct += (y_label_ == y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "        n_samples += X.shape[0]\n",
        "    \n",
        "    print(\n",
        "        f\"エポック {epoch+1:2d}/{N_EPOCHS:2d} \"\n",
        "        f\"訓練損失: {total_loss / n_samples:.3f} \"\n",
        "        f\"訓練精度: {n_correct / n_samples * 100:.2f}%\"\n",
        "    )\n",
        "    \n",
        "    \n",
        "    model.eval()\n",
        "    total_loss, n_correct, n_samples = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_ = model(X)\n",
        "            \n",
        "            _, y_label_ = torch.max(y_, 1)\n",
        "            n_correct += (y_label_ == y).sum().item()\n",
        "            loss = criterion(y_, y)\n",
        "            total_loss += loss.item() * X.shape[0]\n",
        "            n_samples += X.shape[0]\n",
        "\n",
        "    print(\n",
        "        f\"エポック {epoch+1:2d}/{N_EPOCHS:2d} \"\n",
        "        f\"検証損失: {total_loss / n_samples:.3f} \"\n",
        "        f\"検証精度: {n_correct / n_samples * 100:.2f}%\"\n",
        "    )\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習結果を保存\n",
        "torch.save(model,'sala_transfer_learned_from_resnet.pt')\n",
        "\n",
        "if isColab:\n",
        "    # 保存した結果をダウンロード\n",
        "    from google.colab import files\n",
        "    files.download('sala_transfer_learned_from_resnet.pt')"
      ],
      "metadata": {
        "id": "zY2-iQgMmdva"
      },
      "id": "zY2-iQgMmdva",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0627sala_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}