{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMdf3fXa2hawrm3+fSBtFM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1210bit_line_bisection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git > /dev/null\n",
        "    import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    # 2022_0916 現在 PIL のバージョンが古く truetype フォント\n",
        "    # の表示に不具合が出るためバージョン 9.2.0 以上に更新する\n",
        "    !pip install --upgrade Pillow\n",
        "\n",
        "fonts_jp = bit.get_notojp_fonts()\n",
        "fonts_en = bit.get_notoen_fonts()"
      ],
      "metadata": {
        "id": "moT9LtTZDV-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from PIL import ImageFont\n",
        "\n",
        "noto_font_dir = 'fonts'\n",
        "notofonts_fnames = glob(os.path.join(noto_font_dir,'*otf'))\n",
        "notofonts = {fname.split('/')[-1].split('.')[0]:{'fname':fname} for fname in notofonts_fnames}\n",
        "for fontname in notofonts.keys():\n",
        "    notofonts[fontname]['data'] = ImageFont.truetype(notofonts[fontname]['fname'])\n",
        "#notofonts;\n",
        "symbols = bit.BIT(fontdata=notofonts).symbols     # 文字の登録\n",
        "print(symbols)"
      ],
      "metadata": {
        "id": "TJgJgRlyEYK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import typing\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "if isColab:\n",
        "    from PIL import ImageFont\n",
        "    from glob import glob\n",
        "\n",
        "    !pip install pycocotools --quiet\n",
        "    !git clone https://github.com/pytorch/vision.git\n",
        "    !git checkout v0.3.0\n",
        "\n",
        "    # Download TorchVision repo to use some files from references/detection\n",
        "    # os.symlink(src,dst) にした方が良いかも\n",
        "    !cp vision/references/detection/utils.py ./\n",
        "    !cp vision/references/detection/transforms.py ./\n",
        "    !cp vision/references/detection/coco_eval.py ./\n",
        "    !cp vision/references/detection/engine.py ./\n",
        "    !cp vision/references/detection/coco_utils.py ./\n",
        "    \n",
        "    !pip install japanize_matplotlib\n",
        "    #!pip install albumentataions  # 2022_0604 一時的に中断 colab でエラー発生のため\n",
        "    \n",
        "    # 自作ライブラリ\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "\n",
        "    # Noto fonts のダウンロードとインストール\n",
        "    !mkdir Noto_JP_fonts\n",
        "    !wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSerifJP.zip\n",
        "    !wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSansJP.zip\n",
        "    !unzip NotoSerifJP.zip -d Noto_JP_fonts\n",
        "    !unzip -o NotoSansJP.zip -d Noto_JP_fonts  # `-o` means overwrite \n",
        "    !mv Noto_JP_fonts bit\n",
        "    !mkdir data\n",
        "    \n",
        "    noto_font_dir = './bit/Noto_JP_fonts'\n",
        "    notofonts_fnames = glob(os.path.join(noto_font_dir,'*otf'))\n",
        "    notofonts = {fname.split('/')[-1].split('.')[0]:{'fname':fname} for fname in notofonts_fnames}\n",
        "    for fontname in notofonts.keys():\n",
        "        notofonts[fontname]['data'] = ImageFont.truetype(notofonts[fontname]['fname'])\n",
        "else:\n",
        "    # 自分のリポジトリからシンボリックリンクで代用\n",
        "    for file in ['engine.py', 'utils.py', 'coco_utils.py', 'transforms.py', 'coco_eval.py']:\n",
        "        if not os.path.exists(file):\n",
        "            _file = os.path.join('../2020pytorch_vision.git/reference/detection/', file)\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/engine.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/utils.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/coco_utils.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/transforms.py .\n",
        "            !ln -s ../2020pytorch_vision.git/references/detection/coco_eval.py ."
      ],
      "metadata": {
        "id": "6joMqarDDagV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのインポート\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "    \n",
        "\n",
        "# torchvision ライブラリ\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# ヘルパライブラリをインポート\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T"
      ],
      "metadata": {
        "id": "VspHVtq0De3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_object_detection_model(num_classes):\n",
        "    \"\"\"see https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\"\"\"\n",
        "    # MS-COCO で事前に学習させたモデルを読み込み\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # 分類器の入力特徴数の取得\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    print(f'変換前 model.roi_heads:{model.roi_heads}')\n",
        "\n",
        "    # 事前学習済頭部を新しいものに置き換え\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
        "    print(f'変換後 model.roi_heads:{model.roi_heads}')\n",
        "\n",
        "    return model\n",
        "\n",
        "num_classes = len(symbols)\n",
        "#num_classes = len(bit.symbols)\n",
        "bit_model = get_object_detection_model(num_classes)\n",
        "print(f'num_classes:{num_classes}, bit.symbols:{symbols}')\n",
        "#print(f'num_classes:{num_classes}, bit.symbols:{bit.symbols}')\n",
        "#bit_model.roi_heads"
      ],
      "metadata": {
        "id": "7FjfJXKYEnyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4jCzhOgCEUW"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# データの ID を入れて，データを入手\n",
        "download = drive.CreateFile({'id': '1KhP4iAP_tc28EV5fyo95pKuQrNOAX-bT'})\n",
        "download.GetContentFile('2022_0620fine_tuned_bit_line_bisection.cpt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_fname = '2022_0620fine_tuned_bit_line_bisection.cpt'\n",
        "bit_model.load_state_dict(torch.load(pretrained_fname)['model'])"
      ],
      "metadata": {
        "id": "rnwU8keGC_4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_bit = bit.BIT(fontdata=notofonts)\n",
        "images, bboxes = _bit.make_line_bisection_task_images(N=5, n_lines=3)\n",
        "img = images[4] "
      ],
      "metadata": {
        "id": "tT4kGJSrHvFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#images, bboxes = bit.make_line_bisection_task_images(N=1, n_lines=3)\n",
        "#img = images[0] \n",
        "images, bboxes = _bit.make_line_bisection_task_images(N=5, n_lines=3)\n",
        "img = images[4] "
      ],
      "metadata": {
        "id": "6KHyZnsBDQz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "7-vV1OFLHOk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "\n",
        "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
        "    \n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "    return final_prediction\n",
        "\n",
        "\n",
        "def torch_to_pil(img):\n",
        "    \"\"\"torchtensor を PIL 画像に変換する関数\"\"\"\n",
        "    return torchtrans.ToPILImage()(img).convert('RGB')\n",
        "\n",
        "\n",
        "def plot_img_bbox(img, target, title=None):\n",
        "    \"\"\"画像中のバウンディングボックスを可視化する関数\"\"\"\n",
        "    # バウンディングボックスは以下のように定義されます: x-min y-min 幅 高さ\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    fig.set_size_inches(7,7)\n",
        "    ax.imshow(img)\n",
        "    print(target)\n",
        "    \n",
        "    for box in target['boxes']:\n",
        "        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
        "        rect = patches.Rectangle((x, y),\n",
        "                                 width, height,\n",
        "                                 linewidth = 4,\n",
        "                                 edgecolor = 'red',\n",
        "                                 facecolor = 'none')\n",
        "\n",
        "        # 画像上にバウンディングボックスを描画 # Draw the bounding box on top of the image\n",
        "        ax.add_patch(rect)\n",
        "        \n",
        "    if title != None:\n",
        "        ax.set_title(title)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def draw_center_mark(img_pt:torch.Tensor=None,\n",
        "                     prediction:dict=None,\n",
        "                     check_mark_offset:int=6,\n",
        "                     check_mark_width:int=4,\n",
        "                     check_mark_color:tuple=(0,255,0),\n",
        "                     title=None,\n",
        "                     img:PIL.Image=None,\n",
        "                    ):\n",
        "\n",
        "    if img == None:\n",
        "        img = torch_to_pil(img_pt)\n",
        "    _draw = PIL.ImageDraw.Draw(img)\n",
        "    #_draw = ImageDraw.Draw(img)\n",
        "\n",
        "    boxes = prediction['boxes']\n",
        "    for box in boxes:\n",
        "        left, top, right, bottom = box.clone().numpy()\n",
        "        #print(left,top,right,bottom)\n",
        "        h_center = int((right - left)/2 + left)\n",
        "        v_center = int((bottom - top)/2 + top)\n",
        "    \n",
        "        x0 = h_center - check_mark_offset\n",
        "        y0 = v_center - check_mark_offset\n",
        "        x1 = h_center + check_mark_offset\n",
        "        y1 = v_center + check_mark_offset\n",
        "        _draw.line(xy=[(x0,y0),(x1,y1)], fill=check_mark_color, width=check_mark_width, joint=None)\n",
        "    \n",
        "    return img, _draw\n",
        "    "
      ],
      "metadata": {
        "id": "dIBVcKsrHcgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def make_a_prediction(n_lines:int=3):\n",
        "    images, bboxes = _bit.make_line_bisection_task_images(N=1, n_lines=n_lines)\n",
        "    img = images[0] \n",
        "    img_rgb = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "    img_res = cv2.resize(img_rgb, (224, 224), cv2.INTER_AREA)\n",
        "    img_res /= 255.0\n",
        "    img_pt = torch.Tensor(img_res).permute(2,0,1)\n",
        "\n",
        "    bit_model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = bit_model([img_pt.to(device)])[0]\n",
        "        \n",
        "    return img, img_pt, prediction\n",
        "    \n",
        "    \n",
        "def make_a_stim_then_predict(n_lines:int=3,\n",
        "                             verbose:bool=False,\n",
        "                             isDraw:bool=False,\n",
        "                            ):\n",
        "\n",
        "    img, img_pt, prediction = make_a_prediction(n_lines=n_lines)\n",
        "    if verbose:\n",
        "        plot_img_bbox(torch_to_pil(img_pt), \n",
        "                      {'boxes':bboxes[0]}, title=\"正解\")\n",
        "\n",
        "    _img, _draw = draw_center_mark(img_pt=img_pt, prediction=prediction, \n",
        "                                   check_mark_width=2,\n",
        "                                   check_mark_color='red')\n",
        "    if isDraw:\n",
        "        plt.figure(figsize=(7,7))\n",
        "        plt.title('モデル')\n",
        "        plt.imshow(_img)\n",
        "        plt.show()\n",
        "    return prediction, _img, _draw\n",
        "    \n",
        "prediction, img, draw = make_a_stim_then_predict(\n",
        "    isDraw=True,\n",
        "    verbose=False,\n",
        ")\n",
        "#print(prediction)\n",
        "#plt.imshow(img)"
      ],
      "metadata": {
        "id": "MBOVWPkMIC0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juQSIRWQIFU7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}