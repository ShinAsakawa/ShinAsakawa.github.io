{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0205minnichi_lm_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGOEPoodXD0e"
      },
      "source": [
        "- date: 2022_0206\n",
        "- filename: 2022_0205minnichi_lm_generator.ipynb\n",
        "\n",
        "# [「みんなの日本語」](https://www.3anet.co.jp/np/books/2300/) 語彙を用いた [符号化ー復号化 (encoder-decoder) モデル](https://arxiv.org/pdf/1409.3215) による言語生成\n",
        "\n",
        "- 想定発表媒体: 某日本語教育研究会論文誌\n",
        "- 著者: 岩下 智彦，吉原 将大，浅川伸一\n",
        "\n",
        "\n",
        "### かなり無駄な薀蓄:\n",
        "\n",
        "このファイルを自分のローカル PC で動作させるためには，Python の処理系とブラウザベースの統合実行環境，たとえば ```jupyter-notebook``` または ```jupyter-lab``` が必要になります。\n",
        "OS が MacOSX であれば，パッケージ管理 [homebrew](https://brew.sh/) と Python ライブラリ管理 [anaconda](https://www.anaconda.com/products/individual) がインストール済であれば便利です。\n",
        "加えて，`PyTorch`, `MeCab`, `jaconv`, `japanize_matplotlib`, `konoha`, `sacrebleu` と言った，ライブラリをインストールしておく必要があります。\n",
        "以下に上記 4 つのライブラリのインスールを行うサンプルオペレーションを示します。\n",
        "\n",
        "```bash\n",
        "conda install pytorch torchvision torchaudio -c pytorch\n",
        "\n",
        "brew install mecab\n",
        "brew install mecab-ipadic\n",
        "pip install mecab-python3\n",
        "\n",
        "pip install jaconv\n",
        "pip install japanize-matplotlib\n",
        "pip install 'konoha[mecab]'\n",
        "pip install 'sacrebleu[ja]'\n",
        "```\n",
        "\n",
        "ローカル Mac に自力で，環境構築をする場合の老婆(翁)心的基本方針を記して起きます。\n",
        "homebrew にパッケージ管理を極力任せる方が，後々の管理が楽になるでしょう。\n",
        "自力で複数のパッケージを管理すると，依存関係が煩雑になって心折れてしまいます。\n",
        "Homebrew が対応していない場合のみ，anaconda 付属の pip でイントールするという方針で行くと，自分のミスや誤解に起因するインストール済ライブラリの依存関係の不一致に悩む可能性が減ります。\n",
        "\n",
        "本コードをローカル Mac で動作させるためには，git コマンドを用いて Github 上にアップロードした自作クラス `Minnichi` をローカルディスクに保存する必要があります。\n",
        "これは直下セルの 12 行目で実行しているコマンドを，自身のローカル Mac 上で行うことを意味します。\n",
        "具体的には，Mac の「端末エミュレータ」あるいは類似のエミュレータ上で以下のコマンドを実行します。\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/ShinAsakawa/ccap.git\n",
        "```\n",
        "\n",
        "こうすることで，カレントディレクトリ直下に `ccap` というディレクトリが作成されます。\n",
        "この `ccap` ディレクトリ内に `minnichi.py` というファイルがあります。\n",
        "`ccap` とは，本プロジェクトとは異なるプロジェクトです。\n",
        "もちろん，将来的には，別の github レポジトリを作成した方が良いと考えています。\n",
        "ですが，当面のお試しコードの意味合いもありますので，今回は `ccap` プロジェクトのレポジトリに間借りして作成してあります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jd_AqalXD0j"
      },
      "source": [
        "# 0 準備: 必要となるライブラリのインストールなど"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv01za6x05Uj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from termcolor import colored\n",
        "\n",
        "# ローカルと colab との相違を吸収するために\n",
        "# 本ファイルを Google Colaboratory 上で実行する場合に，必要となるライブラリをインストール\n",
        "import platform\n",
        "isColab = platform.system() == 'Linux'\n",
        "if isColab:\n",
        "    ![ -d ccap ] & /bin/rm -rf ccap\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    !pip install japanize_matplotlib > /dev/null 2>&1\n",
        "    !pip install jaconv > /dev/null 2>&1\n",
        "\n",
        "    # MeCab, fugashi, ipadic のインストール\n",
        "    !apt install aptitude swig > /dev/null 2>&1\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null 2>&1\n",
        "    !pip install mecab-python3 > /dev/null 2>&1\n",
        "    !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null 2>&1\n",
        "    !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null 2>&1\n",
        "    \n",
        "    import subprocess\n",
        "    cmd='echo `mecab-config --dicdir`\\\"/mecab-ipadic-neologd\\\"'\n",
        "    path_ipadic = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                                    shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "    !pip install 'konoha[mecab]'\n",
        "    !pip install 'sacrebleu[ja]'\n",
        "    #!pip install 'fugashi[unidic]' > /dev/null 2>&1\n",
        "    #!python -m unidic download > /dev/null 2>&1\n",
        "    #!pip install ipadic > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9vYHICXD0k"
      },
      "source": [
        "# 1「みんなの日本語」語彙データセットの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn7xiIJQnH4A"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import MeCab\n",
        "import jaconv\n",
        "from ccap.minnichi import Minnichi\n",
        "\n",
        "Minn = Minnichi(reload=True)\n",
        "#Minn.save_data()\n",
        "Minn = Minnichi(reload=False)\n",
        "\n",
        "print(Minn.tokenize('お前はトラだ。虎になるのだ----', max_length=25,pad=False)['input_ids'])\n",
        "print(Minn.convert_ids2tokens(Minn.tokenize('お前はトラだ。虎になるのだ----', max_length=20,pad=False)['input_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xlDEaCSXD0k"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print(Minn.lines[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSvXymAtXD0k"
      },
      "source": [
        "## 1.1 語彙頻度の描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeP7fFMo1Fb5"
      },
      "outputs": [],
      "source": [
        "Minn.draw_freq(figsize=(28,8),rotation=25)\n",
        "MAX_LENGTH = Minn.max_length + 1\n",
        "#Minn(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxldxnaXD0k"
      },
      "source": [
        "# 2 学習に用いる，符号化器 (エンコーダ)，復号化器 (デコーダ) の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTWxlIIr1z6R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#データセットのためのクラスを定義\n",
        "class minnichiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encoder:Minnichi):\n",
        "        self.encoder = encoder\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoder(idx)['input_ids']\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.encoder.__len__()\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"RNNによる符号化器\"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    \"\"\"注意付き復号化器の定義\"\"\"\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIX3_2QgXD0l"
      },
      "source": [
        "# 3 訓練関数 `train()` の定義 教師強制付き"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyy7anAe18OQ"
      },
      "outputs": [],
      "source": [
        "def tensorFromIds(sentence_ids):\n",
        "    return torch.tensor(sentence_ids, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "teacher_forcing_ratio = 0.5  # 訳注：教師強制率。文献によっては，訓練中にこの値を徐々に減衰させることも行われます\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden() # 符号化器の中間層を初期化\n",
        "    encoder_optimizer.zero_grad()         # 符号化器の最適化関数の初期化\n",
        "    decoder_optimizer.zero_grad()         # 復号化器の最適化関数の初期化\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[Minn.vocab.index('<SOS>')]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            #if decoder_input.item() == EOS_token:\n",
        "            if decoder_input.item() == Minn.vocab.index('<EOS>'):\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL4a602x2XGu"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    \"\"\"時間変数を見やすいように，分と秒に変換して返す\"\"\"\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{int(m):2d}分 {int(s):2d}秒'\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    \"\"\"開始時刻 since と，現在の処理が全処理中に示す割合 percent を与えて，経過時間と残り時間を計算して表示する\"\"\"\n",
        "    now = time.time()  #現在時刻を取得\n",
        "    s = now - since    # 開始時刻から現在までの経過時間を計算\n",
        "    #s = since - now    \n",
        "    es = s / (percent) # 経過時間を現在までの処理割合で割って終了予想時間を計算\n",
        "    rs = es - s        # 終了予想時刻から経過した時間を引いて残り時間を計算\n",
        "    #return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "    return f'経過時間:{asMinutes(s)} (残り時間 {asMinutes(rs)})'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asy40hI1XD0l"
      },
      "source": [
        "# 4 `fit()` 関数の定義 エポックを反復して `train()` を呼び出す\n",
        "\n",
        "下記のセル 11, 12 行目のコメントアウトを解除し，かつ，13, 14 行目をコメントアウトすると，学習時のアルゴリズムが変わる。\n",
        "\n",
        "SGD は 確率的勾配降下法 (Bottou, 2003 など) であり，[Adam](https://arxiv.org/pdf/1412.6980/) に比べれば低速である。\n",
        "採択するアルゴリズムによって，どのような値に落ち着くのか，反復回数だけでは説明できない収束状況が考えられる。\n",
        "このことから，学習回数と語彙獲得とを並列しては語れないことの傍証になっていると思うのだが，いかがだろうか。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX0oQr2u2g5Z"
      },
      "outputs": [],
      "source": [
        "def fit(encoder:nn.Module, \n",
        "        decoder:nn.Module, \n",
        "        epochs:int=20, \n",
        "        lr:float=0.001, \n",
        "        n_sample:int=3)->list:\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    #encoder_optimizer = optim.SGD(encoder.parameters(), lr=lr)\n",
        "    #decoder_optimizer = optim.SGD(decoder.parameters(), lr=lr)\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.NLLLoss()\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        #エポックごとに学習順をシャッフルする\n",
        "        learning_order = np.random.permutation(len(Minn.lines)) \n",
        "        for i in range(len(Minn.lines)):\n",
        "            x = learning_order[i]   # ランダムにデータを取り出す \n",
        "            inputs = Minn(x)['input_ids']\n",
        "            input_tensor = tensorFromIds(inputs)\n",
        "            target_tensor = tensorFromIds(inputs)\n",
        "            \n",
        "            #訓練の実施\n",
        "            loss = train(input_tensor, target_tensor, \n",
        "                         encoder, decoder, \n",
        "                         encoder_optimizer, decoder_optimizer, \n",
        "                         criterion)\n",
        "            epoch_loss += loss\n",
        "        \n",
        "        losses.append(epoch_loss/len(Minn.vocab))\n",
        "        print(colored(f'エポック:{epoch:2d} 損失:{epoch_loss/len(Minn.vocab):.2f}', 'cyan', attrs=['bold']),\n",
        "              f'{timeSince(start_time, (epoch+1) * len(Minn.vocab)/(epochs * len(Minn.vocab)))}')\n",
        "        \n",
        "        evaluateRandomly(encoder,decoder, n=n_sample)\n",
        "        \n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOpkepXVXD0m"
      },
      "source": [
        "# 5 評価関数 `evaluate()` の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNXfBJNy2n88"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder:nn.Module, \n",
        "             decoder:nn.Module, \n",
        "             input_ids:list, \n",
        "             max_length:int=MAX_LENGTH)->(list,torch.LongTensor):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromIds(input_ids)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[Minn.vocab.index('<SOS>')]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == Minn.vocab.index('<EOS>'):\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(Minn.vocab[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DQVbsmizXD0m"
      },
      "outputs": [],
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "def calc_bleu(predictions:list, references:list)->float:\n",
        "    references = [references]\n",
        "    bleu_score = corpus_bleu(predictions, references,      \n",
        "                             smooth_method=\"exp\",\n",
        "                             smooth_value=0.0,\n",
        "                             force=False,\n",
        "                             lowercase=False,\n",
        "                             tokenize=\"ja-mecab\",\n",
        "                             use_effective_order=False)\n",
        "    return bleu_score.score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9n5wDv02soE"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder:nn.Module, \n",
        "                     decoder:nn.Module, \n",
        "                     n:int=5)->float:\n",
        "    \n",
        "    srcs, preds = [], []\n",
        "    for x in np.random.randint(Minn.__len__(), size=n):\n",
        "        input_ids = Minn(x)['input_ids']\n",
        "        input_sent = \"\".join(Minn(x)['tokens'])\n",
        "        print(f'入力: {input_ids}: {input_sent}')\n",
        "        output_words, attentions = evaluate(encoder, decoder, input_ids)\n",
        "        output_sent = \"\".join(w for w in output_words)\n",
        "\n",
        "        srcs.append(input_sent)\n",
        "        preds.append(output_sent)\n",
        "        print(f'出力: {[Minn.vocab.index(c) for c in output_words]}',\n",
        "              f':{output_sent}')\n",
        "        print('---')\n",
        "    return bleu(srcs, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPqURGJKXD0m"
      },
      "source": [
        "# 6 学習の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zifpy2YC2iud"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "hidden_size = 256\n",
        "encoder = EncoderRNN(len(Minn.vocab), hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, len(Minn.vocab), dropout_p=0.1).to(device)\n",
        "\n",
        "losses = []\n",
        "losses = losses + fit(encoder, decoder, epochs=10, n_sample=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx8TVQSCXD0n"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#losses = []\n",
        "losses = losses + fit(encoder, decoder, epochs=3, n_sample=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAo5bJ8XD0n"
      },
      "source": [
        "# 7 学習経過の描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Llp_LTn2Z7U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points:list)->None:\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2) # this locator puts ticks at regular intervals\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    \n",
        "showPlot(losses)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCbXunAm2vPi"
      },
      "outputs": [],
      "source": [
        "print(f'BLUE スコア: {evaluateRandomly(encoder, decoder, n=5):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghByCEytXD0n"
      },
      "source": [
        "# 8 自由入力文による評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "D7YQMaXPXD0n"
      },
      "outputs": [],
      "source": [
        "def evaluate_free_input(encoder:nn.Module, \n",
        "                        decoder:nn.Module,\n",
        "                        inp=None,\n",
        "                       )->None:\n",
        "    if inp == None:\n",
        "        inp = input()\n",
        "    inp = jaconv.normalize(inp)\n",
        "    inputs = Minn.tokenize(inp, pad=False)\n",
        "    input_ids = inputs['input_ids']\n",
        "    #input_sent = \"\".join(inputs['tokens'])\n",
        "    #print(f'入力: {input_ids}: {input_sent}')\n",
        "    output_tokens, attentions = evaluate(encoder, decoder, input_ids)\n",
        "    output_ids = Minn.convert_tokens2ids(output_tokens)\n",
        "    return input_ids, output_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "UysBpAfkXD0n"
      },
      "outputs": [],
      "source": [
        "inp, out = evaluate_free_input(encoder,decoder, inp='お前は虎だ。虎になるのだ。')\n",
        "print(Minn.convert_ids2tokens(inp))\n",
        "print(Minn.convert_ids2tokens(out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG4WaYiwXD0n"
      },
      "source": [
        "# 9 エンコーダの内部表現の取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydlsTfk-XD0n"
      },
      "outputs": [],
      "source": [
        "def get_an_encoder_representation(encoder:nn.Module,\n",
        "                                  input_ids:list,\n",
        "                                  max_length:int=MAX_LENGTH)->(list,torch.LongTensor):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromIds(input_ids)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        return encoder_hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUAHt7hhXD0n"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((Minn.__len__(),256))\n",
        "for i in range(Minn.__len__()):\n",
        "    x = get_an_encoder_representation(encoder, input_ids = Minn(1)['input_ids'])\n",
        "    X[i] = x.squeeze(0).clone().detach().numpy()[0]\n",
        "\n",
        "print(X.shape)\n",
        "#Minn(1)['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbkhECH9XD0n"
      },
      "outputs": [],
      "source": [
        "import ccap.tsne as tsne\n",
        "#help(tsne)\n",
        "tsne_result = tsne.tsne(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw1fWlXjXD0n"
      },
      "source": [
        "# 10 内部表現の描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVO7G31vXD0n"
      },
      "outputs": [],
      "source": [
        "tsne_result.shape\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(tsne_result[:,0],tsne_result[:,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot_FSaiYXD0n"
      },
      "outputs": [],
      "source": [
        "x_min = tsne_result[:,0].argmin()\n",
        "x_max = tsne_result[:,0].argmax()\n",
        "y_min = tsne_result[:,1].argmin()\n",
        "y_max = tsne_result[:,1].argmax()\n",
        "\n",
        "print(f'X 座標最小値:{Minn(x_min)[\"tokens\"]}')\n",
        "print(f'X 座標最大値:{Minn(x_max)[\"tokens\"]}')\n",
        "print(f'Y 座標最小値:{Minn(y_min)[\"tokens\"]}')\n",
        "print(f'Y 座標最大値:{Minn(y_max)[\"tokens\"]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X630TMTJXD0o"
      },
      "source": [
        "# 11 文章生成のアイデア\n",
        "\n",
        "## 11.1 2 文の内挿による文生成\n",
        "\n",
        "## 11.2 コアとなる文章に乱数を付加した文生成\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC7DAr0mXD0o"
      },
      "source": [
        "## 11.3 国立国語研究所 日本語均衡コーパスによる検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-gNTPD-XD0o"
      },
      "outputs": [],
      "source": [
        "with open('ccap/2022_0206bccwj_minnichi_filtered.txt', 'r', encoding='utf8') as f:\n",
        "    b = f.readlines()\n",
        "bccwj = [_b.strip() for _b in b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5qAmg0XD0o"
      },
      "outputs": [],
      "source": [
        "X = np.random.randint(len(bccwj), size=3)\n",
        "preds, refs = [], []\n",
        "for x in X:\n",
        "    l = bccwj[x]\n",
        "    ref, pred = evaluate_free_input(encoder, decoder, inp=l)\n",
        "    ref_s = \"\".join(w for w in Minn.convert_ids2tokens(ref)).replace('<EOS>','')\n",
        "    pred_s = \"\".join(w for w in Minn.convert_ids2tokens(pred)).replace('<EOS>','')\n",
        "                       \n",
        "    preds.append(pred_s)\n",
        "    refs.append(ref_s)\n",
        "    print(f'入力:{ref_s}')\n",
        "    print(f'出力:{pred_s}')\n",
        "    print('---')\n",
        "    \n",
        "print(f'BLEU スコア:{bleu(preds, refs):.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "2022_0205minnichi_lm_generator.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}