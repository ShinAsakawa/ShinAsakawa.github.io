{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0410iwa_yoshi_presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 岩下，吉原勉強会資料\n",
        "\n",
        "- 文責: 浅川伸一 <askaawa@ieee.org>\n",
        "- date: 2022_0410\n",
        "- filename: `2022_0410iwayoshi_ja_edu.ipynb`\n"
      ],
      "metadata": {
        "id": "Ho-nLXjjqFeV"
      },
      "id": "Ho-nLXjjqFeV"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # `20220324_minnichi_goilist_2202.xlsx` を指定してアップロードする"
      ],
      "metadata": {
        "id": "q9IrA4wmFEmc"
      },
      "id": "q9IrA4wmFEmc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import sys\n",
        "\n",
        "# 次行はローカルな実行環境とクラウド計算環境である google colab との差分を吸収するため\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    !pip install jaconv\n",
        "    !pip install japanize_matplotlib\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git > /dev/null 2>&1\n",
        "    !pip install 'konoha[mecab]'\n",
        "    \n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "HrZ5-6D1Fyb0"
      },
      "id": "HrZ5-6D1Fyb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268614f7-bae0-41f7-b6f4-37f6abbeb170",
      "metadata": {
        "id": "268614f7-bae0-41f7-b6f4-37f6abbeb170"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import jaconv\n",
        "import unicodedata\n",
        "\n",
        "excel_filename = '20220324_minnichi_goilist_2202.xlsx'\n",
        "a = pd.read_excel(excel_filename)\n",
        "\n",
        "# 岩下先生からいただいたエクセルファイルの ['ことば'] 列の単語には，\n",
        "# 末尾に空白文字が入っているようなので  `\" \".join(word.split())` して除去\n",
        "min2022_0327 = [\" \".join(unicodedata.normalize('NFKC',word).split()) for word in sorted(list(a['ことば']))]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上で読み込んだデータを minnichi 辞書として登録\n",
        "minnichi = {}\n",
        "minnichi_vocab = []\n",
        "for l, _w in zip(a.iterrows(), min2022_0327):\n",
        "    num = int(l[0])\n",
        "    _word = _w\n",
        "    _class = l[1][1]\n",
        "    _pos = l[1][2]\n",
        "    minnichi[_word] = {'num':num, \n",
        "                       #'word': _word,\n",
        "                       '課':_class, \n",
        "                       '品詞':_pos}\n",
        "    minnichi_vocab.append(_word)\n",
        "\n",
        "print(f'読み込んだデータ数:{len(minnichi)}')\n",
        "minnichi_vocab =  sorted(set(minnichi_vocab))\n",
        "print(f'でも単語数としては:{len(minnichi_vocab)} です。重複があるのかな？' )\n",
        "a"
      ],
      "metadata": {
        "id": "FnWP7zarEt9w"
      },
      "id": "FnWP7zarEt9w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "459a6322-5d49-4546-9d22-1ff5bd4f1b3b",
      "metadata": {
        "id": "459a6322-5d49-4546-9d22-1ff5bd4f1b3b"
      },
      "outputs": [],
      "source": [
        "# 前回お話した，ユニコードの正規化についてです。\n",
        "# 実際の動作とは関係ありません。\n",
        "# NFC, NFKC, NFD, NFKD と 4 種類があります。\n",
        "# それぞれの意味は，以下のとおりです\n",
        "# NF: Normalized Form\n",
        "# C: コンポーズド  飾り記号を分けて考えない\n",
        "# D: デコンポーズド 飾り記号を分けて考える\n",
        "# K: 互換性を保証する Comaptibility の意味。だが C が composed と競合するので K にしている\n",
        "import unicodedata\n",
        "help(unicodedata.normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee9f5e4-60dc-4fb3-94bf-e44a85a021e2",
      "metadata": {
        "id": "3ee9f5e4-60dc-4fb3-94bf-e44a85a021e2"
      },
      "outputs": [],
      "source": [
        "print(minnichi_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b538736a-2167-4b6b-99ac-55ac169a9680",
      "metadata": {
        "id": "b538736a-2167-4b6b-99ac-55ac169a9680"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Google Colaboratory 上で実行する場合に，必要となるライブラリをインストールする\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    !pip install transformers > /dev/null 2>&1 \n",
        "\n",
        "    # MeCab, fugashi, ipadic のインストール\n",
        "    !apt install aptitude swig > /dev/null 2>&1\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null 2>&1\n",
        "    !pip install mecab-python3 > /dev/null 2>&1\n",
        "    !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null 2>&1\n",
        "    !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null 2>&1\n",
        "    \n",
        "    import subprocess\n",
        "    cmd='echo `mecab-config --dicdir`\\\"/mecab-ipadic-neologd\\\"'\n",
        "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                                     shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "    !pip install 'fugashi[unidic]' > /dev/null 2>&1\n",
        "    !python -m unidic download > /dev/null 2>&1\n",
        "    !pip install ipadic > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b1d64b-5594-4bdb-b9ae-4f7857882e41",
      "metadata": {
        "id": "61b1d64b-5594-4bdb-b9ae-4f7857882e41"
      },
      "outputs": [],
      "source": [
        "# 新しい minnichi を MeCab にしてみる。\n",
        "import MeCab\n",
        "mcb = MeCab.Tagger().parse\n",
        "\n",
        "# MeCab の品詞分類のデフォルト設定は [IPADIC 2.7](https://chasen.naist.jp/snapshot/ipadic/ipadic/doc/ipadic-ja.pdf) \n",
        "# に基づいている。\n",
        "# [IPADIC 大分類](https://hayashibe.jp/tr/mecab/dictionary/ipadic) は以下の通り\n",
        "pos_ipa = ['名詞', '接頭詞', '動詞', '形容詞', '副詞', '連体詞', '接続詞', '連体詞', \n",
        "           '接続詞', '助詞', '助動詞', '感動詞', '記号', 'フィラー', 'その他']\n",
        "\n",
        "for wrd in minnichi.keys():\n",
        "    wrd_splited = mcb(wrd).strip().splitlines()[:-1]\n",
        "    _mcb_data = []\n",
        "    for _wrd in wrd_splited:\n",
        "        x = _wrd.split('\\t')\n",
        "        _x = x[1].split(',')\n",
        "        __x = {'表層形':x[0], \n",
        "              '原形':_x[7],\n",
        "              #'品詞':_x[4],\n",
        "              '品詞':_x[4].split('-')[0],\n",
        "              '品詞1':_x[5],\n",
        "              '品詞2':_x[6]\n",
        "              }\n",
        "        _mcb_data.append(__x)\n",
        "    minnichi[wrd]['mecab'] = _mcb_data\n",
        "\n",
        "#minnichi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import colored\n",
        "import numpy as np\n",
        "\n",
        "for i in range(10):\n",
        "    wrd = minnichi_vocab[np.random.choice(len(minnichi))]\n",
        "    print(colored(wrd,'blue', attrs=['bold']), end=\": \") \n",
        "    #print(colored(minnichi[i]['word'],'blue', attrs=['bold']), end=\": \") \n",
        "    for _i in minnichi[wrd]['mecab']:\n",
        "        print('表層形',colored(_i['表層形'], 'green', attrs=['bold']),\n",
        "              '品詞',  colored(_i['品詞'],  'green', attrs=['bold','blink']), end=\" \") \n",
        "    print()"
      ],
      "metadata": {
        "id": "RgOMqDRbrrUH"
      },
      "id": "RgOMqDRbrrUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 若干の老婆心\n"
      ],
      "metadata": {
        "id": "uMcW7sLZfc9k"
      },
      "id": "uMcW7sLZfc9k"
    },
    {
      "cell_type": "code",
      "source": [
        "# ここで MeCab の使い方を簡単に紹介する。\n",
        "# 入力文を分かち書きしたいだけならば，以下のように '-Owakati' オプションを指定して\n",
        "# MeCab を呼び出せばよい。\n",
        "print(MeCab.Tagger('-Owakati').parse('吾輩は猫である').strip())"
      ],
      "metadata": {
        "id": "xJaMB6wCWXpl"
      },
      "id": "xJaMB6wCWXpl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# あるいは入力文を変数に代入して実行する\n",
        "s = '名前はまだない'\n",
        "print(MeCab.Tagger('-Owakati').parse(s).strip())\n",
        "\n",
        "# 最後に付いている `strip()` は，文字列の最終要素，この場合は改行コード，を取り去るためである。"
      ],
      "metadata": {
        "id": "owR3F2v1futP"
      },
      "id": "owR3F2v1futP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 何度も分かち書きを繰り返して呼び出すのであれば，あらかじめ分かち書きを定義しておく\n",
        "wakati = MeCab.Tagger('-Owakati').parse\n",
        "s2 = 'どこで生れたか頓と見当がつかぬ。'\n",
        "print(wakati(s2).strip())"
      ],
      "metadata": {
        "id": "5JYjhDrgglFW"
      },
      "id": "5JYjhDrgglFW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上記のようにして分かち書きした文は，空白で区切られているので，分割するには `split(' ')` を用いる\n",
        "# `split(' ')` で分割された文は，リストになっているので，表示の際はカギカッコで囲まれている。\n",
        "print(wakati(s2).strip().split(' '))"
      ],
      "metadata": {
        "id": "VniH5wQugm4k"
      },
      "id": "VniH5wQugm4k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ここで，みんなの日本語データが一行に一文で文字列からなるリストであると仮定しよう。\n",
        "# 以下のようにである:\n",
        "minnichi_sentences = [\n",
        "'ジュースをお願いします。',\n",
        "'いらっしゃいませ。メニューです。どうぞ。',\n",
        "'いくらですか。',\n",
        "'1.ホン:カレーとコーヒーをください。',\n",
        "'2.ジル:サンドイッチとジュースをお願いします。']\n",
        "\n",
        "# 上記のデータ `minnichi_sentences` を分かち書きさせてみよう。\n",
        "for s in minnichi_sentences:\n",
        "    print(wakati(s).strip().split(' '))"
      ],
      "metadata": {
        "id": "LqE1iCEhgvPk"
      },
      "id": "LqE1iCEhgvPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ところで MeCab は入力文を構文解析する場合，解析結果をリストとして返す。\n",
        "mcb = MeCab.Tagger().parse  # mecab の定義。念のため再定義\n",
        "s = '何でも薄暗いじめじめした所でニヤーニヤー泣いて居た事丈は記憶して居る。'  # 入力文\n",
        "print(mcb(s))\n",
        "print(len(mcb(s).splitlines()[:-1]))\n"
      ],
      "metadata": {
        "id": "3dG51rPPZiHG"
      },
      "id": "3dG51rPPZiHG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上記を行数を付番して表示してみる。\n",
        "# `enumerate` を使うと連番を得ることができる\n",
        "for i, x in enumerate(mcb(s).splitlines()[:-1]):\n",
        "    print(i, x)\n"
      ],
      "metadata": {
        "id": "lo9hW92Kg4rA"
      },
      "id": "lo9hW92Kg4rA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分かち書きされた結果は更に，タブで表層形とその解析結果に分けられるので，分割して見よう。\n",
        "for i, x in enumerate(mcb(s).splitlines()[:-1]):\n",
        "    surface, content = x.split('\\t')\n",
        "    print(f'{i:2d}, {surface}: {content})')"
      ],
      "metadata": {
        "id": "Y02Skp2FhA8G"
      },
      "id": "Y02Skp2FhA8G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要な情報は，品詞1, 品詞2 および原形だけであるとしよう。\n",
        "# 上記の出力から，# 品詞1 は 0 番目，品詞2 は 1 番目，原形は 7 番目であることが分かるので\n",
        "# これを用いることにする\n",
        "for i, x in enumerate(mcb(s).splitlines()[:-1]):\n",
        "    surface, content = x.split('\\t')\n",
        "    _x = content.split(',')\n",
        "    pos1, pos2 = _x[0], _x[1] # それぞれ品詞1, 品詞2\n",
        "    original_form = surface if len(_x) <= 8 else _x[7]\n",
        "    print(f'{i:2d} 表層形:{surface}, 品詞1:{pos1} 品詞2:{pos2} 原形:{original_form}')\n"
      ],
      "metadata": {
        "id": "51aLGooShEEn"
      },
      "id": "51aLGooShEEn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x in enumerate(mcb(s).splitlines()[:-1]):\n",
        "    surface, content = x.split('\\t')\n",
        "    _x = content.split(',')\n",
        "    pos1, pos2 = _x[0], _x[1] # それぞれ品詞1, 品詞2\n",
        "    original_form = surface if len(_x) <= 8 else _x[7]\n",
        "    # if len(_x) > 8:\n",
        "    #     original_form = _x[7]\n",
        "    # else:\n",
        "    #     original_form = \"\"\n",
        "\n",
        "    print(f'{i:2d} 表層形:{surface}, 品詞1:{pos1} 品詞2:{pos2} 原形:{original_form}')\n"
      ],
      "metadata": {
        "id": "uiKMwpvTezIt"
      },
      "id": "uiKMwpvTezIt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import colored\n",
        "import numpy as np\n",
        "\n",
        "for i in range(10):\n",
        "    wrd = minnichi_vocab[np.random.choice(len(minnichi))]\n",
        "    print(colored(wrd,'blue', attrs=['bold']), end=\": \") \n",
        "    #print(colored(minnichi[i]['word'],'blue', attrs=['bold']), end=\": \") \n",
        "    for _i in minnichi[wrd]['mecab']:\n",
        "        print('表層形',colored(_i['表層形'], 'green', attrs=['bold']),\n",
        "              '品詞',  colored(_i['品詞'],  'green', attrs=['bold','blink']), end=\" \") \n",
        "    print()"
      ],
      "metadata": {
        "id": "5HOxJAAnqDum"
      },
      "id": "5HOxJAAnqDum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ccap import ccap_w2v\n",
        "w2v = ccap_w2v(is2017=True).w2v"
      ],
      "metadata": {
        "id": "9gXzeTXc0Zu-"
      },
      "id": "9gXzeTXc0Zu-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minn_vocab = [minnichi[x] for x in minnichi.keys()]\n",
        "minn_vocab = minnichi.keys()\n",
        "minnichi_not_w2v = []\n",
        "for w in minn_vocab:\n",
        "    if not w in w2v:\n",
        "        minnichi_not_w2v.append(w)\n",
        "    else:\n",
        "        ; \n",
        "        # print(w, end=\"\\t\")\n",
        "print(f'word2vec に存在しない minnichi 単語数:{len(minnichi_not_w2v)}')\n",
        "print(len(minnichi_not_w2v))\n",
        "print(f'最初の 3 語を表示: {minnichi_not_w2v[:3]}')\n",
        "print(f'最後の 3 語を表示: {minnichi_not_w2v[-3:]}')"
      ],
      "metadata": {
        "id": "cPcdIaFoLiy-"
      },
      "id": "cPcdIaFoLiy-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec に存在しないミンニチ語彙を MeCab によって分解し，各分解した語が word2vec に存在するか否かを調べる\n",
        "mcb = MeCab.Tagger().parse\n",
        "\n",
        "for wrd in minnichi_not_w2v:\n",
        "    surfaces = [ent.split('\\t')[0] for ent in mcb(wrd).splitlines()[:-1]]\n",
        "    for _s in surfaces:\n",
        "        color = 'red' if not _s in w2v else 'grey'\n",
        "        if not _s in w2v:\n",
        "            print(colored((wrd,_s), color, attrs=['bold']), end=\" \")    "
      ],
      "metadata": {
        "id": "cse28gnmH8on"
      },
      "id": "cse28gnmH8on",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrd = '本'\n",
        "topn=10\n",
        "wrd_list = [p[0] for p in w2v.most_similar(wrd,topn=topn)]\n",
        "print(wrd_list)"
      ],
      "metadata": {
        "id": "akpFP-8kPDn8"
      },
      "id": "akpFP-8kPDn8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mecab_wakati(phrase:list):\n",
        "    \"\"\"mecab を使って分かち書きにする\n",
        "    colab のインストール状況によっては，分かち書きオプション -Owakati が存在しない。\n",
        "    根本的な解決は，定義ファイルを書けばよい。\n",
        "    だが，ここでは標準の MeCab 出力から等価な出力を実現してみた\n",
        "    \n",
        "    引数: \n",
        "        phrase: list[str]\n",
        "    \n",
        "    戻り値: list\n",
        "    \"\"\"\n",
        "    wakati = \" \".join(ent.split('\\t')[0] for ent in mcb(phrase).splitlines()[:-1])\n",
        "    return wakati\n",
        "\n",
        "print(mecab_wakati('これは，私が図書館で借りた本です。'))\n",
        "\n",
        "def mecab_pos(word:str):\n",
        "    \"\"\"mecab を使って単語の品詞情報を得る\n",
        "    引数: \n",
        "        word: str\n",
        "    戻り値:\n",
        "        list[str]\n",
        "    \"\"\"\n",
        "    # 次行はトリッキーに見えるかも知れないが，MeCab の出力 `mcb(word)` を\n",
        "    # 1. 行に区切り (`.splitlines()`)\n",
        "    # 2. 区切った各項目を更にタブ `('\\t')` で区切り\n",
        "    # 3. その 0 番目の要素である表層形と\n",
        "    # 4. '(',')` で区切った先頭要素を取り出して\n",
        "    # 5. タプルにして返す\n",
        "    # という操作を 1 行でしている\n",
        "    poses = [(ent.split('\\t')[0], ent.split('\\t')[1].split(',')[0]) for ent in mcb(word).splitlines()[:-1]]\n",
        "    return(poses)\n",
        "\n",
        "print(mecab_pos('これは，私が図書館で借りた本です。'))"
      ],
      "metadata": {
        "id": "Lni75hpwsfaS"
      },
      "id": "Lni75hpwsfaS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1d3d14fb-8119-43b3-8d48-26afcd1eb31e",
      "metadata": {
        "id": "1d3d14fb-8119-43b3-8d48-26afcd1eb31e"
      },
      "source": [
        "# 2 「みんなの日本語」ファイルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a525492-fa50-4898-b46d-ea7547481233",
      "metadata": {
        "id": "4a525492-fa50-4898-b46d-ea7547481233"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import unicodedata\n",
        "import glob\n",
        "import jaconv\n",
        "import sys\n",
        "from konoha import SentenceTokenizer\n",
        "splitter = SentenceTokenizer().tokenize\n",
        "\n",
        "if isColab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()  # `2022_0410minnichi.txt` を指定してアップロードする    \n",
        "    with open('2022_0410minnichi.txt', 'r') as f:\n",
        "        minnichi_text = f.readlines()\n",
        "\n",
        "# コメントアウトしてあるのは，ローカル PC での実行のため，\n",
        "# # 岩下先生から頂いた「みんなの日本語」データの読み込み\n",
        "# minnichi_dir = '/Users/asakawa/study/2021jlpt'\n",
        "# minnichi_files = sorted(glob.glob(os.path.join(minnichi_dir, 'MINNICHI_*.txt')))\n",
        "\n",
        "# # みんなの日本語テキストを読み込み\n",
        "# minnichi_text = {}\n",
        "# for fname in minnichi_files:\n",
        "#     _fname = os.path.split(fname)[-1].split('.')[0]\n",
        "\n",
        "#     if not _fname in minnichi_text:\n",
        "#         minnichi_text[_fname] = []\n",
        "#     txt = []\n",
        "#     with open(fname,'r') as f:\n",
        "#         texts = f.readlines()\n",
        "        \n",
        "#         for txt in texts:\n",
        "#             txt = jaconv.normalize(txt.strip())\n",
        "#             if len(txt) > 0:\n",
        "#                 minnichi_text[_fname].append(txt)\n",
        "                \n",
        "\n",
        "# _minn_txt = []\n",
        "# for k, v in minnichi_text.items():\n",
        "#     for ll in minnichi_text[k]:\n",
        "#         for _ll in splitter(ll):\n",
        "#             _minn_txt.append(_ll)\n",
        "\n",
        "# minnichi_text = _minn_txt            \n",
        "# print(f'みんなの日本語テキストの総行数:{len(minnichi_text)}')\n",
        "\n",
        "# 結果を書き出す場合には，次行以下のコメントを削除する\n",
        "# with open('2022_0410minnichi.txt', 'w') as f:\n",
        "#     for l in minnichi_text:\n",
        "#         f.write(l+'\\n')\n",
        "\n",
        "minnichi_pos_dict = {}\n",
        "for l in minnichi_text:\n",
        "    for w, pos in mecab_pos(l):\n",
        "        if pos in minnichi_pos_dict:\n",
        "            minnichi_pos_dict[pos] += 1\n",
        "        else:\n",
        "            minnichi_pos_dict[pos] = 1\n",
        "        \n",
        "print(minnichi_pos_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "問題作成のための，同義語，反意語を探す工夫\n"
      ],
      "metadata": {
        "id": "S8hA99QP4_oQ"
      },
      "id": "S8hA99QP4_oQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# 次行はローカルな実行環境とクラウド計算環境である google colab との差分を吸収するため\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    !pip install --upgrade nltk    \n",
        "    import nltk\n",
        "    nltk.download('all')    \n",
        "    nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "IAMbO8hN5P0n"
      },
      "id": "IAMbO8hN5P0n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd54fcc-302e-4dbb-aee7-b9f89215ee22",
      "metadata": {
        "id": "7fd54fcc-302e-4dbb-aee7-b9f89215ee22"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def wordnet_synonym_antonym(word:str,\n",
        "                            lang:str='jpn'):\n",
        "    \"\"\"nltk の wordnet を使って，同義語と反意語の辞書を返す\n",
        "    引数として word: str をとる。\n",
        "    オプション lang: ['eng', 'jpn'] 英語か日本語かを指定\n",
        "    戻り値: dict\n",
        "        '同義語': list\n",
        "        '反意語': list\n",
        "    使用例:\n",
        "        wordnet_synonym_antonym('英語', lang='jpn')  \n",
        "        # オプション: lang='jpn' は省略可能\n",
        "        \n",
        "        word_synonym_antonym(word='data', lang='eng')\n",
        "    \"\"\"\n",
        "    synonyms, antonyms = [], []\n",
        "\n",
        "    for syn in wn.synsets(word, lang=lang):\n",
        "        for l in syn.lemmas(lang=lang):\n",
        "            synonyms.append(l.name())\n",
        "            if l.antonyms():\n",
        "                antonyms.append(l.antonyms()[0].name())\n",
        "                \n",
        "    return {'同義語':synonyms, '反意語':antonyms}\n",
        "\n",
        "\n",
        "s = 'これは，私が図書館で借りた本です。'\n",
        "s_wakati = mecab_wakati(s).split(' ')\n",
        "for wrd in s_wakati:\n",
        "    print(f'{wrd}: {wordnet_synonym_antonym(wrd)}')\n",
        "\n",
        "print('\\n---\\n')\n",
        "\n",
        "def wordnet_defs_examples(word:str,\n",
        "                          lang='jpn'):\n",
        "    syns = wn.synsets(wrd, lang=lang)\n",
        "    _def, _exmpl = [], []\n",
        "    for syn in wn.synsets(word, lang=lang):\n",
        "        if syn.definition():\n",
        "            _def.append(syn.definition())\n",
        "        if syn.examples():\n",
        "            _exmpl.append(syn.examples())\n",
        "    return {'定義':_def, '例文':_exmpl}\n",
        "                          \n",
        "\n",
        "#wordnet_defs_examples('本')\n",
        "s = 'これは，私が図書館で借りた本です。'\n",
        "s_wakati = mecab_wakati(s).split(' ')\n",
        "for wrd in s_wakati:\n",
        "    print(f'{wrd}: {wordnet_defs_examples(wrd)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syns = wn.synsets('図書', lang='jpn')\n",
        "\n",
        "for syn in syns:\n",
        "    print(f'syn:{syn}')\n",
        "    #print(syn.lemmas(lang='jpn'))\n",
        "    print(syn.definition())\n",
        "    print(syn.examples())"
      ],
      "metadata": {
        "id": "NJNNoAP95LbJ"
      },
      "id": "NJNNoAP95LbJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3bQZpiyN9XNe"
      },
      "id": "3bQZpiyN9XNe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0410iwa_yoshi_presentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}