{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOGY4Ck7TCl72QsjE8LSC/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1112hagoromo_masked_sen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 「はごろも」をもちいた T5 による文章穴埋め問題作成の試み\n",
        "\n",
        "- datafile: `masked_sen.xlsx`   # to be uploaded \n",
        "- date: 2022_1112\n",
        "- author: 浅川伸一\n",
        "- filename: `2022_1112hagoromo_masked_sen.ipynb`\n",
        "\n",
        "「はごろも」とは岩下先生からいただいた，日本語教育用の文法，用法などをまとめたデータベースであるらしい。\n",
        "本コードは，[T5 による，文章穴埋め問題](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0918T5_demo_filling_blank_question.ipynb) の続編として意図されたものである。\n",
        "\n",
        "### 使用上の注意\n",
        "\n",
        "* `[CLS]` を使用すること。`[CLS]` はモデルの学習時に使用されるため，マスクされたトークンを予測するには，必ず文の前に `[CLS]` トークンを追加して，モデルが正しく符号化できるようにする。\n",
        "* トークン化した後に `[MASK]` を使用する。入力文字列に直接 [MASK] を入力するのと，トークン化した後に `[MASK]` で置き換えるのとでは、トークンの並びが異なるので，予測結果も異なる。\n",
        "トークン化後に `[MASK]` を使用する方がよい。\n",
        "これは，モデルがどのように事前学習されたかと一致するためである。\n",
        "しかし Huggingface Inference API は入力文字列に `[MASK]` をタイプすることしかサポートしておらず，よりロバストな予測を生成することができない。\n",
        "* `position_ids` を明示的に引数として与える。\n",
        "`Roberta` モデルでは，モデルに対して `position_ids` が与えられない場合 Huggingface 版の transformers は自動的に `position_ids` を構築する。だが， 0 ではなく `padding_idx` から作成する。これでは `rinna/japanese-roberta-base` では期待通りに動作しない。\n",
        "なぜなら対応するトークナイザーの `padding_idx` が 0 ではないからである。\n",
        "そのため，必ず自分で `position_ids` を `constrcut` して，位置 ID 0 から開始するようにすること。\n",
        "\n",
        "- 参照URL: [【日本語モデル付き】2021年に自然言語処理をする人にお勧めしたい事前学習済みモデル](https://qiita.com/sonoisa/items/a9af64ff641f0bbfed44)\n",
        "- [同 colab](https://colab.research.google.com/github/sonoisa/t5-japanese/blob/main/t5_japanese_article_generation_inference.ipynb)\n",
        "- [HuggingFace Hub](https://huggingface.co/sonoisa/t5-base-japanese)\n"
      ],
      "metadata": {
        "id": "jRn7xqo0CDc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVz-Zi8NB8Iv"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install --upgrade 'fugashi[ipadic]' > /dev/null 2>&1\n",
        "    !pip install --upgrade 'fugashi[unidic]' > /dev/null 2>&1\n",
        "    !python -m unidic download\n",
        "    !pip install --upgrade ipadic > /dev/null 2>&1\n",
        "    !pip install --upgrade sentencepiece > /dev/null 2>&1\n",
        "    !pip install --upgrade transformers > /dev/null 2>&1\n",
        "\n",
        "    !pip install 'konoha[all]' > /dev/null 2>&1\n",
        "    #!pip install --upgrade termcolor > /dev/null 2>&1\n",
        "    !pip install --upgrade jaconv  > /dev/null 2>&1      \n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "    import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer \n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import jaconv  \n",
        "import sys\n",
        "\n",
        "from termcolor import colored\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv\n",
        "    \n",
        "import warnings\n",
        "\n",
        "def load_excel(path: str):\n",
        "    \"\"\"Load data from an Excel file.\"\"\"\n",
        "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "    return pd.read_excel(path)\n",
        "\n",
        "#MODEL_DIR = \"sonoisa/t5-base-japanese-article-generation\"\n",
        "MODEL_DIR = \"rinna/japanese-roberta-base\"\n",
        "# load tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR)\n",
        "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
        "\n",
        "# load model\n",
        "if MODEL_DIR == \"sonoisa/t5-base-japanese-article-generation\":\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
        "elif MODEL_DIR ==  \"rinna/japanese-roberta-base\":\n",
        "    model = RobertaForMaskedLM.from_pretrained(MODEL_DIR)\n",
        "\n",
        "model = model.eval()"
      ],
      "metadata": {
        "id": "fAxeVmwHCHGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 「はごろも」の読み込み\n",
        "\n",
        "`masked_sen.xlsx` をアップロードする"
      ],
      "metadata": {
        "id": "JrjiBYeZCpoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()  # ここで `masekd_sen.xlsx` を指定してアップロード\n",
        "    data_dir = '.'"
      ],
      "metadata": {
        "id": "6zo6VDZJCaci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_hagoromo_fname = 'masked_sen.xlsx'\n",
        "masked_hag = load_excel(masked_hagoromo_fname)\n",
        "masked_hagoromo_dict = masked_hag.to_dict(orient='index')\n",
        "masked_hag_dict = masked_hag[['例文','masked_sen']].to_dict(orient='index')"
      ],
      "metadata": {
        "id": "XyF6SaJcD4hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = True\n",
        "special_tokens = ['<s>', '</s>',  '[SEP]', '[PAD]', '[CLS]', '[MASK]', '。', '、', '「','」'],\n",
        "top_n = 5\n",
        "\n",
        "for i, (k, v) in enumerate(masked_hagoromo_dict.items()):\n",
        "    sent = v['例文']\n",
        "    masked_sent = v['masked_sen'].replace('[mask]','[MASK]')\n",
        "    masked_sent = '[CLS]' + masked_sent\n",
        "    print(colored(f'{i:2d} 入力文       :{sent}', color='blue', attrs=['bold'])) if verbose else None\n",
        "    print(f'   マスク化入力文:{masked_sent}') if verbose else None\n",
        "    m_tokens = tokenizer.tokenize(masked_sent)\n",
        "\n",
        "    # トークン id に変換\n",
        "    m_token_ids = tokenizer.convert_tokens_to_ids(m_tokens)\n",
        "    \n",
        "    # テンソルに変換\n",
        "    m_token_tensor = torch.LongTensor([m_token_ids])\n",
        "\n",
        "    # position ids を作成\n",
        "    m_position_ids = list(range(0, m_token_tensor.size(1)))\n",
        "\n",
        "    m_position_id_tensor = torch.LongTensor([m_position_ids])\n",
        "    \n",
        "    # マスクに対応する上位 top_n 個の候補を取得\n",
        "    m_outputs = model(input_ids=m_token_tensor, \n",
        "                    position_ids=m_position_id_tensor)\n",
        "    m_preds = m_outputs[0]\n",
        "    \n",
        "    for idx in range(m_preds.size(1)):\n",
        "        if m_tokens[idx] == tokenizer.mask_token:\n",
        "            cands = m_preds[0][idx].topk(top_n)\n",
        "            print(colored(tokenizer.convert_ids_to_tokens(cands.indices), \n",
        "                          color='red',\n",
        "                          attrs=['bold']), \n",
        "                  end=\"\")\n",
        "        else:\n",
        "            print(m_tokens[idx], end=\"\")\n",
        "            \n",
        "    print()\n",
        "    "
      ],
      "metadata": {
        "id": "UehBvkvYDDrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(colored('ほげ', color='red'))"
      ],
      "metadata": {
        "id": "UfMGYjciD0la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9Ma4oDvEfKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}