{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMlu19meF5lNg0SXvn4EtGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1209japanese_clip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rinnakk/japanese-clip.git"
      ],
      "metadata": {
        "id": "DRDheas7VbJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b7XlKv0VOOp"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "import torch\n",
        "import japanese_clip as ja_clip\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "model, preprocess = ja_clip.load(\"rinna/japanese-clip-vit-b-16\", cache_dir=\"/tmp/japanese_clip\", device=device)\n",
        "tokenizer = ja_clip.load_tokenizer()\n",
        "\n",
        "img = Image.open(io.BytesIO(requests.get('https://images.pexels.com/photos/2253275/pexels-photo-2253275.jpeg?auto=compress&cs=tinysrgb&dpr=3&h=750&w=1260').content))\n",
        "image = preprocess(img).unsqueeze(0).to(device)\n",
        "encodings = ja_clip.tokenize(\n",
        "    texts=[\"犬\", \"猫\", \"象\"],\n",
        "    max_seq_len=77,\n",
        "    device=device,\n",
        "    tokenizer=tokenizer, # this is optional. if you don't pass, load tokenizer each time\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.get_image_features(image)\n",
        "    text_features = model.get_text_features(**encodings)\n",
        "    \n",
        "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "\n",
        "print(\"Label probs:\", text_probs)  # prints: [[1.0, 0.0, 0.0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "e7yfjAj6VPD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}