{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN59hLDMNGJktFGvlFzd/us",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0916noto_fonts_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noto font を用いた文字認識実験 + PMSP96 単語認識\n",
        "* date: 2022_0906\n",
        "* author: 浅川伸一\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-YLtuYDnPt74"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7-wMwagCEKW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git > /dev/null\n",
        "import bit\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    !pip install --upgrade Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Noto フォントの登録"
      ],
      "metadata": {
        "id": "QpXSbBnHC3SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import  glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "fonts_jp = bit.get_notojp_fonts()\n",
        "fonts_en = bit.get_notoen_fonts()\n",
        "\n",
        "default_width, default_height = 224, 224\n",
        "default_bgcolor=(255,255,255)\n",
        "default_fontsize=28\n",
        "\n",
        "fig, ax = plt.subplots(4, 6, figsize=(18, 12)) \n",
        "i, j = 0, 0\n",
        "j_max = 6\n",
        "for font_name, font in fonts_en.items():\n",
        "    img = Image.new(\n",
        "        mode='RGB', \n",
        "        size=(default_width, default_height), \n",
        "        color=default_bgcolor) \n",
        "    draw_canvas = ImageDraw.Draw(img)\n",
        "    draw_canvas.text(\n",
        "        xy=(2,84),\n",
        "        text=font_name,\n",
        "        font=font,\n",
        "        fill=(0,0,0))\n",
        "    \n",
        "    ax[i,j].imshow(img)\n",
        "    #ax[i,j].set_title(font_name)\n",
        "    ax[i,j].set_xticks([])\n",
        "    ax[i,j].set_yticks([])    \n",
        "    j += 1\n",
        "    if j == j_max:\n",
        "        i+=1; j=0\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYGs5zB6DWDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 PyTorch データセットの設定"
      ],
      "metadata": {
        "id": "6FihFs7UQR5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import  glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def get_text_img(\n",
        "    text:str=\"XYZ\",\n",
        "    x0:int=0,\n",
        "    y0:int=0,\n",
        "    font:PIL.ImageFont.FreeTypeFont=fonts_en['NotoSans-Regular'],  # フォント\n",
        "    bgcolor:tuple=default_bgcolor,  # デフォルト背景色\n",
        "    color:[tuple or str] = 'black', # デフォルト前景色\n",
        "    width:int=default_width,        # デフォルト刺激画面幅\n",
        "    height:int=default_height,      # デフォルト刺激画面高さ\n",
        "    fontsize:int=default_fontsize,  # デフォルトフォントサイズ\n",
        "    target_transform=None):\n",
        "    \n",
        "    img = Image.new(mode='RGB',\n",
        "                    size=(width, height), \n",
        "                    color=bgcolor)\n",
        "    draw_canvas = ImageDraw.Draw(img)\n",
        "\n",
        "    bbox = draw_canvas.textbbox(xy=(x0,y0),\n",
        "                                font=font, \n",
        "                                text=text)\n",
        "    bbox_width = bbox[2] - bbox[0]\n",
        "    bbox_height = bbox[3] - bbox[1]\n",
        "\n",
        "    # print(f'bbox_width:{bbox_width}',\n",
        "    #       f'bbox_height:{bbox_height}',\n",
        "    #       f'(x0,y0)=({x0},{y0})')\n",
        "\n",
        "    if x0 == 0:\n",
        "        x0 = (width >> 1) - (bbox_width >> 1)\n",
        "    if y0 == 0:   \n",
        "        y0 = (height >> 1) - (bbox_height >> 1)\n",
        "    # print(f'bbox_width:{bbox_width}',\n",
        "    #       f'bbox_height:{bbox_height}',\n",
        "    #       f'(x0,y0)=({x0},{y0})')\n",
        "    \n",
        "    draw_canvas.text(xy=(x0, y0), \n",
        "                     text=text,\n",
        "                     font=font,\n",
        "                     stroke_width=1,\n",
        "                     #stroke_fill=\"black\",\n",
        "                     #spacing=-4,\n",
        "                     #fill=(0,0,0),\n",
        "                     fill=color)\n",
        "    \n",
        "    return img, draw_canvas\n",
        "\n",
        "img, draw_canvas = get_text_img(text=\"make\")\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ik8Tou5EuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプル画像を表示するなら，次行 を true にする `verbose=True`\n",
        "verbose = True\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "try:\n",
        "    import japanize_matplotlib \n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "digit_chars = '0123456789'\n",
        "alphabet_chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "_dataset = bit.notoen_dataset(\n",
        "    fonts_dict=fonts_en,\n",
        "    items=[c for c in digit_chars+alphabet_chars],\n",
        "    )\n",
        "\n",
        "print(f'_data.__len__():{_dataset.__len__()}')\n",
        "\n",
        "_labels = set([l[1] for l in _dataset.labels])\n",
        "print(f'len(_labels):{len(_labels)}')\n",
        "\n",
        "if verbose:\n",
        "    # 全データの中から 1 つサンプリング\n",
        "    N = np.random.choice(_dataset.__len__())\n",
        "    img, label = _dataset.__getitem__(N)\n",
        "\n",
        "    # 返ってきたデータは PyTorch.Tensor なので PILImage として表示できるように変換\n",
        "    img = (img.detach().numpy().transpose(1,2,0) / 255).clip(0,1)\n",
        "    plt.figure(figsize=(2,2))\n",
        "    plt.title(f'ラベル:{label}')\n",
        "    plt.imshow(img);plt.show()\n",
        "\n",
        "print(_dataset.__len__())\n",
        "fig, ax = plt.subplots(3, 7, figsize=(12, 6)) \n",
        "i, j = 0, 0\n",
        "j_max = 7\n",
        "x = 0\n",
        "for x in np.random.choice(range(_dataset.__len__()),21):\n",
        "    img, label = _dataset.__getoriginalitem__(x)\n",
        "    ax[i,j].imshow(img)\n",
        "    ax[i,j].set_title(font_name)\n",
        "    ax[i,j].set_xticks([])\n",
        "    ax[i,j].set_yticks([])    \n",
        "    j += 1\n",
        "    if j == j_max:\n",
        "        i+=1\n",
        "        j=0\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m1l-xvXRHp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 PyTorch 乱数の種の設定"
      ],
      "metadata": {
        "id": "OxP4f-9BQgXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch の seed の設定関連 再現性確保のため\n",
        "# https://qiita.com/takubb/items/7d45ae701390912c7629\n",
        "# https://qiita.com/si1242/items/d2f9195c08826d87d6ad\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# リソースの選択（CPU/GPU）\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 乱数シード固定（再現性の担保）\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)     # random\n",
        "    np.random.seed(seed)  # numpy\n",
        "    \n",
        "    # pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "# データローダーのサブプロセスの乱数 seed 固定\n",
        "def worker_init_fn(worker_id):\n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "    print(worker_init_fn(1))\n",
        "    \n",
        " # データローダーの作成\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "#                                            batch_size=16,  # バッチサイズ\n",
        "#                                            shuffle=True,  # データシャッフル\n",
        "#                                            num_workers=2,  # 高速化\n",
        "#                                            pin_memory=True,  # 高速化\n",
        "#                                            worker_init_fn=worker_init_fn\n",
        "#                                            )"
      ],
      "metadata": {
        "id": "H8fjdNolLQvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 訓練データと検証データの作成"
      ],
      "metadata": {
        "id": "skFecPGeLj1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = _dataset.__len__()\n",
        "N_train = int(N / 10 * 8)\n",
        "N_test = N - N_train\n",
        "seed=42\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    _dataset, \n",
        "    [N_train, N_test], \n",
        "    generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "PriLXTuyCPwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 PyTorch データローダの作成"
      ],
      "metadata": {
        "id": "Sn8BENKTMrdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=32,\n",
        "    shuffle=True, \n",
        "    num_workers=0)  # 0 にしないとエラーになる\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "     test_dataset, \n",
        "     batch_size=32,\n",
        "     shuffle=False, \n",
        "     num_workers=0)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, \n",
        "                      one_channel=False,\n",
        "                      figsize=(15,15)\n",
        "                     ):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    img /= 255\n",
        "    npimg = img.numpy().clip(0,1)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        \n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))"
      ],
      "metadata": {
        "id": "TEImdx6HMk2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_labels = sorted(set([l[1] for l in _dataset.labels]))\n",
        "print(len(_labels), _labels)"
      ],
      "metadata": {
        "id": "QVmMslbSM15J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 `train_model()` の定義"
      ],
      "metadata": {
        "id": "pFxujbTsO7YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import train_model"
      ],
      "metadata": {
        "id": "gdcAherjM8ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 LeNet による認識実験"
      ],
      "metadata": {
        "id": "O4vSN9kpPe1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import LeNet_Imagenet\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "lenet = LeNet_Imagenet(out_size=len(_labels))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(lenet.parameters(), lr=0.0001) # , momentum=0.9)\n",
        "optimizer = optim.Adam(lenet.parameters(), lr=0.001) # , momentum=0.9)\n",
        "lenet"
      ],
      "metadata": {
        "id": "08MhZZvxO-Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. 訓練の実施"
      ],
      "metadata": {
        "id": "epZAiStDQ82x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=lenet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMa3ht2qQ1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    outputs = lenet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "CysOeWd_RDsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. ResNet による認識実験"
      ],
      "metadata": {
        "id": "C_AGRBMISgeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from bit import ResNet18\n",
        "\n",
        "resnet = ResNet18(img_channels=3, num_classes=len(_labels))\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=resnet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VeqAMnQ5SRQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    outputs = resnet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "aNTmeClTTj7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. MLP による認識実験"
      ],
      "metadata": {
        "id": "M0LOQ7EDTVI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import MLP_Imagenet"
      ],
      "metadata": {
        "id": "25OCKihZS253"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mlp = MLP_Imagenet(out_size=len(_labels))\n",
        "#optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=mlp,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s-Sy9QZETZFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    outputs = mlp(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "s1q9xaPzUAzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A1. PMSP データの準備"
      ],
      "metadata": {
        "id": "UPFGjQ2GT_Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "# Plaut が用意している PMSP データファイル\n",
        "pmsp_url = 'https://www.cnbc.cmu.edu/~plaut/xerion/PMSPdata.txt'\n",
        "\n",
        "# 上の URL からファイル名を分離\n",
        "pmsp_data_fname = pmsp_url.split('/')[-1]\n",
        "if not os.path.exists(pmsp_data_fname):  \n",
        "    # ファイルが存在しなければダウンロードする\n",
        "    print(f'pmsp_url:{pmsp_url}')\n",
        "    r = requests.get(pmsp_url)\n",
        "    with open(pmsp_data_fname, 'wb') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print(f'{pmsp_data_fname} をダウンロード中 {total_length} バイト')\n",
        "        f.write(r.content)\n",
        "\n",
        "# `PMSPdata.txt` の読み込み\n",
        "with open(pmsp_data_fname, 'r') as f:\n",
        "    x = f.readlines()\n",
        "\n",
        "# 読み込んだデータを辞書に登録    \n",
        "pmsp = {}\n",
        "for i, line in enumerate(x):\n",
        "    x = line.strip().split('\\t')\n",
        "    if len(x) == 7:\n",
        "        word, phon, _type, sim1, sim1raw, sim2sqrt, sim3rt = x\n",
        "        pmsp[word] = {'phon': phon,\n",
        "                     'type': _type,\n",
        "                     'sim1': float(sim1),\n",
        "                     'sim2raw': float(sim1raw),\n",
        "                     'sim2sqrt': float(sim2sqrt),\n",
        "                     'sim3rt': float(sim3rt),\n",
        "                    }\n",
        "    else:\n",
        "        print(i, x)\n",
        "\n",
        "# 書記素情報と音韻情報だけ取り出してリスト化\n",
        "Orth_list, Phon_list = [], []        \n",
        "for i, (k, v) in enumerate(pmsp.items()):\n",
        "    Orth_list.append(k)\n",
        "    Phon_list.append(pmsp[k]['phon'])\n",
        "\n",
        "print(f'len(Orth_list):{len(Orth_list)}, len(Phon_list):{len(Phon_list)}')    \n",
        "\n",
        "# 書記素と音素の構成要素を頻度情報を計測\n",
        "Orth_vocab, Phon_vocab = {}, {}\n",
        "for i, (orth, phon) in enumerate(zip(Orth_list, Phon_list)):\n",
        "    for ch in orth:\n",
        "        if not ch in Orth_vocab:\n",
        "            Orth_vocab[ch] = 1\n",
        "        else:\n",
        "            Orth_vocab[ch] += 1\n",
        "    for p in phon:\n",
        "        if p != '/':\n",
        "            if not p in Phon_vocab:\n",
        "                Phon_vocab[p] = 1\n",
        "            else:\n",
        "                Phon_vocab[p] += 1\n",
        "# print(f'Orth_vocab:{Orth_vocab}, Phon_vocab:{Phon_vocab}')\n",
        "\n",
        "# 書記素情報のグラフ化\n",
        "f2o = {v:k for k, v in Orth_vocab.items()}\n",
        "orth_vocab_freqs = sorted(Orth_vocab.values())[::-1]\n",
        "orth_vocab_freq_tags = [f2o[f] for f in orth_vocab_freqs]\n",
        "plt.plot(orth_vocab_freq_tags, orth_vocab_freqs)\n",
        "plt.title('Orthography frequncy of each letters')\n",
        "plt.show()    \n",
        "\n",
        "# 音素情報のグラフ化\n",
        "f2p = {v:k for k, v in Phon_vocab.items()}\n",
        "phon_vocab_freqs = sorted(Phon_vocab.values())[::-1]\n",
        "phon_vocab_freq_tags = [f2p[f] for f in phon_vocab_freqs]\n",
        "plt.plot(phon_vocab_freq_tags, phon_vocab_freqs)\n",
        "plt.title('Phonology frequncy of each phoneme')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_YHqQNTUAA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Orth_list))\n",
        "_pmsp_dataset = bit.notoen_dataset(\n",
        "    fonts_dict=fonts_en,\n",
        "    items=Orth_list)\n",
        "print(f'_data.__len__():{_pmsp_dataset.__len__()}')\n"
      ],
      "metadata": {
        "id": "H9GXlos5UuOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = _pmsp_dataset.__len__()\n",
        "N_train = int(N / 10 * 8)\n",
        "N_test = N - N_train\n",
        "seed=42\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    _pmsp_dataset, \n",
        "    [N_train, N_test], \n",
        "    generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "PpSi-rfDU5dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=32,\n",
        "    shuffle=True, \n",
        "    num_workers=0)  # 0 にしないとエラーになる\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "     test_dataset, \n",
        "     batch_size=32,\n",
        "     shuffle=False, \n",
        "     num_workers=0)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))"
      ],
      "metadata": {
        "id": "05bTsIChVApN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_pmsp_dataset.__len__()"
      ],
      "metadata": {
        "id": "kO8yh0yWVFg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A1.1 LeNet による PMSP データの訓練\n"
      ],
      "metadata": {
        "id": "he--pv8-VIPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lenet = LeNet_Imagenet(out_size=2998)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(lenet.parameters(), lr=0.0001)\n",
        "optimizer = optim.Adam(lenet.parameters(), lr=0.001)\n",
        "\n",
        "#seed = 42\n",
        "fix_seed(seed=42)\n",
        "\n",
        "losses = train_model(\n",
        "    net=lenet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10)   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nIGjTqeyVJoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    #print(f'labels:{labels}')\n",
        "    #break\n",
        "    outputs = lenet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "PzcB_MZUVS0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lenet.state_dict(), '2022_0914pmsp_lenet.pt')"
      ],
      "metadata": {
        "id": "EgRftQEqVdvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A1.2 ResNet による PMSP データの訓練"
      ],
      "metadata": {
        "id": "1BnGa0-wVg0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from bit import ResNet18\n",
        "\n",
        "resnet = ResNet18(img_channels=3, num_classes=len(Orth_list))\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "fix_seed(seed=42)\n",
        "np.random.seed(42)\n",
        "losses = train_model(\n",
        "    net=resnet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQsgocfUVhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    #print(f'labels:{labels}')\n",
        "    #break\n",
        "    outputs = lenet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "u7y8ZJwBVvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))\n",
        "\n",
        "outputs = resnet(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(f'labels:{labels}')\n",
        "print(f'正解数:{(labels[0] == predicted).sum().detach().numpy()}',\n",
        "      f'/{len(images)}')\n",
        "# for t, c, p in zip(labels[0], labels[1], predicted):\n",
        "#     _t = t.detach().numpy()\n",
        "#     _p = p.detach().numpy()\n",
        "#     print(_t, _p, c)"
      ],
      "metadata": {
        "id": "wyz8o9VCVspQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}