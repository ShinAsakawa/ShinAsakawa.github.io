{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP23itJOJ+zmE4BEh1ORuwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0916noto_fonts_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noto font を用いた文字認識実験 + PMSP96 単語認識\n",
        "* date: 2022_0906\n",
        "* author: 浅川伸一\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-YLtuYDnPt74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf bit\n",
        "#!cat bit/torch_nikogamulin_resnet.py"
      ],
      "metadata": {
        "id": "6otUTfHDKxik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7-wMwagCEKW"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null\n",
        "    !git clone https://github.com/ShinAsakawa/bit.git > /dev/null\n",
        "import bit\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    # 2022_0916 現在 PIL のバージョンが古く truetype フォント\n",
        "    # の表示に不具合が出るためバージョン 9.2.0 以上に更新する\n",
        "    !pip install --upgrade Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Noto フォントの登録"
      ],
      "metadata": {
        "id": "QpXSbBnHC3SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import  glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "fonts_jp = bit.get_notojp_fonts()\n",
        "fonts_en = bit.get_notoen_fonts()\n",
        "\n",
        "default_width, default_height = 224, 224\n",
        "default_bgcolor=(255,255,255)\n",
        "default_fontsize=28\n",
        "\n",
        "fig, ax = plt.subplots(4, 6, figsize=(18, 12)) \n",
        "i, j = 0, 0\n",
        "j_max = 6\n",
        "for font_name, font in fonts_en.items():\n",
        "    img = Image.new(\n",
        "        mode='RGB', \n",
        "        size=(default_width, default_height), \n",
        "        color=default_bgcolor) \n",
        "    draw_canvas = ImageDraw.Draw(img)\n",
        "    draw_canvas.text(\n",
        "        xy=(2,84),\n",
        "        text=font_name,\n",
        "        font=font,\n",
        "        fill=(0,0,0))\n",
        "    \n",
        "    ax[i,j].imshow(img)\n",
        "    #ax[i,j].set_title(font_name)\n",
        "    ax[i,j].set_xticks([])\n",
        "    ax[i,j].set_yticks([])    \n",
        "    j += 1\n",
        "    if j == j_max:\n",
        "        i+=1; j=0\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYGs5zB6DWDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 PyTorch データセットの設定"
      ],
      "metadata": {
        "id": "6FihFs7UQR5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print([x for x in digit_chars+alphabet_chars])\n",
        "from bit import get_text_img\n",
        "img, draw_canvas, bbox = get_text_img(text=\"make\", draw_bbox=True)\n",
        "\n",
        "print(f'bbox:{bbox}')\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "#print(f'type(img):{type(img)}')"
      ],
      "metadata": {
        "id": "3VLrCl_KIiqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbose=True\n",
        "from bit import notoen_dataset\n",
        "from bit import get_notoen_fonts\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "noto_fonts = get_notoen_fonts()\n",
        "\n",
        "digit_chars = '0123456789'\n",
        "alphabet_chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "_dataset = notoen_dataset(\n",
        "    items=[c for c in digit_chars],\n",
        "    #items=[c for c in digit_chars+alphabet_chars],\n",
        "    fonts_dict=noto_fonts)\n",
        "print(f'_dataset.__len__():{_dataset.__len__()}')\n",
        "\n",
        "_labels = set([l[1] for l in _dataset.labels])\n",
        "print(f'len(_labels):{len(_labels)}')\n"
      ],
      "metadata": {
        "id": "XS4TVvqFJGz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 PyTorch 乱数の種の設定"
      ],
      "metadata": {
        "id": "OxP4f-9BQgXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch の seed の設定関連 再現性確保のため\n",
        "# https://qiita.com/takubb/items/7d45ae701390912c7629\n",
        "# https://qiita.com/si1242/items/d2f9195c08826d87d6ad\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# リソースの選択（CPU/GPU）\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 乱数シード固定（再現性の担保）\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)     # random\n",
        "    np.random.seed(seed)  # numpy\n",
        "    \n",
        "    # pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "# データローダーのサブプロセスの乱数 seed 固定\n",
        "def worker_init_fn(worker_id):\n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "    print(worker_init_fn(1))\n",
        "    \n",
        " # データローダーの作成\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "#                                            batch_size=16,  # バッチサイズ\n",
        "#                                            shuffle=True,  # データシャッフル\n",
        "#                                            num_workers=2,  # 高速化\n",
        "#                                            pin_memory=True,  # 高速化\n",
        "#                                            worker_init_fn=worker_init_fn\n",
        "#                                            )"
      ],
      "metadata": {
        "id": "H8fjdNolLQvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 訓練データと検証データの作成"
      ],
      "metadata": {
        "id": "skFecPGeLj1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = _dataset.__len__()\n",
        "N_train = int(N / 10 * 8)\n",
        "N_test = N - N_train\n",
        "seed=42\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    _dataset, \n",
        "    [N_train, N_test], \n",
        "    generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "PriLXTuyCPwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 PyTorch データローダの作成"
      ],
      "metadata": {
        "id": "Sn8BENKTMrdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=32,\n",
        "    shuffle=True, \n",
        "    num_workers=0)  # 0 にしないとエラーになる\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "     test_dataset, \n",
        "     batch_size=32,\n",
        "     shuffle=False, \n",
        "     num_workers=0)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, \n",
        "                      one_channel=False,\n",
        "                      figsize=(15,15)\n",
        "                     ):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    img /= 255\n",
        "    npimg = img.numpy().clip(0,1)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        \n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(14,14))"
      ],
      "metadata": {
        "id": "TEImdx6HMk2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_labels = sorted(set([l[1] for l in _dataset.labels]))\n",
        "print(len(_labels), _labels)"
      ],
      "metadata": {
        "id": "QVmMslbSM15J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 `train_model()` の定義"
      ],
      "metadata": {
        "id": "pFxujbTsO7YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import train_model\n",
        "print(f'train_dataset.__len__():{train_dataset.__len__()},',\n",
        "      f'test_dataset.__len__():{test_dataset.__len__()}')"
      ],
      "metadata": {
        "id": "gdcAherjM8ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 LeNet による認識実験"
      ],
      "metadata": {
        "id": "O4vSN9kpPe1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import LeNet_Imagenet\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'device: {device}')\n",
        "\n",
        "lenet = LeNet_Imagenet(out_size=len(_labels), device=device)\n",
        "#lenet.to(device=device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device=device)\n",
        "#optimizer = optim.Adam(lenet.parameters(), lr=0.0001) # , momentum=0.9)\n",
        "optimizer = optim.Adam(lenet.parameters(), lr=0.001) # , momentum=0.9)\n"
      ],
      "metadata": {
        "id": "08MhZZvxO-Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. 訓練の実施"
      ],
      "metadata": {
        "id": "epZAiStDQ82x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=lenet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMa3ht2qQ1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0].to(device)\n",
        "    images = images.to(device)\n",
        "    outputs = lenet(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "CysOeWd_RDsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. ResNet による認識実験"
      ],
      "metadata": {
        "id": "C_AGRBMISgeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from bit import ResNet18\n",
        "\n",
        "resnet = ResNet18(img_channels=3, \n",
        "                  num_classes=len(_labels),\n",
        "                  device=device)\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=resnet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VeqAMnQ5SRQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels[0].to(device)\n",
        "    outputs = resnet(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "aNTmeClTTj7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. MLP による認識実験"
      ],
      "metadata": {
        "id": "M0LOQ7EDTVI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bit import MLP_Imagenet"
      ],
      "metadata": {
        "id": "25OCKihZS253"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mlp = MLP_Imagenet(out_size=len(_labels))\n",
        "#optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=mlp,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s-Sy9QZETZFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0].to(device)\n",
        "    images = images.to(device)\n",
        "    outputs = mlp(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "s1q9xaPzUAzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A1. PMSP データの準備"
      ],
      "metadata": {
        "id": "UPFGjQ2GT_Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "# Plaut が用意している PMSP データファイル\n",
        "pmsp_url = 'https://www.cnbc.cmu.edu/~plaut/xerion/PMSPdata.txt'\n",
        "\n",
        "# 上の URL からファイル名を分離\n",
        "pmsp_data_fname = pmsp_url.split('/')[-1]\n",
        "if not os.path.exists(pmsp_data_fname):  \n",
        "    # ファイルが存在しなければダウンロードする\n",
        "    print(f'pmsp_url:{pmsp_url}')\n",
        "    r = requests.get(pmsp_url)\n",
        "    with open(pmsp_data_fname, 'wb') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print(f'{pmsp_data_fname} をダウンロード中 {total_length} バイト')\n",
        "        f.write(r.content)\n",
        "\n",
        "# `PMSPdata.txt` の読み込み\n",
        "with open(pmsp_data_fname, 'r') as f:\n",
        "    x = f.readlines()\n",
        "\n",
        "# 読み込んだデータを辞書に登録    \n",
        "pmsp = {}\n",
        "for i, line in enumerate(x):\n",
        "    x = line.strip().split('\\t')\n",
        "    if len(x) == 7:\n",
        "        word, phon, _type, sim1, sim1raw, sim2sqrt, sim3rt = x\n",
        "        pmsp[word] = {'phon': phon,\n",
        "                     'type': _type,\n",
        "                     'sim1': float(sim1),\n",
        "                     'sim2raw': float(sim1raw),\n",
        "                     'sim2sqrt': float(sim2sqrt),\n",
        "                     'sim3rt': float(sim3rt),\n",
        "                    }\n",
        "    else:\n",
        "        print(i, x)\n",
        "\n",
        "# 書記素情報と音韻情報だけ取り出してリスト化\n",
        "Orth_list, Phon_list = [], []        \n",
        "for i, (k, v) in enumerate(pmsp.items()):\n",
        "    Orth_list.append(k)\n",
        "    Phon_list.append(pmsp[k]['phon'])\n",
        "\n",
        "print(f'len(Orth_list):{len(Orth_list)}, len(Phon_list):{len(Phon_list)}')    \n",
        "\n",
        "# 書記素と音素の構成要素を頻度情報を計測\n",
        "Orth_vocab, Phon_vocab = {}, {}\n",
        "for i, (orth, phon) in enumerate(zip(Orth_list, Phon_list)):\n",
        "    for ch in orth:\n",
        "        if not ch in Orth_vocab:\n",
        "            Orth_vocab[ch] = 1\n",
        "        else:\n",
        "            Orth_vocab[ch] += 1\n",
        "    for p in phon:\n",
        "        if p != '/':\n",
        "            if not p in Phon_vocab:\n",
        "                Phon_vocab[p] = 1\n",
        "            else:\n",
        "                Phon_vocab[p] += 1\n",
        "# print(f'Orth_vocab:{Orth_vocab}, Phon_vocab:{Phon_vocab}')\n",
        "\n",
        "# 書記素情報のグラフ化\n",
        "f2o = {v:k for k, v in Orth_vocab.items()}\n",
        "orth_vocab_freqs = sorted(Orth_vocab.values())[::-1]\n",
        "orth_vocab_freq_tags = [f2o[f] for f in orth_vocab_freqs]\n",
        "plt.plot(orth_vocab_freq_tags, orth_vocab_freqs)\n",
        "plt.title('Orthography frequncy of each letters')\n",
        "plt.show()    \n",
        "\n",
        "# 音素情報のグラフ化\n",
        "f2p = {v:k for k, v in Phon_vocab.items()}\n",
        "phon_vocab_freqs = sorted(Phon_vocab.values())[::-1]\n",
        "phon_vocab_freq_tags = [f2p[f] for f in phon_vocab_freqs]\n",
        "plt.plot(phon_vocab_freq_tags, phon_vocab_freqs)\n",
        "plt.title('Phonology frequncy of each phoneme')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_YHqQNTUAA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Orth_list))\n",
        "_pmsp_dataset = bit.notoen_dataset(\n",
        "    fonts_dict=fonts_en,\n",
        "    items=Orth_list)\n",
        "print(f'_data.__len__():{_pmsp_dataset.__len__()}')\n"
      ],
      "metadata": {
        "id": "H9GXlos5UuOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = _pmsp_dataset.__len__()\n",
        "N_train = int(N / 10 * 8)\n",
        "N_test = N - N_train\n",
        "seed=42\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    _pmsp_dataset, \n",
        "    [N_train, N_test], \n",
        "    generator=torch.Generator().manual_seed(seed))"
      ],
      "metadata": {
        "id": "PpSi-rfDU5dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# dataloaders\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=32,\n",
        "    shuffle=True, \n",
        "    num_workers=0)  # 0 にしないとエラーになる\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "     test_dataset, \n",
        "     batch_size=32,\n",
        "     shuffle=False, \n",
        "     num_workers=0)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))"
      ],
      "metadata": {
        "id": "05bTsIChVApN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_pmsp_dataset.__len__()"
      ],
      "metadata": {
        "id": "kO8yh0yWVFg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A1.1 LeNet による PMSP データの訓練\n"
      ],
      "metadata": {
        "id": "he--pv8-VIPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lenet = LeNet_Imagenet(out_size=2998)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(lenet.parameters(), lr=0.0001)\n",
        "optimizer = optim.Adam(lenet.parameters(), lr=0.001)\n",
        "\n",
        "seed = 42\n",
        "fix_seed(seed=seed)\n",
        "\n",
        "losses = train_model(\n",
        "    net=lenet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10)   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nIGjTqeyVJoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    #print(f'labels:{labels}')\n",
        "    #break\n",
        "    outputs = lenet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "PzcB_MZUVS0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lenet.state_dict(), '2022_0914pmsp_lenet.pt')"
      ],
      "metadata": {
        "id": "EgRftQEqVdvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A1.2 ResNet による PMSP データの訓練"
      ],
      "metadata": {
        "id": "1BnGa0-wVg0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from bit import ResNet18\n",
        "\n",
        "resnet = ResNet18(img_channels=3, num_classes=len(Orth_list))\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "fix_seed(seed=42)\n",
        "np.random.seed(42)\n",
        "losses = train_model(\n",
        "    net=resnet,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQsgocfUVhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    labels = labels[0]\n",
        "    #print(f'labels:{labels}')\n",
        "    #break\n",
        "    outputs = lenet(torch.autograd.Variable(images))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'検証データセットでの精度: {int(100 * correct / total):3d} %')\n"
      ],
      "metadata": {
        "id": "u7y8ZJwBVvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))\n",
        "\n",
        "outputs = resnet(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(f'labels:{labels}')\n",
        "print(f'正解数:{(labels[0] == predicted).sum().detach().numpy()}',\n",
        "      f'/{len(images)}')"
      ],
      "metadata": {
        "id": "wyz8o9VCVspQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B. PyTorch 公式訓練済モデルによる文字認識"
      ],
      "metadata": {
        "id": "DmutWg_RgyQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# 各モデルを定義し，訓練済み結合係数をダウンロード\n",
        "DNNs = {}\n",
        "DNNs['resnet18'] = models.resnet18(weights='DEFAULT', progress=True)\n",
        "DNNs['alexnet'] = models.alexnet(weights='DEFAULT', progress=True)\n",
        "DNNs['vgg16'] = models.vgg16(weights='DEFAULT', progress=True)\n",
        "DNNs['squeezenet']= models.squeezenet1_0(weights='DEFAULT', progress=True)\n",
        "DNNs['densenet'] = models.densenet161(weights='DEFAULT', progress=True)\n",
        "DNNs['inception'] = models.inception_v3(weights='DEFAULT', progress=True)\n",
        "DNNs['googlenet'] = models.googlenet(weights='DEFAULT', progress=True)\n",
        "DNNs['shufflenet'] = models.shufflenet_v2_x1_0(weights='DEFAULT', progress=True)\n",
        "DNNs['mobilenet'] = models.mobilenet_v2(weights='DEFAULT', progress=True)\n",
        "DNNs['resnext50_32x4d'] = models.resnext50_32x4d(weights='DEFAULT', progress=True)\n",
        "DNNs['wide_resnet50_2'] = models.wide_resnet50_2(weights='DEFAULT', progress=True)\n",
        "DNNs['mnasnet'] = models.mnasnet1_0(weights='DEFAULT', progress=True)"
      ],
      "metadata": {
        "id": "qkfje5uJg4Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上の中から試したいモデルを選んでください。最後のモデルが有効になります。\n",
        "net = DNNs['resnet18'] \n",
        "#net = DNNs['squeezenet']\n",
        "#net = DNNs['googlenet']\n",
        "#net = DNNs['shufflenet']\n",
        "#net = DNNs['mobilenet']\n",
        "#net = DNNs['vgg16']\n",
        "#net = DNNs['alexnet']"
      ],
      "metadata": {
        "id": "VzU-CSORg7Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "# RGB 各チャンネルの平均と分散の定義。CNN 唯一の前処理\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "# モデルのインスタンスを生成し，事前学習済の結合係数をロード\n",
        "use_pretrained = True  # 学習済みのパラメータを使用\n",
        "resnet_pt = models.resnet18(pretrained=use_pretrained)\n",
        "#resnet_pt"
      ],
      "metadata": {
        "id": "lQ-wlqnBg-hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの最終直下層の出力ユニット数を データに合わせて変更する\n",
        "resnet_pt.fc = nn.Linear(in_features=512, out_features=2998)\n",
        "\n",
        "for name, param in resnet_pt.named_parameters():\n",
        "    param.requires_grad = True\n",
        "resnet_pc"
      ],
      "metadata": {
        "id": "VKgyzcisk4fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(resnet_pt.parameters(), lr=0.0001)\n",
        "#optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "fix_seed(seed=42)\n",
        "np.random.seed(42)\n",
        "losses = train_model(\n",
        "    net=resnet_pt,            \n",
        "    dataloaders_dict={'train':train_dataloader, 'val':test_dataloader},\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=10,\n",
        "    )   \n",
        "\n",
        "for phase in losses.keys():\n",
        "    print(f'{phase} {losses[phase]}')\n",
        "    plt.plot(losses[phase], label=phase)\n",
        "plt.legend()    \n",
        "plt.title('ResNet による文字認識')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VeHZClSZhDZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(test_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=False, figsize=(10,10))\n",
        "\n",
        "outputs = resnet(images)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(f'labels:{labels}')\n",
        "print(f'正解数:{(labels[0] == predicted).sum().detach().numpy()}',\n",
        "      f'/{len(images)}')\n",
        "# for t, c, p in zip(labels[0], labels[1], predicted):\n",
        "#     _t = t.detach().numpy()\n",
        "#     _p = p.detach().numpy()\n",
        "#     print(_t, _p, c)"
      ],
      "metadata": {
        "id": "HME42PDKlMgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname_saved = '2022_0916pytorch_resnet18_pmsp.pt'\n",
        "torch.save(resnet.state_dict(), model_fname_saved)  # 29163175\n"
      ],
      "metadata": {
        "id": "m3dUrrCClOMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. 日本語による文字認識"
      ],
      "metadata": {
        "id": "1Y71fsexjHS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプル画像を表示するなら，次行 を true にする `verbose=True`\n",
        "verbose = False\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import jaconv\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "\n",
        "hira_chars = 'ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん'\n",
        "kata_chars = 'ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "# 以下の文字はどうしましょうかね?\n",
        "# ゔヷヸヹヺ\n",
        "digit_chars = '０１２３４５６７８９'\n",
        "alphabet_chars = 'ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "symbol_chars = '、。，．・：；？！゛゜ヽヾゝゞ〃仝々〆〇＋−±×÷＝≠＜＞≦≧∞∴♂♀°′″℃¥＄¢£％＃＆＊＠§☆★○●◎◇◆□■△▲▽▼※〒→←↑↓〓∈∋⊆⊇⊂⊃∪∩∧∨¬⇒⇔∀∃∠⊥⌒∂∇≡≒≪≫√∽∝∵∫∬Å‰♯♭♪†‡¶◯０'\n",
        "\n",
        "# 常用漢字\n",
        "jyoyo_chars = '亜哀愛悪握圧扱安暗案以位依偉囲委威尉意慰易為異移維緯胃衣違遺医井域育一壱逸稲芋印員因姻引飲院陰隠韻右宇羽雨渦浦運雲営影映栄永泳英衛詠鋭液疫益駅悦謁越閲円園宴延援沿演炎煙猿縁遠鉛塩汚凹央奥往応押横欧殴王翁黄沖億屋憶乙卸恩温穏音下化仮何価佳加可夏嫁家寡科暇果架歌河火禍稼箇花荷華菓課貨過蚊我画芽賀雅餓介会解回塊壊快怪悔懐戒拐改械海灰界皆絵開階貝劾外害慨概涯街該垣嚇各拡格核殻獲確穫覚角較郭閣隔革学岳楽額掛潟割喝括活渇滑褐轄且株刈乾冠寒刊勘勧巻喚堪完官寛干幹患感慣憾換敢棺款歓汗漢環甘監看管簡緩缶肝艦観貫還鑑間閑関陥館丸含岸眼岩頑顔願企危喜器基奇寄岐希幾忌揮机旗既期棋棄機帰気汽祈季紀規記貴起軌輝飢騎鬼偽儀宜戯技擬欺犠疑義議菊吉喫詰却客脚虐逆丘久休及吸宮弓急救朽求泣球究窮級糾給旧牛去居巨拒拠挙虚許距漁魚享京供競共凶協叫境峡強恐恭挟教橋況狂狭矯胸脅興郷鏡響驚仰凝暁業局曲極玉勤均斤琴禁筋緊菌襟謹近金吟銀九句区苦駆具愚虞空偶遇隅屈掘靴繰桑勲君薫訓群軍郡係傾刑兄啓型契形径恵慶憩掲携敬景渓系経継茎蛍計警軽鶏芸迎鯨劇撃激傑欠決潔穴結血月件倹健兼券剣圏堅嫌建憲懸検権犬献研絹県肩見謙賢軒遣険顕験元原厳幻弦減源玄現言限個古呼固孤己庫弧戸故枯湖誇雇顧鼓五互午呉娯後御悟碁語誤護交侯候光公功効厚口向后坑好孔孝工巧幸広康恒慌抗拘控攻更校構江洪港溝甲皇硬稿紅絞綱耕考肯航荒行衡講貢購郊酵鉱鋼降項香高剛号合拷豪克刻告国穀酷黒獄腰骨込今困墾婚恨懇昆根混紺魂佐唆左差査砂詐鎖座債催再最妻宰彩才採栽歳済災砕祭斎細菜裁載際剤在材罪財坂咲崎作削搾昨策索錯桜冊刷察撮擦札殺雑皿三傘参山惨散桟産算蚕賛酸暫残仕伺使刺司史嗣四士始姉姿子市師志思指支施旨枝止死氏祉私糸紙紫肢脂至視詞詩試誌諮資賜雌飼歯事似侍児字寺慈持時次滋治璽磁示耳自辞式識軸七執失室湿漆疾質実芝舎写射捨赦斜煮社者謝車遮蛇邪借勺尺爵酌釈若寂弱主取守手朱殊狩珠種趣酒首儒受寿授樹需囚収周宗就州修愁拾秀秋終習臭舟衆襲週酬集醜住充十従柔汁渋獣縦重銃叔宿淑祝縮粛塾熟出術述俊春瞬准循旬殉準潤盾純巡遵順処初所暑庶緒署書諸助叙女序徐除傷償勝匠升召商唱奨宵将小少尚床彰承抄招掌昇昭晶松沼消渉焼焦照症省硝礁祥称章笑粧紹肖衝訟証詔詳象賞鐘障上丈乗冗剰城場壌嬢常情条浄状畳蒸譲醸錠嘱飾植殖織職色触食辱伸信侵唇娠寝審心慎振新森浸深申真神紳臣薪親診身辛進針震人仁刃尋甚尽迅陣酢図吹垂帥推水炊睡粋衰遂酔錘随髄崇数枢据杉澄寸世瀬畝是制勢姓征性成政整星晴正清牲生盛精聖声製西誠誓請逝青静斉税隻席惜斥昔析石積籍績責赤跡切拙接摂折設窃節説雪絶舌仙先千占宣専川戦扇栓泉浅洗染潜旋線繊船薦践選遷銭銑鮮前善漸然全禅繕塑措疎礎祖租粗素組訴阻僧創双倉喪壮奏層想捜掃挿操早曹巣槽燥争相窓総草荘葬藻装走送遭霜騒像増憎臓蔵贈造促側則即息束測足速俗属賊族続卒存孫尊損村他多太堕妥惰打駄体対耐帯待怠態替泰滞胎袋貸退逮隊代台大第題滝卓宅択拓沢濯託濁諾但達奪脱棚谷丹単嘆担探淡炭短端胆誕鍛団壇弾断暖段男談値知地恥池痴稚置致遅築畜竹蓄逐秩窒茶嫡着中仲宙忠抽昼柱注虫衷鋳駐著貯丁兆帳庁弔張彫徴懲挑朝潮町眺聴脹腸調超跳長頂鳥勅直朕沈珍賃鎮陳津墜追痛通塚漬坪釣亭低停偵貞呈堤定帝底庭廷弟抵提程締艇訂逓邸泥摘敵滴的笛適哲徹撤迭鉄典天展店添転点伝殿田電吐塗徒斗渡登途都努度土奴怒倒党冬凍刀唐塔島悼投搭東桃棟盗湯灯当痘等答筒糖統到討謄豆踏逃透陶頭騰闘働動同堂導洞童胴道銅峠匿得徳特督篤毒独読凸突届屯豚曇鈍内縄南軟難二尼弐肉日乳入如尿任妊忍認寧猫熱年念燃粘悩濃納能脳農把覇波派破婆馬俳廃拝排敗杯背肺輩配倍培媒梅買売賠陪伯博拍泊白舶薄迫漠爆縛麦箱肌畑八鉢発髪伐罰抜閥伴判半反帆搬板版犯班畔繁般藩販範煩頒飯晩番盤蛮卑否妃彼悲扉批披比泌疲皮碑秘罷肥被費避非飛備尾微美鼻匹必筆姫百俵標氷漂票表評描病秒苗品浜貧賓頻敏瓶不付夫婦富布府怖扶敷普浮父符腐膚譜負賦赴附侮武舞部封風伏副復幅服福腹複覆払沸仏物分噴墳憤奮粉紛雰文聞丙併兵塀幣平弊柄並閉陛米壁癖別偏変片編辺返遍便勉弁保舗捕歩補穂募墓慕暮母簿倣俸包報奉宝峰崩抱放方法泡砲縫胞芳褒訪豊邦飽乏亡傍剖坊妨帽忘忙房暴望某棒冒紡肪膨謀貿防北僕墨撲朴牧没堀奔本翻凡盆摩磨魔麻埋妹枚毎幕膜又抹末繭万慢満漫味未魅岬密脈妙民眠務夢無矛霧婿娘名命明盟迷銘鳴滅免綿面模茂妄毛猛盲網耗木黙目戻問紋門匁夜野矢厄役約薬訳躍柳愉油癒諭輸唯優勇友幽悠憂有猶由裕誘遊郵雄融夕予余与誉預幼容庸揚揺擁曜様洋溶用窯羊葉要謡踊陽養抑欲浴翌翼羅裸来頼雷絡落酪乱卵欄濫覧利吏履理痢裏里離陸律率立略流留硫粒隆竜慮旅虜了僚両寮料涼猟療糧良量陵領力緑倫厘林臨輪隣塁涙累類令例冷励礼鈴隷零霊麗齢暦歴列劣烈裂廉恋練連錬炉路露労廊朗楼浪漏老郎六録論和話賄惑枠湾腕'\n",
        "\n",
        "all_chars = hira_chars + kata_chars + digit_chars + alphabet_chars + symbol_chars + jyoyo_chars\n",
        "all_chars = hira_chars + kata_chars + digit_chars + alphabet_chars + jyoyo_chars\n",
        "#all_chars = hira_chars + kata_chars + digit_chars + alphabet_chars\n",
        "print('事前に定義した文字数:',\n",
        "      colored(f' {len(all_chars)}',\"blue\", attrs=['bold']),\n",
        "      ' 文字 (ひらがな，カタカナ，数字，常用漢字)')\n",
        "print('ひらがな:',\n",
        "      colored(f'{len(hira_chars)}', 'blue', attrs=['bold']),\n",
        "      '文字')\n",
        "print('カタカナ:',\n",
        "      colored(f' {len(kata_chars)}', 'blue', attrs=['bold']),\n",
        "      '文字')\n",
        "print('数字:',\n",
        "      colored(f'{len(digit_chars)}', 'blue', attrs=['bold']),\n",
        "      '文字')\n",
        "print('アルファベット:',\n",
        "      colored(f'{len(alphabet_chars)}', 'blue', attrs=['bold']),\n",
        "      '文字')\n",
        "print('常用漢字:',\n",
        "      colored(f'{len(jyoyo_chars)}', 'blue', attrs=['bold']),\n",
        "      '文字')\n",
        "\n",
        "print('len(all_chars):',\n",
        "      colored(f'{len(all_chars)}', 'blue', attrs=['bold']))"
      ],
      "metadata": {
        "id": "HKdGz9jGjLqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Dr8gDHElD6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}