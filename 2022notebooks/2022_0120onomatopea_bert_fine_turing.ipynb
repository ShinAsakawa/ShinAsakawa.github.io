{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0120onomatopea_bert_fine_turing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f11cc3-a7a0-408b-be54-c99e95f9ca41",
      "metadata": {
        "id": "41f11cc3-a7a0-408b-be54-c99e95f9ca41"
      },
      "source": [
        "- filename: 2022_0120onomatopea_bert_fine_tuing.ipynb\n",
        "- memo: 2022年01月20日現在，\n",
        "\n",
        "transformers は M1 Mac では動作しない。Intel Mac such as pasiphae では動作する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6640bdc1-716e-4c76-a12c-829914444287",
      "metadata": {
        "id": "6640bdc1-716e-4c76-a12c-829914444287"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "from termcolor import colored\n",
        "\n",
        "# 本ファイルを Google Colaboratory 上で実行する場合に，必要となるライブラリをインストールする\n",
        "import platform\n",
        "isColab = platform.system() == 'Linux'\n",
        "if isColab:\n",
        "    !pip install transformers > /dev/null 2>&1 \n",
        "\n",
        "    # MeCab, fugashi, ipadic のインストール\n",
        "    !apt install aptitude swig > /dev/null 2>&1\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null 2>&1\n",
        "    !pip install mecab-python3 > /dev/null 2>&1\n",
        "    !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null 2>&1\n",
        "    !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null 2>&1\n",
        "    \n",
        "    import subprocess\n",
        "    cmd='echo `mecab-config --dicdir`\\\"/mecab-ipadic-neologd\\\"'\n",
        "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                                     shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "    !pip install 'fugashi[unidic]' > /dev/null 2>&1\n",
        "    !python -m unidic download > /dev/null 2>&1\n",
        "    !pip install ipadic > /dev/null 2>&1\n",
        "    !pip install jaconv > /dev/null 2>&1 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021/Jan 近藤先生からいただいたオノマトペ辞典のデータの読み込み\n",
        "\n",
        "#'日本語オノマトペ辞典4500より.xls' は著作権の問題があり，公にできません。\n",
        "# そのため Google Colab での解法，ローカルファイルよりアップロードしてください\n",
        "if isColab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()  # ここで `日本語オノマトペ辞典4500より.xls` を指定してアップロードする\n",
        "    data_dir = '.'\n",
        "else:\n",
        "    data_dir = '/Users/asakawa/study/2021ccap/notebooks'\n",
        "\n",
        "import pandas as pd\n",
        "import jaconv\n",
        "\n",
        "onomatopea_excel = '2021-0325日本語オノマトペ辞典4500より.xls'\n",
        "onmtp2761 = pd.read_excel(os.path.join(data_dir, onomatopea_excel), sheet_name='2761語')\n",
        "\n",
        "\n",
        "#すべてカタカナ表記にしてデータとして利用する場合\n",
        "#`日本語オノマトペ辞典4500` はすべてひらがな表記だが，一般にオノマトペはカタカナ表記されることが多いはず\n",
        "#onomatopea = list(sorted(set([jaconv.hira2kata(o) for o in onmtp2761['オノマトペ']])))\n",
        "# Mac と Windows の表記の相違を吸収\n",
        "onomatopea = list(sorted(set([jaconv.normalize(o) for o in onmtp2761['オノマトペ']])))\n",
        "print(f'データファイル名: {os.path.join(data_dir, onomatopea_excel)}\\n',\n",
        "      f'オノマトペ単語総数: len(onomatopea):{len(onomatopea)}')"
      ],
      "metadata": {
        "id": "1-uefORQKvfM"
      },
      "id": "1-uefORQKvfM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a514e28d-3aaa-4c58-b519-6d7940e663ac",
      "metadata": {
        "id": "a514e28d-3aaa-4c58-b519-6d7940e663ac"
      },
      "outputs": [],
      "source": [
        "# 近藤先生 (2021年12月22日） から送っていただいた，オノマトペ文章データ 'original.csv' を読み込む\n",
        "import jaconv\n",
        "\n",
        "if isColab:\n",
        "    uploaded = files.upload()  # original.csv をアップロード\n",
        "    data_dir = '.'\n",
        "else:\n",
        "    data_dir = '/Users/asakawa/study/2021kondo_project'\n",
        "\n",
        "original = []\n",
        "n = 0\n",
        "with open(os.path.join(data_dir,'original.csv'), 'r', encoding='utf8') as f:\n",
        "    s = f.read()\n",
        "    for s_ in s.split('\\n'):\n",
        "        if n == 0:\n",
        "            n += 1\n",
        "            continue\n",
        "        idx, sent = s_.split(',')\n",
        "        \n",
        "        # Mac と Windows との unicode 符号化の差分を吸収する\n",
        "        # jaconv.normalize は内部で unicodedata.normalize('NFKC') を呼び出しているので\n",
        "        # 差異 between Mac and Windows を吸収できる\n",
        "        sent = ''.join(jaconv.normalize(x) for x in sent)\n",
        "        original.append(sent)\n",
        "        #original[int(idx)] = sent\n",
        "\n",
        "print(f'{len(original)} has been read')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4976eb75-17a4-49a8-894f-d2597808de18",
      "metadata": {
        "tags": [],
        "id": "4976eb75-17a4-49a8-894f-d2597808de18"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import torch\n",
        "from transformers import BertConfig\n",
        "#from transformers import BertModel\n",
        "from transformers import BertForPreTraining\n",
        "from transformers import BertJapaneseTokenizer\n",
        "from transformers import BertForMaskedLM\n",
        "\n",
        "\n",
        "model_ja_name = 'cl-tohoku/bert-base-japanese' \n",
        "model = BertForMaskedLM.from_pretrained(model_ja_name)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "config = BertConfig.from_pretrained(model_ja_name)\n",
        "\n",
        "# トークナイザ の修正\n",
        "tknz1 = BertJapaneseTokenizer.from_pretrained(model_ja_name)\n",
        "# BPE (or sentencepiece) による下位単語分割あり\n",
        "\n",
        "tknz1.add_tokens(onomatopea)\n",
        "model.resize_token_embeddings(len(tknz1))\n",
        "\n",
        "print(f' len(tknz1):{len(tknz1)}\\n', \n",
        "      f'len(tknz1.vocab):{len(tknz1.vocab)}\\n',  # 一見すると，この数字からオノマトペが追加されていないように見える。\n",
        "      f'tknz1.vocab_size:{tknz1.vocab_size}')    # 駄菓子菓子，下で見るように，正しく動作しているように見受けられる\n",
        "\n",
        "# 確認用\n",
        "for w in onomatopea[-5:]:\n",
        "    idx = tknz1.convert_tokens_to_ids(w)\n",
        "    w_ = tknz1.convert_ids_to_tokens(idx)\n",
        "    print(f'{w} id:{idx} -> token:{w_}')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44121703-ceac-4b99-9977-b2b256a4008c",
      "metadata": {
        "id": "44121703-ceac-4b99-9977-b2b256a4008c"
      },
      "outputs": [],
      "source": [
        "# こちらも確認用，オノマトペを追加していないトークナイザwを tknz2 とする\n",
        "tknz2 = BertJapaneseTokenizer.from_pretrained(model_ja_name)\n",
        "print(tknz1.tokenize('雨がしとしとと降る'))  #オノマトペ追加バージョンの出力\n",
        "print(tknz2.tokenize('雨がしとしとと降る'))  #without オノマトペのトークナイザによる出力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04315406-2538-440a-aefc-edb187fd562d",
      "metadata": {
        "id": "04315406-2538-440a-aefc-edb187fd562d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# ランダムサンプリングしてデータを印字して確認\n",
        "for _ in range(3):\n",
        "    N = np.random.randint(low=0, high=len(original))\n",
        "    sent0 = original[N]\n",
        "    sent1 = re.sub('\\(と\\)','と',original[N]) # original に含まれる `(と)` のような表現を削除する\n",
        "    \n",
        "    print(colored(sent0, attrs=['bold']))  # 送っていただいた元の文\n",
        "    print(colored('\\t分かち書き','blue'), tknz1.tokenize(sent0)) # その分かち書き\n",
        "    print(colored('\\tトークン ID', 'blue'), tknz1.encode(sent0))     # 分かち書き結果の単語 ID 化\n",
        "\n",
        "    if sent0 != sent1:\n",
        "        print(colored('\\t分かち書き','red'), tknz1.tokenize(sent1)) # その分かち書き\n",
        "        print(colored('\\tトークンID', 'red'), tknz1.encode(sent1))      # 分かち書き結果の単語 ID 化\n",
        "\n",
        "# MeCab で単語分割が行われて、MeCab が単語として認識しても、その単語が語鎮リスト vocab.txt に登録されていない場合は\n",
        "# subword である WordPiece が起動され、その単語が適当に分割されます。そのように分割された単語には '##' が単語の前に付与されます。\n",
        "# また、未知語の場合もWordPieceが起動され、同様に分割されます。\n",
        "\n",
        "print('\\n', '-' * 77)\n",
        "print('# 以下は，特殊トークンと対応するトークン ID との関係を表示。')\n",
        "print('# 英語版で標準的に用いられる `bert-base-uncased` と東北大学乾研の特殊トークンの ID は異なることに注意')\n",
        "print(colored(f'tknz.all_special_ids:{tknz1.all_special_ids}',attrs=['bold']))  #  [1, 3, 0, 2, 4]\n",
        "print(colored(f'tknz.all_special_tokens:{tknz1.all_special_tokens}', attrs=['bold']))  #  ['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "592b9da1-b8fc-4b1e-9cec-d99de088f3d4",
      "metadata": {
        "id": "592b9da1-b8fc-4b1e-9cec-d99de088f3d4"
      },
      "outputs": [],
      "source": [
        "text = tuple(original)  # 全文をタプルに変換\n",
        "\n",
        "# トークナイザにかけて出力を得る。`max_length` のデフォルトは 512 だが，今回は長文である必要がないと考えられる\n",
        "# ので 32 にしている。512 でも動作するが，学習に要する時間が増える\n",
        "inputs = tknz1(text, return_tensors='pt', max_length=32, truncation=True, padding='max_length')\n",
        "\n",
        "#`labels` キーを追加する。実際には inputs_ids なのでラベルではなくトークンID の系列\n",
        "inputs['labels'] = inputs.input_ids.detach().clone()\n",
        "\n",
        "#トークン ID を走査して，オノマトペ単語であれば，[MASK] トークンに置き換える。\n",
        "l_ = []\n",
        "for l in inputs['labels']:\n",
        "    l_.append([tknz1.mask_token_id if w in onomatopea else tknz1.convert_tokens_to_ids(w) for w in tknz1.convert_ids_to_tokens(l)])\n",
        "\n",
        "inputs['input_ids'] = torch.LongTensor(l_)\n",
        "#print(inputs['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f73e593-c87f-432d-89cf-0db3b4a945bc",
      "metadata": {
        "id": "9f73e593-c87f-432d-89cf-0db3b4a945bc"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "#print(f'# 直上で定義した `inputs` は全オノマトペの著者，小野による説明文すべてである。総数は {len(inputs.input_ids)}')\n",
        "#print('これを一通り評価するにはどれほどの時間がかかkるのか，時間を計測してみる')\n",
        "#outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d28f508-82da-4522-8299-e9a41c81fa46",
      "metadata": {
        "id": "7d28f508-82da-4522-8299-e9a41c81fa46"
      },
      "outputs": [],
      "source": [
        "#print(inputs['input_ids'][0][:32])\n",
        "#print(inputs['labels'][0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3bd44d-2b76-4f7d-81f3-dd8246464ce2",
      "metadata": {
        "id": "dd3bd44d-2b76-4f7d-81f3-dd8246464ce2"
      },
      "outputs": [],
      "source": [
        "#データセットのためのクラスを定義\n",
        "class onmtpDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encoder):\n",
        "        self.encoder = encoder\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return {key:torch.tensor(val[idx]) for key, val in self.encoder.items()}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.encoder.input_ids)\n",
        "    \n",
        "dataset = onmtpDataset(inputs)\n",
        "\n",
        "#データローダを準備\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# GPU/CPU 使用を設定し，モデルの訓練モードを起動 #Setup GPU/CPU usage and activate the training mode of our model.\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# そしてモデルを選択したデバイスに移動 # and move our model over to the selected device\n",
        "model.to(device)\n",
        "# 訓練モードに設定 #activate training mode\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c748723f-3fa0-4009-85d4-3dcea720fbd9",
      "metadata": {
        "id": "c748723f-3fa0-4009-85d4-3dcea720fbd9"
      },
      "outputs": [],
      "source": [
        "#最適化関数を初期化 (AdamW は重み付き崩壊で，過学習の可能性を減らします) \n",
        "#Initialize our optimizer (Adam with weighted decay - reduces chance of overfitting).\n",
        "\n",
        "from transformers import AdamW\n",
        "#最適化関数を初期化 # initialize optimizer\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f813d84-5688-4956-a71e-4481f43bba65",
      "metadata": {
        "id": "5f813d84-5688-4956-a71e-4481f43bba65"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm  # for our progress bar\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # setup loop with TQDM and dataloader\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        # process\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        labels=labels)\n",
        "        # extract loss\n",
        "        loss = outputs.loss\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tknz1.convert_ids_to_tokens(\n",
        "a = input_ids.detach().squeeze()\n",
        "print(tknz1.convert_ids_to_tokens(a))\n",
        "x = outputs.logits.detach()\n",
        "\n",
        "print('-' * 77)\n",
        "_x = x.squeeze(0).detach().clone()\n",
        "print(tknz1.convert_ids_to_tokens(torch.argmax(_x, dim=1, keepdim=True)))\n",
        "#help(torch.argmax)"
      ],
      "metadata": {
        "id": "OZB2iYxxZXnd",
        "outputId": "d0fc3497-ddf6-4c84-ca70-9714aaa70d7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OZB2iYxxZXnd",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '疲れ', 'て', '[MASK]', 'と', 'いかに', '##も', 'だ', '##る', 'そう', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "-----------------------------------------------------------------------------\n",
            "['[CLS]', '疲れ', 'て', 'ぐたっ', 'と', 'いかに', '##も', 'だ', '##る', 'そう', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fad1d3b7-99e0-4c65-8ad0-9a0ac1d356c8",
      "metadata": {
        "id": "fad1d3b7-99e0-4c65-8ad0-9a0ac1d356c8",
        "outputId": "a095abdd-f57a-4e12-b7da-f01f1ff51b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2469, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "inputs['input_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0a5fe218-c57c-46a9-bfee-684455f134b5",
      "metadata": {
        "id": "0a5fe218-c57c-46a9-bfee-684455f134b5",
        "outputId": "7a7b5cf6-d503-4551-f8c0-30d6ec0ce20f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 33711])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "outputs.logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b376fa0c-dcf1-454f-9ee4-e4b8081c8ad8",
      "metadata": {
        "id": "b376fa0c-dcf1-454f-9ee4-e4b8081c8ad8",
        "outputId": "b5be9846-cf35-4427-c535-a285e273989a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# input_ids = batch['input_ids'].to(device)\n",
        "# attention_mask = batch['attention_mask'].to(device)\n",
        "# labels = batch['labels'].to(device)\n",
        "# outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "_sent = '\b\b今日は寒くて，体が[MASK]とふるえる'\n",
        "_inp = tknz1(_sent)\n",
        "type(_inp.input_ids)\n",
        "#_out = model(_inp.input_ids)\n",
        "# print(_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimr.state_dict():\n",
        "    print(var_name, \"\\t\", optim.state_dict()[var_name])"
      ],
      "metadata": {
        "id": "ifL8B3ndkqHr"
      },
      "id": "ifL8B3ndkqHr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '2022_0120onomatopea.pt')\n",
        "#\n",
        "\n",
        "model = BertForMaskedLMK() #.from_pretrained(model_ja_name)\n",
        "model.load_state_dict(torch.load('2022_0120onomatopea.pt'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "fT6reXlxkq9F"
      },
      "id": "fT6reXlxkq9F",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "2022_01220onomatopea_bert_fine_turing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}