{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNA3/xJd8GtfS6F+ozVbY7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1020lam_making_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "try:\n",
        "    import bit\n",
        "except ImportError:\n",
        "    !pip install ipynbname --upgrade > /dev/null 2>&1 \n",
        "    !git clone https://github.com/ShinAsakawa/bit.git\n",
        "import bit\n",
        "\n",
        "isColab = bit.isColab\n",
        "HOME = bit.HOME\n",
        "\n",
        "if isColab:\n",
        "    # 近藤先生のご指摘によりインストールされる全ライブラリのメッセージを表示させることにした\n",
        "    !apt install aptitude\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "    !pip install mecab-python3==0.7\n",
        "    !pip install -q konoha[all]\n",
        "    !pip install jaconv\n",
        "    !pip install japanize_matplotlib\n",
        "    \n",
        "    import MeCab\n",
        "    wakati = MeCab.Tagger('-Owakati').parse\n",
        "    yomi = MeCab.Tagger('-Oyomi').parse\n",
        "else:\n",
        "    from ccap.mecab_settings import yomi\n",
        "    from ccap.mecab_settings import wakati\n"
      ],
      "metadata": {
        "id": "VGgy0mta3D3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 自作ライブラリ LAM の読み込み\n",
        "if isColab:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    !git clone https://github.com/ShinAsakawa/lam.git"
      ],
      "metadata": {
        "id": "anVZ6V3N-9is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # upload `psylex71utf8.txt` from local drive\n",
        "# # Be carefull! This file is copyright protected. \n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# !mv psylex71utf8.txt ccap"
      ],
      "metadata": {
        "id": "mydF09TND7yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ここはお遊びなので，スキップしても良い\n",
        "import IPython\n",
        "IPython.display.Image(url=\"https://livedoor.blogimg.jp/ftb001/imgs/b/4/b4629a79.jpg\")"
      ],
      "metadata": {
        "id": "2lMc1L0EDhZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim\n",
        "\n",
        "# 自作ライブラリ LAM の読み込み\n",
        "import lam \n",
        "from lam import EncoderRNN\n",
        "from lam import AttnDecoderRNN\n",
        "from lam import convert_ids2tensor\n",
        "from lam import train\n",
        "from lam import asMinutes, timeSince\n",
        "#from lam import fit\n",
        "from lam import convert_ids2tensor\n",
        "from lam import fix_seed\n",
        "from lam import worker_init_fn\n",
        "from lam import make_vocab_dataset\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import typing\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import copy\n",
        "from termcolor import colored\n",
        "\n",
        "# from tqdm import tqdm         #commandline で実行時\n",
        "from tqdm.notebook import tqdm  #jupyter で実行時\n",
        "\n",
        "# from tqdm import tqdm         #commandline で実行時\n",
        "from tqdm.notebook import tqdm  #jupyter で実行時\n",
        "\n",
        "# シミュレーションに必要なパラメータの設定\n",
        "params = {\n",
        "    'traindata_size':   10000,    # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    #'traindata_size': 301612,    # 訓練データ数，NTT 日本語語彙特性の高頻度語を上位から抽出\n",
        "    'epochs': 20,                # 学習のためのエポック数\n",
        "    'hidden_size': 24,           # 中間層のニューロン数\n",
        "    'random_seed': 42,           # 乱数の種。ダグラス・アダムス著「銀河ヒッチハイカーズガイド」\n",
        "\n",
        "    # 以下 `source` と `target` を定義することで，別の課題を実行可能\n",
        "    'source': 'orthography',        # ['orthography', 'phonology', 'mora', 'mora_p', 'mora_p_r']\n",
        "    'target': 'mora_p_r',          # ['orthography', 'phonology', 'mora', 'mora_p', 'mora_p_r']\n",
        "    # 'orthography': 書記素, \n",
        "    # 'phonology': 音韻, \n",
        "    # 'mora': モーラ\n",
        "    # 'mora_p': モーラを silius による音分解\n",
        "    # 'mora_p_r': モーラの silius 音分解の逆\n",
        "    'pretrained': False,          # True であれば訓練済ファイルを読み込む\n",
        "    #'pretrained': True,          # True であれば訓練済ファイルを読み込む\n",
        "    'isTrain'   : True,          # True であれば学習する\n",
        "    \n",
        "    # 学習済のモデルパラメータを保存するファイル名\n",
        "    #'path_saved': '2022_0607lam_o2p_hid32_vocab10k.pt', \n",
        "    #'path_saved': '2022_0829lam_p2p_hid24_vocab10k.pt',\n",
        "    'path_saved': False,                      # 保存しない場合\n",
        "    \n",
        "    # 結果の散布図を保存するファイル名    \n",
        "    'path_graph': '2022_0829lam_p2p_hid24_vocab10k.pdf',\n",
        "    #'path_graph': False,                      # 保存しない場合\n",
        "\n",
        "    'lr': 0.001,                              # 学習率\n",
        "    'dropout_p': 0.0,                         # ドロップアウト率\n",
        "    'teacher_forcing_ratio': 0.5,             # 教師強制を行う確率\n",
        "    'optim_func': torch.optim.Adam,           # 最適化アルゴリズム ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.AdamW']\n",
        "    'loss_func' :torch.nn.CrossEntropyLoss(), # 交差エントロピー損失 ['torch.nn.NLLLoss()', or 'torch.nn.CrossEntropyLoss()']\n",
        "}\n",
        "\n",
        "device = lam.device  # CPU or GPU の選択\n",
        "\n",
        "for param in params:\n",
        "    print(colored(f'{param}','blue',attrs=['bold']), colored(f': {params[param]}','grey'))\n",
        "    \n",
        "# 乱数シード固定（再現性担保のため）\n",
        "fix_seed(seed = params['random_seed'])\n",
        "print(worker_init_fn(1))    \n",
        "\n",
        "_vocab = lam.VOCAB(traindata_size=params['traindata_size'], yomi=yomi)"
      ],
      "metadata": {
        "id": "hUjOGlRE_iq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果を保存するなら，このセルを実行\n",
        "import json\n",
        "tmp_data = {}\n",
        "for x in dir(_vocab):\n",
        "    if not x.startswith('__'):\n",
        "        if isinstance(eval(f'_vocab.{x}'), dict):\n",
        "            if len(eval(f'_vocab.{x}')) != 0:\n",
        "                tmp_data[x] = eval(f'_vocab.{x}')\n",
        "                print(colored((x, len(tmp_data[x])), 'blue', attrs=['bold']))\n",
        "        elif isinstance(eval(f'_vocab.{x}'), list):\n",
        "            tmp_data[x] = eval(f'_vocab.{x}')\n",
        "            print(colored((x, len(tmp_data[x])), 'red', attrs=['bold']))\n",
        "        elif isinstance(eval(f'_vocab.{x}'), int):\n",
        "            tmp_data[x] = eval(f'_vocab.{x}')\n",
        "            print(colored((x, tmp_data[x]), 'green', attrs=['bold']))\n",
        "        elif isinstance(eval(f'_vocab.{x}'), str):\n",
        "            tmp_data[x] = eval(f'_vocab.{x}')\n",
        "            print(colored((x, tmp_data[x]), 'yellow', attrs=['bold']))\n",
        "        else:\n",
        "            print(x, type(eval(f'_vocab.{x}')))\n",
        "\n",
        "#zip_fname = '2022_1011lam_traindata.json.gz'\n",
        "#zip_fname = '2022_1011lam_traindata10k.json.gz'\n",
        "zip_fname = '2022_1018lam_traindata10k.json.gz'\n",
        "with gzip.open(zip_fname, 'wt', encoding='utf-8') as fp:\n",
        "    json.dump(tmp_data,fp)\n",
        "        \n",
        "with gzip.open(zip_fname, 'r') as fp:\n",
        "    x = json.load(fp)\n",
        "\n",
        "print(tmp_data.keys())\n",
        "print(x.keys())"
      ],
      "metadata": {
        "id": "wyLd2v5cOmVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}