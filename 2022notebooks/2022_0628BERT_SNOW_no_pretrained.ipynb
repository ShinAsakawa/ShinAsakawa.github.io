{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0628BERT_SNOW_no_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "685cf5c1-71dd-47ec-b65b-e8a2d66fa96f",
      "metadata": {
        "id": "685cf5c1-71dd-47ec-b65b-e8a2d66fa96f"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    !pip install jaconv > /dev/null 2>&1 \n",
        "    !pip install transformers fugashi ipadic  > /dev/null 2>&1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891af644-47fc-4966-b3d1-d1bdc03eedaf",
      "metadata": {
        "id": "891af644-47fc-4966-b3d1-d1bdc03eedaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacf7e22-8a7f-4a93-9c5b-506a09b303a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "エクセルファイル読込...url:https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/T15-2020.1.7.xlsx\n",
            "T15-2020.1.7.xlsx をダウンロード中 3634132 バイト\n",
            "url:https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/T23-2020.1.7.xlsx\n",
            "T23-2020.1.7.xlsx をダウンロード中 3641507 バイト\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from termcolor import colored\n",
        "import jaconv\n",
        "\n",
        "# やさしい日本語をダウンロード\n",
        "SNOWs={'T15': {'url':\"https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/T15-2020.1.7.xlsx\"},\n",
        "       'T23': {'url':\"https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/T23-2020.1.7.xlsx\"},\n",
        "      }\n",
        "print('エクセルファイル読込', end='...')\n",
        "for corpus in SNOWs:\n",
        "    url = SNOWs[corpus]['url']\n",
        "    excel_fname = corpus + '-2020.1.7.xlsx'\n",
        "    \n",
        "    if not os.path.exists(excel_fname):  # ファイルが存在しない場合ダウンロード\n",
        "        print(f'url:{url}')\n",
        "        r = requests.get(url)\n",
        "        with open(excel_fname, 'wb') as f:\n",
        "            total_length = int(r.headers.get('content-length'))\n",
        "            print(f'{excel_fname} をダウンロード中 {total_length} バイト')\n",
        "            f.write(r.content)\n",
        "\n",
        "    SNOWs[corpus]['df'] = pd.read_excel(excel_fname)\n",
        "    SNOWs[corpus]['df'] = SNOWs[corpus]['df'].rename(columns={'#日本語(原文)': 'ja', \n",
        "                                                              '#やさしい日本語':'easy_ja',\n",
        "                                                              '#英語(原文)':'en'})\n",
        "# 2 つのデータをあわせる    \n",
        "_snow = SNOWs['T15']['df']['easy_ja'].tolist() + SNOWs['T23']['df']['easy_ja'].tolist()\n",
        "snow = [jaconv.normalize(line, 'NFKC') for line in _snow] # 正規化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6436543-dc1d-4bd5-935e-48c52bbb9f52",
      "metadata": {
        "id": "c6436543-dc1d-4bd5-935e-48c52bbb9f52"
      },
      "source": [
        "BERT の事前訓練には，マスク化言語モデル (**MLM**) と次文予測 (**NSP**) という 2 つの独自の学習アプローチがある。\n",
        "ここでは，マスク化言語モデルを用いて，モデルを微調整 fine-tuning する方法を試してみることとする。\n",
        "\n",
        "# 1. マスク化言語モデル MLM\n",
        "\n",
        "MLM とは BERT モデルに対して，文を入力として与え，BERT 内部の重みを最適化して，側に同じ文を出力することである。\n",
        "このとき，文中の任意の単語，または単語の断片を マスクトークンに置き換えることを行う。\n",
        "BERT はこの，マスクトークンの位置に正しいトークンを予測することが求められる。\n",
        "\n",
        "実際に BERT にその入力文を与える前に，トークンを定義するなどが，必要になる。\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1400/1*phTLnQ8itb3ZX5_h9BWjWw.png\" width=\"600px\"><br/>\n",
        "本図では，トークン を BERT に渡す前に，リンカーン・トークンを [MASK] に置き換えてマスクしている。\n",
        "</center>\n",
        "\n",
        "すなわち，実際には不完全な文章を入力して，BERT に，その文章を完成させるように依頼している。\n",
        "国語の教科教育，あるいは外国語の習得おける，穴埋め問題とみなしうる。\n",
        "\n",
        "## 1.1 マスクを埋める\n",
        "\n",
        "例えば以下のような文章が与えられたとする:\n",
        "\n",
        "`秋 に は ， ___ が 木 から 落ちる 。`\n",
        "\n",
        "アンダーライン部分の単語を推定することを考えてみる。\n",
        "答えは，所与の文章かから，文脈を類推し予測していることになる。\n",
        "\n",
        "「落ちる」 と 「木」 という単語が出てきましたが，足りない単語は木から落ちるものだということがわかる。\n",
        "\n",
        "どんぐり，枝，葉など，木から落ちるものはたくさんある。\n",
        "だが，秋という別の条件があるので，秋に木から落ちる可能性が最も高いのは葉だということで，検索対象が絞られる。\n",
        "\n",
        "人間はは，一般的な世界の知識と言語的な理解を組み合わせて，その結論を導き出す。\n",
        "BERT の場合，この推測は，コーパスから，たくさんの文章を与えられることで，言語パターンを学んでいることから適切な単語を得ることとなる。\n",
        "\n",
        "BERT は，秋，木，葉が何であるかを知らないかもしれません。\n",
        "だが，言語パターンとこれらの単語の文脈から，答えが葉である可能性が最も高いことを知ることとなる。\n",
        "\n",
        "この処理の結果，BERT にとっては，使用されている言語のスタイルの理解度が向上する。\n",
        "\n",
        "\n",
        "## 1.2 実際の処理\n",
        "\n",
        "MLM が何をしているかは理解できたと思うが，実際にはどのように機能するのだろうか?\n",
        "コード上で必要となる論理的なステップは何だろうか？\n",
        "以下のように考えることができよう:\n",
        "\n",
        "1. テキストをトークン化する\n",
        "通常の変換機と同じように，まずテキストをトークン化する。\n",
        "BERT の標準的な手続きでは，トークン化により，3 つの異なるテンソルが得られる。\n",
        "\n",
        "* input_ids\n",
        "* token_type_ids\n",
        "* attention_mask\n",
        "\n",
        "MLM には `token_type_ids` は必要ない。\n",
        "本例では `attention_mask` はそれほど重要ではない。\n",
        "\n",
        "この問題設定では `input_ids` テンソルが重要である。\n",
        "`input_ids` はトークン化済みの文表現であり，これを修正していくこととする。\n",
        "\n",
        "2. `labels tensor` を作成\n",
        "\n",
        "ここではモデルを訓練しているので，損失を計算して最適化するためのラベルテンソルが必要である。\n",
        "実際には `labels tensor` は単純に `input_ids` なので，これをコピーするだけである。\n",
        "\n",
        "3. `input_ids` のトークンをマスクする\n",
        "\n",
        "label 用の `input_ids` のコピーを作成した後，トークン系列内のランダムな位置のトークンを選択し，マスクする。\n",
        "\n",
        "\n",
        "BERT 論文では，モデルの事前訓練中に，いくつかの追加ルールを用いて，各トークンを 15％ の確率でマスク化している。\n",
        "ここではこれを簡略化して，各単語を 15％ の確率でマスク化することとする。\n",
        "\n",
        "\n",
        "4. 損失を計算する\n",
        "\n",
        "`input_ids` と `labels` のテンソルを BERT モデルで処理し，両者の間の損失を計算する。\n",
        "この損失値を用いて，BERT による必要な勾配変化を計算し，モデルの重みを最適化する。\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1400/1*0KvOrY6rY055m9oq36HRkg.png\" width=\"600px\"><br/>\n",
        "<div style=\"text-align:left; width:66%; background-color:cornsilk\">\n",
        "\n",
        "512 個のトークンはすべて，モデルの語彙サイズに等しいベクトル長を持つ。\n",
        "このベクトルを BERT に与えることにより，最終的な出力埋め込みベクトルであるロジット(確率比) が生成される。\n",
        "予測されたトークン ID は，ソフトマックスと argmax 変換を用いて，このロジットから抽出される。\n",
        "</div>    \n",
        "</center>    \n",
        "\n",
        "損失は，各「トークン」の出力確率分布と，真のワンホット符号化ラベルとの差として計算される。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677aa827-b7ef-4824-ab70-7d71665330d1",
      "metadata": {
        "id": "677aa827-b7ef-4824-ab70-7d71665330d1"
      },
      "source": [
        "# 2. マスク化言語モデル MLM の実装\n",
        "\n",
        "HuggingFace のトランスフォーマーと PyTorch を用いて実装を検討する。\n",
        "標的言語が英語の場合には `bert-base-uncased` モデルを使用する。\n",
        "日本語の場合には，複数の訓練済モデルが提案されている。\n",
        "ここでは，東北大学版の訓練済モデル `cl-tohoku/bert-base-japanese` を用いた実装を試みる。\n",
        "\n",
        "まず全てをインポートして初期化する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40c979f-9cfd-4905-ae03-45c9036cb262",
      "metadata": {
        "id": "d40c979f-9cfd-4905-ae03-45c9036cb262"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers    \n",
        "from transformers import BertJapaneseTokenizer\n",
        "from transformers import BertForMaskedLM\n",
        "from transformers import BertConfig\n",
        "\n",
        "# BERT 訓練済モデルをダウロード\n",
        "model_name_ja = 'cl-tohoku/bert-base-japanese'  # 東北大学乾研による 日本語 BERT 実装\n",
        "# see https://huggingface.co/sonoisa/sentence-bert-base-ja-mean-tokens-v2\n",
        "# model_name_ja = 'sonoisa/sentence-bert-base-ja-mean-tokens-v2'  # 東北大学乾研による 日本語 BERT 実装\n",
        "\n",
        "tknz = BertJapaneseTokenizer.from_pretrained(model_name_ja)\n",
        "# ここだけが異なる\n",
        "config = BertConfig.from_pretrained(model_name_ja)  \n",
        "bert_model = BertForMaskedLM(config=config) #return_dict = True)\n",
        "# bert_model = BertForMaskedLM.from_pretrained(model_name_ja, return_dict = True)\n",
        "\n",
        "# リソースの選択（CPU/GPU）\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f8d7b0-d0e5-4b86-ac6f-aee979d7c70f",
      "metadata": {
        "id": "d4f8d7b0-d0e5-4b86-ac6f-aee979d7c70f"
      },
      "source": [
        "最大トークン長 `max_length` を設定する必要があるため，SNOW コーパスの最大長を求めておく。\n",
        "BPE (Byte-per-encoding) では，任意の文章のトークン数が，その文章の文字数以上になることはあり得ないことから，\n",
        "SNOW コーパスに現れる全文から，最大文字数の文章を探して，その文章の文字数を最大値として利用することとしてみる。\n",
        "\n",
        "BPE の詳細については，ここでは触れない。\n",
        "簡単に説明すると，どのような言語でも，文字数 <= 単語数 という関係が成り立つ。\n",
        "そのため，入力ベクトル表現の次元数は，文字ベースではれば小さくなり，単語ベースであれば，総語彙分の次元を用意しなければならない。\n",
        "一方，単語ベースでは任意の単語の持つ意味表現を，表現できてはいない。\n",
        "そこで，単語ベースの次元数の少なさと，単語ベースの意味表現の長所の折衷案を考える。\n",
        "まず単語ベースの表現を考えて全文を走査する。\n",
        "そして，頻出する文字の並びを，新たなトークンとみなして，新たなトークンを作成する。\n",
        "望むトークン数の上限に達するまで，この操作を繰り返す。\n",
        "これにより，単語ベースの入力ベクトル次元数の小ささと，\n",
        "頻出語彙は登録されているため，意味情報を反映できるという，両者の長所を捉えた表現が可能である。\n",
        "これが BPE の本質である。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a3b017-2dfa-433a-9a33-128a75b82212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a3b017-2dfa-433a-9a33-128a75b82212",
        "outputId": "94701429-82a2-4abd-c505-f6bc90200b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "やさしい日本語における一文の最長文字数:99\n",
            "torch.Size([84300, 100])\n"
          ]
        }
      ],
      "source": [
        "max_length = 0\n",
        "for line in snow:\n",
        "    max_length = len(line) if len(line) > max_length else max_length\n",
        "print(f'やさしい日本語における一文の最長文字数:{max_length}')\n",
        "inputs = tknz(snow, return_tensors='pt', max_length=max_length+1, truncation=True, padding='max_length')\n",
        "# トークンの分割数が文字数以上になることはないので `max_length=max_length+1`とした\n",
        "print(inputs.input_ids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe96e8d-8674-41c2-9ffc-70a82ee7fafa",
      "metadata": {
        "id": "6fe96e8d-8674-41c2-9ffc-70a82ee7fafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba5d6ff-a002-4809-dbd3-2a7fe7285d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['##鵠', '##Š', '##ˈ', '##ヱ', '##丑', '##唖', '##娩', '##彪', '##忽', '##托', '##桧', '##楡', '##珀', '##祢', '##稷', '##竈', '##粥', '##臧', '##蟄', '##訣', '##賽', '##銑', '##鯱', '##ē', '##ł', '##з', '##侃', '##嬪', '##崋', '##巽']\n",
            "['誰', 'が', '一番', 'に', '着く', 'か', '私', 'に', 'は', '分かり', 'ませ', 'ん', '。']\n",
            "[2, 3654, 14, 4749, 7, 17324, 29, 1325, 7, 9, 14604, 6769, 1058, 8, 3]\n"
          ]
        }
      ],
      "source": [
        "#type(tknz.vocab)  # collections.OrderedDict\n",
        "#len(tknz.vocab)    # 3200\n",
        "\n",
        "# BERT のトークン化器に登録されている語彙のうち，最後の 30 トークンを表示させてみる\n",
        "print(list(tknz.vocab.keys())[-30:])\n",
        "\n",
        "# やさしい日本語コーパスの最初の文のトークン化を表示させてみる\n",
        "print(tknz.tokenize(snow[0]))\n",
        "\n",
        "# 直上の，やさしい日本語コーパスの最初の文に対応するトークン ID を表示させてみる\n",
        "print(tknz(snow[0])['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca177ef-e158-4cb2-a244-7905a619cce4",
      "metadata": {
        "id": "7ca177ef-e158-4cb2-a244-7905a619cce4"
      },
      "source": [
        "## 2.1 文章のトークン化\n",
        "\n",
        "試みに，最初の 3 文だけトークン化器にとおして，戻り値を観察して理解を深めておきたい。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d685d8f9-7c84-4b1d-9c64-9d7a1b720251",
      "metadata": {
        "id": "d685d8f9-7c84-4b1d-9c64-9d7a1b720251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2559371-86d5-41eb-8262-a862876aedee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['誰が一番に着くか私には分かりません。', '多くの動物が人間によって殺された。', '私はテニス部員です。']\n",
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "{'input_ids': tensor([[    2,  3654,    14,  4749,     7, 17324,    29,  1325,     7,     9,\n",
            "         14604,  6769,  1058,     8,     3],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,    10,\n",
            "             8,     3,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     8,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "print(snow[:3])  # やさしい日本語コーパスの最初の 3 文\n",
        "\n",
        "# やさしい日本語コーパスの最初の 3 文をトークナイズして `inputs` に代入\n",
        "inputs = tknz(snow[:3], return_tensors='pt', padding=True)\n",
        "\n",
        "# 代入した結果が `dict` として返ってくるので，その `dict` の key を表示\n",
        "print(inputs.keys())\n",
        "\n",
        "# 返ってきた `dict` の内容を表示\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dcd7602-cda9-4dfb-aafc-2e729821acf1",
      "metadata": {
        "id": "9dcd7602-cda9-4dfb-aafc-2e729821acf1"
      },
      "source": [
        "## ラベル作成\n",
        "\n",
        "`input_ids` テンソルを新しい labels テンソルに複製 `clone()` して，結果を `inputs` 変数に格納する。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91588018-5aa5-49b3-8e96-955cced3bbd2",
      "metadata": {
        "id": "91588018-5aa5-49b3-8e96-955cced3bbd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c026224b-1484-4315-8778-b34d3b0940b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,  3654,    14,  4749,     7, 17324,    29,  1325,     7,     9,\n",
            "         14604,  6769,  1058,     8,     3],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,    10,\n",
            "             8,     3,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     8,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[    2,  3654,    14,  4749,     7, 17324,    29,  1325,     7,     9,\n",
            "         14604,  6769,  1058,     8,     3],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,    10,\n",
            "             8,     3,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     8,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0]])}\n"
          ]
        }
      ],
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f370fc20-6d86-40d4-ab80-824f80de077c",
      "metadata": {
        "id": "f370fc20-6d86-40d4-ab80-824f80de077c"
      },
      "source": [
        "## 2.2 マスクの作成\n",
        "\n",
        "BERT の原著論文では，マスク化率が 15% のときに，BERT の性能が高くなるとの記述がある。\n",
        "そこで，この 15% の割合で，ランダムなマスクを作成する。\n",
        "\n",
        "トークンを 15% の確率でマスク化するためには `torch.rand` を用いて乱数を発生させ，その発生した値と $<0.15$ を比較することで，マスク化すべきトークン位置を決定することとする。\n",
        "このときの，マスクを示す配列を `mask_arr` とする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6be4a8-e2e6-41a7-bcdc-a0615034baf5",
      "metadata": {
        "id": "1a6be4a8-e2e6-41a7-bcdc-a0615034baf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290bb959-7dcd-45c7-8c3a-ada60fda6d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False],\n",
            "        [False, False, False,  True,  True, False, False, False, False,  True,\n",
            "         False, False,  True, False, False]])\n"
          ]
        }
      ],
      "source": [
        "# input_idsと同じ次元の浮動小数点数のランダムな配列を作成\n",
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "\n",
        "# 乱数配列が 0.15 より小さい場合は `true` を設定\n",
        "mask_arr = rand < 0.15\n",
        "\n",
        "# 結果としてできあがったマスク化配列を印字\n",
        "print(mask_arr) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb3290f-f18d-49c7-a13c-635ee3addda5",
      "metadata": {
        "id": "6cb3290f-f18d-49c7-a13c-635ee3addda5"
      },
      "source": [
        "- [MASK] トークンを配置する場所を選ぶために mask_arr を用いる。\n",
        "- 駄菓子菓子，[CLS] トークンや [SEP] トークンなどの特殊トークン (それぞれ `tknz.cls_token_id` と `tknz.sep_token_id` で取得可能) の上に MASK トークンを配置したくはない。\n",
        "\n",
        "そこで，さらに条件を追加する必要がある。\n",
        "トークン ID `tknz.cls_token_id` または `tknz.sep_token_id` を含む位置をチェックしてみることとする。\n",
        "\n",
        "その前に，どの特殊トークンが，どのトークン ID を持つのかを調べてみよう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff179178-beed-47f0-b91e-5f4a7e3efdd2",
      "metadata": {
        "id": "ff179178-beed-47f0-b91e-5f4a7e3efdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784083e2-76f6-497e-8017-c7b5af025aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 = 4\n",
            "2 = 2\n",
            "3 = 3\n"
          ]
        }
      ],
      "source": [
        "print(tknz.vocab['[MASK]'], '=', tknz.mask_token_id)\n",
        "print(tknz.vocab['[CLS]'], '=', tknz.cls_token_id)\n",
        "print(tknz.vocab['[SEP]'], '=', tknz.sep_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d09f0b0-7a48-4776-8bd5-4e54da94ab4c",
      "metadata": {
        "id": "6d09f0b0-7a48-4776-8bd5-4e54da94ab4c"
      },
      "source": [
        "上記のように，マスクトークンは `.mask_token_id`, 文トークンは `.cls_token_id`, 2 文の分離トークンは `sep_token_id` で参照される。\n",
        "これら特殊トークンの語彙辞書内のトークン番号は， `.vocab[トークン]` で参照可能である。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30967253-51f4-448f-bf7b-13aecf0462c9",
      "metadata": {
        "id": "30967253-51f4-448f-bf7b-13aecf0462c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cd644c-3462-4567-e910-5620daa473f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n",
            "[('[UNK]', 1), ('[SEP]', 3), ('[PAD]', 0), ('[CLS]', 2), ('[MASK]', 4)]\n"
          ]
        }
      ],
      "source": [
        "# 特殊トークンを表示\n",
        "print(tknz.special_tokens_map)\n",
        "\n",
        "# 各特殊トークンが，どのようなトークン番号を持つかを表示\n",
        "print([(value,tknz.vocab[value]) for token, value in tknz.special_tokens_map.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fe24f8-046c-4664-bcd2-81b74c828049",
      "metadata": {
        "id": "e9fe24f8-046c-4664-bcd2-81b74c828049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070246d7-d43d-4022-9c33-a20fb86ed4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True, False],\n",
            "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True, False,  True,  True,  True],\n",
            "        [False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
            "          True,  True,  True,  True,  True]])\n"
          ]
        }
      ],
      "source": [
        "# 入力文 `input_ids` 内のトークンが [CLS] ではなく，かつ，分離トークン [SEP] でもない 場合には `True` となる\n",
        "print((inputs.input_ids != tknz.cls_token_id) * (inputs.input_ids != tknz.sep_token_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698e0ab6-d47a-4fc3-a147-4cfb5930f3b1",
      "metadata": {
        "id": "698e0ab6-d47a-4fc3-a147-4cfb5930f3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d82325b-c6b6-49b9-b447-322ceb1e59ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False],\n",
            "        [False, False, False,  True,  True, False, False, False, False,  True,\n",
            "         False, False,  True, False, False]])\n"
          ]
        }
      ],
      "source": [
        "# 入力文 `input_ids` 内のトークンが [CLS] ではなく，かつ，分離トークン [SEP] でもなく\n",
        "# かつ，15% のマスク配列が `True` である場合には `True` となる\n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != tknz.cls_token_id) * (inputs.input_ids != tknz.sep_token_id)\n",
        "print(mask_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6206fb1c-6b0c-4468-985f-67e22a7d998b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6206fb1c-6b0c-4468-985f-67e22a7d998b",
        "outputId": "f3c31d32-392c-44dd-f2f3-bf1dd4ce384b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 11, 2, 3, 2, 4, 2, 9, 2, 12]\n"
          ]
        }
      ],
      "source": [
        "# 直上セルで作成した mask_arr から selection を計算して作成\n",
        "selection = torch.flatten((mask_arr).nonzero()).tolist()\n",
        "print(selection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb059596-8700-4828-a4d4-992fd414f71b",
      "metadata": {
        "id": "bb059596-8700-4828-a4d4-992fd414f71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f029908c-7939-4ca2-8a2d-9f16074723f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    4,  3654,     4,     4,     4, 17324,    29,  1325,     7,     4,\n",
            "         14604,     4,     4,     8,     3],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,    10,\n",
            "             8,     3,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     8,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[    2,  3654,    14,  4749,     7, 17324,    29,  1325,     7,     9,\n",
            "         14604,  6769,  1058,     8,     3],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,    10,\n",
            "             8,     3,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     8,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0]])}\n"
          ]
        }
      ],
      "source": [
        "# selection で表現された文中の位置情報を `inputs.input_ids` へ適用し MASK トークンに置き換える\n",
        "inputs.input_ids[0, selection] = tknz.vocab[tknz.mask_token]\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205ce6d9-aa35-4ed3-960e-d15cc76d7072",
      "metadata": {
        "id": "205ce6d9-aa35-4ed3-960e-d15cc76d7072"
      },
      "source": [
        "上の結果から `input_ids` テンソル内に MASK トークン `4` が存在することを確認せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820861da-f8a9-4c81-a39e-662bc2f1e101",
      "metadata": {
        "id": "820861da-f8a9-4c81-a39e-662bc2f1e101"
      },
      "source": [
        "## 2.3 損失の計算\n",
        "\n",
        "最後のステップは，一般的なモデルの訓練処理と変わりない。\n",
        "`input_ids` テンソルと `labels` テンソルが `input` に入っているので，これをモデルに渡してモデルの損失を返すことができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece89f0e-36cc-4b58-a825-5c7d5cef1c63",
      "metadata": {
        "id": "ece89f0e-36cc-4b58-a825-5c7d5cef1c63"
      },
      "outputs": [],
      "source": [
        "outputs = bert_model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb7e526-8854-49cc-9d51-99dd7a451fda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cb7e526-8854-49cc-9d51-99dd7a451fda",
        "outputId": "4fa7beee-7dc9-40bc-d5da-4d14948ed813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['loss', 'logits'])\n"
          ]
        }
      ],
      "source": [
        "# 戻り値 `outputs` は `dict` であり，この `output` 辞書のキーには `loss` (損失値) と `logits` (確率) とがある。\n",
        "print(outputs.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b776b1e-19a4-4180-9217-e2341258fed7",
      "metadata": {
        "id": "4b776b1e-19a4-4180-9217-e2341258fed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911e27b3-2d03-4504-f014-2b93e64f9c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.4411, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 損失値を印字\n",
        "print(outputs.loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9912fb70-d3f1-4bca-97cd-e249294f0898",
      "metadata": {
        "id": "9912fb70-d3f1-4bca-97cd-e249294f0898"
      },
      "source": [
        "# 3. 学習\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "572e5702-67f5-4351-89ed-8fbb219e2066",
      "metadata": {
        "id": "572e5702-67f5-4351-89ed-8fbb219e2066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b30f97a-8e89-4eea-f497-95ca432e6017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,  3654,    14,  ...,     0,     0,     0],\n",
            "        [    2,   378,     5,  ...,     0,     0,     0],\n",
            "        [    2,  1325,     9,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2, 16682,    11,  ...,     0,     0,     0],\n",
            "        [    2,  7843,     7,  ...,     0,     0,     0],\n",
            "        [    2,   811,     5,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
            "CPU times: user 11.4 s, sys: 189 ms, total: 11.6 s\n",
            "Wall time: 11.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# やさしい日本語コーパス SNOW 全文をトークン化器に与え，結果を `inputs` に代入する\n",
        "inputs = tknz(snow, return_tensors='pt', max_length=100, truncation=True, padding='max_length')\n",
        "\n",
        "# 結果を表示\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a622617c-59a6-4818-9d17-5275653a3ba4",
      "metadata": {
        "id": "a622617c-59a6-4818-9d17-5275653a3ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c505dc-49b1-4062-c02b-db9e9365f1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['input_ids'].size() 戻り値 inputs の大きさ:torch.Size([84300, 100])\n",
            "type(inputs.input_ids.detach()) 戻り値 inputs の型:<class 'torch.Tensor'>\n",
            "type(inputs.input_ids.detach().numpy()) 戻り値を numpy 行列に変換した際の型:<class 'numpy.ndarray'>\n",
            "inputs.input_ids.detach().numpy().shape 戻り値を numpy 行列に変換した際の行列サイズ:(84300, 100)\n",
            "inputs.input_ids.detach().numpy()[:2] numpy 変換した際の最初の 2 文:[[    2  3654    14  4749     7 17324    29  1325     7     9 14604  6769\n",
            "   1058     8     3     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]\n",
            " [    2   378     5  2056    14  1410   230  6030    20    10     8     3\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0]]\n",
            "type(snow) snow の型:<class 'list'>, len(snow) snow のデータ長:84300\n"
          ]
        }
      ],
      "source": [
        "print(f\"inputs['input_ids'].size() 戻り値 inputs の大きさ:{inputs['input_ids'].size()}\")\n",
        "print(f'type(inputs.input_ids.detach()) 戻り値 inputs の型:{type(inputs.input_ids.detach())}')\n",
        "print(f'type(inputs.input_ids.detach().numpy()) 戻り値を numpy 行列に変換した際の型:{type(inputs.input_ids.detach().numpy())}')\n",
        "print(f'inputs.input_ids.detach().numpy().shape 戻り値を numpy 行列に変換した際の行列サイズ:{inputs.input_ids.detach().numpy().shape}')\n",
        "print(f'inputs.input_ids.detach().numpy()[:2] numpy 変換した際の最初の 2 文:{inputs.input_ids.detach().numpy()[:2]}')\n",
        "print(f'type(snow) snow の型:{type(snow)}, len(snow) snow のデータ長:{len(snow)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b3889e-8636-49cf-9edb-ad9347d517f4",
      "metadata": {
        "id": "77b3889e-8636-49cf-9edb-ad9347d517f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebf7ef3-07ea-4ba2-f99b-c6d881a05fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '誰', 'が', '一番', 'に', '着く', 'か', '私', 'に', 'は', '分かり', 'ませ', 'ん', '。', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', '多く', 'の', '動物', 'が', '人間', 'によって', '殺さ', 'れ', 'た', '。', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "# 今一度，各トークン番号が，どのようなトークンを表しているのかを\n",
        "# トークナイザの `convert_ids_to_tokens()` 関数を使ってトークンに再変換して印字\n",
        "for line in inputs.input_ids[:2].detach().numpy():\n",
        "    print(tknz.convert_ids_to_tokens(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea49d76-70b5-4fa4-aa22-bd0c52d8c5ff",
      "metadata": {
        "id": "1ea49d76-70b5-4fa4-aa22-bd0c52d8c5ff"
      },
      "source": [
        "次に `input_id` をクローンして，ラベルテンソルを作成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f498c4-e7a9-4c0a-955e-842cc8e6f411",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43f498c4-e7a9-4c0a-955e-842cc8e6f411",
        "outputId": "7dda26e6-2456-434b-b76e-8e16d016b10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
          ]
        }
      ],
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()\n",
        "print(inputs.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8587cd1c-a89a-4e2f-ac51-5fc79c824e51",
      "metadata": {
        "id": "8587cd1c-a89a-4e2f-ac51-5fc79c824e51"
      },
      "source": [
        "次に，マスクのコードですが，マスクに PAD トークンを含めてはいけない (CLS や SEP では以前のとおりにあつかう)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec5cc58b-6135-441d-a0b4-db0dc2aac745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5cc58b-6135-441d-a0b4-db0dc2aac745",
        "outputId": "95c161c8-7763-465c-b9d1-87170aa6e912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tknz.pad_token_id:0\n",
            "tknz.mask_token_id:4\n",
            "tknz.sep_token_id:3\n"
          ]
        }
      ],
      "source": [
        "print(f'tknz.pad_token_id:{tknz.pad_token_id}')\n",
        "print(f'tknz.mask_token_id:{tknz.mask_token_id}')\n",
        "print(f'tknz.sep_token_id:{tknz.sep_token_id}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef68b05a-19b0-443d-987e-7a7b3ff16f99",
      "metadata": {
        "id": "ef68b05a-19b0-443d-987e-7a7b3ff16f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574688c7-c6fe-43be-e1d9-b60194e6281b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False,  True, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        ...,\n",
            "        [False, False,  True,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "# input_ids テンソルと同じ次元の乱数配列を作成 \n",
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "\n",
        "# mask 配列の作成 \n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != tknz.cls_token_id) * \\\n",
        "           (inputs.input_ids != tknz.sep_token_id) * (inputs.input_ids != tknz.pad_token_id)\n",
        "print(mask_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db28a1e3-2144-41eb-9416-5e0e483b99f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db28a1e3-2144-41eb-9416-5e0e483b99f2",
        "outputId": "712512d7-8a76-435a-cde3-fe3ac650587e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1], [9], [6], [6], [5]]\n"
          ]
        }
      ],
      "source": [
        "selection = []\n",
        "\n",
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    selection.append(\n",
        "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "    )\n",
        "print(selection[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d507f86d-53a8-4cfe-b004-07dd45114374",
      "metadata": {
        "id": "d507f86d-53a8-4cfe-b004-07dd45114374"
      },
      "source": [
        "次に，これらのインデックスを `input_ids` の各行に適用し，これらのインデックスの値をそれぞれ `tknz.mask_token_id` として割り当てる。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f36c7a-5a19-443d-add2-5b228438f2e3",
      "metadata": {
        "id": "d2f36c7a-5a19-443d-add2-5b228438f2e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab87618-ca2f-4bd3-8a25-7f9c5d7099d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "tensor([[    2,     4,    14,  4749,     7, 17324,    29,  1325,     7,     9,\n",
            "         14604,  6769,  1058,     8,     3,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [    2,   378,     5,  2056,    14,  1410,   230,  6030,    20,     4,\n",
            "             8,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [    2,  1325,     9,  6889, 12328,  2992,     4,     3,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ],
      "source": [
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    inputs.input_ids[i, selection[i]] = tknz.mask_token_id\n",
        "\n",
        "print(tknz.mask_token_id)\n",
        "print(inputs.input_ids[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9dc3ca-6d4f-47c0-b880-036e6895b5d8",
      "metadata": {
        "id": "6a9dc3ca-6d4f-47c0-b880-036e6895b5d8"
      },
      "source": [
        "`mask_arr` テンソルの `True` 値と同じ位置に `tknz.mask_token_id` が割り当てられている\n",
        "\n",
        "これで入力テンソルの準備が整い，学習時にモデルに入力するための設定を始めることができる。\n",
        "\n",
        "学習時には PyTorch の `DataLoader` を使ってデータを読み込みます。\n",
        "これを使うには，データを PyTorch の `Dataset` オブジェクトにフォーマットする必要がある\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c85628d-40a2-4299-8233-0ebab62a9a43",
      "metadata": {
        "id": "6c85628d-40a2-4299-8233-0ebab62a9a43"
      },
      "outputs": [],
      "source": [
        "class snowDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "    \n",
        "dataset = snowDataset(inputs) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af04dd4-fc0f-49d5-b3c6-aeae8af2f761",
      "metadata": {
        "id": "9af04dd4-fc0f-49d5-b3c6-aeae8af2f761"
      },
      "source": [
        "`dataloader` を初期化する。\n",
        "`dataloader` は，訓練時にモデルにデータを読み込むために使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef55b9f9-6ec9-4c57-9cdd-c76e15763128",
      "metadata": {
        "id": "ef55b9f9-6ec9-4c57-9cdd-c76e15763128"
      },
      "outputs": [],
      "source": [
        "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8971d04-ef07-4fe0-b362-a1182fe83672",
      "metadata": {
        "id": "e8971d04-ef07-4fe0-b362-a1182fe83672"
      },
      "source": [
        "これで，反復訓練に入る準備が整った。\n",
        "反復学習を始める前に，以下の 3 つを設定する必要がある:\n",
        "\n",
        "1. モデルを GPU/CPU (GPU が利用可能あれば) に移動\n",
        "2. モデルの訓練モードを有効にする\n",
        "3. 重み付けされた重み崩壊付き最適化 `AdamW` を初期化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cdd99cc-2f4b-43de-87f8-9a5f21a7c690",
      "metadata": {
        "id": "4cdd99cc-2f4b-43de-87f8-9a5f21a7c690"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "bert_model.to(device) # モデルを選択したデバイスに移動\n",
        "bert_model.train();   # 訓練モードに設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85265c5b-3f38-4fef-8ac8-473c4e8b60f3",
      "metadata": {
        "id": "85265c5b-3f38-4fef-8ac8-473c4e8b60f3"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "optim = AdamW(bert_model.parameters(), lr=5e-5)  # 最適化関数を初期化"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2a12c2-7a9d-45da-bc1a-2ff26624827e",
      "metadata": {
        "id": "5d2a12c2-7a9d-45da-bc1a-2ff26624827e"
      },
      "source": [
        "これでようやくセットアップが完了し，訓練を開始することができる。\n",
        "ここでは PyTorch の典型的な訓練ループを導入してみる。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b71e4c-5801-45f9-a464-4e012ce1c008",
      "metadata": {
        "id": "10b71e4c-5801-45f9-a464-4e012ce1c008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "b5f73d4a3bab493fad01e09939beb107",
            "9de0de49beea46b197918c6626ff0f64",
            "43cb3b1fdbfe4bada834c5cd8bf3ae4c",
            "c693894262344c3ea01c9f4c9f2d32b7",
            "7166d6df644640eb83acd86b17c0107c",
            "cbb0fe821efe4200a562f2ded1d4c559",
            "89068ffb9fcc4c56992e8ee103b671a7",
            "263b0842fd824e88b4b9a4d2229447a7",
            "64c50a496df64bb497e6456d76b5e14b",
            "cf5a716bf0054e9d843e3767b8a8cf5b",
            "d71c7a391b4d4aecbd85d326bada7794",
            "fe23c08bc9374673bb641f9c3411406d",
            "4533ec3f97b94407b847311f0003643c",
            "f4e81a4b1252450e909b9181e75f6064",
            "db3b3abddb014eecacaf885aa4b1d600",
            "d815a5b1f76b4800a495fb2f54fd7726",
            "4e4d49aba65841c3bc93318a963616f3",
            "1d718c303ad044a7807ac40e0badc261",
            "f7c74eb839a144f39323c66e85385466",
            "11053222195c4c62824bbc6831509827",
            "81110ee496464f47b83bb61d1f65c698",
            "69271ca259b6405eb007cb353e1ff3ab"
          ]
        },
        "outputId": "7149bbdc-b201-4d3c-e824-181baf054003"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f73d4a3bab493fad01e09939beb107"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe23c08bc9374673bb641f9c3411406d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22min 31s, sys: 13min 37s, total: 36min 8s\n",
            "Wall time: 35min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from collections import OrderedDict\n",
        "from tqdm.notebook import tqdm\n",
        "#from tqdm import tqdm  # for our progress bar\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch in loop:\n",
        "        \n",
        "        optim.zero_grad()\n",
        "        \n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        loop.set_description(f'エポック {epoch}')\n",
        "        loop.set_postfix(OrderedDict(loss=loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習結果を保存\n",
        "torch.save(bert_model,'2022_0628bert_model_ja_no_pretrained.pt')"
      ],
      "metadata": {
        "id": "QLFs_xpKr0Xh"
      },
      "id": "QLFs_xpKr0Xh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if isColab:\n",
        "    # 保存した結果をダウンロード\n",
        "    from google.colab import files\n",
        "    files.download('2022_0628bert_model_ja_no_pretrained.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3GySvPLbr1ii",
        "outputId": "6d606d8e-feb1-4e55-f93e-85f9bb3f1598"
      },
      "id": "3GySvPLbr1ii",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_76513b02-d4ea-46c5-a172-379b1f4fd5fd\", \"2022_0628bert_model_ja_no_pretrained.pt\", 442712617)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeEW70Te1jjR",
        "outputId": "a73f034e-a4b3-4461-cf59-8d3403a4e298"
      },
      "id": "DeEW70Te1jjR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls -tl \"drive/MyDrive/Colab Notebooks\"\n",
        "#!mkdir drive/MyDrive/2022torch_pt\n",
        "!cp -p 2022_0628bert_model_ja_no_pretrained.pt drive/MyDrive/2022torch_pt"
      ],
      "metadata": {
        "id": "PjMKU6Ee5TD-"
      },
      "id": "PjMKU6Ee5TD-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec1d00f-cf7e-4135-bc44-b9475443e57c",
      "metadata": {
        "id": "dec1d00f-cf7e-4135-bc44-b9475443e57c"
      },
      "outputs": [],
      "source": [
        "class snowDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "dataset = snowDataset(inputs)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "for data in dataloader:\n",
        "    print(data.keys(), type(data))\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0628BERT_SNOW_no-pretrained.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5f73d4a3bab493fad01e09939beb107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9de0de49beea46b197918c6626ff0f64",
              "IPY_MODEL_43cb3b1fdbfe4bada834c5cd8bf3ae4c",
              "IPY_MODEL_c693894262344c3ea01c9f4c9f2d32b7"
            ],
            "layout": "IPY_MODEL_7166d6df644640eb83acd86b17c0107c"
          }
        },
        "9de0de49beea46b197918c6626ff0f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb0fe821efe4200a562f2ded1d4c559",
            "placeholder": "​",
            "style": "IPY_MODEL_89068ffb9fcc4c56992e8ee103b671a7",
            "value": "エポック 0: 100%"
          }
        },
        "43cb3b1fdbfe4bada834c5cd8bf3ae4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263b0842fd824e88b4b9a4d2229447a7",
            "max": 5269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64c50a496df64bb497e6456d76b5e14b",
            "value": 5269
          }
        },
        "c693894262344c3ea01c9f4c9f2d32b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf5a716bf0054e9d843e3767b8a8cf5b",
            "placeholder": "​",
            "style": "IPY_MODEL_d71c7a391b4d4aecbd85d326bada7794",
            "value": " 5269/5269 [17:55&lt;00:00,  5.14it/s, loss=0.0759]"
          }
        },
        "7166d6df644640eb83acd86b17c0107c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb0fe821efe4200a562f2ded1d4c559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89068ffb9fcc4c56992e8ee103b671a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "263b0842fd824e88b4b9a4d2229447a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c50a496df64bb497e6456d76b5e14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf5a716bf0054e9d843e3767b8a8cf5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71c7a391b4d4aecbd85d326bada7794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe23c08bc9374673bb641f9c3411406d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4533ec3f97b94407b847311f0003643c",
              "IPY_MODEL_f4e81a4b1252450e909b9181e75f6064",
              "IPY_MODEL_db3b3abddb014eecacaf885aa4b1d600"
            ],
            "layout": "IPY_MODEL_d815a5b1f76b4800a495fb2f54fd7726"
          }
        },
        "4533ec3f97b94407b847311f0003643c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4d49aba65841c3bc93318a963616f3",
            "placeholder": "​",
            "style": "IPY_MODEL_1d718c303ad044a7807ac40e0badc261",
            "value": "エポック 1: 100%"
          }
        },
        "f4e81a4b1252450e909b9181e75f6064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c74eb839a144f39323c66e85385466",
            "max": 5269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11053222195c4c62824bbc6831509827",
            "value": 5269
          }
        },
        "db3b3abddb014eecacaf885aa4b1d600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81110ee496464f47b83bb61d1f65c698",
            "placeholder": "​",
            "style": "IPY_MODEL_69271ca259b6405eb007cb353e1ff3ab",
            "value": " 5269/5269 [17:55&lt;00:00,  5.13it/s, loss=0.0443]"
          }
        },
        "d815a5b1f76b4800a495fb2f54fd7726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4d49aba65841c3bc93318a963616f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d718c303ad044a7807ac40e0badc261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c74eb839a144f39323c66e85385466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11053222195c4c62824bbc6831509827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81110ee496464f47b83bb61d1f65c698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69271ca259b6405eb007cb353e1ff3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}