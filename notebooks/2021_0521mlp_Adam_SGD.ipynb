{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021_0521mlp_Adam_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LPXv9c1pLY"
      },
      "source": [
        "# 3 層パーセプトロンと確率的勾配降下法のデモ\n",
        "\n",
        "- author: 浅川伸一\n",
        "- date: 2021_0521\n",
        "- filename: 2021_0521mlp_Adam_SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eXXYBH990nH6"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True, precision=3)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b6t1IWiY1pLd"
      },
      "outputs": [],
      "source": [
        "# 自力で 3 種の出力関数 sigmoid, tanh, ReLU を定義\n",
        "# `back=True` であれば，逆伝播用の微係数を返す\n",
        "def sigmoid(x, back=False):\n",
        "    if back:\n",
        "        return (x * (1. - x))\n",
        "    else:\n",
        "        return 1/(1+np.exp(-x))\n",
        "\n",
        "def tanh(x, back=False):\n",
        "    if back:\n",
        "        return 1 - x ** 2\n",
        "    else:\n",
        "        return np.tanh(x)\n",
        "\n",
        "def ReLU(x, back=False):\n",
        "    if back:\n",
        "        return ((x > 0) * 1.)\n",
        "    else:\n",
        "        return x * (x > 0)\n",
        "\n",
        "class layer(object):\n",
        "    \"\"\"素朴にニューラルネットワークの層を実装\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_inp=2,\n",
        "                 n_out=4,\n",
        "                 act_f=tanh,\n",
        "                 lr=1e-1):\n",
        "        self.n_inp, self.out = n_inp, n_out\n",
        "        self.act_f = act_f\n",
        "        self.W = np.random.randn(n_out * n_inp).reshape(n_inp, n_out) / np.sqrt(n_inp + n_out)\n",
        "        self.bias = np.zeros((n_out,))\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, X):\n",
        "        affine = X @ self.W + self.bias\n",
        "        return self.act_f(affine)\n",
        "\n",
        "\n",
        "    def backward(self, dY, Y, X):\n",
        "        gradY = dY * self.act_f(Y, back=True)\n",
        "        dX = gradY @ self.W.T\n",
        "        dW =  X.T @ gradY\n",
        "        #d_bias = dW.mean()\n",
        "        return dX, dW #, d_bias, gradY\n",
        "\n",
        "    def update(self, dW):\n",
        "        self.W -= self.lr * dW\n",
        "        self.bias -= self.lr * dW.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGVkh7tp1pLe"
      },
      "outputs": [],
      "source": [
        "# 排他的論理和の入力データと教師信号を定義\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "Tch = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "n_hid = 6  # 中間層のニューロン数\n",
        "lr = 1e-1  # 学習率\n",
        "\n",
        "#LayerH = layer(n_out=n_hid, n_inp=2, act_f=sigmoid, lr=lr)\n",
        "#LayerH = layer(n_out=n_hid, n_inp=2, act_f=ReLU, lr=lr)\n",
        "\n",
        "# 中間層の定義\n",
        "LayerH = layer(n_out=n_hid, n_inp=2, act_f=tanh, lr=lr)\n",
        "\n",
        "# 出力層の定義\n",
        "LayerO = layer(n_out=1, n_inp=n_hid, act_f=sigmoid, lr=lr)\n",
        "\n",
        "# エポック数\n",
        "epochs = 10 ** 3\n",
        "\n",
        "# 途中経過の出力間隔\n",
        "interval = epochs >> 2  # >> 2 は全体の 1/4 毎の意味\n",
        "losses = []   # 損失値を格納しておくリストの定義\n",
        "\n",
        "for epoch in range(epochs+1):\n",
        "    # 訓練の実施\n",
        "    H = LayerH.forward(X)  # 入力層から中間層へ\n",
        "    O = LayerO.forward(H)  # 中間層から出力層へ\n",
        "\n",
        "    deltaO = O - Tch       # 誤差信号の定義\n",
        "    deltaH, dWo = LayerO.backward(deltaO, O, H)  # 誤差逆伝播出力層から中間層へ\n",
        "    deltaX, dWh = LayerH.backward(deltaH, H, X)  # 誤差逆伝播中間層から出力層へ\n",
        "    LayerO.update(dWo)                           # 結合係数の更新 中間層から出力層\n",
        "    LayerH.update(dWh)                           # 結合係数の更新 入力層から中間層\n",
        "\n",
        "    losses.append((deltaO ** 2).mean())          # 損失値の計算\n",
        "    if epoch % interval == 0:\n",
        "        print(f'エポック:{epoch:>5d}, 損失値: {losses[-1]:.3f}', end=\" \")\n",
        "        print(f'出力:{O.T}')\n",
        "\n",
        "# 結果の描画\n",
        "plt.ylim((0,0.28))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('エポック数')\n",
        "plt.ylabel('平均損失')\n",
        "plt.title(f'XOR デモ 中間層ニューロン数:{n_hid}, 学習係数:{lr}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gAUMjo2N1pLf"
      },
      "outputs": [],
      "source": [
        "# 上で行ったことクラスとして再定義し，後の利用可能性のための便宜に供する\n",
        "class XOR_demo(object):\n",
        "    def __init__(self,\n",
        "                 n_hid:int=8,                  # 中間層の素子数\n",
        "                 lr:float=1e-1,                # 学習率\n",
        "                 act_f=tanh,                   # 活性化関数\n",
        "                 max_epochs:int= 3 * 10 ** 3,  # 最大エポック数\n",
        "                 interval:int=(10 ** 3)>>3):   # 途中経過出力間隔\n",
        "\n",
        "        if act_f != None:\n",
        "            self.act_f = act_f\n",
        "\n",
        "        self.X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "        self.Tch = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "        self.max_epochs = max_epochs\n",
        "        self.interval = interval\n",
        "        self.n_hid = n_hid\n",
        "        self.lr = lr\n",
        "\n",
        "        self.LayerH = layer(n_out=n_hid, n_inp=2, act_f=self.act_f, lr=lr)\n",
        "        self.LayerO = layer(n_out=1, n_inp=n_hid, act_f=sigmoid, lr=lr)\n",
        "\n",
        "\n",
        "    def fit(self,\n",
        "            max_epochs:int=None,\n",
        "            interval:bool=None,\n",
        "            draw_graph:bool=True,\n",
        "            title:str=\"\",\n",
        "            verbose:bool=False):\n",
        "        if max_epochs != None:\n",
        "            self.max_epochs = max_epochs\n",
        "        if interval != None:\n",
        "            self.interval = interval\n",
        "\n",
        "        losses = []\n",
        "        for epoch in range(self.max_epochs+1):\n",
        "            #順伝播\n",
        "            H = self.LayerH.forward(X)\n",
        "            O = self.LayerO.forward(H)\n",
        "\n",
        "            #逆伝播\n",
        "            deltaO = (O - Tch)\n",
        "            deltaH, dWo = self.LayerO.backward(deltaO, O, H)\n",
        "            deltaX, dWh = self.LayerH.backward(deltaH, H, X)\n",
        "\n",
        "            #パラメータの更新\n",
        "            self.LayerO.update(dWo)\n",
        "            self.LayerH.update(dWh)\n",
        "\n",
        "            losses.append((deltaO ** 2).mean())\n",
        "            if epoch % self.interval == 0 and verbose:\n",
        "                print(f'エポック:{epoch:>5d}, 損失: {losses[-1]:.3f}', end=\" \")\n",
        "                print(f'出力:{O.T}')\n",
        "\n",
        "        if draw_graph:\n",
        "            plt.ylim((0,0.28))\n",
        "            plt.plot(losses)\n",
        "            plt.xlabel('エポック数')\n",
        "            plt.ylabel('平均損失')\n",
        "            plt.title(title) # f'XOR デモ 中間層ニューロン数:{n_hid}, 学習係数:{lr}')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhcYtzyu1pLf"
      },
      "outputs": [],
      "source": [
        "# 定義したクラスを用いてデモの実施\n",
        "demo = XOR_demo(act_f=sigmoid)\n",
        "demo.fit(title=\"活性化関数:シグモイド\")\n",
        "\n",
        "demo2 = XOR_demo(act_f=tanh)\n",
        "demo2.fit(title=\"活性化関数:tanh\")\n",
        "\n",
        "demo3 = XOR_demo(act_f=ReLU, )\n",
        "demo3.fit(title=\"活性化関数:ReLU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocWn9wP51pLg"
      },
      "source": [
        "# SGD と ADAM の比較\n",
        "\n",
        "<!-- - source: https://github.com/jrios6/Adam-vs-SGD-Numpy.git-->\n",
        "<!--This is a response to Siraj Raval's [Coding Challenge](https://github.com/llSourcell/The_evolution_of_gradient_descent/) to implement the Adam Optimization Strategy.\n",
        "ta), and comparing the performance difference between a standard Stochastic Gradient Descent and Adam.\n",
        "-->\n",
        "\n",
        "参照 URL\n",
        "1. [Adam: A method for Stochastic Optimization](https://arxiv.org/abs/1412.6980) by Diederik P. Kingma, Jimmy Ba  \n",
        "2. [CS231: Neural Networks](http://cs231n.github.io/neural-networks-3/#update) by Andrej Karpathy\n",
        "3. [Optimizing Gradient Descent](http://sebastianruder.com/optimizing-gradient-descent/index.html#adam) by Sebastian Ruder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4plQ6nX1pLg"
      },
      "source": [
        "## データセットの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi8CORz-1pLg"
      },
      "outputs": [],
      "source": [
        "# データセットの準備\n",
        "import numpy as np\n",
        "import sys\n",
        "import requests\n",
        "\n",
        "# 3 つのうちの一つを設定すること\n",
        "data = 'mnist'\n",
        "#data = 'fashionmnist'\n",
        "#data = 'kmnist'\n",
        "\n",
        "mnist_urls = {\n",
        "    #http://yann.lecun.com/exdb/mnist/\n",
        "    'Xtrain':'https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain':'https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "fashionmnist_urls = {\n",
        "    #https://github.com/zalandoresearch/fashion-mnist\n",
        "    #'Xtrain': 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
        "    #'Ytrain': 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
        "    #'Xtest': 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
        "    #'Ytest':'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "fashionmnist_urls = {\n",
        "    #https://github.com/zalandoresearch/fashion-mnist\n",
        "    'Xtest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
        "    'Xtrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "kmnist_urls = {\n",
        "    #http://codh.rois.ac.jp/kmnist/\n",
        "    'Xtrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "\n",
        "def download_mnist(dataset_urls):\n",
        "    #上で定義したデータセットの情報を元にデータをダウンロードする\n",
        "    for name, url in dataset_urls.items():\n",
        "        fname = url.split('/')[-1]\n",
        "        print(url, fname)\n",
        "        r = requests.get(url, timeout=35) #timeout=None はサーバからの応答が遅い場合永遠に待ち続ける\n",
        "        with open(fname, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "fashionmnist_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat' , \\\n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "kmnist_labels = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
        "# '0,U+304A,お', '1,U+304D,き', '2,U+3059,す', '3,U+3064,つ', '4,U+306A,な',\n",
        "# '5,U+306F,は', '6,U+307E,ま', '7,U+3084,や', '8,U+308C,れ', '9,U+3092,を'\n",
        "\n",
        "if data == 'mnist':\n",
        "    labels = mnist_labels\n",
        "    dataset_urls = mnist_urls\n",
        "elif data == 'fashionmnist':\n",
        "    labels = fashionmnist_labels\n",
        "    dataset_urls = fashionmnist_urls\n",
        "elif data == 'kmnist':\n",
        "    dataset_urls = kmnist_urls\n",
        "    labels = kmnist_labels\n",
        "else:\n",
        "    print('data が指定されていません')\n",
        "    sys.exit()\n",
        "\n",
        "download_mnist(dataset_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NwaJK-Y20nIA"
      },
      "outputs": [],
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    \"\"\"ダウンロードしたデータを読み込む関数\"\"\"\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte.gz')\n",
        "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte.gz')\n",
        "\n",
        "    print(f'labels_path:{labels_path}')\n",
        "    with gzip.open(labels_path, 'rb') as fp:\n",
        "        labels = np.frombuffer(fp.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as fp:\n",
        "        images = np.frombuffer(fp.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fqdybBbT1pLh",
        "outputId": "e760b173-af52-43ad-da3d-4d0fe3871897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_path:./train-labels-idx1-ubyte.gz\n",
            "labels_path:./t10k-labels-idx1-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "#データの表示\n",
        "import matplotlib.pyplot as plt\n",
        "X_train, Y_train = load_mnist('.', kind='train')\n",
        "X_test, Y_test = load_mnist('.', kind='t10k')\n",
        "\n",
        "_Y = np.zeros((len(Y_train),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_train[i]] = 1\n",
        "Y_train = _Y\n",
        "\n",
        "_Y = np.zeros((len(Y_test),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_test[i]] = 1\n",
        "Y_test = _Y\n",
        "\n",
        "# 時間節約のためデータ数を制限\n",
        "n_train = 3000  # 訓練データ数\n",
        "n_val = 500     # 検証データ数\n",
        "n_test = 500    # テストデータ数\n",
        "X_train = X_train[-n_train:]\n",
        "Y_train = Y_train[-n_train:]\n",
        "X_val = X_train[-n_val:]\n",
        "Y_val = Y_train[-n_val:]\n",
        "X_test = X_test[-n_test:]\n",
        "Y_test = Y_test[-n_test:]\n",
        "\n",
        "# #次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです\n",
        "# No = int(input('次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです:'))\n",
        "# #No = 666\n",
        "# plt.figure(figsize=(2,2))    #表示する縦横の大きさ，単位はインチ\n",
        "# plt.title('label:{}'.format(labels[np.argmax(Y_train[No])]))\n",
        "# plt.axis(False)\n",
        "# plt.imshow(X_train[No].reshape(28,28), cmap='gray')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrows, ncols = 3, 10\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10,4))\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        idx = i * ncols + j\n",
        "        axes[i,j].set_title(f'{labels[np.argmax(Y_train[idx])]}')\n",
        "        axes[i,j].axis(False)\n",
        "        axes[i,j].imshow(X_train[idx].reshape(28,28), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jcy6NfMIRJhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi1rNv421pLh"
      },
      "source": [
        "## 3 層ニューラルネットワーク MLP の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OnVqJXl81pLi"
      },
      "outputs": [],
      "source": [
        "class MLP3:\n",
        "    def __init__(self,\n",
        "                 n_inp:int,    # 入力層のニューロン数\n",
        "                 n_hid:int,    # 中間層のニューロン数\n",
        "                 n_out:int,    # 出力層のニューロン数\n",
        "                 lr:float,     # 学習率\n",
        "                 act_f=tanh):  # 活性化関数\n",
        "        \"\"\"A three-layered feedforward neural network.\n",
        "        ただし，最適化手法として SGD と Adam とを実装している\n",
        "        \"\"\"\n",
        "        if act_f == None:\n",
        "            act_f = tanh\n",
        "\n",
        "        self.n_inp, self.n_hid, self.n_out = n_inp, n_hid, n_out\n",
        "        self.act_f, self.lr = act_f, lr\n",
        "\n",
        "        self.V_m, self.U_m = 0, 0  # 1 次のモーメント, 慣性モーメント\n",
        "        self.V_v, self.U_v = 0, 0  # 2 次のモーメント, 速度モーメンタム\n",
        "        self.t = 0\n",
        "\n",
        "        # 結合係数行列の初期化\n",
        "        self.U = np.random.randn((n_inp * n_hid)).reshape(n_inp, n_hid) / np.sqrt(n_inp + n_hid)\n",
        "        self.V = np.random.randn((n_hid * n_out)).reshape(n_hid, n_out) / np.sqrt(n_hid + n_out)\n",
        "\n",
        "\n",
        "    def train(self, X, Tch, optimizer, decay1 = None, decay2 = None, epsilon = 1e-7):\n",
        "        # 順伝播\n",
        "        H = self.act_f(X @ self.U)\n",
        "        Y = self.act_f(H @ self.V)\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        Y_delta = Y - Tch\n",
        "        Y_grad  = Y_delta * self.act_f(Y, back=True)\n",
        "        H_delta = Y_grad @ self.V.T\n",
        "        H_grad  = H_delta * self.act_f(H, back=True)\n",
        "\n",
        "        if optimizer == 'sgd':\n",
        "            # Update Weights\n",
        "            self.V -= self.lr * H.T @ Y_grad\n",
        "            self.U -= self.lr * X.T @ H_grad\n",
        "\n",
        "        if optimizer == 'adam':\n",
        "            # Gradients for each layer\n",
        "            g1 = H.T.dot(Y_grad)\n",
        "            g0 = X.T.dot(H_grad)\n",
        "\n",
        "            self.t += 1         # 時刻の更新\n",
        "\n",
        "            # 中間層と出力層とに対する慣性モーメントを計算\n",
        "            self.V_m = self.V_m * decay1 + (1 - decay1) * g1\n",
        "            self.U_m = self.U_m * decay1 + (1 - decay1) * g0\n",
        "\n",
        "            # 中間層と出力層とに対する 2 次モーメントを計算\n",
        "            self.V_v = self.V_v * decay2 + (1 - decay2) * (g1 ** 2)\n",
        "            self.U_v = self.U_v * decay2 + (1 - decay2) * (g0 ** 2)\n",
        "\n",
        "            # 出力層モーメントへの時刻補正\n",
        "            V_mc = self.V_m / (1 - (decay1 ** self.t))\n",
        "            V_vc = self.V_v / (1 - (decay2 ** self.t))\n",
        "\n",
        "            # 入力層モーメントへの時刻補正\n",
        "            U_mc = self.U_m / (1 - (decay1 ** self.t))\n",
        "            U_vc = self.U_v / (1 - (decay2 ** self.t))\n",
        "\n",
        "            # パラメータ更新\n",
        "            dV = V_mc / (np.sqrt(V_vc) + epsilon)\n",
        "            dU = U_mc / (np.sqrt(U_vc) + epsilon)\n",
        "\n",
        "            self.V -= self.lr * dV\n",
        "            self.U -= self.lr * dU\n",
        "\n",
        "    def run(self, X):\n",
        "        H = self.act_f(X @ self.U)\n",
        "        Y = self.act_f(H @ self.V)\n",
        "        return Y\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.run(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "enT64Gwc1pLi"
      },
      "outputs": [],
      "source": [
        "def MSE(y, Y):\n",
        "    return np.mean((y-Y)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MtNG_VLP1pLi"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "\n",
        "def build_and_run(network, epochs=100, optimizer='adam', n_batch=64):\n",
        "    losses = {'train':[], 'validation':[]} # For Plotting of MSE\n",
        "    start = time.time()\n",
        "    interval = epochs >> 3\n",
        "\n",
        "    # Iterating Over Epochs\n",
        "    for i in range(epochs):\n",
        "\n",
        "        if optimizer == 'sgd':\n",
        "            # Iterating over mini batches\n",
        "            for k in range(X_train.shape[0] // n_batch):\n",
        "                batch = np.random.choice(len(X_train), size=n_batch)\n",
        "                X, y = X_train[batch], Y_train[batch]\n",
        "                network.train(X, y, optimizer)\n",
        "                train_loss = MSE(network.run(X_train), Y_train)\n",
        "                val_loss = MSE(network.run(X_val), Y_val)\n",
        "            if i % interval == 0:\n",
        "                print(f'エポック数:{i:05d}, 訓練損失:{train_loss:0.3f}, 検証損失: {val_loss:0.3f}')\n",
        "\n",
        "        if optimizer == 'adam':\n",
        "            # Iterating over mini batches\n",
        "            for k in range(X_train.shape[0]// n_batch):\n",
        "                batch = np.random.choice(len(X_train), size=n_batch)\n",
        "                X, y = X_train[batch], Y_train[batch]\n",
        "                #print(f'30 X.shape: {X.shape}, y.shape: {y.shape}')\n",
        "                network.train(X, y, optimizer,\n",
        "                              decay1 = 0.9, decay2 = 0.99,\n",
        "                              epsilon = 10e-8)\n",
        "                train_loss = MSE(network.run(X_train), Y_train)\n",
        "                val_loss = MSE(network.run(X_val), Y_val)\n",
        "            if i % interval == 0:\n",
        "                print(f'エポック数:{i:05d}, 訓練損失:{train_loss:0.3f}, 検証損失: {val_loss:0.3f}')\n",
        "\n",
        "        losses['train'].append(train_loss)\n",
        "        losses['validation'].append(val_loss)\n",
        "\n",
        "    print(f'総計算時間:{time.time()-start:.4f} 秒')\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfIrGsj41pLi"
      },
      "outputs": [],
      "source": [
        "epochs = 101\n",
        "lr = 1e-4\n",
        "n_hid = 128\n",
        "\n",
        "n_out = 10\n",
        "batch_size = 128\n",
        "\n",
        "act_f = tanh\n",
        "print('活性化関数:tanh 最適化手法:Adam')\n",
        "model_tanh_adam = MLP3(X_train.shape[1], n_hid, n_out, lr, act_f=act_f)\n",
        "losses_adam_tanh = build_and_run(model_tanh_adam, epochs, 'adam', batch_size)\n",
        "\n",
        "print('活性化関数:tanh 最適化手法:SGD')\n",
        "model_tanh_sgd = MLP3(X_train.shape[1], n_hid, n_out, lr, act_f=act_f)\n",
        "losses_sgd_tanh = build_and_run(model_tanh_sgd, epochs, 'sgd', batch_size)\n",
        "\n",
        "act_f = sigmoid\n",
        "print('活性化関数:シグモイド 最適化手法:Adam')\n",
        "model_sigmoid_adam = MLP3(X_train.shape[1], n_hid, n_out, lr, act_f=act_f)\n",
        "losses_adam_sigmoid = build_and_run(model_sigmoid_adam, epochs, 'adam', batch_size)\n",
        "\n",
        "print('活性化関数:シグモイド 最適化手法:SGD')\n",
        "model_sigmoid_sgd = MLP3(X_train.shape[1], n_hid, n_out, lr, act_f=act_f)\n",
        "losses_sgd_sigmoid = build_and_run(model_sigmoid_sgd, epochs, 'sgd', batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2_WIK8o1pLj"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses_adam_sigmoid['train'], label='Adam(sigmoid) 訓練データ損失')\n",
        "#plt.plot(losses_adam_sigmoid['validation'], label='Adam(sigmoid) 検証データ損失')\n",
        "\n",
        "plt.plot(losses_sgd_sigmoid['train'], label='SGD(sigmoid) 訓練データ損失')\n",
        "#plt.plot(losses_sgd_sigmoid['validation'], label='SGD(sigmoid) 検証データ損失')\n",
        "\n",
        "plt.plot(losses_adam_tanh['train'], label='Adam(tanh) 訓練データ損失')\n",
        "#plt.plot(losses_adam_tanh['validation'], label='Adam(tanh) 検証データ損失')\n",
        "\n",
        "plt.plot(losses_sgd_tanh['train'], label='SGD(tanh) 訓練データ損失')\n",
        "#plt.plot(losses_sgd_tanh['validation'], label='SGD(tanh) 検証データ損失')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmXGdHmc0nIB"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses_adam_tanh['train'], label='Adam(tanh) 訓練データ損失')\n",
        "plt.plot(losses_adam_tanh['validation'], label='Adam(tahn) 検証データ損失')\n",
        "\n",
        "plt.plot(losses_sgd_tanh['train'], label='SGD(tanh) 訓練データ損失')\n",
        "plt.plot(losses_sgd_tanh['validation'], label='SGD(tanh) 検証データ損失')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh8J4ldd1pLj"
      },
      "source": [
        "<!--\n",
        "From the plots, we can observed that using Adam, weights of the neural network are more smoothly adjusted to reduce the training loss.\n",
        "Try increasing the learning rate, and you can see that Adam converges much faster compared to SGD, using an adaptive learning rate.\n",
        "\n",
        "The benefits of using Adam are not so obvious as the size of the data is very small and increasing training epochs tend to lead to overfitting and early-stopping is required.\n",
        "It is recommended to set the epochs for Adam to around 200 for the above hyperparameters configuration, as the training and validation loss starts diverging.\n",
        "However, we kept the epochs for both networks the same for plotting.\n",
        "\n",
        "Lastly, in this implementation, Adam is much faster to compute compared to SGD as it is processed as an entire training batch.  \n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqH6FDz1pLj"
      },
      "source": [
        "## テストデータ による検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0xuEtkr1pLj"
      },
      "outputs": [],
      "source": [
        "def test_model(network):\n",
        "    test_predictions = network.run(X_test)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(len(test_predictions)):\n",
        "        total += 1\n",
        "        if np.argmax(test_predictions[i]) ==  np.argmax(Y_test[i]):\n",
        "            correct += 1\n",
        "    return correct/total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qGjMkgy1pLj"
      },
      "outputs": [],
      "source": [
        "print('テストデータセットに対する精度')\n",
        "print(f'Adam (シグモイド) : {test_model(model_sigmoid_adam)}')\n",
        "print(f'SGD  (シグモイド) : {test_model(model_sigmoid_sgd)}')\n",
        "print(f'Adam (tahn)     : {test_model(model_sigmoid_adam)}')\n",
        "print(f'SGD  (tanh)     : {test_model(model_sigmoid_sgd)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXOBOEJk1pLj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}