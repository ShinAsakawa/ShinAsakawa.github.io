{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-0406onomatopea.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLFH/fnHw9wMZcGZstX7P5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021_0406onomatopea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks_uLBm4Dg9P"
      },
      "source": [
        "# 射影行列の視覚化\n",
        "\n",
        "- 本日のポイント\n",
        "射影行列を作って，オノマトペ（に限らず，特定の語句の意味ベクトル such as BERT, word2vec から構成される部分）空間へ任意のベクトルを射影するとき，\n",
        "元のベクトルで比較するのか，それとも，射影された空間内で比較するのが良いのか\n",
        "\n",
        "一般に 行列 $X$ が $(n,m)$ サイズで $n>m$ である場合，列次元の n 次元ベクトルから射影行列 \n",
        "$P_n$ を作成し，行の次元 m から $P_m$ を作成します。\n",
        "すると，射影行列はたかだか $m$ 次元にしかなりません。\n",
        "word2vec の次元を 200 とすれば，$n>200$ の語彙を使って射影行列を作っても，構成される射影空間の次元は 200 を超えません。\n",
        "word2vec のどのような語彙から部分空間を構成してもその空間は 200 次元を超えません。\n",
        "\n",
        "であれば，どんな語彙ベクトルでもその空間に落とし込んでから比較してみるということを行ってみました。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRlpKDKr9rwS"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=2)  # numpy の表示桁数設定\n",
        "\n",
        "from gensim.models import KeyedVectors   # word2vec でーた処理のため gensim を使う\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# ファイルの所在に応じて変更してください\n",
        "w2v_base = '.'\n",
        "w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "\n",
        "# word2vec データの読み込み\n",
        "# ローカルディスクから読み込むようになっています。colab でお使いの場合には適宜変更してください\n",
        "# word2vec の訓練済モデルを入手\n",
        "!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz\n",
        "#!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_sgns.bin.gz\n",
        "#!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid300_win20_neg20_sgns.bin.gz\n",
        "#!wget http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz\n",
        "\n",
        "print('#訓練済 word2vec，訓練データは wikipedia 全文  読み込みに時間がかかります...', end=\"\")\n",
        "#w2v_base = '/Users/asakawa/study/2016wikipedia/'\n",
        "w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "#w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg10_cbow.bin.gz'\n",
        "#w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_sgns.bin.gz'\n",
        "#w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg10_sgns.bin.gz'\n",
        "w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "w2v = KeyedVectors.load_word2vec_format(w2v_file, \n",
        "                                        encoding='utf-8', \n",
        "                                        unicode_errors='replace',\n",
        "                                        binary=True) \n",
        "print('done')\n",
        "\n",
        "# Colab では以下の 2 行の行頭の # を削除してから実行してください\n",
        "!pip install jaconv\n",
        "!pip install japanize_matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "#2021/Jan 近藤先生からいただいたオノマトペ辞典のデータ\n",
        "#ひとつ下の '日本語オノマトペ辞典4500より.xls' は著作権の問題があり，公にできません。\n",
        "# そのため Google Colab での解法，ローカルファイルよりアップロードする\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # ここで `日本語オノマトペ辞典4500より.xls` を指定してアップロードする\n",
        "ccap_base = '.'\n",
        "#onomatopea_excel = '日本語オノマトペ辞典4500より.xlsx'\n",
        "onomatopea_excel = '2021-0325日本語オノマトペ辞典4500より.xls'\n",
        "onmtp2761 = pd.read_excel(os.path.join(ccap_base, onomatopea_excel), sheet_name='2761語')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLUDTGIV98Ze"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "import scipy\n",
        "#from scipy import stats\n",
        "\n",
        "#import tqdm\n",
        "#import termcolor\n",
        "\n",
        "# ひらがなカタカナ変換用 `pip install jaconv` してください\n",
        "!pip install jaconv\n",
        "import jaconv  \n",
        "\n",
        "# matplotlib の日本語表示\n",
        "!pip install japanize_matplotlib\n",
        "import japanize_matplotlib  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYBpeHuX-DKG"
      },
      "source": [
        "onomatopea = list(set(sorted(onmtp2761['オノマトペ'])))\n",
        "\n",
        "print('# オノマトペのうち，word2vec に登録があるかどうかを調査')\n",
        "kana_entries, kata_entries = [], []\n",
        "count = 0\n",
        "for word in onomatopea:\n",
        "    count += 1\n",
        "    if word in w2v.vocab:\n",
        "        kana_entries.append(word)\n",
        "\n",
        "    kata_w = jaconv.hira2kata(word)\n",
        "    if kata_w in w2v.vocab:\n",
        "        kata_entries.append(kata_w)\n",
        "        \n",
        "entries = kana_entries + kata_entries\n",
        "print('There are ', len(entries), ' in ', len(onomatopea), ' onomatopea words in word2vec from jawikipedia')\n",
        "print('総数がオノマトペデータより多いのは，平仮名表記とカタカナ表記と両者で wikipedia に登録があった場合に重複してカウントしているからです。')\n",
        "print('カタカナ オノマトペ総数:', len(kata_entries))\n",
        "print('ひらがな オノマトペ総数:', len(kana_entries))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbXm17GQ-MOS"
      },
      "source": [
        "# 行列の印字桁数の設定\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "\n",
        "def w2v_similarity_matrix(words, w2v=w2v):\n",
        "    \"\"\"word2vec を用いて単語間の類似度行列を算出\"\"\"\n",
        "    ret = np.eye(len(words))\n",
        "    for i, w0 in enumerate(words):\n",
        "        j = i\n",
        "        for w1 in words[i+1:]:\n",
        "            ret[i,j+1] = w2v.similarity(w0,w1)\n",
        "            ret[j+1,i] = ret[i,j+1]\n",
        "            j += 1\n",
        "        \n",
        "    return ret\n",
        "\n",
        "\n",
        "def Mat_orth(X, dtype=np.float):\n",
        "    \"\"\"Return Orthogonal Projection and its complement matrices of X\n",
        "    直交射影行列とその補空間への射影行列を返す。\n",
        "    X を (n行 m列)としたとき， (m,m) 型の逆行列を算出。(n,n)型ではないことに注意\n",
        "    \n",
        "    引数\n",
        "    X: np.array (n,m)\n",
        "       入力行列\n",
        "    戻り値\n",
        "    Pn: np.array (n,n)\n",
        "        入力行列の行次元に対応した射影行列 $P_n = X(X^t X)^{-1} X^t$\n",
        "    Qn: np.arrary(n,n)\n",
        "        Pn の 直交補空間への射影行列 $Q_n = I_n - P_n$\n",
        "    Pm: np.array(m,m)\n",
        "        入力行列の列次元に対応した射影行列 $P_m = X^t (X X^t)^{-1} X$\n",
        "    Qm: np.array(m,m)\n",
        "        Pm の直交補空間への射影行列 $Q_m = I_m - P_m$\n",
        "\n",
        "    \"\"\"\n",
        "    n, m = X.shape\n",
        "    Xt = X.T\n",
        "    X_Xt, Xt_X = np.dot(X, Xt), np.dot(Xt, X)\n",
        "    iXXt, iXtX = np.linalg.inv(X_Xt), np.linalg.inv(Xt_X)\n",
        "    In, Im = np.eye((n),dtype=dtype), np.eye((m), dtype=dtype)\n",
        "    Pn, Pm = np.dot(X, iXtX), np.dot(Xt, iXXt)\n",
        "    Pn, Pm = np.dot(Pn, Xt), np.dot(Pm, X)\n",
        "    Qn, Qm = In - Pn, Im - Pm\n",
        "    return Pn, Qn, Pm, Qm\n",
        "\n",
        "\n",
        "def w2vMat(wordlist=['イヌ','ネコ', 'トラ', 'ライオン'], w2v=w2v):\n",
        "    \"\"\"len(wordlist)行，word2vec 次元数 列を持つ行列 を返す\"\"\"\n",
        "\n",
        "    if w2v == None:\n",
        "        assert('Set a `gensim.models.keyedvectors.Word2VecKeyedVectors` as an w2v argument')\n",
        "        \n",
        "    # 行列の確保\n",
        "    X = np.zeros((len(wordlist), w2v.vector_size), dtype=np.float)\n",
        "        \n",
        "    # 各行に word2vec ベクトルをコピー\n",
        "    for i, word in enumerate(wordlist):\n",
        "        X[i] = np.copy(w2v[word])\n",
        "            \n",
        "    return X\n",
        "\n",
        "\n",
        "def _similarity_matrix(X):\n",
        "    \"\"\"行列 X の 各行ベクトルから距離行列を算出して返す\"\"\"\n",
        "    ret = np.eye(X.shape[0])\n",
        "    X_ = np.copy(X)\n",
        "    for i in range(X_.shape[0]):\n",
        "        X_[i] -= X_[i].mean()\n",
        "        X_[i] /= np.sqrt(X_[i].var())\n",
        "        \n",
        "    for i in range(X_.shape[0]):\n",
        "        for j in range(X_.shape[0]-i):\n",
        "            #print(i,j+i)\n",
        "            ret[j+i][i] = np.dot(X_[j+i],X_[i]) / (np.linalg.norm(X_[j+i]) * np.linalg.norm(X_[i]))\n",
        "            ret[i][j+i] = ret[j+i][i]\n",
        "    return ret\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm9zlQoT-WnO"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "#from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "inches = 5\n",
        "def ax_scatter_gram(ax, pca1, pca2, wordlist, title=None):\n",
        "    ax.scatter(pca1[:1], pca2[:1], s=200, color='red')\n",
        "    ax.scatter(pca1[1:], pca2[1:], s=200, color='cyan')\n",
        "    for i, label in enumerate(wordlist):\n",
        "        ax.annotate(label, (pca1[i], pca2[i]),fontsize=14)\n",
        "    ax.set_xlabel(\"第一主成分\")\n",
        "    ax.set_ylabel(\"第二主成分\")\n",
        "    ax.set_title(title,fontsize=18)\n",
        "\n",
        "\n",
        "def compare3plots(wordlist, whole_words, inches=4):\n",
        "\n",
        "    def plot_pca(ax, R, i, title=\"\"):\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_result = pca.fit_transform(R)\n",
        "        pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "        print('\\tExplained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "        ax_scatter_gram(ax, pca1, pca2, wordlist, title=title)\n",
        "\n",
        "    print(wordlist)\n",
        "    fig = plt.figure(figsize=(inches * 3.3,inches))\n",
        "    ax = fig.add_subplot(1,3,1)\n",
        "    fontsize = 10\n",
        "\n",
        "    Own_space = w2vMat(wordlist)\n",
        "    Pn, Qn, Pm_onmtp, Qm = Mat_orth(w2vMat(wordlist=whole_words))\n",
        "    y_onmtp = np.dot(Own_space, Pm_onmtp)\n",
        "    R = _similarity_matrix(y_onmtp)\n",
        "    #print(R)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1]  #; print(Sim_sorted)\n",
        "    print('オノマトペ空間への射影:',[wordlist[s] for s in Sim_sorted])\n",
        "    ax = fig.add_subplot(1,3,1)\n",
        "    plot_pca(ax, R, 1, title='オノマトペ空間への射影:')\n",
        "\n",
        "    Pn, Qn, Pm_inn, Qm = Mat_orth(w2vMat(wordlist=wordlist))\n",
        "    y_inn = np.dot(Own_space, Pm_inn)\n",
        "    R = _similarity_matrix(y_inn)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1]  #; print(Sim_sorted)\n",
        "    print('構成単語空間への射影:', [wordlist[s] for s in Sim_sorted])\n",
        "    #print(R)\n",
        "    ax = fig.add_subplot(1,3,2)\n",
        "    plot_pca(ax, R, 2, title='構成単語空間への射影:')\n",
        "\n",
        "    R = _similarity_matrix(Own_space)\n",
        "    #print(R)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1] #; print(Sim_sorted)\n",
        "    print('Original word2vec', [wordlist[s] for s in Sim_sorted])\n",
        "    ax = fig.add_subplot(1,3,3)\n",
        "    plot_pca(ax, R, 3, title='Original word2vec')\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "#compare3plots(wordlist, entries)\n",
        "#wordlist = np.random.choice(entries,4)\n",
        "#compare3plots(wordlist, entries)\n",
        "\n",
        "\n",
        "wordlist=['イヌ', 'ワンワン','キャンキャン', 'ニャーニャー', 'しくしく']\n",
        "compare3plots(wordlist,entries)\n",
        "\n",
        "for N in range(8,12):\n",
        "    wordlist = np.random.choice(entries,N)\n",
        "    compare3plots(wordlist,entries)\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UacMvwSbIcrO"
      },
      "source": [
        "---\n",
        "\n",
        "以下のセルはオノマトペではありません。\n",
        "ですがヒントになりそうですので，提示します。\n",
        "「ある目標語は，続いて提示される 4つの選択肢の中のどれが一番近いか？もっとも適切なものを選べ」という設問があったとき，\n",
        "４つの選択肢で構成される空間に，目標語を射影し，射影空間内で距離を測るということを行いました。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YL_urTH-bVC"
      },
      "source": [
        "Pn, Qn, Pm, Qm = Mat_orth(w2vMat(wordlist=entries))\n",
        "\n",
        "test_list = [\n",
        "    ['黒板', '学校', '郵便局', '工場', 'デパート'],\n",
        "    ['オートバイ', 'ヘルメット', '帽子', '麦わら帽子', '兜'],\n",
        "    ['柿', '五重塔', '駅', '教会', '病院'],\n",
        "    ['鹿', '大仏', '東京タワー', '原爆ドーム', '時計台'],\n",
        "    ['鹿', '奈良', '東京', '広島', '札幌'],\n",
        "    ['象', 'ピエロ', 'バレエ', '漫才', '歌手'],\n",
        "    ['急須', '湯呑み', '杯', 'コーヒーカップ', 'コップ'],\n",
        "#    ['猪', 'うさぎ', 'カンガルー', 'パンダ', 'キリン'],\n",
        "#    ['そろばん', '電卓', '電池', 'スライド', 'ビデオ'],\n",
        "#    ['かもめ', '海', '滝', '水田', '池'],\n",
        "#    ['汽車', 'バス', 'トラック', 'ダンプカー', 'パトカー'],\n",
        "#    ['急須', '湯呑み', '杯', 'コーヒーカップ', 'コップ'],\n",
        "#    ['猿', 'ゴリラ', '猫', 'コアラ', '熊'],\n",
        "]\n",
        "\n",
        "inches = 5\n",
        "def ax_scatter_gram(ax, pca1, pca2, wordlist, title=None):\n",
        "    ax.scatter(pca1[:1], pca2[:1], s=200, color='red')\n",
        "    ax.scatter(pca1[1:], pca2[1:], s=200, color='cyan')\n",
        "    for i, label in enumerate(wordlist):\n",
        "        ax.annotate(label, (pca1[i], pca2[i]),fontsize=14)\n",
        "    ax.set_xlabel(\"第一主成分\")\n",
        "    ax.set_ylabel(\"第二主成分\")\n",
        "    ax.set_title(title,fontsize=18)\n",
        "    \n",
        "for i, x in enumerate(test_list):\n",
        "    wordlist = x\n",
        "    print('{0:02d} {1}'.format(i,wordlist))\n",
        "\n",
        "    X = w2vMat(wordlist)\n",
        "    Pn, Qn, Pm, Qm = Mat_orth(X[1:,])\n",
        "    Y = np.dot(X, Pm)\n",
        "    R = _similarity_matrix(Y)\n",
        "    print('\\t射影ベクトルによる類似度行列\\n', R)\n",
        "    \n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(R)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "    fig = plt.figure(figsize=(inches * 2,inches))\n",
        "    ax = fig.add_subplot(1,2,1)\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title='選択肢単語空間への射影')\n",
        "\n",
        "    print('\\tword2vec オリジナルの類似度行列\\n', w2v_similarity_matrix(wordlist))\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(X)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "    ax = fig.add_subplot(1,2,2)\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title=\"word2vec単語空間への射影\")\n",
        "    plt.show()\n",
        "\n",
        "sys.exit()\n",
        "\n",
        "for i, stim_words in enumerate(test_list):\n",
        "    \n",
        "    print('{0:02d} {1}'.format(i+1,stim_words))\n",
        "    sim_mat = w2v_similarity_matrix(stim_words)\n",
        "    print(sim_mat)\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(sim_mat)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "    plt.figure(figsize=(inches,inches))\n",
        "    plt.scatter(pca1, pca2, s=200, color='cyan')\n",
        "    for i, label in enumerate(stim_words):\n",
        "        plt.annotate(label, (pca1[i], pca2[i]), fontsize=14)\n",
        "    plt.title('各単語の主成分プロット')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39cf_7ckJUlV"
      },
      "source": [
        "def plot_test(wordlist, Pmat=Pm, inches=5):\n",
        "    #print('{0:02d} {1}'.format(i,wordlist))\n",
        "    X = w2vMat(wordlist)\n",
        "    #Pn, Qn, Pm, Qm = Mat_orth(X[1:,])\n",
        "    Y = np.dot(X, Pmat)\n",
        "    R = _similarity_matrix(Y)\n",
        "    print('\\t射影ベクトルによる類似度行列\\n', R)\n",
        "    \n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(R)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "    fig = plt.figure(figsize=(inches * 2,inches))\n",
        "    ax = fig.add_subplot(1,2,1)\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title='選択肢単語空間への射影')\n",
        "\n",
        "    print('\\tword2vec オリジナルの類似度行列\\n', w2v_similarity_matrix(wordlist))\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(X)\n",
        "    pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "\n",
        "    ax = fig.add_subplot(1,2,2)\n",
        "    ax_scatter_gram(ax, pca1, pca2, wordlist, title=\"word2vec単語空間への射影\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print('#オノマトペ語辞書から N=5 個の単語を選んで，オノマトペ空間へ射影してみる。')\n",
        "print('#次元が縮約しているので射影した後での空間附置が異なることに注意')\n",
        "N=5\n",
        "test_list = np.random.choice(entries, N)\n",
        "print(test_list)\n",
        "plot_test(test_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TtmAN9HF7-b"
      },
      "source": [
        "---\n",
        "\n",
        "ここから下が本番です。\n",
        "任意の単語リストを作成し，作成したリストの一番先頭の要素が，それ以外の要素との距離を比較します。\n",
        "例えば，`wordlist = ['イヌ', 'ネコ', '自転車', '弁護士', 'ワーワー']` の要素があった場合，\n",
        "word2vec 空間内での距離とオノマトペ空間内での距離が変化するか否かを検討します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-vzh5e_5f4"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "#from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "inches = 5\n",
        "def ax_scatter_gram(ax, pca1, pca2, wordlist, title=None):\n",
        "    ax.scatter(pca1[:1], pca2[:1], s=200, color='red')\n",
        "    ax.scatter(pca1[1:], pca2[1:], s=200, color='cyan')\n",
        "    for i, label in enumerate(wordlist):\n",
        "        ax.annotate(label, (pca1[i], pca2[i]),fontsize=14)\n",
        "    ax.set_xlabel(\"第一主成分\")\n",
        "    ax.set_ylabel(\"第二主成分\")\n",
        "    ax.set_title(title,fontsize=18)\n",
        "\n",
        "def compare3plots(wordlist, whole_words, inches=4):\n",
        "\n",
        "    def plot_pca(ax, R, i, title=\"\"):\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_result = pca.fit_transform(R)\n",
        "        pca1, pca2 = pca_result[:,0], pca_result[:,1] \n",
        "        print('\\tExplained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "        ax_scatter_gram(ax, pca1, pca2, wordlist, title=title)\n",
        "\n",
        "    print(wordlist)\n",
        "    fig = plt.figure(figsize=(inches * 3.3,inches))\n",
        "    fontsize = 10\n",
        "\n",
        "    Own_space = w2vMat(wordlist)\n",
        "    Pn, Qn, Pm_onmtp, Qm = Mat_orth(w2vMat(wordlist=whole_words))\n",
        "    y_onmtp = np.dot(Own_space, Pm_onmtp)\n",
        "    R = _similarity_matrix(y_onmtp)\n",
        "    #print(R)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1]  #; print(Sim_sorted)\n",
        "    print('オノマトペ空間への射影:',[wordlist[s] for s in Sim_sorted], end=\" \")\n",
        "    ax = fig.add_subplot(1,3,1)\n",
        "    plot_pca(ax, R, 1, title='オノマトペ空間への射影:')\n",
        "\n",
        "    Pn, Qn, Pm_inn, Qm = Mat_orth(w2vMat(wordlist=wordlist))\n",
        "    y_inn = np.dot(Own_space, Pm_inn)\n",
        "    R = _similarity_matrix(y_inn)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1]  #; print(Sim_sorted)\n",
        "    print('構成単語空間への射影:', [wordlist[s] for s in Sim_sorted], end=\" \")\n",
        "    #print(R)\n",
        "    ax = fig.add_subplot(1,3,2)\n",
        "    plot_pca(ax, R, 2, title='構成単語空間への射影:')\n",
        "\n",
        "    R = _similarity_matrix(Own_space)\n",
        "    #print(R)\n",
        "    Sim_sorted = np.argsort(R[0])[::-1] #; print(Sim_sorted)\n",
        "    print('Original word2vec', [wordlist[s] for s in Sim_sorted], end=\" \")\n",
        "    ax = fig.add_subplot(1,3,3)\n",
        "    plot_pca(ax, R, 3, title='Original word2vec')\n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "#compare3plots(wordlist, entries)\n",
        "#wordlist = np.random.choice(entries,4)\n",
        "#compare3plots(wordlist, entries)\n",
        "\n",
        "\n",
        "#wordlist=['イヌ', 'ワンワン','キャンキャン', 'ニャーニャー', 'しくしく']\n",
        "wordlist=['イヌ', 'パイナップル', '自転車', '弁護士', 'キャンキャン']\n",
        "compare3plots(wordlist,entries)\n",
        "\n",
        "for N in range(8,12):\n",
        "    wordlist = np.random.choice(entries,N)\n",
        "    compare3plots(wordlist,entries)\n",
        "   \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFl63vuFx1B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}