{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020SightVisit_RL_ogawa_2_3_policy_gradient.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020SightVisit_RL_ogawa_2_3_policy_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRa50yeh3M9l"
      },
      "source": [
        "# 方策勾配法のデモ\n",
        "\n",
        " <a href=\"mailto:asakawa@ieee.org\">浅川伸一</a>\n",
        "\n",
        "本ファイルは小川雄太郎の「[つくりながら学ぶ！深層強化学習](https://www.amazon.co.jp/dp/4839965625/)」(マイナビ出版 2018/6/28) \n",
        "の 2.2. 迷路とエージェントを実装，にでてくる[方策勾配法による迷路探索コード](https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book/blob/master/program/2_3_Policygradient.ipynb) です。\n",
        "\n",
        "すぐれた教科書を書かれた小川さんに感謝いたします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYaC0DiI2eM0"
      },
      "source": [
        "# 使用するパッケージの宣言\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6pYVX42gGd"
      },
      "source": [
        "# 初期位置での迷路の様子\n",
        "\n",
        "# 図を描く大きさと、図の変数名を宣言\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = plt.gca()\n",
        "\n",
        "# 赤い壁を描く\n",
        "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
        "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
        "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
        "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
        "\n",
        "# 状態を示す文字S0～S8を描く\n",
        "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
        "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
        "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
        "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
        "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
        "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
        "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
        "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
        "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
        "plt.text(0.5, 2.3, 'START', ha='center')\n",
        "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
        "\n",
        "# 描画範囲の設定と目盛りを消す設定\n",
        "ax.set_xlim(0, 3)\n",
        "ax.set_ylim(0, 3)\n",
        "plt.tick_params(axis='both', which='both', bottom='off', top='off',\n",
        "                labelbottom='off', right='off', left='off', labelleft='off')\n",
        "\n",
        "# 現在地S0に緑丸を描画する\n",
        "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OafZngaV2iaa"
      },
      "source": [
        "# 初期の方策を決定するパラメータtheta_0を設定\n",
        "\n",
        "# 行は状態0～7、列は移動方向で↑、→、↓、←を表す\n",
        "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
        "                    [np.nan, 1, np.nan, 1],  # s1\n",
        "                    [np.nan, np.nan, 1, 1],  # s2\n",
        "                    [1, 1, 1, np.nan],  # s3\n",
        "                    [np.nan, np.nan, 1, 1],  # s4\n",
        "                    [1, np.nan, np.nan, np.nan],  # s5\n",
        "                    [1, np.nan, np.nan, np.nan],  # s6\n",
        "                    [1, 1, np.nan, np.nan],  # s7、※s8はゴールなので、方策はなし\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P-UUcjI2loe"
      },
      "source": [
        "# 方策パラメータthetaを行動方策piにソフトマックス関数で変換する手法の定義\n",
        "\n",
        "\n",
        "def softmax_convert_into_pi_from_theta(theta):\n",
        "    '''ソフトマックス関数で割合を計算する'''\n",
        "\n",
        "    beta = 1.0\n",
        "    [m, n] = theta.shape  # thetaの行列サイズを取得\n",
        "    pi = np.zeros((m, n))\n",
        "\n",
        "    exp_theta = np.exp(beta * theta)  # thetaをexp(theta)へと変換\n",
        "\n",
        "    for i in range(0, m):\n",
        "        # pi[i, :] = theta[i, :] / np.nansum(theta[i, :])\n",
        "        # simpleに割合の計算の場合\n",
        "\n",
        "        pi[i, :] = exp_theta[i, :] / np.nansum(exp_theta[i, :])\n",
        "        # softmaxで計算の場合\n",
        "\n",
        "    pi = np.nan_to_num(pi)  # nanを0に変換\n",
        "\n",
        "    return pi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML8R9Xad72yC"
      },
      "source": [
        "# 初期の方策pi_0を求める\n",
        "pi_0 = softmax_convert_into_pi_from_theta(theta_0)\n",
        "print(pi_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUjoX4g26yRn"
      },
      "source": [
        "# 行動aと1step移動後の状態sを求める関数を定義\n",
        "\n",
        "\n",
        "def get_action_and_next_s(pi, s):\n",
        "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
        "    # pi[s,:]の確率に従って、directionが選択される\n",
        "    next_direction = np.random.choice(direction, p=pi[s, :])\n",
        "\n",
        "    if next_direction == \"up\":\n",
        "        action = 0\n",
        "        s_next = s - 3  # 上に移動するときは状態の数字が3小さくなる\n",
        "    elif next_direction == \"right\":\n",
        "        action = 1\n",
        "        s_next = s + 1  # 右に移動するときは状態の数字が1大きくなる\n",
        "    elif next_direction == \"down\":\n",
        "        action = 2\n",
        "        s_next = s + 3  # 下に移動するときは状態の数字が3大きくなる\n",
        "    elif next_direction == \"left\":\n",
        "        action = 3\n",
        "        s_next = s - 1  # 左に移動するときは状態の数字が1小さくなる\n",
        "\n",
        "    return [action, s_next]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwbuOZUm650-"
      },
      "source": [
        "# 迷路を解く関数の定義、状態と行動の履歴を出力\n",
        "\n",
        "\n",
        "def goal_maze_ret_s_a(pi):\n",
        "    s = 0  # スタート地点\n",
        "    s_a_history = [[0, np.nan]]  # エージェントの移動を記録するリスト\n",
        "\n",
        "    while (1):  # ゴールするまでループ\n",
        "        [action, next_s] = get_action_and_next_s(pi, s)\n",
        "        s_a_history[-1][1] = action\n",
        "        # 現在の状態（つまり一番最後なのでindex=-1）の行動を代入\n",
        "\n",
        "        s_a_history.append([next_s, np.nan])\n",
        "        # 次の状態を代入。行動はまだ分からないのでnanにしておく\n",
        "\n",
        "        if next_s == 8:  # ゴール地点なら終了\n",
        "            break\n",
        "        else:\n",
        "            s = next_s\n",
        "\n",
        "    return s_a_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY3Lb1sO8MBG"
      },
      "source": [
        "# 初期の方策で迷路を解く\n",
        "s_a_history = goal_maze_ret_s_a(pi_0)\n",
        "print(s_a_history)\n",
        "print(\"迷路を解くのにかかったステップ数は\" + str(len(s_a_history) - 1) + \"です\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYl4xh_T7MoN"
      },
      "source": [
        "# thetaの更新関数を定義します\n",
        "\n",
        "\n",
        "def update_theta(theta, pi, s_a_history):\n",
        "    eta = 0.1 # 学習率\n",
        "    T = len(s_a_history) - 1  # ゴールまでの総ステップ数\n",
        "\n",
        "    [m, n] = theta.shape  # thetaの行列サイズを取得\n",
        "    delta_theta = theta.copy()  # Δthetaの元を作成、ポインタ参照なので、delta_theta = thetaはダメ\n",
        "\n",
        "    # delta_thetaを要素ごとに求めます\n",
        "    for i in range(0, m):\n",
        "        for j in range(0, n):\n",
        "            if not(np.isnan(theta[i, j])):  # thetaがnanでない場合\n",
        "\n",
        "                SA_i = [SA for SA in s_a_history if SA[0] == i]\n",
        "                # 履歴から状態iのものを取り出すリスト内包表記です\n",
        "\n",
        "                SA_ij = [SA for SA in s_a_history if SA == [i, j]]\n",
        "                # 状態iで行動jをしたものを取り出す\n",
        "\n",
        "                N_i = len(SA_i)  # 状態iで行動した総回数\n",
        "                N_ij = len(SA_ij)  # 状態iで行動jをとった回数\n",
        "                \n",
        "                # 初版では符号の正負に間違いがありました（修正日：180703）\n",
        "                #delta_theta[i, j] = (N_ij + pi[i, j] * N_i) / T\n",
        "                delta_theta[i, j] = (N_ij - pi[i, j] * N_i) / T\n",
        "\n",
        "    new_theta = theta + eta * delta_theta\n",
        "\n",
        "    return new_theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSQ0qcM37Qo3"
      },
      "source": [
        "# 方策の更新\n",
        "new_theta = update_theta(theta_0, pi_0, s_a_history)\n",
        "pi = softmax_convert_into_pi_from_theta(new_theta)\n",
        "print(pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNukPTVE8eUs"
      },
      "source": [
        "# 方策勾配法で迷路を解く\n",
        "\n",
        "# 初版で、def update_thetaに間違いがあった関係で、終了条件を変更します（修正日：180703）\n",
        "#stop_epsilon = 10**-8  # 10^-8よりも方策に変化が少なくなったら学習終了とする\n",
        "stop_epsilon = 10**-4  # 10^-4よりも方策に変化が少なくなったら学習終了とする\n",
        "\n",
        "\n",
        "theta = theta_0\n",
        "pi = pi_0\n",
        "\n",
        "is_continue = True\n",
        "count = 1\n",
        "while is_continue:  # is_continueがFalseになるまで繰り返す\n",
        "    s_a_history = goal_maze_ret_s_a(pi)  # 方策πで迷路内を探索した履歴を求める\n",
        "    new_theta = update_theta(theta, pi, s_a_history)  # パラメータΘを更新\n",
        "    new_pi = softmax_convert_into_pi_from_theta(new_theta)  # 方策πの更新\n",
        "\n",
        "    print(np.sum(np.abs(new_pi - pi)))  # 方策の変化を出力\n",
        "    print(\"迷路を解くのにかかったステップ数は\" + str(len(s_a_history) - 1) + \"です\")\n",
        "\n",
        "    if np.sum(np.abs(new_pi - pi)) < stop_epsilon:\n",
        "        is_continue = False\n",
        "    else:\n",
        "        theta = new_theta\n",
        "        pi = new_pi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSQcc5WK8l4H"
      },
      "source": [
        "# 最終的な方策を確認\n",
        "np.set_printoptions(precision=3, suppress=True)  # 有効桁数3、指数表示しないという設定\n",
        "print(pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apyShJbJ8nZw"
      },
      "source": [
        "# エージェントの移動の様子を可視化します\n",
        "# 参考URL http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "def init():\n",
        "    # 背景画像の初期化\n",
        "    line.set_data([], [])\n",
        "    return (line,)\n",
        "\n",
        "\n",
        "def animate(i):\n",
        "    # フレームごとの描画内容\n",
        "    state = s_a_history[i][0]  # 現在の場所を描く\n",
        "    x = (state % 3) + 0.5  # 状態のx座標は、3で割った余り+0.5\n",
        "    y = 2.5 - int(state / 3)  # y座標は3で割った商を2.5から引く\n",
        "    line.set_data(x, y)\n",
        "    return (line,)\n",
        "\n",
        "\n",
        "#　初期化関数とフレームごとの描画関数を用いて動画を作成\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(\n",
        "    s_a_history), interval=200, repeat=False)\n",
        "\n",
        "HTML(anim.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}