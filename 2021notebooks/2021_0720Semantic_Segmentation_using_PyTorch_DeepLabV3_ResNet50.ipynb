{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0720Semantic_Segmentation_using_PyTorch_DeepLabV3_ResNet50.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPgNcPI/gD9kz3eb58sowMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2021notebooks/2021_0720Semantic_Segmentation_using_PyTorch_DeepLabV3_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZZ69CRGewRC"
      },
      "source": [
        "# Semantic Segmentation using PyTorch DeepLabV3 ResNet50\n",
        "\n",
        "- source: https://debuggercafe.com/semantic-segmentation-using-pytorch-deeplabv3-resnet50/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56I6_bWvfXa6"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K980zFB1frez"
      },
      "source": [
        "inp_fname = 'Portrait2.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxcoevtabGDh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = 12, 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfaRWdLBbJuE"
      },
      "source": [
        "label_color_map = [\n",
        "               (0, 0, 0),  # background\n",
        "               (128, 0, 0), # aeroplane\n",
        "               (0, 128, 0), # bicycle\n",
        "               (128, 128, 0), # bird\n",
        "               (0, 0, 128), # boat\n",
        "               (128, 0, 128), # bottle\n",
        "               (0, 128, 128), # bus \n",
        "               (128, 128, 128), # car\n",
        "               (64, 0, 0), # cat\n",
        "               (192, 0, 0), # chair\n",
        "               (64, 128, 0), # cow\n",
        "               (192, 128, 0), # dining table\n",
        "               (64, 0, 128), # dog\n",
        "               (192, 0, 128), # horse\n",
        "               (64, 128, 128), # motorbike\n",
        "               (192, 128, 128), # person\n",
        "               (0, 64, 0), # potted plant\n",
        "               (128, 64, 0), # sheep\n",
        "               (0, 192, 0), # sofa\n",
        "               (128, 192, 0), # train\n",
        "               (0, 64, 128) # tv/monitor\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n56aEaKebM46"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# define the torchvision image transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def get_segment_labels(image, model, device):\n",
        "    # transform the image to tensor and load into computation device\n",
        "    image = transform(image).to(device)\n",
        "    image = image.unsqueeze(0) # add a batch dimension\n",
        "    outputs = model(image)\n",
        "    return outputs\n",
        "\n",
        "def draw_segmentation_map(outputs):\n",
        "    labels = torch.argmax(outputs.squeeze(), dim=0).detach().cpu().numpy()\n",
        "\n",
        "    # create Numpy arrays containing zeros\n",
        "    # later to be used to fill them with respective red, green, and blue pixels\n",
        "    red_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    green_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    blue_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    \n",
        "    for label_num in range(0, len(label_color_map)):\n",
        "        index = labels == label_num\n",
        "        red_map[index] = np.array(label_color_map)[label_num, 0]\n",
        "        green_map[index] = np.array(label_color_map)[label_num, 1]\n",
        "        blue_map[index] = np.array(label_color_map)[label_num, 2]\n",
        "        \n",
        "    segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
        "    return segmentation_map\n",
        "\n",
        "def image_overlay(image, segmented_image):\n",
        "    alpha = 1 # transparency for the original image\n",
        "    beta = 0.8 # transparency for the segmentation map\n",
        "    gamma = 0 # scalar added to each sum\n",
        "\n",
        "    segmented_image = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR)\n",
        "    image = np.array(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.addWeighted(image, alpha, segmented_image, beta, gamma, image)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEilPSUfbQoH"
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# set computation device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# download or load the model from disk\n",
        "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
        "# model to eval() model and load onto computation devicce\n",
        "model.eval().to(device)\n",
        "\n",
        "# read the image\n",
        "image = Image.open(inp_fname)\n",
        "#image = Image.open(args['input'])\n",
        "# do forward pass and get the output dictionary\n",
        "outputs = get_segment_labels(image, model, device)\n",
        "# get the data from the `out` key\n",
        "outputs = outputs['out']\n",
        "segmented_image = draw_segmentation_map(outputs)\n",
        "\n",
        "final_image = image_overlay(image, segmented_image)\n",
        "#save_name = \"test_output\"\n",
        "# show the segmented image and save to disk\n",
        "# cv2.imshow('Segmented image', final_image)\n",
        "# cv2.waitKey(0)\n",
        "cv2.imwrite(\"test_output.jpg\", final_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os-ULgTPdcQ3"
      },
      "source": [
        "image = plt.imread('test_output.jpg')\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C4DI9VGeZjK"
      },
      "source": [
        "!ls input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxdgf7Ngdiud"
      },
      "source": [
        "import torchvision\n",
        "import cv2\n",
        "import torch\n",
        "import argparse\n",
        "import time\n",
        "#import segmentation_utils\n",
        "\n",
        "# set the computation device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# download or load the model from disk\n",
        "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
        "# load the model onto the computation device\n",
        "model = model.eval().to(device)\n",
        "\n",
        "cap = cv2.VideoCapture('input/video_1.mp4')\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Please check path again')\n",
        "\n",
        "# get the frame width and height\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "#save_name = f\"{args['input'].split('/')[-1].split('.')[0]}\"\n",
        "save_name ='test_outvideo'\n",
        "# define codec and create VideoWriter object \n",
        "out = cv2.VideoWriter(f\"outputs/{save_name}.mp4\", \n",
        "                      cv2.VideoWriter_fourcc(*'mp4v'), 30, \n",
        "                      (frame_width, frame_height))\n",
        "\n",
        "frame_count = 0 # to count total frames\n",
        "total_fps = 0 # to get the final frames per second\n",
        "\n",
        "# read until end of video\n",
        "while(cap.isOpened()):\n",
        "    # capture each frame of the video\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        # get the start time\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            # get predictions for the current frame\n",
        "            outputs = get_segment_labels(rgb_frame, model, device)\n",
        "        \n",
        "        # obtain the segmentation map\n",
        "        segmented_image = draw_segmentation_map(outputs['out'])\n",
        "        # get the final image with segmentation map overlayed on original iimage\n",
        "        final_image = image_overlay(rgb_frame, segmented_image)\n",
        "\n",
        "        # get the end time\n",
        "        end_time = time.time()\n",
        "        # get the current fps\n",
        "        fps = 1 / (end_time - start_time)\n",
        "        # add current fps to total fps\n",
        "        total_fps += fps\n",
        "        # increment frame count\n",
        "        frame_count += 1\n",
        "        print(f\"Frame: {frame_count}, FPS: {fps:.3f}\")\n",
        "        # put the FPS text on the current frame\n",
        "        cv2.putText(final_image, f\"{fps:.3f} FPS\", (20, 35), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        # press `q` to exit\n",
        "        # cv2.imshow('image', final_image)\n",
        "        out.write(final_image)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# release VideoCapture()\n",
        "cap.release()\n",
        "# close all frames and video windows\n",
        "cv2.destroyAllWindows()\n",
        "# calculate and print the average FPS\n",
        "avg_fps = total_fps / frame_count\n",
        "print(f\"Average FPS: {avg_fps:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6goTIDtd3Am"
      },
      "source": [
        "!zip -r /content/outputs outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vph_t9juetnE"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputs.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}