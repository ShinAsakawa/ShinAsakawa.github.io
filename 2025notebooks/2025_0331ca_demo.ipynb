{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2025notebooks/2025_0331ca_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfd19697-66c2-429e-81d7-42c85a0dabb8",
      "metadata": {
        "id": "cfd19697-66c2-429e-81d7-42c85a0dabb8"
      },
      "source": [
        "# 藤本先生からいただいた対応分析を Python で再実装する試み\n",
        "\n",
        "* Date: 2025_0331\n",
        "* Author: 浅川伸一"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b3c3fc-c166-4cac-82fd-fe5d8f7d27a1",
      "metadata": {
        "id": "69b3c3fc-c166-4cac-82fd-fe5d8f7d27a1"
      },
      "source": [
        "## 0.1 下準備 データファイルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273f21e1-ffbc-4081-8825-64bd0d242f81",
      "metadata": {
        "id": "273f21e1-ffbc-4081-8825-64bd0d242f81"
      },
      "outputs": [],
      "source": [
        "excel_fname = \"失語6例_TLPA呼称データ_241212_藤本先生コラボ用_送信版.xlsx\"\n",
        "\n",
        "# Google Colab で実行する場合，データのエクセルファイルをアップロードする必要がある。\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbc9517-dcd9-4933-bbb2-0c5a7f833e40",
      "metadata": {
        "id": "4dbc9517-dcd9-4933-bbb2-0c5a7f833e40"
      },
      "outputs": [],
      "source": [
        "# 必要となるライブラリのインストール\n",
        "try:\n",
        "    import mca\n",
        "except ImportError:\n",
        "    !pip install mca\n",
        "    import mca\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c7db0a-bdfd-4fba-9705-4c6e3199e039",
      "metadata": {
        "id": "68c7db0a-bdfd-4fba-9705-4c6e3199e039"
      },
      "source": [
        "# 1. データファイルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61ca105-f993-4ee9-ac6d-5c28f2d6fe21",
      "metadata": {
        "id": "e61ca105-f993-4ee9-ac6d-5c28f2d6fe21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "excel_fname = \"失語6例_TLPA呼称データ_241212_藤本先生コラボ用_送信版.xlsx\"\n",
        "\n",
        "# 藤本先生の R コードでは d0 という名前でデータを扱っていた。そのためここでも同じ変数名 d0 を用いる。\n",
        "d0 = pd.read_excel(excel_fname)[['カテゴリー','症例A', '症例B', '症例C', '症例D', '症例E', '症例F']]\n",
        "\n",
        "# 反応の型を定義している部分を抜き出す\n",
        "resp_types = pd.read_excel(excel_fname)[['Unnamed: 15', 'Unnamed: 16']].to_numpy()[1:9]\n",
        "resps = {i[0]:i[1] for i in resp_types}\n",
        "\n",
        "print(f'反応の種類:{resps}')\n",
        "print(f'刺激図版の種類:{d0.カテゴリー.unique()}')\n",
        "\n",
        "stim_cats = {c:i+1 for i, c in enumerate(d0.カテゴリー.unique())}\n",
        "print(f'刺激図版のカテゴリー番号:{stim_cats}')\n",
        "\n",
        "# 刺激図版のカテゴリを数値に変換して格納\n",
        "stim_cat_nums = [stim_cats[x] for x in d0.カテゴリー.to_numpy()]\n",
        "pd.options.mode.copy_on_write = True\n",
        "d0['stim_cat_nums'] = stim_cat_nums\n",
        "\n",
        "# 読み込んだデータ, pandas のデータフレームに格納してある。そのデータを表示。\n",
        "d0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b0ead48-496a-4463-8640-80320be1d7e2",
      "metadata": {
        "id": "9b0ead48-496a-4463-8640-80320be1d7e2"
      },
      "outputs": [],
      "source": [
        "# 各症例ごとに反応を集計\n",
        "for case in ['症例A', '症例B', '症例C', '症例D', '症例E', '症例F']:\n",
        "    print(pd.crosstab(d0.stim_cat_nums, d0.eval(case)), end=\"\\n---\\n\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8da526a-6d04-43bc-a791-5c44b99214bd",
      "metadata": {
        "id": "e8da526a-6d04-43bc-a791-5c44b99214bd"
      },
      "source": [
        "# 2. 対応分析の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfde0c9-0eb3-4933-a1a5-de2193f4b44e",
      "metadata": {
        "id": "4bfde0c9-0eb3-4933-a1a5-de2193f4b44e"
      },
      "outputs": [],
      "source": [
        "# 症例 A を取り出して対応分析実施\n",
        "\n",
        "d1 = pd.crosstab(d0.stim_cat_nums, d0.症例A)\n",
        "mca_counts = mca.MCA(d1, benzecri=False)\n",
        "\n",
        "print(f'行に関する因子得点\\n{mca_counts.fs_r(N=2)}')\n",
        "print(f'列に関する因子得点\\n{mca_counts.fs_c(N=2)}')\n",
        "d1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc889f7-e1bc-413f-8991-610f03933f8f",
      "metadata": {
        "id": "3cc889f7-e1bc-413f-8991-610f03933f8f"
      },
      "outputs": [],
      "source": [
        "rows = mca_counts.fs_r(N=2)\n",
        "cols = mca_counts.fs_c(N=2)\n",
        "\n",
        "plt.scatter( rows[:,0], rows[:,1], marker=\"None\")\n",
        "labels = d0.カテゴリー\n",
        "labels = [i for i in stim_cats]\n",
        "for label,x,y in zip(labels,rows[:,0],rows[:,1]):\n",
        "    plt.annotate(label,xy = (x, y), c=\"b\")\n",
        "\n",
        "plt.scatter(cols[:, 0], cols[:, 1], marker=\"None\")\n",
        "#labels = df.columns\n",
        "labels = [resps[c] for c in pd.crosstab(d0.stim_cat_nums, d0.症例A).columns]\n",
        "for label, x, y in zip(labels, cols[:, 0], cols[:, 1]):\n",
        "    plt.annotate(label, xy=(x, y), c=\"r\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e441e829-38f3-49a6-b6f4-73351578b8ea",
      "metadata": {
        "id": "e441e829-38f3-49a6-b6f4-73351578b8ea"
      },
      "source": [
        "# 3. 同じデータに対して PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e5bb45e0-817d-44a3-8074-e21c69f1d7a9",
      "metadata": {
        "id": "e5bb45e0-817d-44a3-8074-e21c69f1d7a9"
      },
      "outputs": [],
      "source": [
        "# 下準備\n",
        "try:\n",
        "    import seaborn as sns\n",
        "except ImportError:\n",
        "    !pip install --upgrade seaborn\n",
        "    import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2dc793-5ade-4187-afe3-91d5e95bd7b5",
      "metadata": {
        "id": "3f2dc793-5ade-4187-afe3-91d5e95bd7b5"
      },
      "outputs": [],
      "source": [
        "X = StandardScaler().fit_transform(d1.to_numpy())\n",
        "pca = PCA(n_components=2).fit(X)\n",
        "X_reduced = pca.transform(X)\n",
        "\n",
        "loadings = pca.components_[:2].T\n",
        "pvars = pca.explained_variance_ratio_[:2] * 100\n",
        "arrows = loadings * np.ptp(X_reduced, axis=0)\n",
        "width = -0.0075 * np.min([np.subtract(*plt.xlim()), np.subtract(*plt.ylim())])\n",
        "\n",
        "plt.scatter(X_reduced[:,0], X_reduced[:,1])\n",
        "for label,x,y in zip(stim_cats, X_reduced[:,0],X_reduced[:,1]):\n",
        "    plt.annotate(label, xy = (x, y), c=\"b\")\n",
        "# Plot arrows.\n",
        "horizontal_alignment = ['right', 'left', 'right', 'right']\n",
        "vertical_alignment = ['bottom', 'top', 'top', 'bottom']\n",
        "for (i, arrow), ha, va in zip(enumerate(arrows), horizontal_alignment, vertical_alignment):\n",
        "    plt.arrow(0, 0, *arrow, color='k', alpha=0.5, width=width, ec='none',\n",
        "              length_includes_head=True)\n",
        "    plt.text(*(arrow * 1.05), [x[1] for x in resp_types][i], ha=ha, va=va,\n",
        "    #plt.text(*(arrow * 1.05), list(stim_cats.keys())[i], ha=ha, va=va,\n",
        "             fontsize='large', color='green')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57dd1f8-ace8-474b-bab7-d484e0287cef",
      "metadata": {
        "id": "e57dd1f8-ace8-474b-bab7-d484e0287cef"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}