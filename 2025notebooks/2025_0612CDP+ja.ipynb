{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2025notebooks/2025_0612CDP%2Bja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce496ec-2d3c-48b2-9e88-ce66421100a2",
      "metadata": {
        "id": "fce496ec-2d3c-48b2-9e88-ce66421100a2"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in IPython.sys.modules\n",
        "\n",
        "import torch\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "#device='cpu'\n",
        "print(f'device:{device}')\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 必要なライブラリの輸入\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import operator\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "\n",
        "if isColab:\n",
        "    !pip uninstall numpy thinc spacy --yes\n",
        "    !pip install --upgrade numpy==1.26.4 --force-reinstall\n",
        "    !pip install --upgrade gensim==4.3.3\n",
        "\n",
        "    import numpy as np\n",
        "    print(f'np.__version__:{np.__version__}')\n",
        "\n",
        "    import gensim\n",
        "    print(f'gensim.__version__:{gensim.__version__}')\n",
        "\n",
        "    !pip install --upgrade jaconv\n",
        "\n",
        "try:\n",
        "    import RAM\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "    import RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9026f18c-c1b7-44d3-85cf-c91aecacd9eb",
      "metadata": {
        "id": "9026f18c-c1b7-44d3-85cf-c91aecacd9eb",
        "outputId": "2b9b7ed5-dca1-443e-c1cd-3408f4d3d484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(grph_list):1099\n",
            "全書記素 grph_list:ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん０１２３４５６７８９一右雨円王音下火花貝学気休玉金九空月犬見五口校左三山四子糸字耳七車手十出女小上森人水正生青石赤先千川早草足村大男竹中虫町天田土二日入年白八百文本名木目夕立力林六引羽雲園遠黄何夏家科歌画会回海絵外角楽活間丸岩顔帰汽記弓牛魚京強教近兄形計元原言古戸午後語交光公工広考行高合国黒今才細作算姉市思止紙寺時自室社弱首秋週春書少場色食心新親図数星晴声西切雪線船前組走多太体台谷知地池茶昼朝長鳥直通弟店点電冬刀東当答頭同道読内南肉馬買売麦半番父風分聞米歩母方北妹毎万明鳴毛門夜野矢友曜用来理里話悪安暗委意医育員飲院運泳駅横屋温化荷界開階寒感漢館岸期起客宮急球究級去橋業局曲銀区苦具君係軽決血研県庫湖向幸港号根祭坂皿仕使始指死詩歯事持次式実写者主取守酒受州拾終習集住重宿所暑助勝商昭消章乗植深申真神身進世整昔全想相送息速族他打対待代第題炭短談着柱注丁帳調追定庭笛鉄転登都度島投湯等豆動童農波配倍箱畑発反板悲皮美鼻筆氷表病秒品夫負部服福物平返勉放味命面問役薬油有由遊予様洋羊葉陽落流旅両緑礼列練路和愛案以位囲胃衣印栄英塩央億加果課貨芽改械害街各覚完官管観関願喜器希旗機季紀議救求泣給挙漁競共協鏡極訓軍郡型径景芸欠結健建験固候功好康航告差最菜材昨刷察札殺参散産残司史士氏試児治辞失借種周祝順初唱松焼照省笑象賞信臣成清静席積折節説戦浅選然倉巣争側束続卒孫帯隊達単置仲貯兆腸低停底的典伝徒努灯働堂得特毒熱念敗梅博飯費飛必標票不付府副粉兵別変辺便包法望牧末満未脈民無約勇要養浴利陸料良量輪類令例冷歴連労老録圧易移因営永衛液益演往応恩仮価可河過賀解快格確額刊幹慣眼基寄規技義逆久旧居許境興均禁句群経潔件券検険減現限個故護効厚構耕講鉱混査再妻採災際在罪財桜雑賛酸師志支枝資飼似示識質舎謝授修術述準序承招証常情条状織職制勢性政精製税績責接設絶舌銭祖素総像増造則測属損態貸退団断築張提程敵適統導銅徳独任燃能破判版犯比肥非備俵評貧婦富布武復複仏編弁保墓報豊暴貿防務夢迷綿輸余預容率略留領異遺域宇映延沿我灰拡閣革割株巻干看簡危揮机貴疑吸供胸郷勤筋敬系警劇激穴憲権絹厳源呼己誤后孝皇紅鋼降刻穀骨困砂座済裁策冊蚕姿私至視詞誌磁射捨尺若樹収宗就衆従縦縮熟純処署諸除傷将障城蒸針仁垂推寸盛聖誠宣専泉洗染善創奏層操窓装臓蔵存尊宅担探誕暖段値宙忠著庁潮頂賃痛展党糖討届難乳認納脳派俳拝背肺班晩否批秘腹奮並閉陛片補暮宝訪亡忘棒枚幕密盟模訳優郵幼欲翌乱卵覧裏律臨朗論\n",
            "len(phon_list):87\n",
            "全音素 phon_list:['ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ヮ', 'ワ', 'ヰ', 'ヱ', 'ヲ', 'ン', 'ヴ', 'ヵ', 'ヶ', '一']\n",
            "入力層の素子数 len(grph_list) + len(special_tokens)=1103\n",
            "出力層の素子数 len(phon_list) + len(special_tokens)=91\n"
          ]
        }
      ],
      "source": [
        "# 書記素の定義，書記素のうちカタカナを音韻表現としても利用\n",
        "\n",
        "seed = 42\n",
        "special_tokens = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "alphabet_upper_chars='ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'\n",
        "alphabet_lower_chars='ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "num_chars='０１２３４５６７８９'\n",
        "hira_chars='ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん'\n",
        "kata_chars='ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "#kata_chars=kata_chars+'一'  # カタカナ文字に伸ばし記号を加える\n",
        "phon_list = list(kata_chars+'一')\n",
        "\n",
        "# 句点コード\n",
        "from RAM.char_ja import kuten as kuten\n",
        "kuten_chars=kuten().chars\n",
        "\n",
        "# 常用漢字\n",
        "from RAM.char_ja import chars_joyo as chars_joyo\n",
        "joyo_chars = \"\".join([ch for ch in chars_joyo().char_list])\n",
        "\n",
        "# 学習漢字 学年別\n",
        "_gakushu_list = ['一右雨円王音下火花貝学気休玉金九空月犬見五口校左三山四子糸字耳七車手十出女小上森人水正生青石赤先千川早草足村大男竹中虫町天田土二日入年白八百文本名木目夕立力林六',\n",
        "'引羽雲園遠黄何夏家科歌画会回海絵外角楽活間丸岩顔帰汽記弓牛魚京強教近兄形計元原言古戸午後語交光公工広考行高合国黒今才細作算姉市思止紙寺時自室社弱首秋週春書少場色食心新親図数星晴声西切雪線船前組走多太体台谷知地池茶昼朝長鳥直通弟店点電冬刀東当答頭同道読内南肉馬買売麦半番父風分聞米歩母方北妹毎万明鳴毛門夜野矢友曜用来理里話',\n",
        "'悪安暗委意医育員飲院運泳駅横屋温化荷界開階寒感漢館岸期起客宮急球究級去橋業局曲銀区苦具君係軽決血研県庫湖向幸港号根祭坂皿仕使始指死詩歯事持次式実写者主取守酒受州拾終習集住重宿所暑助勝商昭消章乗植深申真神身進世整昔全想相送息速族他打対待代第題炭短談着柱注丁帳調追定庭笛鉄転登都度島投湯等豆動童農波配倍箱畑発反板悲皮美鼻筆氷表病秒品夫負部服福物平返勉放味命面問役薬油有由遊予様洋羊葉陽落流旅両緑礼列練路和',\n",
        "'愛案以位囲胃衣印栄英塩央億加果課貨芽改械害街各覚完官管観関願喜器希旗機季紀議救求泣給挙漁競共協鏡極訓軍郡型径景芸欠結健建験固候功好康航告差最菜材昨刷察札殺参散産残司史士氏試児治辞失借種周祝順初唱松焼照省笑象賞信臣成清静席積折節説戦浅選然倉巣争側束続卒孫帯隊達単置仲貯兆腸低停底的典伝徒努灯働堂得特毒熱念敗梅博飯費飛必標票不付府副粉兵別変辺便包法望牧末満未脈民無約勇要養浴利陸料良量輪類令例冷歴連労老録',\n",
        "'圧易移因営永衛液益演往応恩仮価可河過賀解快格確額刊幹慣眼基寄規技義逆久旧居許境興均禁句群経潔件券検険減現限個故護効厚構耕講鉱混査再妻採災際在罪財桜雑賛酸師志支枝資飼似示識質舎謝授修術述準序承招証常情条状織職制勢性政精製税績責接設絶舌銭祖素総像増造則測属損態貸退団断築張提程敵適統導銅徳独任燃能破判版犯比肥非備俵評貧婦富布武復複仏編弁保墓報豊暴貿防務夢迷綿輸余預容率略留領',\n",
        "'異遺域宇映延沿我灰拡閣革割株巻干看簡危揮机貴疑吸供胸郷勤筋敬系警劇激穴憲権絹厳源呼己誤后孝皇紅鋼降刻穀骨困砂座済裁策冊蚕姿私至視詞誌磁射捨尺若樹収宗就衆従縦縮熟純処署諸除傷将障城蒸針仁垂推寸盛聖誠宣専泉洗染善創奏層操窓装臓蔵存尊宅担探誕暖段値宙忠著庁潮頂賃痛展党糖討届難乳認納脳派俳拝背肺班晩否批秘腹奮並閉陛片補暮宝訪亡忘棒枚幕密盟模訳優郵幼欲翌乱卵覧裏律臨朗論']\n",
        "\n",
        "_l = []\n",
        "for g in _gakushu_list:\n",
        "    for ch in g:\n",
        "        _l += ch\n",
        "gakushu_chars = \"\".join(ch for ch in _l)\n",
        "\n",
        "grph_list = []\n",
        "for x in [hira_chars, num_chars, gakushu_chars]:\n",
        "    for ch in x:\n",
        "        grph_list.append(ch)\n",
        "print(f'len(grph_list):{len(grph_list)}')\n",
        "print(f'全書記素 grph_list:{\"\".join([ch for ch in grph_list])}')\n",
        "\n",
        "print(f'len(phon_list):{len(phon_list)}')\n",
        "print(f'全音素 phon_list:{phon_list}')\n",
        "\n",
        "print(f'入力層の素子数 len(grph_list) + len(special_tokens)={len(grph_list) + len(special_tokens)}')\n",
        "print(f'出力層の素子数 len(phon_list) + len(special_tokens)={len(phon_list) + len(special_tokens)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in IPython.sys.modules\n",
        "\n",
        "if isColab:\n",
        "    !pip install googledrivedownloader==0.4\n",
        "\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    import os\n",
        "\n",
        "    # 共有ファイルのIDを指定\n",
        "    file_id = '1eBJDN392BsUckg5LBFbbw5KT9PCsmnxI' # 'psylex71utf8_.txt'\n",
        "    # https://drive.google.com/file/d/1eBJDN392BsUckg5LBFbbw5KT9PCsmnxI/view?usp=drive_link\n",
        "\n",
        "    # 保存したい場所とファイル名を指定\n",
        "    # 例: /content/ ディレクトリに original_file_name.拡張子 という名前で保存\n",
        "    destination_path = '/content/psylex71utf8_.txt' # ファイルの拡張子を適切に設定してください\n",
        "\n",
        "    try:\n",
        "        print(f\"ファイルのダウンロードを開始します (ファイルID: {file_id})...\")\n",
        "        gdd.download_file_from_google_drive(file_id=file_id,\n",
        "                                            dest_path=destination_path,\n",
        "                                            # unzip=True if file_id is for a zip file\n",
        "                                           )\n",
        "        print(f\"ファイルのダウンロードが完了しました。'{destination_path}' に保存されました。\")\n",
        "\n",
        "        # ダウンロードしたファイルを読み込む例 (テキストファイルの場合)\n",
        "        if os.path.exists(destination_path):\n",
        "            print(\"\\nダウンロードしたファイルの内容 (最初の数行):\")\n",
        "            with open(destination_path, 'r') as f:\n",
        "                # ファイルの内容を表示 (例: 最初の5行)\n",
        "                for i in range(5):\n",
        "                    line = f.readline()\n",
        "                    if not line:\n",
        "                        break\n",
        "                    print(line.strip())\n",
        "        else:\n",
        "             print(f\"エラー: ダウンロード先のファイル '{destination_path}' が見つかりません。\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ファイルのダウンロード中にエラーが発生しました: {e}\")"
      ],
      "metadata": {
        "id": "iHll7Cpvg7fH",
        "outputId": "c1d3c73a-c902-41e3-ffc8-3943109716cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iHll7Cpvg7fH",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader==0.4 in /usr/local/lib/python3.11/dist-packages (0.4)\n",
            "ファイルのダウンロードを開始します (ファイルID: 1eBJDN392BsUckg5LBFbbw5KT9PCsmnxI)...\n",
            "ファイルのダウンロードが完了しました。'/content/psylex71utf8_.txt' に保存されました。\n",
            "\n",
            "ダウンロードしたファイルの内容 (最初の数行):\n",
            "﻿000001 z 　 　 記 332311 14022 15429 17146 21312 25136 23139 22580 25404 29787 27731 28380 29957 25999 26289\n",
            "000002 z 、 、 記 15266632 882868 874817 937982 1158101 1217775 1188700 1028706 1016779 1127783 1139956 1176201 1208479 1150457 1158028\n",
            "000003 z 。 。 記 10370238 510725 522786 559585 713590 765180 744548 674873 694299 792829 821837 859286 899095 889073 922532\n",
            "000004 z ， ， 記 7086 568 593 575 1236 1369 1004 741 469 78 107 113 72 95 66\n",
            "000005 z ． ． 記 133586 15526 15500 16469 17484 17834 16544 13181 15510 976 1094 938 840 924 766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1a58b357-946d-411c-8353-1ed90e00f713",
      "metadata": {
        "id": "1a58b357-946d-411c-8353-1ed90e00f713",
        "outputId": "eb643010-213e-439e-c52b-e8c4b19bb1ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "読み込んだ psylex71.txt の単語数 len(psylex71raw):360850\n",
            "Psylex71 の総単語数 len(_psylex71_):52734\n",
            "作成したデータベース辞書の項目数 len(Psylex71):48907\n",
            "ヨミの最長文字数 maxlen_phon:8\n",
            "音素 (読みのカタカナ文字)数 len(phon_cands):87\n",
            "Psylex71 におけるカタカナ以外のヨミのある単語数 len(ng_yomi_words):1414\n",
            "Psylex71 における ID 番号の重複数 len(dups_idx):3827\n"
          ]
        }
      ],
      "source": [
        "# NTT 日本語の語彙特性単語頻度データ psylex71.txt の読み込み\n",
        "#HOME = os.environ['HOME']\n",
        "if isColab:\n",
        "    ntt_base = '/content'\n",
        "else:\n",
        "    ntt_base = os.path.join(HOME, 'study/2017_2009AmanoKondo_NTTKanjiData')\n",
        "psy71_fname = os.path.join(HOME, ntt_base, 'psylex71utf8_.txt')  # ファイル名\n",
        "psylex71raw = open(psy71_fname, 'r').readlines()\n",
        "psylex71raw = [lin.strip().split(' ')[:6] for lin in psylex71raw]   # 空白 ' ' で分離し，年度ごとの頻度を削除\n",
        "\n",
        "# Psylex71 一行のデータは 0:共通ID, 1:独自ID, 2:表記, 3:ヨミ, 4:品詞, 5:頻度 を取り出す。\n",
        "n_idx=0; n_wrd=2; n_yomi=3; n_pos=4; n_frq=5\n",
        "idxes = {'n_idx':0, 'n_idx2':1, 'n_wrd':2, 'n_yomi':3, 'n_pos':4, 'n_frq':5}\n",
        "\n",
        "kata_chars='ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "kata_chars=kata_chars+'一'\n",
        "\n",
        "maxlen_grph = 2 # 書記素最大文字数 + 2 しているのは, 単語の前後に特殊トークン <SOW> <EOW> をつけるため\n",
        "_psylex71_ = []\n",
        "ng_yomi_words = []\n",
        "dups_idx = []\n",
        "\n",
        "valid_chars=gakushu_chars\n",
        "valid_chars=grph_list\n",
        "\n",
        "grph_cands=valid_chars\n",
        "#phon_cands=kata_chars\n",
        "phon_cands = phon_list\n",
        "\n",
        "Psylex71 = OrderedDict()\n",
        "for lin in psylex71raw:\n",
        "    wrd = lin[n_wrd]\n",
        "    idx = lin[n_idx]\n",
        "    yomi = lin[n_yomi]\n",
        "    pos = lin[n_pos]\n",
        "    frq = lin[n_frq]\n",
        "\n",
        "    if len(wrd) == maxlen_grph:  # 長さが maxlen_grph 文字である語に対して処理を行う\n",
        "\n",
        "        # ヨミの中にカタカナ以外の文字が入っていれば NG_flag を True にする\n",
        "        is_kata_yomi = True\n",
        "        for p in yomi:\n",
        "            if not p in kata_chars:\n",
        "                is_kata_yomi = False\n",
        "\n",
        "        # ヨミにカタカナ以外の文字が含まれていれば ng_yomi_words に加える\n",
        "        if is_kata_yomi == False:\n",
        "            ng_yomi_words.append((wrd,yomi))\n",
        "        else:\n",
        "\n",
        "            # valid_chars (学習漢字+)で構成されているか否かを判断\n",
        "            is_valid_grph = True\n",
        "            for i in range(maxlen_grph):\n",
        "                if not wrd[i] in valid_chars:\n",
        "                    is_valid_grph = False\n",
        "\n",
        "            if is_valid_grph == True:\n",
        "                _psylex71_.append(lin)\n",
        "\n",
        "                if idx in Psylex71:   # すでに ID 番号が登録されていれば dups_idx リストに加える\n",
        "                    dups_idx.append((idx,lin, (Psylex71[idx]['単語'],Psylex71[idx]['ヨミ'])))\n",
        "\n",
        "                Psylex71[idx] = {'単語': wrd, 'ヨミ': yomi, '品詞': pos,'頻度': frq}\n",
        "\n",
        "\n",
        "# 読み (音韻表現) の最大長値を探す\n",
        "maxlen_phon = 0\n",
        "for a in _psylex71_:\n",
        "    if len(a[n_yomi]) > maxlen_phon:\n",
        "         maxlen_phon = len(a[n_yomi])\n",
        "\n",
        "# 結果の表示\n",
        "print(f'読み込んだ psylex71.txt の単語数 len(psylex71raw):{len(psylex71raw)}')\n",
        "print(f'Psylex71 の総単語数 len(_psylex71_):{len(_psylex71_)}')\n",
        "print(f'作成したデータベース辞書の項目数 len(Psylex71):{len(Psylex71)}')\n",
        "print(f'ヨミの最長文字数 maxlen_phon:{maxlen_phon}')\n",
        "print(f'音素 (読みのカタカナ文字)数 len(phon_cands):{len(phon_cands)}')\n",
        "print(f'Psylex71 におけるカタカナ以外のヨミのある単語数 len(ng_yomi_words):{len(ng_yomi_words)}')\n",
        "print(f'Psylex71 における ID 番号の重複数 len(dups_idx):{len(dups_idx)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f0bdb138-4ce6-45d7-b745-bde4934eb29e",
      "metadata": {
        "id": "f0bdb138-4ce6-45d7-b745-bde4934eb29e",
        "outputId": "f2e17c8b-b2a6-4aab-c8b5-92f715ee3127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "psylex71_ds.ids2inp(inp):['険', '悪'] [786 337] psylex71_ds.ids2tgt(tgt):['<SOW>', 'ケ', 'ン', 'ア', 'ク', '<EOW>'] [ 2 20 86  5 18  1]\n",
            "psylex71_ds.ids2inp(inp):['貝', '貨'] [106 553] psylex71_ds.ids2tgt(tgt):['<SOW>', 'バ', 'イ', 'カ', '<EOW>'] [ 2 51  7 14  1]\n",
            "psylex71_ds.ids2inp(inp):['一', '野'] [ 97 328] psylex71_ds.ids2tgt(tgt):['<SOW>', 'カ', 'ズ', 'ノ', '<EOW>'] [ 2 14 29 49  1]\n",
            "psylex71_ds.ids2inp(inp):['唱', '導'] [633 876] psylex71_ds.ids2tgt(tgt):['<SOW>', 'シ', 'ョ', 'ウ', 'ド', 'ウ', '<EOW>'] [ 2 26 74  9 44  9  1]\n",
            "psylex71_ds.ids2inp(inp):['富', 'む'] [895  67] psylex71_ds.ids2tgt(tgt):['<SOW>', 'ト', 'ム', '<EOW>'] [ 2 43 67  1]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "class Psylex71_Dataset(torch.utils.data.Dataset):\n",
        "    '''ニューラルネットワークモデルに Psylex71 を学習させるための PyTorch 用データセットのクラス'''\n",
        "\n",
        "    def __init__(self,\n",
        "                 dic=Psylex71,\n",
        "                 grph_list=grph_list,\n",
        "                 phon_list=phon_list,\n",
        "                 special_tokens=special_tokens,\n",
        "                 maxlen_phon=maxlen_phon +2, # ＋2 しているのは <SOW>,<EOW> という 2 つのスペシャルトークンを付加するため\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.dic = dic\n",
        "        self.special_tokens = special_tokens\n",
        "        self.maxlen_phon = maxlen_phon\n",
        "        self.grph_list = grph_list\n",
        "        self.phon_list = phon_list\n",
        "        self.input_cands = special_tokens + grph_list\n",
        "        self.target_cands = special_tokens + phon_list\n",
        "        self.inputs = [v['単語'] for v in dic.values()]\n",
        "        self.targets = [v['ヨミ'] for v in dic.values()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dic)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp, tgt = self.inputs[idx], self.targets[idx]\n",
        "\n",
        "        # 入力信号にも <SOW>, <EOW> トークンを付与する場合\n",
        "        #inp = [self.input_cands.index('<SOW>')]  + [self.input_cands.index(x) for x in inp]  + [self.input_cands.index('<EOW>')]\n",
        "\n",
        "        # 入力信号にはスペシャルトークンを付与しない場合\n",
        "        inp = [self.input_cands.index(x) for x in inp]\n",
        "\n",
        "        # ターゲット (教師)信号 には <SOW>, <EOW> を付与する\n",
        "        tgt = [self.target_cands.index('<SOW>')] + [self.target_cands.index(x) for x in tgt] + [self.target_cands.index('<EOW>')]\n",
        "\n",
        "        inp = torch.tensor(inp, dtype=torch.int64)\n",
        "        tgt = torch.tensor(tgt, dtype=torch.int64)\n",
        "        return inp, tgt\n",
        "\n",
        "    def getitem(self, idx):\n",
        "        wrd = self.inputs[idx]\n",
        "        phn = self.targets[idx]\n",
        "        return wrd, phn\n",
        "\n",
        "    def ids2argmax(self, ids):\n",
        "        out = np.array([torch.argmax(idx).numpy() for idx in ids], dtype=np.int32)\n",
        "        return out\n",
        "\n",
        "    def ids2tgt(self, ids):\n",
        "        #out = [self.target_cands[torch.argmax(idx)] for idx in ids]\n",
        "        out = [self.target_cands[idx] for idx in ids]\n",
        "        return out\n",
        "\n",
        "    def ids2inp(self, ids):\n",
        "        out = [self.input_cands[idx] for idx in ids]\n",
        "        return out\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "        ret = []\n",
        "        for idx in ids:\n",
        "            if idx == self.target_cands.index('<EOW>'):\n",
        "                return ret+['<EOW>']\n",
        "            ret.append(self.target_cands[idx])\n",
        "        return ret\n",
        "\n",
        "\n",
        "psylex71_ds = Psylex71_Dataset()\n",
        "for N in np.random.permutation(psylex71_ds.__len__())[:5]:\n",
        "    inp, tgt = psylex71_ds.__getitem__(N)\n",
        "    print(f'psylex71_ds.ids2inp(inp):{psylex71_ds.ids2inp(inp)}',\n",
        "          f'{inp.numpy()}',\n",
        "          f'psylex71_ds.ids2tgt(tgt):{psylex71_ds.ids2tgt(tgt)}',\n",
        "          f'{tgt.numpy()}')\n",
        "\n",
        "\n",
        "train_size = int(psylex71_ds.__len__() * 0.7)\n",
        "valid_size = psylex71_ds.__len__() - train_size\n",
        "train_ds, valid_ds = torch.utils.data.random_split(dataset=psylex71_ds, lengths=(train_size, valid_size), generator=torch.Generator().manual_seed(seed))\n",
        "#print(train_ds.__len__(), valid_ds.__len__())\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=256, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "def _collate_fn(batch):\n",
        "    inps, tgts = list(zip(*batch))\n",
        "    inps = list(inps)\n",
        "    tgts = list(tgts)\n",
        "    return inps, tgts\n",
        "\n",
        "batch_size = 10\n",
        "train_dl = torch.utils.data.DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=_collate_fn)\n",
        "\n",
        "valid_dl = torch.utils.data.DataLoader(\n",
        "    dataset=valid_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=_collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/refs/heads/master/2025figs/1998Zorzi_CDP_fig1.svg\">\n",
        "Zorzi+(1998) Fig.1 Architecture of the model. The arrow means full connectivity between layers. Each box stand for a group of letters (26) or phonemes (44).<br/>\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/refs/heads/master/2025figs/1998Zorzi_CDP_fig8.svg\">\n",
        "<p>Zorzi+(1998) Fig.8. Architecture of the model with the hidden layer pathway. In both the direct pathway and the mediated pathway the layers are fully connected (arrows).</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "HvOSz0_Uiy8W"
      },
      "id": "HvOSz0_Uiy8W"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4b59214b-c657-4cb6-8452-b32749beaf19",
      "metadata": {
        "id": "4b59214b-c657-4cb6-8452-b32749beaf19",
        "outputId": "4b4c46a5-030a-40d7-d74d-d871780119d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx:20457: inp:tensor([676, 152]) tch:tensor([ 2, 49, 77, 13,  1])\n",
            "train_ds.dataset.ids2inp(tensor([676, 152])):['典', '男']\n",
            "train_ds.dataset.ids2tgt(tensor([ 2, 49, 77, 13,  1])):['<SOW>', 'ノ', 'リ', 'オ', '<EOW>']\n",
            "X.size():torch.Size([1, 2])\n",
            "0:_emb.size():torch.Size([1, 128])\n",
            "1:_emb.size():torch.Size([1, 128])\n",
            "_embs.size():torch.Size([1, 256])\n",
            "X.size():torch.Size([1, 128])\n",
            "出力: ['ヮ', 'ゴ', 'ヂ', 'ヮ', 'モ', 'ペ', 'ニ', 'ス', 'ヌ', 'ヂ']: 出力 ids: [81, 23, 37, 81, 69, 61, 46, 28, 47, 37]\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class TLA(torch.nn.Module):\n",
        "    '''TLA: Two Layered Association Network '''\n",
        "\n",
        "    def __init__(self,\n",
        "                 # maxlen_phon+2 しているのは単語の前後に <SOW>, <EOW> トークンを付けるため\n",
        "                 inp_size= (len(grph_list)+len(special_tokens)), # * (maxlen_grph + 2),\n",
        "                 inp_len=maxlen_grph, #  + 2,\n",
        "                 out_size=len(phon_list)+len(special_tokens),\n",
        "                 out_len=maxlen_phon+2,\n",
        "                 hid_size=128,\n",
        "                 device='cpu',\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.inp_size=inp_size\n",
        "        self.inp_len=inp_len\n",
        "        self.out_size=out_size\n",
        "        self.out_len=out_len\n",
        "        self.hid_size=hid_size\n",
        "\n",
        "        #self.hid_layer = torch.nn.Linear(in_features=inp_len * inp_size, out_features=hid_size)\n",
        "        #self.emb_layer = torch.nn.Embedding(num_embeddings=inp_size, embedding_dim=hid_size, padding_idx=0).to(device)\n",
        "        self.emb_layers = [torch.nn.Embedding(num_embeddings=inp_size, embedding_dim=hid_size, padding_idx=0).to(device) for _ in range(inp_len)]\n",
        "        self.hid_layer = torch.nn.Linear(in_features=hid_size * inp_len, out_features=hid_size).to(device)\n",
        "        self.out_layers = [torch.nn.Linear(in_features=hid_size, out_features=out_size).to(device) for _ in range(out_len)]\n",
        "\n",
        "    def forward(self, inp):\n",
        "        X = inp\n",
        "        print(f'X.size():{X.size()}')\n",
        "\n",
        "        batch_size = X.size(0)\n",
        "        n_grph = X.size(1)\n",
        "        #print(f'batch_size:{batch_size}')\n",
        "        #print(f'n_grph:{n_grph}')\n",
        "\n",
        "        embs = []\n",
        "        for i in range(n_grph):\n",
        "            _emb = self.emb_layers[i](X[:,i])\n",
        "            print(f'{i}:_emb.size():{_emb.size()}')\n",
        "            embs.append(_emb)\n",
        "\n",
        "        _embs = torch.concat(embs,dim=1)\n",
        "        print(f'_embs.size():{_embs.size()}')\n",
        "\n",
        "        X = _embs\n",
        "        X = self.hid_layer(X)         # 中間層次元へ変換\n",
        "        print(f'X.size():{X.size()}')\n",
        "        #sys.exit()\n",
        "\n",
        "        # 出力層の音韻表現ごとへ変換\n",
        "        #outputs = [out_layer(X) for out_layer in self.out_layers]\n",
        "        outputs = []\n",
        "        for i in range(self.out_len):\n",
        "            _out = self.out_layers[i](X)\n",
        "            outputs.append(_out)\n",
        "\n",
        "        # softmax 変換\n",
        "        outputs = [torch.nn.functional.softmax(out,dim=1) for out in outputs]\n",
        "        return outputs\n",
        "\n",
        "tla = TLA(device=device)\n",
        "tla.eval()\n",
        "\n",
        "# idx に整数を指定して,対応するデータを取得する\n",
        "idx = np.random.choice(train_ds.__len__())\n",
        "\n",
        "# データセットから返ってくる値は入力信号 inp と教師信号 tch\n",
        "inp, tch = train_ds.__getitem__(idx)\n",
        "print(f'idx:{idx}:', f'inp:{inp}', f'tch:{tch}')\n",
        "\n",
        "# 入出力信号はトークン ID 番号であるため人間が読みやすいように変換して表示\n",
        "print(f'train_ds.dataset.ids2inp({inp}):{train_ds.dataset.ids2inp(inp)}')\n",
        "print(f'train_ds.dataset.ids2tgt({tch}):{train_ds.dataset.ids2tgt(tch)}')\n",
        "\n",
        "inp = pad_sequence(inp.unsqueeze(0), batch_first=True).to(device)\n",
        "\n",
        "outs = tla(inp)\n",
        "outs = [out.cpu() for out in outs]\n",
        "print('出力:', train_ds.dataset.ids2tgt([int(idx[0].argmax().numpy()) for idx in outs]), end=\": \")\n",
        "print('出力 ids:', [int(out.argmax().numpy()) for out in outs])\n",
        "# print('出力:', train_ds.dataset.ids2tgt([int(idx[0][0].argmax().numpy()) for idx in outs]) )\n",
        "# print('出力 ids:', [int(out[0][0].argmax().numpy()) for out in outs])\n",
        "\n",
        "#_outs = train_ds.dataset.ids2tgt([out.argmax(dim=1).numpy() for out in outs[0]])\n",
        "#print('出力:', train_ds.dataset.ids2tgt([int(idx.numpy()) for idx in outs[0][0].argmax(dim=1)]))\n",
        "#[int(out.argmax()) for out in outs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb0dc3d-8d17-46a5-9165-9195f4cdd11b",
      "metadata": {
        "id": "1eb0dc3d-8d17-46a5-9165-9195f4cdd11b"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "optimizer = optim.Adam(tla.parameters(), lr=0.01)\n",
        "\n",
        "EPOCH_NUM = 30\n",
        "all_losses = []\n",
        "for epoch in range(1, EPOCH_NUM+1):\n",
        "\n",
        "    epoch_loss = 0 # epoch毎のloss\n",
        "    for inp, tgt in train_dl:\n",
        "        optimizer.zero_grad()  # 勾配の初期化\n",
        "\n",
        "        # データをテンソルに変換\n",
        "        inp_ids = pad_sequence(inp, batch_first=True).to(device)\n",
        "        tgt_ids = pad_sequence(tgt, batch_first=True).to(device)\n",
        "\n",
        "        out = tla(inp_ids)\n",
        "        print(type(out))\n",
        "\n",
        "        for j in range(out.size()[1]):\n",
        "            # バッチ毎にまとめて loss 計算\n",
        "            loss += criterion(out[:, j, :], tgt_ids[:, j])\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()  # 誤差逆伝播\n",
        "        optimizer.step()  # パラメータ更新\n",
        "\n",
        "    # 損失を表示\n",
        "    print(\"Epoch %d: %.2f\" % (epoch, epoch_loss))\n",
        "    all_losses.append(epoch_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e1cf12-3c3e-45f4-8d33-53623c95ba3b",
      "metadata": {
        "id": "47e1cf12-3c3e-45f4-8d33-53623c95ba3b"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def fit_tla(\n",
        "    model:torch.nn.modules.module.Module=tla,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=train_ds,\n",
        "    #batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    dataloader:torch.utils.data.dataloader.DataLoader=train_dl,\n",
        "    optimizer:torch.optim=None,\n",
        "    #criterion:torch.nn.modules.loss=torch.nn.NLLLoss(ignore_index=-1),\n",
        "    criterion:torch.nn.modules.loss=torch.nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for inp, tch in dataloader:\n",
        "            #_tch = torch.nn.functional.one_hot(tch, num_classes=(len(kata_list)+len(special_tokens))).to(device)\n",
        "            outs = model(inp)\n",
        "\n",
        "            print(f'train_ds.dataset.ids2inp({inp[0]}):{train_ds.dataset.ids2inp(inp[0])}')\n",
        "            print(f'train_ds.dataset.ids2tgt({tch[0]}):{train_ds.dataset.ids2tgt(tch[0])}')\n",
        "            XX = [out.argmax(dim=1).numpy() for out in outs]\n",
        "            #print(f'len(XX):{len(XX)}')\n",
        "            print(f'len(inp):{len(inp)}')\n",
        "            print(f'len(tch):{len(tch)}')\n",
        "            print(f'len(outs):{len(outs)}')\n",
        "            print(f'outs[0].size():{outs[0].size()}')\n",
        "            print(f'tch.size():{tch.size()}')\n",
        "            #print(f'_tch[0].size:{_tch[0].size}')\n",
        "            #print(f'train_ds.dataset.ids2tgt(XX[0]):{train_ds.dataset.ids2tgt(XX[0])}')\n",
        "            _outs = train_ds.dataset.ids2tgt([out.argmax().numpy() for out in outs])\n",
        "            print(f'出力:{\"\".join(ch for ch in _outs)}')\n",
        "\n",
        "            #loss = criterion(out[0], tch[0].long())\n",
        "            #loss = criterion(out[0], tch[0])\n",
        "            #loss = criterion(out[0], tch[0])\n",
        "            #loss = criterion(out[0][0], tch[0])\n",
        "            loss = criterion(outs[0], tch)\n",
        "            #sys.exit()\n",
        "\n",
        "            #loss = criterion(out, _tch)\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:2d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "fit_tla(epochs=1, model=tla, ds=train_ds,interval=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d54824f-2bc6-4d34-a9ac-bb35f192ffde",
      "metadata": {
        "id": "1d54824f-2bc6-4d34-a9ac-bb35f192ffde"
      },
      "outputs": [],
      "source": [
        "#len(kata_list)+len(special_tokens)\n",
        "#print(train_dl.batch_size)\n",
        "help(torch.nn.CrossEntropyLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e269cb6-dbe4-42c8-bd0f-76152cf5553f",
      "metadata": {
        "id": "0e269cb6-dbe4-42c8-bd0f-76152cf5553f"
      },
      "outputs": [],
      "source": [
        "for inp, out in valid_dl:\n",
        "    print(out[0].size())\n",
        "    print(torch.nn.functional.one_hot(out, num_classes=len(kata_list)+len(special_tokens))[0][0])\n",
        "    #print(torch.nn.functional.one_hot(out[0], num_classes=len(kata_list)+len(special_tokens))[0])\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540894be-9de6-476c-8f12-f1f44e079e6e",
      "metadata": {
        "id": "540894be-9de6-476c-8f12-f1f44e079e6e"
      },
      "outputs": [],
      "source": [
        "help(torch.nn.functional.one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9511fa7e-7d68-467c-b618-8875d4b9cc54",
      "metadata": {
        "id": "9511fa7e-7d68-467c-b618-8875d4b9cc54"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65dbe30-fdcc-4a14-909d-a389fc39b4b6",
      "metadata": {
        "id": "f65dbe30-fdcc-4a14-909d-a389fc39b4b6"
      },
      "outputs": [],
      "source": [
        "# 上のセルで作成した Psylex71 を pandas のデータフレームに変換し， さらにエクセルファイルとして書き出す\n",
        "import pandas as pd\n",
        "\n",
        "NTT71 = pd.DataFrame.from_dict(data=Psylex71, orient='index')\n",
        "\n",
        "NTT71.columns=['単語','ヨミ','品詞','頻度']\n",
        "#NTT71.to_excel('NTT_Psylex71_学習漢字2文字語.xlsx')\n",
        "NTT71"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7e1a49-2f57-4030-8770-a613d21249ab",
      "metadata": {
        "id": "0f7e1a49-2f57-4030-8770-a613d21249ab"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class Seq2Seq_wAtt(nn.Module):\n",
        "    \"\"\" 注意つき符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "class Seq2Seq_(nn.Module):\n",
        "    \"\"\" 注意なし符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp) # .zero_()\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "# 以下確認作業\n",
        "ds = train_ds\n",
        "n_layers=1\n",
        "bidirectional=False\n",
        "n_hid = 128\n",
        "batch_size = 256\n",
        "cdp = Seq2Seq_(enc_vocab_size=len(ds.dataset.orth_list),\n",
        "#cdp = Seq2Seq_wAtt(enc_vocab_size=len(ds.dataset.orth_list),\n",
        "                   dec_vocab_size=len(ds.dataset.phon_list),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "print(cdp.eval())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d3d88a-c883-431f-a081-5bd0c716dcc8",
      "metadata": {
        "id": "25d3d88a-c883-431f-a081-5bd0c716dcc8"
      },
      "outputs": [],
      "source": [
        "# #print(dir(cdp.decoder))\n",
        "# print(torch.tensor([3,3]).zero_())\n",
        "print(dir(cdp.decoder))\n",
        "cdp.decoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f44038-21f8-4a6f-9042-a288f46c91f6",
      "metadata": {
        "id": "f2f44038-21f8-4a6f-9042-a288f46c91f6"
      },
      "outputs": [],
      "source": [
        "def fit_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=cdp,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=psylex71_ds,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    #dataloader:torch.utils.data.dataloader.DataLoader=dl_o2p,\n",
        "    optimizer:torch.optim=None,\n",
        "    criterion:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "    \"\"\" Seq2seq の訓練に用いる関数\"\"\"\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "        #interval = int(ds.__len__()/batch_size) >> 3\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for _inp, _tch in dataloader:\n",
        "            enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "            dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "            tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "            out = model(enc_inp, dec_inp)\n",
        "            loss = criterion(out[0], tch[0])\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:03d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "# _ = fit_seq2seq(epochs=2, model=cdp, ds=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac931f6-da47-405e-adc5-1fc9b991667d",
      "metadata": {
        "id": "cac931f6-da47-405e-adc5-1fc9b991667d"
      },
      "outputs": [],
      "source": [
        "def eval_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=cdp,\n",
        "    ds:Dataset=train_ds,\n",
        "    isPrint:bool=False,\n",
        "    errors:list=None):\n",
        "\n",
        "    model.eval()\n",
        "    if errors == None:\n",
        "        errors=[]\n",
        "\n",
        "    for N in tqdm(range(ds.__len__())):\n",
        "        x, y = ds.__getitem__(N)\n",
        "        enc_inp, dec_inp = x.unsqueeze(0).to(device), y.unsqueeze(0).to(device)\n",
        "        grand_truth = y.detach().numpy()[1:-1]\n",
        "        y_hat = model(enc_inp, dec_inp).to('cpu')\n",
        "        y_hat = np.argmax(y_hat.squeeze(0).detach().numpy(), axis=1)[1:-1]\n",
        "\n",
        "        if len(y_hat) == len(grand_truth):\n",
        "            n_correct = np.array((y_hat == grand_truth).sum())\n",
        "            isOK = n_correct == len(grand_truth)\n",
        "        else:\n",
        "            isOK = False\n",
        "\n",
        "        if not isOK:\n",
        "            #wrd = ds.getitem(N)[0]\n",
        "            wrd = ds.dataset.getitem(N) #[0]\n",
        "            _out = ds.dataset.target_ids2target(y_hat)\n",
        "            errors.append((N, wrd, _out,y_hat))\n",
        "            if isPrint:\n",
        "                color = 'grey' if isOK else 'red'\n",
        "                wrd = ds.getitem(N)[0]\n",
        "                print(colored(f'{N:05d}', color),\n",
        "                      colored(wrd, color='grey'), # , attrs=[\"bold\"]),\n",
        "                      colored(y_hat,color,attrs=[\"bold\"]),\n",
        "                      colored(ds.target_ids2target(y_hat), color, attrs=[\"bold\"]),\n",
        "                      f'<-{ds.target_ids2target(grand_truth)}')\n",
        "\n",
        "    cr = len(errors) / N\n",
        "    return {'エラー':errors,\n",
        "            '正解率': (1.-cr) * 100}\n",
        "\n",
        "#_ = eval_seq2seq(model=cdp, ds=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8c03dc-3f7d-486f-a2e8-99811d74ea74",
      "metadata": {
        "id": "2c8c03dc-3f7d-486f-a2e8-99811d74ea74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_epochs, eval_epochs = [],[]\n",
        "for _ in range(5):\n",
        "    train_epochs.append(fit_seq2seq(epochs=30, model=cdp, ds=train_ds, isDraw=False))\n",
        "    eval_epochs.append(eval_seq2seq(model=cdp, ds=valid_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23e9cfd-6162-4e95-8029-fcb97f8850ba",
      "metadata": {
        "id": "e23e9cfd-6162-4e95-8029-fcb97f8850ba"
      },
      "outputs": [],
      "source": [
        "eval_epochs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb72143c-3844-40cd-b3ab-5652ff665ae0",
      "metadata": {
        "id": "cb72143c-3844-40cd-b3ab-5652ff665ae0"
      },
      "outputs": [],
      "source": [
        "cdp.eval()\n",
        "inp, tch = psylex71_ds.__getitem__(0)\n",
        "cdp(inp.unsqueeze(0), tch.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2d002d-1531-4a84-abc5-b340c682cc7b",
      "metadata": {
        "id": "2e2d002d-1531-4a84-abc5-b340c682cc7b"
      },
      "source": [
        "# JALEX の処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993801a0-edac-40a1-a0ac-a343f65135eb",
      "metadata": {
        "id": "993801a0-edac-40a1-a0ac-a343f65135eb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mecab を使ってヨミを得るために MeCab を import する\n",
        "from ccap.mecab_settings import wakati, yomi #, parser\n",
        "\n",
        "jalex_base = '/Users/asakawa/study/2025_2014jalex'\n",
        "jalex_xls_fname = 'JALEX.xlsx'\n",
        "jalex_fname = os.path.join(jalex_base, jalex_xls_fname)\n",
        "DF = pd.read_excel(jalex_fname)\n",
        "jalex_words = DF['目標語']\n",
        "\n",
        "df_dict = DF.to_dict(orient='index')\n",
        "jalex_cands = []\n",
        "for k,v in list(df_dict.items())[:]:\n",
        "    wrd = v['目標語']\n",
        "\n",
        "    if len(wrd) == maxlen_orth: # maxlen_orth 文字で構成された語のみを選択する\n",
        "\n",
        "        # 2 文字とも学習漢字 (valid_chars) であれば jalex_cands に加える。\n",
        "        if (wrd[0] in valid_chars) and (wrd[1] in valid_chars):\n",
        "            jalex_cands.append(v)\n",
        "\n",
        "# jalex_cands を pandas DataFrame に変換\n",
        "Jalex_df = pd.DataFrame.from_dict(data=jalex_cands)\n",
        "Jalex_df\n",
        "#len(list(Jalex_df.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6350f226-fbf8-4768-9394-04e20005bb7e",
      "metadata": {
        "id": "6350f226-fbf8-4768-9394-04e20005bb7e"
      },
      "outputs": [],
      "source": [
        "# MeCab を使ってヨミを得る\n",
        "_yomis = []\n",
        "for x in jalex_cands[:]:\n",
        "    wrd = x['目標語']\n",
        "    _yomi = yomi(wrd).strip()\n",
        "    _yomis.append(_yomi)\n",
        "print(len(_yomis))\n",
        "\n",
        "Jalex_df['ヨミ'] =_yomis\n",
        "Jalex_df.columns\n",
        "cols = ['目標語', 'ヨミ', '項目', '試行数', '平均反応時間 ミリ秒', '反応時間の標準偏差', '反応時間の標準誤差', '正解率', '英訳語', 'ONS 書記素隣接語数', 'PNS 音韻隣接語数', 'OLD20']\n",
        "Jalex_df = Jalex_df[cols]\n",
        "\n",
        "# エクセルファイルとして書き出す\n",
        "#Jalex_df.to_excel('2025_0610Jalex学習漢字2文字語.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7e8fef-9997-4c5a-bbce-934223d1763a",
      "metadata": {
        "id": "cc7e8fef-9997-4c5a-bbce-934223d1763a"
      },
      "outputs": [],
      "source": [
        "special_tokens = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "n_stokens = len(special_tokens)\n",
        "maxlen_orth = 4\n",
        "phon_maxlen = 10\n",
        "\n",
        "NTT71_data = []\n",
        "for x, v in NTT71[['語','ヨミ']].to_dict(orient='index').items():\n",
        "    orth, phon = v['語'], v['ヨミ']\n",
        "    #orth_idx = [gakushu_chars.index(o)+n_stokens for o in orth]\n",
        "    orth_idx = [valid_chars.index(o)+n_stokens for o in orth]\n",
        "    orth_idx = [special_tokens.index('<SOW>')] + orth_idx + [special_tokens.index('<EOW>')]\n",
        "\n",
        "    phon_idx = [kata_chars.index(p)+n_stokens for p in phon]\n",
        "    phon_idx = [special_tokens.index('<SOW>')] + phon_idx + [special_tokens.index('<EOW>')]\n",
        "    for j in range(phon_maxlen - len(phon_idx)):\n",
        "        phon_idx.append(special_tokens.index('<PAD>'))\n",
        "    NTT71_data.append((orth, orth_idx, phon, phon_idx))\n",
        "len(NTT71_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06926067-288a-4935-8933-17ed60ce73e4",
      "metadata": {
        "id": "06926067-288a-4935-8933-17ed60ce73e4"
      },
      "outputs": [],
      "source": [
        "inconsist = []\n",
        "for d in NTT71_data:\n",
        "    yomi2 = yomi(d[0]).strip()\n",
        "    if d[2] != yomi2:\n",
        "        inconsist.append((d[0], d[2], yomi2))\n",
        "print(f'ヨミが NTTPsylex71 と Mecab で不一致な語数 len(inconsist):{len(inconsist)}')\n",
        "\n",
        "print(NTT71_data[0])\n",
        "print(f'入力素子数:{(len(valid_chars) + len(special_tokens)) * maxlen_orth}')\n",
        "print(f'(len(kata_chars)+len(special_tokens)) * phon_maxlen:{(len(kata_chars)+len(special_tokens)) * phon_maxlen}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540c77ec-f1eb-4690-9a19-ba7dca252445",
      "metadata": {
        "id": "540c77ec-f1eb-4690-9a19-ba7dca252445"
      },
      "outputs": [],
      "source": [
        "print(gakushu_chars[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4def5f26-a714-4488-83d7-ff412e63ef35",
      "metadata": {
        "id": "4def5f26-a714-4488-83d7-ff412e63ef35"
      },
      "outputs": [],
      "source": [
        "target_words = []\n",
        "char_list = jchar_list\n",
        "char_list = gakushu_chars\n",
        "for wrd in jalex_words:\n",
        "    if len(wrd) == 2:\n",
        "        if (wrd[0] in char_list) and (wrd[1] in char_list):\n",
        "            target_words.append(wrd)\n",
        "print(f'len(target_words):{len(target_words)}')\n",
        "\n",
        "jalex_dict = {}\n",
        "for wrd in target_words[:100]:\n",
        "    #print(f'{wrd}:{yomi(wrd).strip()}')\n",
        "    jalex_dict[wrd] = (wrd, yomi(wrd).strip())\n",
        "print(jalex_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8090e2-5b26-425a-8ac3-874c2248eff8",
      "metadata": {
        "id": "0a8090e2-5b26-425a-8ac3-874c2248eff8"
      },
      "outputs": [],
      "source": [
        "# 日本語文字\n",
        "import IPython\n",
        "isColab = 'colab' in str(IPython.get_ipython())\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "alphabet_upper_chars = 'ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'\n",
        "alphabet_lower_chars = 'ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "num_chars = '０１２３４５６７８９'\n",
        "hira_chars = 'ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん'\n",
        "kata_chars = 'ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "\n",
        "jchars = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "\n",
        "for ch in hira_chars+kata_chars+gakushu_chars:\n",
        "    for ch in x:\n",
        "        jchars.append(ch)\n",
        "print(f'len(jchars):{len(jchars)}')\n",
        "\n",
        "\n",
        "def make_psylex71_data(psylex71_fname:str=None):\n",
        "    \"\"\"\n",
        "    # NTT日本語語彙特性 (天野，近藤; 1999, 三省堂)より頻度情報を取得\n",
        "\n",
        "    戻り値:\n",
        "    * psylex71_freq_sorted: list 頻度順にソートされた単語リスト\n",
        "    * _psylex_dict: dict 単語をキーとした，品詞，頻度，よみ(カタカナ表記された) を値として持つ辞書\n",
        "    * all_words: list psylex71 全単語からなるリスト\n",
        "    * _psylex71_symbols: 登録単語の品詞が｢記｣である単語からなるリスト\n",
        "    \"\"\"\n",
        "\n",
        "    # NTT 日本語語彙特性の utf-8 へ変換済 `psylex71.txt` の読み込み\n",
        "    HOME = os.environ[\"HOME\"]\n",
        "    if isColab:\n",
        "        ntt_base = '/contents'\n",
        "    else:\n",
        "        ntt_base = os.path.join(HOME, 'study/2017_2009AmanoKondo_NTTKanjiData')\n",
        "\n",
        "    if psylex71_fname == None:\n",
        "        psy71_fname = 'psylex71utf8.txt'  # ファイル名\n",
        "        with open(os.path.join(ntt_base, psy71_fname), 'rt', encoding='utf-8') as f:\n",
        "            psylex71raw = f.readlines()\n",
        "    else:\n",
        "        with open(ps71_fname, 'r') as f:\n",
        "            psylex71raw = f.readlines()\n",
        "\n",
        "    # 空白で区切られたフィードの前頭 5 つ tmp に格納\n",
        "    tmp  = [line.strip().split(' ')[:6] for line in psylex71raw]\n",
        "\n",
        "    # 上で定義した tmp から 0:ID, 2:表記, 4:品詞, 5:頻度, 4:読み を取り出す。\n",
        "    tmp2 = [[int(line[0]), line[2], line[4], int(line[5]), line[3]] for line in tmp]\n",
        "\n",
        "    tmp3 = []\n",
        "    for line in tmp2:\n",
        "        wrd = line[1]\n",
        "        if len(wrd) == 2:\n",
        "            tmp3.append(line)\n",
        "\n",
        "    cands  = []\n",
        "    _dict = {}\n",
        "    for x in tmp3:\n",
        "        idx = x[0]\n",
        "        wrd = x[1]\n",
        "\n",
        "        wrd = wrd.replace('・', '')\n",
        "        if len(wrd) == 2:\n",
        "            if (wrd[0] in jchars) and (wrd[1] in jchars):\n",
        "                cands.append(x)\n",
        "                _dict[idx] = {'wrd': wrd, 'POS': x[2], 'Frq': int(x[3]), 'yomi': x[4]}\n",
        "\n",
        "\n",
        "    # Freq = np.zeros((len(_dict)), dtype=np.uint)\n",
        "    # for i, (k,v) in enumerate(_dict.items()):\n",
        "    #     Freq[i] = v['頻度']\n",
        "\n",
        "    # all_words = list(_dict.keys())\n",
        "    # Freq_sorted = np.argsort(Freq)[::-1]  # 頻度降順に並べ替え\n",
        "    # _freq_sorted = [all_words[idx] for idx in Freq_sorted]\n",
        "\n",
        "    # _char_freq = {}\n",
        "    # for wrd in _dict.keys():\n",
        "    #     for ch in wrd:\n",
        "    #         if not ch in _char_freq:\n",
        "    #             _char_freq[ch] = _dict[wrd]['頻度']\n",
        "    #         else:\n",
        "    #             _char_freq[ch] += _dict[wrd]['頻度']\n",
        "\n",
        "    # return _freq_sorted, _dict, all_words, _symbols, _char_freq\n",
        "    return cands, tmp3, _dict\n",
        "\n",
        "#psylex71_freq, psylex71_dict, all_words, psylex71_symbols, psylex71_char_freq = make_psylex71_data()\n",
        "#print(psylex71_dict)\n",
        "#print(all_words)\n",
        "\n",
        "psylex71_camds, X, dic = make_psylex71_data()\n",
        "print(psylex71_data[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c2ac4a-e177-42b8-a89c-8c8e81d1d82f",
      "metadata": {
        "id": "c1c2ac4a-e177-42b8-a89c-8c8e81d1d82f"
      },
      "outputs": [],
      "source": [
        "print(len(dic))\n",
        "print(len(X)) #X[-10:]\n",
        "print(len(psylex71_data))\n",
        "print(X[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807f6172-c5d2-4043-8ce1-c0f7e27c6b95",
      "metadata": {
        "id": "807f6172-c5d2-4043-8ce1-c0f7e27c6b95"
      },
      "outputs": [],
      "source": [
        "# Plaut の PMSP データを読み込む\n",
        "import IPython\n",
        "isColab = True if 'google.colab' in str(IPython.get_ipython()) else False\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "pmsp_url='https://www.cnbc.cmu.edu/~plaut/xerion/PMSPdata.txt'\n",
        "# このデータは以下のような一行一データであり tsv ファイルである。\n",
        "# 以下のような構造である\n",
        "#orth\\tphon\\ttype\\tSim 1\\t\\tSim 2 (raw)\\tSim 2 (sqrt)\\tSim 3 (RT)\\n',\n",
        "\n",
        "if isColab:\n",
        "    xerion_dir = ''\n",
        "else:\n",
        "    xerion_dir = 'study/2022plaut_homepage/xerion'\n",
        "pmsp_fname = 'PMSPdata.txt'\n",
        "fname = os.path.join(HOME, xerion_dir, pmsp_fname)\n",
        "\n",
        "# もしファイルが存在しなかったら ダウンロードする\n",
        "if not os.path.exists(fname):\n",
        "    r = requests.get(pmsp_url)\n",
        "    with open(fname, 'w') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print('Downloading {0} - {1} bytes'.format(pmsp_fname, (total_length)))\n",
        "        f.write(r.content)\n",
        "\n",
        "with open(fname, 'r') as f:\n",
        "    a = f.readlines()\n",
        "\n",
        "Z = {}\n",
        "for i,l in enumerate(a):\n",
        "    x = l.strip().split('\\t')\n",
        "    if len(x) != 7:\n",
        "        print(x)\n",
        "    else:\n",
        "        Z[i] = {'orth':x[0],\n",
        "                'phon':x[1],\n",
        "                'type':x[2],\n",
        "                'Sim1':np.float32(x[3]),\n",
        "                'Sim2_raw':np.float32(x[4]),\n",
        "                'Sim2_sqrt':np.float32(x[5]),\n",
        "                'Sim3_RT':np.float32(x[6]),\n",
        "               }\n",
        "\n",
        "orth_list =[v['orth'] for k, v in Z.items()]\n",
        "phon_list =[v['phon'] for k, v in Z.items()]\n",
        "\n",
        "Orth, Phon = {},{}\n",
        "Orth['<PAD>'] = {'idx': 0}\n",
        "Orth['<UNK>'] = {'idx': 1}\n",
        "Orth['<SOW>'] = {'idx': 2}\n",
        "Orth['<EOW>'] = {'idx': 3}\n",
        "Phon['<PAD>'] = {'idx': 0}\n",
        "Phon['<UNK>'] = {'idx': 1}\n",
        "Phon['<SOW>'] = {'idx': 2}\n",
        "Phon['<EOW>'] = {'idx': 3}\n",
        "\n",
        "ort2phn, phn2ort = {}, {}\n",
        "for o, p in zip(orth_list, phon_list):\n",
        "    for _o in o:\n",
        "        if not _o in Orth:\n",
        "            Orth[_o] = {'idx': len(Orth), 'cnt':1}\n",
        "        else:\n",
        "            Orth[_o]['cnt'] += 1\n",
        "    for _p in p:\n",
        "        if not _p in Phon:\n",
        "            Phon[_p] = {'idx': len(Phon), 'cnt':1}\n",
        "        else:\n",
        "            Phon[_p]['cnt'] += 1\n",
        "    ort2phn[o] = p\n",
        "    phn2ort[p] = o\n",
        "\n",
        "print(f'len(Orth):{len(Orth)}, Orth: {Orth}')\n",
        "print(f'len(Phon):{len(Phon)}, Phon: {Phon}')\n",
        "#print(sorted(set(Orth.keys())))\n",
        "#print(sorted(set(Phon.keys())))\n",
        "ort2idx = {k:v['idx'] for k, v in Orth.items()}\n",
        "#idx2ort = ort2idx.keys() # {v:k for k, v in ort2idx.items()}\n",
        "idx2ort = list(ort2idx.values()) # {v:k for k, v in ort2idx.items()}\n",
        "phn2idx = {k:v['idx'] for k, v in Phon.items()}\n",
        "idx2phn = list(phn2idx.values()) # {k:v['idx'] for k, v in Phon.items()}\n",
        "#idx2ort = {v:k for k, v in phn2idx.items()}\n",
        "print(f'len(ort2phn): {len(ort2phn)}')\n",
        "#print(f'ort2phn: {ort2phn}')\n",
        "print(f'len(phn2ort): {len(phn2ort)}')\n",
        "#print(f'phn2ort: {phn2ort}')\n",
        "print(f'ort2idx: {ort2idx}')\n",
        "print(f'idx2ort: {idx2ort}')\n",
        "print(f'phn2idx: {phn2idx}')\n",
        "print(f'idx2ort: {idx2ort}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6f2571-0d1b-4c2b-b4da-e8b615912b03",
      "metadata": {
        "id": "ca6f2571-0d1b-4c2b-b4da-e8b615912b03"
      },
      "outputs": [],
      "source": [
        "# D = Orth\n",
        "# count = {}\n",
        "# for k, v in D.items():\n",
        "#     if 'cnt' in list(v.keys()):\n",
        "#         count[k] = v['cnt']\n",
        "# count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "# plt.figure(figsize=(14,4))\n",
        "# N = np.array([x[1] for x in count.items()]).sum()\n",
        "# plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "# plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "# plt.title('文字頻度')\n",
        "# plt.grid()\n",
        "# #plt.savefig('2023_1113chihaya_charfreq.pdf')\n",
        "# plt.show()\n",
        "\n",
        "for D, _title in [(Phon, 'Phon'), (Orth, 'Orth')]:\n",
        "    count = {}\n",
        "    for k, v in D.items():\n",
        "        if k == '/':\n",
        "            continue\n",
        "        if 'cnt' in list(v.keys()):\n",
        "            count[k] = v['cnt']\n",
        "    count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    plt.figure(figsize=(14,4))\n",
        "    N = np.array([x[1] for x in count.items()]).sum()\n",
        "    plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "    plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "    plt.title(f'{_title} 文字頻度')\n",
        "    plt.grid()\n",
        "    #plt.savefig('2023_1113chihaya_charfreq.pdf')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb94292-05de-47a2-8409-de7d49d0ea06",
      "metadata": {
        "id": "3fb94292-05de-47a2-8409-de7d49d0ea06"
      },
      "outputs": [],
      "source": [
        "Phon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2142593-03a0-4982-8148-68ca8a64a43c",
      "metadata": {
        "id": "b2142593-03a0-4982-8148-68ca8a64a43c"
      },
      "outputs": [],
      "source": [
        "def pmsp_ort2idx(word:str,\n",
        "                 ort2idx:dict=ort2idx):\n",
        "    ret = [ort2idx[c] if c in ort2idx else ort2idx['<UNK>'] for c in word]\n",
        "    return ret\n",
        "\n",
        "\n",
        "def pmsp_idx2ort(ids:list,\n",
        "                idx2ort:list=idx2ort):\n",
        "    return [idx2ort.index(idx) for idx in ids]\n",
        "\n",
        "\n",
        "for i, wrd in enumerate(orth_list):\n",
        "    print(wrd, end=\": \") #, ort2idx['<SOW>'], end=\" \")\n",
        "    print(pmsp_ort2idx(wrd))\n",
        "    print(pmsp_idx2ort(pmsp_ort2idx(wrd)))\n",
        "    print(ort2phn[wrd])\n",
        "\n",
        "    if i >= 2:\n",
        "          break\n",
        "['orth', 'phon', 'type', 'Sim 1', '', 'Sim 2 (raw)', 'Sim 2 (sqrt)', 'Sim 3 (RT)']\n",
        "ace: [4, 5, 6]\n",
        "[4, 5, 6]\n",
        "/As/\n",
        "ache: [4, 5, 7, 6]\n",
        "[4, 5, 7, 6]\n",
        "/Ak/\n",
        "act: [4, 5, 8]\n",
        "[4, 5, 8]\n",
        "/@kt/\n",
        "#print(ort2idx)\n",
        "#print(idx2ort)\n",
        "#[1,2,3].index(2)\n",
        "idx2ort\n",
        "['<PAD>',\n",
        " '<UNK>',\n",
        " '<SOW>',\n",
        " '<EOW>',\n",
        " 'a',\n",
        " 'c',\n",
        " 'e',\n",
        " 'h',\n",
        " 't',\n",
        " 'd',\n",
        " 'f',\n",
        " 'g',\n",
        " 'i',\n",
        " 'l',\n",
        " 'm',\n",
        " 'r',\n",
        " 's',\n",
        " 'p',\n",
        " 'n',\n",
        " 'k',\n",
        " 'u',\n",
        " 'w',\n",
        " 'x',\n",
        " 'b',\n",
        " '*',\n",
        " 'y',\n",
        " 'z',\n",
        " 'o',\n",
        " 'v',\n",
        " 'j',\n",
        " 'q']\n",
        "# coding: utf-8\n",
        "#import argparse\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "#import data\n",
        "#import model\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 RNN/LSTM/GRU/Transformer Language Model')\n",
        "# parser.add_argument('--data', type=str, default='./data/wikitext-2',\n",
        "#                     help='location of the data corpus')\n",
        "# parser.add_argument('--model', type=str, default='LSTM',\n",
        "#                     help='type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU, Transformer)')\n",
        "# parser.add_argument('--emsize', type=int, default=200,\n",
        "#                     help='size of word embeddings')\n",
        "# parser.add_argument('--nhid', type=int, default=200,\n",
        "#                     help='number of hidden units per layer')\n",
        "# parser.add_argument('--nlayers', type=int, default=2,\n",
        "#                     help='number of layers')\n",
        "# parser.add_argument('--lr', type=float, default=20,\n",
        "#                     help='initial learning rate')\n",
        "# parser.add_argument('--clip', type=float, default=0.25,\n",
        "#                     help='gradient clipping')\n",
        "# parser.add_argument('--epochs', type=int, default=40,\n",
        "#                     help='upper epoch limit')\n",
        "# parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
        "#                     help='batch size')\n",
        "# parser.add_argument('--bptt', type=int, default=35,\n",
        "#                     help='sequence length')\n",
        "# parser.add_argument('--dropout', type=float, default=0.2,\n",
        "#                     help='dropout applied to layers (0 = no dropout)')\n",
        "# parser.add_argument('--tied', action='store_true',\n",
        "#                     help='tie the word embedding and softmax weights')\n",
        "# parser.add_argument('--seed', type=int, default=1111,\n",
        "#                     help='random seed')\n",
        "# parser.add_argument('--cuda', action='store_true',\n",
        "#                     help='use CUDA')\n",
        "# parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
        "#                     help='report interval')\n",
        "# parser.add_argument('--save', type=str, default='model.pt',\n",
        "#                     help='path to save the final model')\n",
        "# parser.add_argument('--onnx-export', type=str, default='',\n",
        "#                     help='path to export the final model in onnx format')\n",
        "\n",
        "# parser.add_argument('--nhead', type=int, default=2,\n",
        "#                     help='the number of heads in the encoder/decoder of the transformer model')\n",
        "# parser.add_argument('--dry-run', action='store_true',\n",
        "#                     help='verify the code and the model')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "class _parser():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.data = '/Users/_asakawa/study/2020pytorch_examples.git/word_language_model/data/wikitext-2/'\n",
        "        self.model = 'LSTM'\n",
        "        self.emsize = 200\n",
        "        self.nhid = 200\n",
        "        self.nlayers = 2\n",
        "        self.lr = 20\n",
        "        self.clip = 0.25\n",
        "        self.epochs = 40\n",
        "        self.batch_size = 20\n",
        "        self.bptt = 35\n",
        "        self.dropout = 0.2\n",
        "        self.tied = True\n",
        "        self.seed = 42\n",
        "        self.cuda = False\n",
        "        self.log_interval=200\n",
        "        self.save='model.pt'\n",
        "        self.onnx_export = ''\n",
        "        self.nhead = 2\n",
        "        self.dry_run = True\n",
        "\n",
        "args = _parser()\n",
        "print(dir(args))\n",
        "print(args.data)\n",
        "\n",
        "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_size', 'bptt', 'clip', 'cuda', 'data', 'dropout', 'dry_run', 'emsize', 'epochs', 'log_interval', 'lr', 'model', 'nhead', 'nhid', 'nlayers', 'onnx_export', 'save', 'seed', 'tied']\n",
        "/Users/_asakawa/study/2020pytorch_examples.git/word_language_model/data/wikitext-2/\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids\n",
        "\n",
        "corpus = Corpus(args.data)\n",
        "#corpus = data.Corpus(args.data)\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, args.batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)\n",
        "!pwd\n",
        "!gln -s /Users/_asakawa/study/2020pytorch_examples.git/word_language_model/model.py ./pytorch_official_model.py\n",
        "import pytorch_official_model as model\n",
        "/Users/_asakawa/study/2022ccap/notebooks\n",
        "gln: failed to create symbolic link './pytorch_official_model.py': File exists\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "if args.model == 'Transformer':\n",
        "    model = model.TransformerModel(ntokens, args.emsize, args.nhead, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "else:\n",
        "    model = model.RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if args.model == 'Transformer':\n",
        "                output = model(data)\n",
        "                output = output.view(-1, ntokens)\n",
        "            else:\n",
        "                output, hidden = model(data, hidden)\n",
        "                hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(args.batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cbad9a9-1726-477d-990b-7d13149f41c2",
      "metadata": {
        "id": "0cbad9a9-1726-477d-990b-7d13149f41c2"
      },
      "outputs": [],
      "source": [
        "Not_list = []\n",
        "for ch in kuten_chars:\n",
        "    if not ch in jchar_list:\n",
        "        Not_list.append(ch)\n",
        "    else:\n",
        "        jchar_list.append(ch)\n",
        "\n",
        "print(len(Not_list))\n",
        "#kuten_chars\n",
        "#print(\"\".join([ch for ch in joyo_chars]))\n",
        "print(f'len(jchar_list):{len(jchar_list)}')\n",
        "print(f'jchar_list:{\"\".join([ch for ch in jchar_list])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ad1609-3469-4fe8-8ada-559fc1ceffc8",
      "metadata": {
        "id": "47ad1609-3469-4fe8-8ada-559fc1ceffc8"
      },
      "outputs": [],
      "source": [
        "!gls RAM/*.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3cbce83-780a-4a44-a826-10460f0deb68",
      "metadata": {
        "id": "a3cbce83-780a-4a44-a826-10460f0deb68"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}