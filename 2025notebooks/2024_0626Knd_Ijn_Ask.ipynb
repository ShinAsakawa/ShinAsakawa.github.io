{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2025notebooks/2024_0626Knd_Ijn_Ask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lpR6RRALog6X",
      "metadata": {
        "id": "lpR6RRALog6X"
      },
      "outputs": [],
      "source": [
        "# 2025 年 05 月 01 日時点でのメモ\n",
        "# numpy のバージョンを強制的に 1.26.4 にダウングレードした場合，ランタイムの再起動をしないと\n",
        "# ダウングレードした numpy が実行時に反映されない。\n",
        "# このため一度このセルを実行した後に,上のメニューバー左から 5 つ目の「ランタイム」から「セッションを再起動する」\n",
        "# を選択して再度このセルを実行する必要がある。\n",
        "\n",
        "# Google Colab 上で実行しているかどうかを判定\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "# Google colab で実行している場合必要なライブラリをインストールして word2vec ファイルをダウンロードする\n",
        "if isColab:\n",
        "    # Install PyDrive\n",
        "    !pip install pydrive2\n",
        "    #!pip install PyDrive2\n",
        "\n",
        "    #Import modules\n",
        "    from pydrive2.auth import GoogleAuth\n",
        "    #from pydrive.auth import GoogleAuth\n",
        "    from pydrive2.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "\n",
        "    #Authenticate and create the PyDrive client\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    #Get the Shareable link\n",
        "    # 2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz: 1Rp3HbDkbpzMg5ehq1ARwCATX8iZAxTgj\n",
        "    # 2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_sgns.bin.gz: 19BKVOBNHESt1K8725UTM9J3OpqK7YlVb\n",
        "    downloaded = drive.CreateFile({'id':\"1Rp3HbDkbpzMg5ehq1ARwCATX8iZAxTgj\"})\n",
        "    downloaded.GetContentFile('2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz')\n",
        "\n",
        "    # 2021_05jawiki_hid200_win20_neg20_sgns.bin.gz: 1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s\n",
        "    # 2021_05jawiki_hid200_win20_neg20_cbow.bin.gz: 1VPL2Mr9JgWHik9HjRmcADoxXIdrQ3ds7\n",
        "    # 2021_05jawiki_hid128_win10_neg10_sgns.bin.gz: 1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M\n",
        "    # 2021_05jawiki_hid128_win10_neg10_cbow.bin.gz: 1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb\n",
        "    # 上記は cbow で訓練済ファイルをダウンロードしています。\n",
        "    # skip gram モデルで訓練済モデルに変更する場合には，上記情報に従って 27 行目と 28 行目を書き換えてください。\n",
        "\n",
        "    !pip uninstall numpy thinc spacy --yes\n",
        "    !pip install --upgrade numpy==1.26.4 --force-reinstall\n",
        "    !pip install --upgrade gensim==4.3.3\n",
        "    #!pip install --upgrade numpy==1.26.4 gensim==4.3.3 --force-reinstall\n",
        "\n",
        "    import numpy as np\n",
        "    print(f'np.__version__:{np.__version__}')\n",
        "\n",
        "    import gensim\n",
        "    print(f'gensim.__version__:{gensim.__version__}')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "w2v = KeyedVectors.load_word2vec_format(\n",
        "    '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz',\n",
        "    encoding='utf-8',\n",
        "    unicode_errors='replace',\n",
        "    binary=True)\n",
        "\n",
        "# # 以下は動作確認です。\n",
        "# # 埋め込みベクトルを得る\n",
        "# print(w2v['心理学'])\n",
        "\n",
        "# # 最も近い単語を得る\n",
        "# print(w2v.most_similar('認知科学'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1982d5-b8ec-4d17-83f7-cabacc3e907a",
      "metadata": {
        "id": "bc1982d5-b8ec-4d17-83f7-cabacc3e907a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "\n",
        "# 利用可能な GPU device の検出と設定\n",
        "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "print(f'device:{device}')\n",
        "\n",
        "# 必要なライブラリの輸入\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "from termcolor import colored\n",
        "\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b2be91-f5ca-4d9a-b4ee-599d114b1ae0",
      "metadata": {
        "id": "77b2be91-f5ca-4d9a-b4ee-599d114b1ae0",
        "tags": []
      },
      "source": [
        "* date: 2023_1027\n",
        "* author: 浅川伸一\n",
        "* filename: 2024_0528Knd_Ijn_Ask.ipynb 名前変更，旧名は `2023_1027Knd_Ijn_Ask_s2p_p2s.ipynb` 理由は orthgraphy も追加したから。\n",
        "\n",
        "## 覚書\n",
        "\n",
        "# 符号化器‐復号化器 (encoder-decoder a.k.a seq2seq) モデルによる，単語認識過程 beyond triangle\n",
        "\n",
        "`fit_seq2seq()`, `eval_seq2seq()` は，encoder 側が 系列データでも，埋め込みベクトルでも動作する。\n",
        "従って，o2o, o2p, p2o, p2p, s2o, s2p の 6 モデルはこれで良いようだ。\n",
        "残された，o2s, p2s, s2s を開発すれば良い。\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2006Kello_fig4.svg\" style=\"width:39%\">\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2006Kello_junction_fig5.svg\" style=\"width:39%\">\n",
        "<!-- <img src=\"2006Kello_fig4.svg\" width=\"39%\"><img src=\"2006Kello_junction_fig5.svg\" style=\"width:39%\"> -->\n",
        "<div style=\"background-color:lavender;text-align:left;width:66%\">\n",
        "左: RNN を用いた符号化器 (encoder) -復号化器 (decoder) モデル。\n",
        "右: Kello らの結節点 (junction) モデル。中央の語彙ノード (lexical nodes) 上の数字 45263 は，交差点モデルが扱うことが可能な語彙数。<br/>\n",
        "左: Kello+2006 Fig.4, 右: Kello+2006 Fig5\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig1_extended.svg\" style=\"width:39%\">\n",
        "<!-- <img src=\"2004Harm_Seidenberg_fig1_extended.svg\" width=\"39%\"> -->\n",
        "<div style=\"background-color:lavender;text-align:center;width:44%\">\n",
        "Harm\\&Seidenberg2004 Fig. 1 を改変。\n",
        "</div>\n",
        "</center>\n",
        "\n",
        "1. O(rthgraphy), P(honology), S(emnatics) のそれぞれに対して，ソースとターゲットと見立てた，9 つのデータセット，モデルを用意した。\n",
        "モデル名を下表に示す。\n",
        "表中の x2y は，ソースが x [o,p,s] でターゲットが y [o,p,s] であるモデルを意味する。\n",
        "カッコ内は，ソースとターゲットのそれぞれが，系列データであれば Seq であり，埋め込みベクトルデータであれば Vec である。\n",
        "\n",
        "|source\\target   | O   | P   |  S |\n",
        "|:--:|:--:|:---:|:--:|\n",
        "| O | o2o (Seq2seq)| o2p (Seq2Seq)| o2s (Seq2Vec)|\n",
        "| P | p2o (Seq2Seq)| p2p (Seq2Seq)| p2s (Seq2Vec)|\n",
        "| S | s2o (Vec2Seq)| s2p (Vec2Seq)| s2s (Vec2Vec)|\n",
        "\n",
        "ソースからターゲットへと系列データかベクトル埋め込みデータかによって，モデルは 4 種類に分類できる。\n",
        "\n",
        "1. 系列から系列へ: 4 (o2o, o2p, p2o, p2p)，\n",
        "2. 系列からベクトル埋め込みへ: 2 (o2s, p2s)\n",
        "3. ベクトル埋め込みから系列へ: 2 (s2o, s2p)\n",
        "4. ベクトル埋め込みからベクトル埋め込み 1\n",
        "\n",
        "## メモ\n",
        "\n",
        "1. 2023_1027 に近藤先生には，このコードのプロトタイプをお見せした。\n",
        "すなわち GitHub にアップロード済である。\n",
        "このファイルには，その後の改良が加えられている。\n",
        "ただし，最初のセルで MeCab をソースコードからダウンロードして，コンパイル & インストールに時間を要したため，実施まではお見せしていない。\n",
        "\n",
        "2. MeCab の使用は，未知語が入力として与えられた場合，仮のヨミを得るために使用している。\n",
        "上記の役割を除けば MeCab は不要だと判断し，MeCab の使用を中止した\n",
        "\n",
        "\n",
        "<center>\n",
        "<!-- <img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4c.svg\"><br/>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4d.svg\"><br/> -->\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4ab.svg\"><br/>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4c.svg\">\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2004Harm_Seidenberg_fig4d.svg\"><br/>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/1999Levelt_blueprint.jpg\" width=49%\"><br/>\n",
        "<!-- <img src=\"2004Harm_Seidenberg_fig4ab.svg\"><br/>\n",
        "<img src=\"2004Harm_Seidenberg_fig4c.svg\">\n",
        "<img src=\"2004Harm_Seidenberg_fig4d.svg\"><br/> -->\n",
        "`Harm & Seidenberg (2004)`, Figure 4 c, and d,\n",
        "`Levelt 1999\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2015Loung_fig1.svg\" width=\"24%\"><br/>\n",
        "ニューラル翻訳モデル。\n",
        "青色がソース言語モデル，赤がターゲット言語モデルである。\n",
        "ソース言語モデルの，最終時刻の中間層状態を，ターゲット言語モデルの開始時の中間層状態として用いる。\n",
        "Loung+2015 Fig.1 より。    \n",
        "</center>\n",
        "\n",
        "\n",
        "* 文献\n",
        "    * Harm & Seidenberg (2004) Computing the Meanings of Words in Reading: Cooperative Division of Labor Between Visual and Phonological Processes, Psychological Review, DOI:10.1037/0033-295X.111.3.662\n",
        "    * Seq2seq 翻訳モデル: Sutskever+ (2014) Sequence to Sequence Learning with Neural Networks, [arXiv:1409.3215](https://arxiv.org/abs/1409.3215)\n",
        "    * 注意つき符号化器‐復号化器モデル: Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, [arXiv:1409.0473](https://arxiv.org/abs/1409.0473)\n",
        "    * もう一つの注意つき符号化器‐復号化器モデル Luong+ (2015) Effective Approaches to Attention-based Neural Machine Translation, [arXiv:1508.04025](https://arxiv.org/abs/1508.04025)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d329e1-040a-4fab-b524-4dab9323c25a",
      "metadata": {
        "id": "97d329e1-040a-4fab-b524-4dab9323c25a"
      },
      "source": [
        "# 準備\n",
        "\n",
        "## 自作ライブラリの輸入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81e137d-f5b3-412d-985d-191972ae9b11",
      "metadata": {
        "id": "a81e137d-f5b3-412d-985d-191972ae9b11",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "try:\n",
        "    import RAM\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "    import RAM\n",
        "\n",
        "# 近藤先生との議論から音韻情報の代替案として，ローマ字表記を採用することとした。\n",
        "# このとき，訓令式の表記にすることとした。ヘボン式，パスポート式ではないことに注意\n",
        "try:\n",
        "    from kunrei import kunrei\n",
        "except ImportError:\n",
        "    !wget https://shinasakawa.github.io/2023notebooks/kunrei.py -O kunrei.py\n",
        "    from kunrei import kunrei"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba9c3bd-6967-4ce7-9425-1552f88cca02",
      "metadata": {
        "id": "0ba9c3bd-6967-4ce7-9425-1552f88cca02"
      },
      "source": [
        "## 意味表現として word2vec による意味埋め込みベクトルを使う"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f58cac7-fd74-4e65-8118-3d489ddf1598",
      "metadata": {
        "id": "3f58cac7-fd74-4e65-8118-3d489ddf1598"
      },
      "outputs": [],
      "source": [
        "RAMja_chars = RAM.ja_chars()\n",
        "# print(f'len(RAMja_chars):{len(RAMja_chars)}')\n",
        "# print(f'type(RAMja_chars):{type(RAMja_chars)}')\n",
        "\n",
        "w2v_chars = {}\n",
        "for word in w2v.index_to_key[1:]:\n",
        "    for ch in word:\n",
        "        if not ch in w2v_chars:\n",
        "            w2v_chars[ch] = 1\n",
        "        else:\n",
        "            w2v_chars[ch] += 1\n",
        "\n",
        "print(f'len(w2v_chars):{len(w2v_chars)} word2vec で用いられれている文字総数')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9688246-f6c2-4507-bd64-adeec74e5b4a",
      "metadata": {
        "id": "e9688246-f6c2-4507-bd64-adeec74e5b4a"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "\n",
        "count_sorted = sorted(w2v_chars.items(), key=operator.itemgetter(1), reverse=True)\n",
        "plt.figure(figsize=(14,4))\n",
        "N = np.array([x[1] for x in w2v_chars.items()]).sum()\n",
        "\n",
        "topN = 80\n",
        "title = f'NTT日本語の語彙特性 文字頻度 上位:{topN}文字/全{len(w2v_chars)}文字'\n",
        "plt.figure(figsize=(15,3))\n",
        "plt.bar(range(len(count_sorted[:topN])), [x[1]/N for x in count_sorted[:topN]])\n",
        "plt.xticks(ticks=range(len(count_sorted[:topN])), labels=[c[0] for c in count_sorted[:topN]])\n",
        "plt.title(title)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3866102-52a1-459a-a31a-f21bbed22ddb",
      "metadata": {
        "id": "c3866102-52a1-459a-a31a-f21bbed22ddb"
      },
      "outputs": [],
      "source": [
        "kanji_end = 10892\n",
        "kanji_start = kanji_end - 9200\n",
        "kanji_start = 900\n",
        "#print(chrs[kanji_start:kanji_start+1900])\n",
        "#print(chrs[kanji_end-9500:kanji_end+1])\n",
        "print(f'kanji_start:{kanji_start}')\n",
        "print(f'kanji_end  :{kanji_end}')\n",
        "\n",
        "chars_cands  = list(sorted(set(w2v_chars.keys())))[886:914] # [kanji_start:kanji_end+1]\n",
        "print(f'chars_cands:{chars_cands}')\n",
        "print(f'削除した文字記号{list(sorted(set(w2v_chars.keys())))[914:947]}')\n",
        "chars_cands += list(sorted(set(w2v_chars.keys())))[947:1024] # [kanji_start:kanji_end+1]\n",
        "print(f'len(chars_cands):{len(chars_cands)}')\n",
        "print(chars_cands[:120], kanji_start, kanji_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0374bec2-bff6-42f4-8962-8fabd0ae311e",
      "metadata": {
        "id": "0374bec2-bff6-42f4-8962-8fabd0ae311e"
      },
      "outputs": [],
      "source": [
        "print(list(sorted(set(w2v_chars.keys())))[1170:1777])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d02f45-fe1f-4da5-9be9-f1f459863866",
      "metadata": {
        "id": "38d02f45-fe1f-4da5-9be9-f1f459863866"
      },
      "outputs": [],
      "source": [
        "# 2024 年後期に使った文字と word2vec との差分を求める\n",
        "not_in_RAMjachars = []\n",
        "in_RAMjachars = []\n",
        "for ch in chars_cands:\n",
        "    if ch in RAMja_chars.all_chars:\n",
        "        in_RAMjachars.append(ch)      # RAM (2024年後期 cnps 沖縄) に存在した文字\n",
        "        #in_RAMjachars += ch      # RAM (2024年後期 cnps 沖縄) に存在した文字\n",
        "    else:\n",
        "        not_in_RAMjachars.append(ch)  # RAM に存在しない文字\n",
        "        #not_in_RAMjachars += ch  # RAM に存在しない文字\n",
        "\n",
        "# RAM に存在しない文字列をもう一度変換\n",
        "not_in_RAMjachars = sorted(set(not_in_RAMjachars))\n",
        "# _not_in_RAMjachars = \"\"\n",
        "# for ch in not_in_RAMjachars:\n",
        "#     _not_in_RAMjachars += ch\n",
        "# not_in_RAMjachars = _not_in_RAMjachars\n",
        "\n",
        "print(f'len(w2v_chars):{len(w2v_chars)} word2vec で用いられれている文字総数')\n",
        "print(f'len(RAMja_chars.all_chars):{len(RAMja_chars.all_chars)} RAM 2024 年夏時点での登録文字数')\n",
        "print(f'len(not_in_RAMjachars):{len(not_in_RAMjachars)}')\n",
        "\n",
        "#print(f'len(RAMja_chars.all_chars):{RAMja_chars.all_chars}')\n",
        "#print(RAMja_chars.all_chars)\n",
        "#print(not_in_RAMjachars)\n",
        "#A = sorted(set(RAMja_chars.all_chars))\n",
        "#B = sorted(set(w2v_chrs))\n",
        "#print(set(A) - set(B)) # - set(B))\n",
        "#RAMja_chars.all_chars\n",
        "#print(w2v_chars)\n",
        "\n",
        "#print(len(sorted(RAMja_chars.all_chars + not_in_RAMjachars)))\n",
        "#print(len(sorted(set(RAMja_chars.all_chars + not_in_RAMjachars))))\n",
        "\n",
        "counter = 0\n",
        "for ch in not_in_RAMjachars:\n",
        "    if ch in RAMja_chars.all_chars:\n",
        "        counter += 1\n",
        "        print(ch, end=\"\")\n",
        "\n",
        "print(len(RAMja_chars.all_chars)+len(not_in_RAMjachars))\n",
        "print(f'counter:{counter}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1293afe5-9160-48fb-b200-37977fbb1827",
      "metadata": {
        "id": "1293afe5-9160-48fb-b200-37977fbb1827"
      },
      "outputs": [],
      "source": [
        "A = sorted(set(RAMja_chars.all_chars)) # or set(not_in_RAMjachars))\n",
        "B = sorted(set(not_in_RAMjachars))\n",
        "\n",
        "# for ch in A:\n",
        "#     if not ch in B:\n",
        "#         print(ch)\n",
        "\n",
        "print(f'len(A):{len(A)}, len(B):{len(B)}')\n",
        "print(A[:3], B[:3])\n",
        "print(RAMja_chars.all_chars[:3])\n",
        "print(not_in_RAMjachars[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11fb582c-3043-4c72-be98-fab860a4c135",
      "metadata": {
        "id": "11fb582c-3043-4c72-be98-fab860a4c135"
      },
      "source": [
        "## データセット Psylex71_Dataset の読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9057cfa3-bd54-497c-950a-3c34576b8b64",
      "metadata": {
        "id": "9057cfa3-bd54-497c-950a-3c34576b8b64",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# データセットとしての Psylex71_Dataset の読み込み\n",
        "from RAM import Psylex71_Dataset\n",
        "\n",
        "psylex71_ds = Psylex71_Dataset(max_words=30000)\n",
        "print(f'psylex71_ds の単語数:{psylex71_ds.__len__()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a15caf-f155-4ec6-a025-e49d9cd99188",
      "metadata": {
        "id": "c5a15caf-f155-4ec6-a025-e49d9cd99188"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "print(f'psylex71_ds.__getitem__(idx):{psylex71_ds.__getitem__(idx)}')\n",
        "\n",
        "inp, tgt = psylex71_ds.__getitem__(idx)\n",
        "print(f'inp:{inp}, psylex71_ds.source_ids2tkn(inp):{psylex71_ds.source_ids2tkn(inp)}')\n",
        "print(f'tgt:{tgt}, psylex71_ds.target_ids2tkn(tgt):{psylex71_ds.target_ids2tkn(tgt)}')  # 教師データインデックスをトークンに変換して印字"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4995d2-8a4f-4721-8a79-eca7330b961b",
      "metadata": {
        "id": "bd4995d2-8a4f-4721-8a79-eca7330b961b"
      },
      "source": [
        "### データセットのヒストグラム描画"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ff4af1-2184-4304-bef0-64bf2504e40e",
      "metadata": {
        "id": "45ff4af1-2184-4304-bef0-64bf2504e40e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from RAM import draw_word_char_histgram\n",
        "draw_word_char_histgram(_dict=psylex71_ds.data_dict, key='phon', title='音韻', figsize2=(8,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ddbc27f-5ebb-4fbd-9d75-da7585048341",
      "metadata": {
        "id": "1ddbc27f-5ebb-4fbd-9d75-da7585048341"
      },
      "source": [
        "## 0.4 psylex71_ds に存在する全単語を word2vec の埋め込みベクトル行列にする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cd4aab-6dbb-41f4-bb02-b74f2768043c",
      "metadata": {
        "id": "94cd4aab-6dbb-41f4-bb02-b74f2768043c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# psylex71_ds データから word2vec の埋め込みベクトル行列を得る\n",
        "_words = [dct['orth'] for dct in psylex71_ds.data_dict.values()]\n",
        "\n",
        "# gensim() の `vectors_for_all()` 関数を持ちて，望む語彙で構成される word2vec 単語埋め込みモデルを作成\n",
        "w2v_psylex71 = w2v.vectors_for_all(_words)\n",
        "\n",
        "# NaN データが入っている可能性がるので変換\n",
        "w2v_psylex71.vectors = np.nan_to_num(w2v_psylex71.vectors)\n",
        "print(f'w2v_psylex71.vectors.shape:{w2v_psylex71.vectors.shape}')\n",
        "words = w2v_psylex71.index_to_key\n",
        "#len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4baeee79-6f53-459d-b1ed-688788eae64b",
      "metadata": {
        "id": "4baeee79-6f53-459d-b1ed-688788eae64b"
      },
      "source": [
        "## 0.5 psylex71 データセット中の単語における w2v の表示テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf14fdcf-d6b5-461e-ac0a-f5f9fe55a9fd",
      "metadata": {
        "id": "bf14fdcf-d6b5-461e-ac0a-f5f9fe55a9fd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "Wrd = input('単語を入力してください:')\n",
        "color = 'blue'\n",
        "while (Wrd != \"\"):\n",
        "    if Wrd in w2v_psylex71:\n",
        "        Idx = w2v_psylex71.key_to_index[Wrd]\n",
        "        print(f'入力単語 Wrd:{colored(Wrd, color, attrs=[\"bold\"])},',\n",
        "              f'対応する単語番号 Idx:{colored(Idx, color, attrs=[\"bold\"])},',\n",
        "              f'w2v_psylex71.get_index({Wrd}):{colored(w2v_psylex71.get_index(Wrd), color, attrs=[\"bold\"])}')\n",
        "    else:\n",
        "        print(colored(f'{Wrd} という単語はありません。','red', attrs=['bold']))\n",
        "    Wrd = input('単語を入力してください (終了するには改行のみを入力):')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f386089a-8e73-4640-a13d-71fbcd59c404",
      "metadata": {
        "id": "f386089a-8e73-4640-a13d-71fbcd59c404"
      },
      "source": [
        "## 0.6 書記素リストの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46064f0e-355d-47cf-8eb5-9fdd983edfd2",
      "metadata": {
        "id": "46064f0e-355d-47cf-8eb5-9fdd983edfd2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import RAM\n",
        "\n",
        "def _grapheme(words=words):\n",
        "    \"\"\"必要と思われる書記素リストを返す\"\"\"\n",
        "\n",
        "    num_alpha='０１２３４５６７８９ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "    hira = 'あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわゐゑをんぁぃぅぇっゃゅょゎ'+'ゔ'\n",
        "    kata = 'アイウエオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモヤユヨラリルレロワヰヱヲン'+'ヴヷヸヹヺァィゥヵヶェォッャョュヮ'\n",
        "    symbols='、。，．・：；？！゛゜´｀¨＾‾＿ヽヾゝゞ〃仝々〆〇ー—‐／＼〜‖｜…‥‘’“”（）〔〕［］｛｝〈〉《》「」『』【】＋−±×÷＝≠＜＞≦≧∞∴♂♀°′″℃¥＄¢£％＃＆＊＠§☆★○●◎◇' + '◆□■△▲▽▼※〒→←↑↓〓∈∋⊆⊇⊂⊃∪∩∧∨¬⇒⇔∀∃∠⊥⌒∂∇≡≒≪≫√∽∝∵∫∬Å‰♯♭♪†‡¶◯'\n",
        "    #greek='ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩαβγδεζηθικλμνξοπρστυφχψω'\n",
        "    #rosian='АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
        "    #digit_symbols='①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳⑴⑵⑶⑷⑸⑹⑺⑻⑼⑽⑾⑿⒀⒁⒂⒃⒄⒅⒆⒇❶❷❸❹❺❻❼❽❾⒈⒉⒊⒋⒌⒍⒎⒏⒐'\n",
        "    #alpha_symbols='ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩⅪⅫⅰⅱⅲⅳⅴⅵⅶⅷⅸⅹⅺⅻ⒜⒝⒞⒟⒠⒡⒢⒣⒤⒥⒦⒧⒨⒩⒪⒫⒬⒭⒮⒯⒰⒱⒲⒳⒴⒵'\n",
        "    #units='㎜㎟㎝㎠㎤㎡㎥㎞㎢㎎㎏㏄㎖㎗ℓ㎘㎳㎲㎱㎰℉㏔㏋㎐㎅㎆㎇№㏍℡'\n",
        "    #suits='♤♧♡♢♠♣♥♦〠☎〄☞☜☝☟⇆⇄⇅⇨⇦⇧⇩'\n",
        "    #etc='①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ㍉㌔㌢㍍㌘㌧㌃㌶㍑㍗㌍㌦㌣㌫㍊㌻㎜㎝㎞㎎㎏㏄㎡㍻〝〟№㏍℡㊤㊥㊦㊧㊨㈱㈲㈹㍾㍽㍼≒≡∫∮∑√⊥∠∟⊿∵∩∪㊙'\n",
        "    #etc2='㍉㌢㍍㌔㌖㌅㌳㍎㌃㌶㌘㌕㌧㍑㍊㌹㍗㌍㍂㌣㌦㌻㌫㌀㌞㌪㌱㍇㍾㍽㍼㍻㍿∮∟⊿〝'\n",
        "\n",
        "    # RAM で作成済の常用漢字リストを用いて単漢字リストを作成\n",
        "    # 平成 22 年の改定により常用漢字は 2136 文字ある\n",
        "    chars_list = [ch for ch in num_alpha+hira+kata+symbols]+ RAM.chars_joyo().char_list\n",
        "    not_chars_list = []\n",
        "    for wrd in tqdm(words):\n",
        "        for ch in wrd:\n",
        "            if (ch not in chars_list) and (ch not in not_chars_list):\n",
        "                not_chars_list.append(ch)\n",
        "    not_chars_list = sorted(not_chars_list)\n",
        "    grapheme = chars_list + not_chars_list\n",
        "    # 上記の処理により grapheme には 2768 文字である。\n",
        "    # これに特殊トークン 4 つ ['<PAD>', '<SOW>', '<EOW>', '<UNK>'] を加えたリストを返す\n",
        "\n",
        "    return ['<PAD>', '<SOW>', '<EOW>', '<UNK>'] + grapheme\n",
        "\n",
        "grapheme = _grapheme()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab15140-dca3-4f07-8080-4d8b10503bcc",
      "metadata": {
        "id": "2ab15140-dca3-4f07-8080-4d8b10503bcc",
        "tags": []
      },
      "source": [
        "## 0.7 データセット定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c5962c-2596-4e67-b7e0-3e58bae4f8bf",
      "metadata": {
        "id": "e1c5962c-2596-4e67-b7e0-3e58bae4f8bf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import gensim\n",
        "\n",
        "def _collate_fn(batch):\n",
        "    inps, tgts = list(zip(*batch))\n",
        "    inps = list(inps)\n",
        "    tgts = list(tgts)\n",
        "    return inps, tgts\n",
        "\n",
        "\n",
        "class psylex71_w2v_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 #direction='s2p',  # ['s2p', 'p2s']\n",
        "                 source='seme',    # エンコーダ用 入力データ, ['orth', seme', 'phon'] のいずれか一つ\n",
        "                 target='phon',    # デコーダ用 出力データ ,  ['orth', seme', 'phon'] のいずれか一つ\n",
        "                 w2v:gensim.models.keyedvectors.KeyedVectors=w2v_psylex71,\n",
        "                 old_ds:RAM.dataset.Psylex71_Dataset=psylex71_ds,\n",
        "                 #mecab_yomi=yomi,\n",
        "                 grapheme:list=grapheme,\n",
        "                ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.ds_name = 'psylex71_'+source+\"2\"+target\n",
        "        self.source, self.target = source, target\n",
        "\n",
        "        self.w2v = w2v\n",
        "        self.old_ds = old_ds\n",
        "        #self.mecab_yomi = yomi         # 未知の単語が入力された場合 MeCab を使って読みをえるため\n",
        "        self.grapheme = grapheme\n",
        "\n",
        "        self.words = w2v.index_to_key  # gensim の KeyedVectors を利用して単語リストとする\n",
        "        self.W = w2v.vectors\n",
        "\n",
        "        # 訓令式に従った日本語ローマ字表記 `kurei.py` 参照\n",
        "        self.phoneme = ['<PAD>', '<SOW>', '<EOW>', '<UNK>', # 特殊トークン，純に，埋め草，語頭，語末，未知\n",
        "                        'a', 'i', 'u', 'e', 'o',            # 母音\n",
        "                        'a:', 'i:', 'u:', 'e:', 'o:',       # 長母音\n",
        "                        'N', 'Q',                           # 撥音，拗音\n",
        "                        'b', 'by', 'ch', 'd', 'dy', 'f', 'g', 'gy', 'h', 'hy', # 子音\n",
        "                        'j', 'k', 'ky', 'm', 'my', 'n', 'ny',  'p', 'py', 'r', # 子音\n",
        "                        'ry', 's', 'sy', 't', 'ty', 'w', 'y', 'z', 'zy']       # 子音\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        wrd = self.words[idx]\n",
        "\n",
        "        if self.source == 'phon':\n",
        "            src = torch.LongTensor(self.wrd2phon_ids(wrd))\n",
        "        elif self.source == 'seme':\n",
        "            src = torch.tensor(self.w2v.get_vector(idx))\n",
        "        elif self.source == 'orth':\n",
        "            src = torch.LongTensor(self.wrd2orth_ids(wrd))\n",
        "        else:\n",
        "            src = None\n",
        "\n",
        "        if self.target == 'phon':\n",
        "            tgt = torch.LongTensor(self.wrd2phon_ids(wrd))\n",
        "        elif self.target == 'seme':\n",
        "            tgt = torch.tensor(self.w2v.get_vector(idx))\n",
        "        elif self.target == 'orth':\n",
        "            tgt = torch.LongTensor(self.wrd2orth_ids(wrd))\n",
        "        else:\n",
        "            tgt = None\n",
        "\n",
        "        return src, tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.w2v)\n",
        "\n",
        "    def getitem(self,\n",
        "                idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        _yomi = self.wrd2yomi(wrd)\n",
        "        _yomi = kunrei(_yomi).split(' ')\n",
        "        phon_ids = [self.phoneme.index(idx) for idx in _yomi]\n",
        "        orth_ids = [self.grapheme.index(idx) for idx in wrd]\n",
        "        return wrd, _yomi, phon_ids, orth_ids\n",
        "\n",
        "    def source_ids2source(self, ids:list):\n",
        "\n",
        "        if self.source == 'phon':\n",
        "            return self.phon_ids2phn(ids)\n",
        "        elif self.source == 'orth':\n",
        "            return self.orth_ids2orth(ids)\n",
        "        elif self.source == 'seme':\n",
        "            wrd = self.getitem(ids)[0]\n",
        "            return w2v.similar_by_word(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "\n",
        "        if self.target == 'phon':\n",
        "            return self.phon_ids2phn(ids)\n",
        "        elif self.target == 'orth':\n",
        "            return self.orth_ids2orth(ids)\n",
        "        elif self.target == 'seme':\n",
        "            wrd = self.getitem(ids)[0]\n",
        "            return w2v.similar_by_word(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def wrd2orth_ids(self, wrd:str)->list:\n",
        "        ids = [self.grapheme.index(ch) for ch in wrd]\n",
        "        ids = [self.grapheme.index('<SOW>')] + ids + [self.grapheme.index('<EOW>')]\n",
        "        #ids = [[self.grapheme.index('<SOW>')] + ids + [self.grapheme.index('<EOW>')]]\n",
        "        return ids\n",
        "\n",
        "    def wrd2phon_ids(self, wrd:str)->list:\n",
        "        _yomi = self.wrd2yomi(wrd)\n",
        "        _yomi = kunrei(_yomi).split(' ')\n",
        "        ids = [self.phoneme.index(idx) for idx in _yomi]\n",
        "        ids = [self.phoneme.index('<SOW>')] + ids + [self.phoneme.index('<EOW>')]\n",
        "        return ids\n",
        "\n",
        "    def get_wrdidx_from_word(self, wrd:str):\n",
        "        if wrd in self.words:\n",
        "            wrd_idx = self.w2v.get_index(wrd)\n",
        "        else:\n",
        "            wrd_idx = -1\n",
        "        return wrd_idx\n",
        "\n",
        "    def wrd2emb(self, wrd:str)->np.ndarray:\n",
        "        if wrd in self.words:\n",
        "            return self.w2v.get_vector(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def wrd2wrd_ids(self, wrd:str)->int:\n",
        "        if wrd in self.words:\n",
        "            return self.words.index(wrd)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def orth_ids2orth(self,\n",
        "                      ids:np.ndarray)->str:\n",
        "    #def orth_ids2orth(self, ids:list)->str:\n",
        "        ret = [self.grapheme[idx] for idx in ids]\n",
        "        return ret\n",
        "\n",
        "    def wrd_idx2wrd(self, idx:int)->str:\n",
        "        if 0 <= idx and idx < len(self.words):\n",
        "            return self.words[idx]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def wrd2onehot(self, wrd:str)->np.ndarray:\n",
        "        ret = np.zeros((self.W.shape[0],), dtype=np.int32)\n",
        "        if wrd in self.words:\n",
        "            ret[self.w2v.get_index(wrd)] = 1\n",
        "            return ret\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def phon_ids2phn(self, ids:np.ndarray):\n",
        "        ret = \"\".join([self.phoneme[idx] for idx in ids])\n",
        "        return ret\n",
        "\n",
        "    def wrd2yomi(self, wrd:str)->list:\n",
        "        if wrd in self.words:\n",
        "            _yomi = self.old_ds.orth2info_dict[wrd]['ヨミ']\n",
        "        else:\n",
        "            _yomi = self.mecab_yomi(wrd).strip().split()[0]\n",
        "        return _yomi\n",
        "\n",
        "    def wrd2info(self, wrd:str)->dict:\n",
        "        if wrd in self.words:\n",
        "            return self.old_ds.orth2info_dict[wrd]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "# 全部で 9 通りのデータセットを定義\n",
        "psylex71_ds_o2o = psylex71_w2v_Dataset(source='orth', target='orth')\n",
        "psylex71_ds_o2p = psylex71_w2v_Dataset(source='orth', target='phon')\n",
        "psylex71_ds_o2s = psylex71_w2v_Dataset(source='orth', target='seme')\n",
        "\n",
        "psylex71_ds_p2o = psylex71_w2v_Dataset(source='phon', target='orth')\n",
        "psylex71_ds_p2p = psylex71_w2v_Dataset(source='phon', target='phon')\n",
        "psylex71_ds_p2s = psylex71_w2v_Dataset(source='phon', target='seme')\n",
        "\n",
        "psylex71_ds_s2o = psylex71_w2v_Dataset(source='seme', target='orth')\n",
        "psylex71_ds_s2p = psylex71_w2v_Dataset(source='seme', target='phon')\n",
        "psylex71_ds_s2s = psylex71_w2v_Dataset(source='seme', target='seme')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e4c599-f8b6-46ac-b796-6d1cc9b3bd37",
      "metadata": {
        "id": "c2e4c599-f8b6-46ac-b796-6d1cc9b3bd37",
        "tags": []
      },
      "source": [
        "### 訓練データセットとテストデータへの分割。現時点で未使用"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88af86b-c0a6-4fa0-8c29-653b8c38f8bf",
      "metadata": {
        "id": "f88af86b-c0a6-4fa0-8c29-653b8c38f8bf"
      },
      "source": [
        "# モデルの定義\n",
        "\n",
        "<div style=\"font-family:serif;font-size:14pt;color:purple;font-weight:900\">\n",
        "\n",
        "PyTorch RNN モデルの実装に対する注意メモ\n",
        "    \n",
        "* Encoder 側のデータと Decoder 側のデータそれぞれに対して Padding の処理を行う。\n",
        "* Encoder 側のデータには Padding 値として `0` で埋める。\n",
        "* Decoder 側のデータをモデルの forward で使う場合には、Padding 値は `0` を埋める。\n",
        "* ただし，Decoder 側のデータを教師データとして使う場合には，Padding 値には -1 を用いて，埋めることに注意。\n",
        "* `nn.Embedding()` のオプションに `padding_idx=O` を付け，`CrosEntropyLoss` のオプションに `ignore_index=-1` を付ける。\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac647e5-1ebf-44fa-9293-de95372408c8",
      "metadata": {
        "id": "fac647e5-1ebf-44fa-9293-de95372408c8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 全モデル共通使用するライブラリの輸入\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05775c3e-2e5c-4961-b4ec-d0775a1d7546",
      "metadata": {
        "id": "05775c3e-2e5c-4961-b4ec-d0775a1d7546"
      },
      "source": [
        "## 0 共通のハイパーパラメータ宣言"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7122e7d5-4988-4b75-adce-b459b3a8c92b",
      "metadata": {
        "id": "7122e7d5-4988-4b75-adce-b459b3a8c92b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Hyper parameters\n",
        "n_hid = 128\n",
        "n_layers = 1\n",
        "bidirectional=False\n",
        "batch_size = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c34d476-fca6-428c-9c2f-bdf80e8090cd",
      "metadata": {
        "id": "5c34d476-fca6-428c-9c2f-bdf80e8090cd"
      },
      "source": [
        "## 1 Seq2Seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e05e9b-1478-41bc-9f85-9d689a3fd03b",
      "metadata": {
        "id": "66e05e9b-1478-41bc-9f85-9d689a3fd03b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Seq2Seq_wAtt(nn.Module):\n",
        "    \"\"\" 注意つき符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "# 以下確認作業\n",
        "ds = psylex71_ds_o2p\n",
        "o2p = Seq2Seq_wAtt(enc_vocab_size=len(ds.grapheme),\n",
        "                   dec_vocab_size=len(ds.phoneme),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "print(o2p.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bb00c1f-ed2c-4b51-b12a-3c68adf840d7",
      "metadata": {
        "id": "1bb00c1f-ed2c-4b51-b12a-3c68adf840d7"
      },
      "source": [
        "## 2 Vec2Seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29c1a4c-7b79-4a15-b66b-942cdf86ca8a",
      "metadata": {
        "id": "d29c1a4c-7b79-4a15-b66b-942cdf86ca8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Vec2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sem_dim:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # 単語の意味ベクトル a.k.a 埋め込み表現 を decoder の中間層に接続するための変換層\n",
        "        # 別解としては，入力層に接続する方法があるが，それはまた別実装にする\n",
        "        self.enc_transform_layer = nn.Linear(\n",
        "            in_features=sem_dim,\n",
        "            out_features=n_hid)\n",
        "        self.decoder_emb = nn.Embedding(\n",
        "            num_embeddings=dec_vocab_size,\n",
        "            embedding_dim=n_hid,\n",
        "            padding_idx=0)\n",
        "\n",
        "        self.decoder = nn.LSTM(\n",
        "            input_size=n_hid,\n",
        "            hidden_size=n_hid,\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.bi_fact = 2 if bidirectional else 1\n",
        "        self.out_layer = nn.Linear(self.bi_fact * n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "        enc_emb = self.enc_transform_layer(enc_inp)\n",
        "        hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "        hnx = hnx.unsqueeze(0)\n",
        "        cnx = cnx.unsqueeze(0)\n",
        "\n",
        "        if self.bi_fact == 2:\n",
        "            hnx = hnx.repeat(2)\n",
        "            cnx = cnx.repeat(2)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "\n",
        "        batch_size = enc_inp.size(0)\n",
        "        exp_hid_size = self.decoder.get_expected_hidden_size(enc_inp, batch_sizes=[batch_size])\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        return self.out_layer(dec_out)\n",
        "\n",
        "# 以下確認作業\n",
        "ds = psylex71_ds_s2p\n",
        "s2p = Vec2Seq(\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_hid=n_hid,\n",
        "    n_layers=n_layers,\n",
        "    bidirectional=bidirectional).to(device)\n",
        "print(s2p.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "453fdaa7-c8e5-4f5b-a6b5-a61a5256e8a3",
      "metadata": {
        "id": "453fdaa7-c8e5-4f5b-a6b5-a61a5256e8a3"
      },
      "source": [
        "## 3 Seq2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681269af-44b8-4ecd-a968-89274e82610f",
      "metadata": {
        "id": "681269af-44b8-4ecd-a968-89274e82610f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Seq2Vec(nn.Module):\n",
        "    \"\"\" 系列データを符号化器に与え，埋め込みデータ (ベクトル) を復号化するモデル\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        sem_dim:int,\n",
        "        enc_vocab_size:int,\n",
        "        n_hid:int,\n",
        "        n_layers:int=2,\n",
        "        bidirectional:bool=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder_emb = nn.Embedding(\n",
        "            num_embeddings=enc_vocab_size,\n",
        "            embedding_dim=n_hid,\n",
        "            padding_idx=0)\n",
        "\n",
        "        self.encoder = nn.LSTM(\n",
        "            input_size=n_hid,\n",
        "            hidden_size=n_hid,\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional)\n",
        "\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "\n",
        "        self.encoder_out = nn.Linear(\n",
        "            in_features=n_hid * bi_fact,\n",
        "            out_features=enc_vocab_size)\n",
        "\n",
        "        self.out_layer = nn.Linear(\n",
        "            in_features=n_hid * bi_fact,\n",
        "            out_features=sem_dim)\n",
        "\n",
        "    def forward(self, enc_inp):\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hid, cel) = self.encoder(enc_emb)\n",
        "        _enc_out = self.encoder_out(enc_out)\n",
        "        _sem = self.out_layer(hid)\n",
        "        return _sem, _enc_out\n",
        "\n",
        "# 以下確認作業\n",
        "ds = psylex71_ds_o2s\n",
        "o2s = Seq2Vec(sem_dim=ds.w2v.vector_size,\n",
        "              enc_vocab_size=len(ds.grapheme),\n",
        "              n_layers=n_layers,\n",
        "              bidirectional=bidirectional,\n",
        "              n_hid=n_hid).to(device)\n",
        "print(o2s.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a042eb9-352e-4b6b-8dfb-f4e864b0f058",
      "metadata": {
        "id": "0a042eb9-352e-4b6b-8dfb-f4e864b0f058"
      },
      "source": [
        "## 4 Vec2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68918a0-95ff-4453-ad0f-acad3b5e833c",
      "metadata": {
        "id": "a68918a0-95ff-4453-ad0f-acad3b5e833c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Vec2Vec(nn.Module):\n",
        "    \"\"\" ベクトル埋め込み表現をベクトル埋め込み表現へと変換\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 sem_dim:int,\n",
        "                 n_hid:int):\n",
        "\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(sem_dim, n_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hid, sem_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# 以下確認作業\n",
        "ds = psylex71_ds_s2s\n",
        "s2s = Vec2Vec(sem_dim=ds.w2v.vector_size,\n",
        "              n_hid=n_hid).to(device)\n",
        "print(s2s.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac5a19c-c8e7-4cb7-b35b-7be06f177765",
      "metadata": {
        "id": "fac5a19c-c8e7-4cb7-b35b-7be06f177765"
      },
      "source": [
        "## 5 各モデルの宣言"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517b02e8-32ee-4ac8-90de-69d90b50d575",
      "metadata": {
        "id": "517b02e8-32ee-4ac8-90de-69d90b50d575",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(colored('# 1 写字モデル o2o', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_o2o\n",
        "o2o = Seq2Seq_wAtt(\n",
        "    enc_vocab_size=len(ds.grapheme),\n",
        "    dec_vocab_size=len(ds.grapheme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(o2o.eval())\n",
        "\n",
        "print(colored('# 2 o2p 音読モデル意味関与なし', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_o2p\n",
        "o2p = Seq2Seq_wAtt(\n",
        "    enc_vocab_size=len(ds.grapheme),\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(o2p.eval())\n",
        "\n",
        "print(colored('# 3 o2s 印字理解モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_o2s\n",
        "o2s = Seq2Vec(\n",
        "    enc_vocab_size=len(ds.grapheme),\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(o2s.eval())\n",
        "\n",
        "print(colored('# 4 p2o 聞き書き ディクテーションモデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_p2o\n",
        "p2o = Seq2Seq_wAtt(\n",
        "    enc_vocab_size=len(ds.phoneme),\n",
        "    dec_vocab_size=len(ds.grapheme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(p2o.eval())\n",
        "\n",
        "print(colored('# 5 p2p 復唱モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_p2p\n",
        "p2p = Seq2Seq_wAtt(\n",
        "    enc_vocab_size=len(ds.phoneme),\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(p2p.eval())\n",
        "\n",
        "print(colored('# 6 p2s 聴理解モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_p2s\n",
        "p2s = Seq2Vec(\n",
        "    enc_vocab_size=len(ds.phoneme),\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    n_hid=n_hid, n_layers=n_layers, bidirectional=bidirectional).to(device)\n",
        "print(p2s.eval())\n",
        "\n",
        "print(colored('# 7 s2o 書字モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_s2o\n",
        "s2o = Vec2Seq(\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    dec_vocab_size=len(ds.grapheme),\n",
        "    n_hid=n_hid, n_layers=n_layers, bidirectional=bidirectional).to(device)\n",
        "print(s2o.eval())\n",
        "\n",
        "print(colored('# 8 s2p 発話モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_s2p\n",
        "s2p = Vec2Seq(\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(s2p.eval())\n",
        "\n",
        "print(colored('# 9 s2s 意味理解モデル', color='blue', attrs=[\"bold\"]))\n",
        "ds = psylex71_ds_s2s\n",
        "s2s = Vec2Vec(\n",
        "    sem_dim=ds.w2v.vector_size,\n",
        "    n_hid=n_hid).to(device)\n",
        "print(s2s.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f9c2a7e-ca5b-4ce4-8681-011fb86f7443",
      "metadata": {
        "id": "8f9c2a7e-ca5b-4ce4-8681-011fb86f7443"
      },
      "source": [
        "# 2 訓練手続きの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661e106b-89e0-4b12-b3aa-a24e2ff4e695",
      "metadata": {
        "id": "661e106b-89e0-4b12-b3aa-a24e2ff4e695"
      },
      "source": [
        "## `fit_seq2seq()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b330320-414c-46b3-989f-191d70f65736",
      "metadata": {
        "id": "6b330320-414c-46b3-989f-191d70f65736",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def fit_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=o2p,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=psylex71_ds_o2p,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    #dataloader:torch.utils.data.dataloader.DataLoader=dl_o2p,\n",
        "    optimizer:torch.optim=None,\n",
        "    criterion:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "    \"\"\" Seq2seq の訓練に用いる関数\"\"\"\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for _inp, _tch in dataloader:\n",
        "            enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "            dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "            tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "            out = model(enc_inp, dec_inp)\n",
        "            loss = criterion(out[0], tch[0])\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:2d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "fit_seq2seq(epochs=1, model=o2p, ds=psylex71_ds_o2p); # 音読モデル\n",
        "fit_seq2seq(epochs=1, model=p2p, ds=psylex71_ds_p2p); # 復唱モデル\n",
        "fit_seq2seq(epochs=1, model=p2o, ds=psylex71_ds_p2o); # ディクテーションモデル\n",
        "fit_seq2seq(epochs=1, model=o2o, ds=psylex71_ds_o2o); # 写字モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b11f8cb0-fc1e-43b6-821d-ae9e99385fa1",
      "metadata": {
        "id": "b11f8cb0-fc1e-43b6-821d-ae9e99385fa1"
      },
      "source": [
        "## `eval_seq2seq()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e73c29e4-fd71-4455-936e-9719f6c69815",
      "metadata": {
        "id": "e73c29e4-fd71-4455-936e-9719f6c69815",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def eval_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=o2p,\n",
        "    ds:Dataset=psylex71_ds_o2p,\n",
        "    isPrint:bool=False,\n",
        "    errors:list=None):\n",
        "\n",
        "    model.eval()\n",
        "    if errors == None:\n",
        "        errors=[]\n",
        "\n",
        "    for N in tqdm(range(ds.__len__())):\n",
        "        x, y = ds.__getitem__(N)\n",
        "        enc_inp, dec_inp = x.unsqueeze(0).to(device), y.unsqueeze(0).to(device)\n",
        "        grand_truth = y.detach().numpy()[1:-1]\n",
        "        y_hat = model(enc_inp, dec_inp).to('cpu')\n",
        "        y_hat = np.argmax(y_hat.squeeze(0).detach().numpy(), axis=1)[1:-1]\n",
        "\n",
        "        if len(y_hat) == len(grand_truth):\n",
        "            n_correct = np.array((y_hat == grand_truth).sum())\n",
        "            isOK = n_correct == len(grand_truth)\n",
        "        else:\n",
        "            isOK = False\n",
        "\n",
        "        if not isOK:\n",
        "            wrd = ds.getitem(N)[0]\n",
        "            _out = ds.target_ids2target(y_hat)\n",
        "            errors.append((N, wrd, _out,y_hat))\n",
        "            if isPrint:\n",
        "                color = 'grey' if isOK else 'red'\n",
        "                wrd = ds.getitem(N)[0]\n",
        "                print(colored(f'{N:05d}', color),\n",
        "                      colored(wrd, color='grey'), # , attrs=[\"bold\"]),\n",
        "                      colored(y_hat,color,attrs=[\"bold\"]),\n",
        "                      colored(ds.target_ids2target(y_hat), color, attrs=[\"bold\"]),\n",
        "                      f'<-{ds.target_ids2target(grand_truth)}')\n",
        "\n",
        "    cr = len(errors) / N\n",
        "    return {'エラー':errors,\n",
        "            '正解率': (1.-cr) * 100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95ca21fb-ba97-46ed-b00e-421c4a8649ec",
      "metadata": {
        "id": "95ca21fb-ba97-46ed-b00e-421c4a8649ec",
        "tags": []
      },
      "outputs": [],
      "source": [
        "_ = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "#result_o2p = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be3beb4-62cd-4aba-9dcc-d1fc7d35f857",
      "metadata": {
        "id": "3be3beb4-62cd-4aba-9dcc-d1fc7d35f857",
        "tags": []
      },
      "outputs": [],
      "source": [
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7268ec-ebcf-431a-98d8-bbca1f5a8297",
      "metadata": {
        "id": "bc7268ec-ebcf-431a-98d8-bbca1f5a8297",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# 読字モデル\n",
        "errors_o2p = fit_seq2seq(epochs=10, model=o2p, ds=psylex71_ds_o2p)\n",
        "errors = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "\n",
        "# 復唱モデル\n",
        "errors_p2p = fit_seq2seq(epochs=10, model=p2p, ds=psylex71_ds_p2p)\n",
        "result_p2p = eval_seq2seq(model=p2p, ds=psylex71_ds_p2p)\n",
        "\n",
        "# 書き取りディクテーションモデル\n",
        "errors_p2o = fit_seq2seq(epochs=10, model=p2o, ds=psylex71_ds_p2o)\n",
        "result_p2o = eval_seq2seq(model=p2o, ds=psylex71_ds_p2o)\n",
        "\n",
        "# 写字モデル\n",
        "errors_o2o = fit_seq2seq(epochs=10, model=o2o, ds=psylex71_ds_o2o)\n",
        "result_o2o = eval_seq2seq(model=o2o, ds=psylex71_ds_o2o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91dd48c6-e15e-4761-a54b-6c1b8df47efe",
      "metadata": {
        "id": "91dd48c6-e15e-4761-a54b-6c1b8df47efe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 読字モデル\n",
        "print(errors_o2p)\n",
        "print(result_o2p)\n",
        "\n",
        "# 復唱モデル\n",
        "print(errors_p2p)\n",
        "print(result_p2p)\n",
        "\n",
        "# 書き取りディクテーションモデル\n",
        "print(errors_p2o)\n",
        "print(result_p2o)\n",
        "\n",
        "# 写字モデル\n",
        "print(errors_o2o)\n",
        "print(result_o2o)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f5a035-27a6-4c1c-ad38-b8c29221edd6",
      "metadata": {
        "id": "e3f5a035-27a6-4c1c-ad38-b8c29221edd6"
      },
      "source": [
        "## o2p だけもう一度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5394dbbe-8176-451e-a5ce-fcbac5d54961",
      "metadata": {
        "id": "5394dbbe-8176-451e-a5ce-fcbac5d54961",
        "tags": []
      },
      "outputs": [],
      "source": [
        "errors_o2p = fit_seq2seq(epochs=10, model=o2p, ds=psylex71_ds_o2p)\n",
        "errors = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "print(errors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af7921e-7f09-4452-bcfd-87217c32bac6",
      "metadata": {
        "id": "4af7921e-7f09-4452-bcfd-87217c32bac6"
      },
      "source": [
        "## o2p だけ結果をファイルに保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3574a73b-c4d5-4bc2-b4ec-a2d6b6501f23",
      "metadata": {
        "id": "3574a73b-c4d5-4bc2-b4ec-a2d6b6501f23",
        "tags": []
      },
      "outputs": [],
      "source": [
        "o2p.eval()\n",
        "fname_saved = '2023_1117o2p_h128.pt'\n",
        "torch.save(o2p.state_dict(), fname_saved)\n",
        "state_dict = torch.load(fname_saved)\n",
        "\n",
        "ds = psylex71_ds_o2p\n",
        "_o2p = Seq2Seq_wAtt(\n",
        "    enc_vocab_size=len(ds.grapheme),\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_layers=n_layers, bidirectional=bidirectional, n_hid=n_hid).to(device)\n",
        "print(_o2p.eval())\n",
        "\n",
        "_o2p.load_state_dict(state_dict)\n",
        "errors = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "print(errors['正解率'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26f5274f-734b-4a4f-9d2b-c0b297216e0b",
      "metadata": {
        "id": "26f5274f-734b-4a4f-9d2b-c0b297216e0b",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## `fit_vec2sec()` の定義\n",
        "実際には `fit_seq2seq()` を用いるため何もしない。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf49830-1e0c-4873-af64-285e09def02c",
      "metadata": {
        "id": "1cf49830-1e0c-4873-af64-285e09def02c"
      },
      "source": [
        "## `eval_vec2sec()` は `eval_seq2seq()` と同じ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7c4fe6-d17d-42c1-a5a9-109d9ce18fb2",
      "metadata": {
        "id": "4f7c4fe6-d17d-42c1-a5a9-109d9ce18fb2"
      },
      "source": [
        "## `fit_seq2vec()` の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c19162-57de-48fe-a567-c56b0364b169",
      "metadata": {
        "id": "93c19162-57de-48fe-a567-c56b0364b169"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41b26b7-653f-4152-8248-97bb2c8f205e",
      "metadata": {
        "id": "c41b26b7-653f-4152-8248-97bb2c8f205e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def fit_seq2vec(\n",
        "    model:torch.nn.modules.module.Module=o2p,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=psylex71_ds_o2s,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    #dataloader:torch.utils.data.dataloader.DataLoader=dl_o2s,\n",
        "    optimizer:torch.optim=None,\n",
        "    lr:float=0.001,\n",
        "    criterion_dec:torch.nn.modules.loss=nn.MSELoss(),\n",
        "    criterion_enc:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "    \"\"\" Seq2vec の訓練に用いる関数\"\"\"\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    criterion_dec = nn.MSELoss()\n",
        "    criterion_enc = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "    #criterion_enc = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for _inp, _tch in dataloader:\n",
        "            enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "            tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "            out, enc_out = model(enc_inp)\n",
        "\n",
        "            out = out.squeeze(0)\n",
        "            loss = criterion_dec(out, tch)\n",
        "            for _x, _y in zip(enc_out[:,:-1,:], enc_inp[:,1:]):\n",
        "                loss += criterion_enc(_x, _y)\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:2d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time': total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time }\n",
        "\n",
        "result = fit_seq2vec(epochs=10, model=p2s, lr=0.0001, ds=psylex71_ds_p2s) # , dataloader=dl_p2s); # 聴理解モデル\n",
        "#fit_seq2vec(epochs=50, model=o2s, lr=0.0001, ds=psylex71_ds_o2s, dataloader=dl_o2s); # 印字理解モデル\n",
        "#fit_seq2vec(epochs=20, model=o2s, lr=0.00001, ds=psylex71_ds_o2s, dataloader=dl_o2s); # 印字理解モデル\n",
        "#fit_seq2vec(epochs=20, model=o2s, lr=0.0001, ds=psylex71_ds_o2s); # 印字理解モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e37d3ac-368e-4a47-9cff-f95d57151d44",
      "metadata": {
        "id": "0e37d3ac-368e-4a47-9cff-f95d57151d44"
      },
      "source": [
        "## `eval_seq2vec()` の定義 ーーー"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b59e19-b13b-4d58-9a3c-7037bdab2e5a",
      "metadata": {
        "id": "e3b59e19-b13b-4d58-9a3c-7037bdab2e5a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "isPrint = True\n",
        "\n",
        "errors = []\n",
        "model = o2s\n",
        "model = p2s\n",
        "model.eval()\n",
        "\n",
        "ds = psylex71_ds_o2s\n",
        "ds = psylex71_ds_p2s\n",
        "\n",
        "top_N = 3  # 上位候補のうち N 位まで表示させる\n",
        "for N in tqdm(range(ds.__len__()>>8)):\n",
        "    _inp, _tch  = ds.__getitem__(N)\n",
        "\n",
        "    # dataset から入力データと教師データを得る\n",
        "    enc_inp, dec_inp = _inp.to(device), _tch.to(device)\n",
        "\n",
        "    # モデルに入力して出力を取得する\n",
        "    out_vec, _ = model(enc_inp) # .to('cpu')\n",
        "    out_vec = out_vec.detach().squeeze(0).numpy()\n",
        "\n",
        "    grand_truth = ds.getitem(N)  # 正解を得る\n",
        "    tgt_wrd = grand_truth[0]     # 正解単語を得る\n",
        "\n",
        "    # 正解単語の意味的類似語を得る。最後に [1:] しているのは自分自身は不要だから\n",
        "    tgt_neighbors = ds.w2v.most_similar(_tch.detach().numpy())[1:]\n",
        "\n",
        "    # モデル出力から得られた単語ベクトルの意味的類似語を得る\n",
        "    out_neighbors = ds.w2v.similar_by_vector(out_vec)\n",
        "    #out_neighbors = ds.w2v.similar_by_vector(out_vec.detach().squeeze(0).numpy())\n",
        "    out_neighbors = ds.w2v.most_similar(out_vec)\n",
        "    #out_neighbors = ds.w2v.most_similar(out_vec.squeeze(0).detach().numpy())\n",
        "    #print(out_neighbors_)\n",
        "\n",
        "    # 正解単語の埋め込みベクトルを得る\n",
        "    tgt_vec = ds.w2v.get_vector(tgt_wrd)\n",
        "    tch_vec = _tch.detach().squeeze(0).numpy()\n",
        "\n",
        "    w2v_cos = ds.w2v.cosine_similarities(out_vec,[tch_vec])\n",
        "    spy_euc = scipy.spatial.distance.euclidean(out_vec, tch_vec)\n",
        "\n",
        "    print(f'{N:5d} '\n",
        "          f'正解:{tgt_wrd},', end=\" \")\n",
        "    print('出力:', end=\"\")\n",
        "    for _ in out_neighbors[:top_N]:\n",
        "        print(colored(f'{_[0]}:{_[1]:.3f}',color='blue',attrs=['bold']), end=\" \")\n",
        "\n",
        "    print('<- 正解:', end=\"\")\n",
        "    for _ in tgt_neighbors[:top_N]:\n",
        "        print(f'{_[0]}:{_[1]:.3f}', end=\" \")\n",
        "    print(f'出力と正解との距離 cos_sim: {w2v_cos[0]:.3f},'\n",
        "          f'euc_dist: {spy_euc:.3f}',\n",
        "         )\n",
        "    #print(\"\")\n",
        "    #sys.exit()\n",
        "\n",
        "#cr = len(errors) / N\n",
        "#cr = len(errors) / _psylex71_ds.__len__()\n",
        "#print(f'総エラー数:{len(errors)}',\n",
        "#      f'正解率:{(1.-cr)*100:.3f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c877e77f-b53f-46d1-9a4e-13495c3cad0a",
      "metadata": {
        "id": "c877e77f-b53f-46d1-9a4e-13495c3cad0a"
      },
      "source": [
        "# 3 各モデルの訓練と評価\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd883282-6970-4999-9613-1734f1914b87",
      "metadata": {
        "id": "fd883282-6970-4999-9613-1734f1914b87"
      },
      "source": [
        "## 3.1 印字音読モデル o2p 書記から音韻"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3a875c-ab59-4edd-90ac-578d2008a690",
      "metadata": {
        "id": "fa3a875c-ab59-4edd-90ac-578d2008a690"
      },
      "outputs": [],
      "source": [
        "# 音読モデルの訓練\n",
        "# 音読モデル\n",
        "errors_o2p = fit_seq2seq(epochs=10, model=o2p, dataloader=dl_o2p)\n",
        "\n",
        "# 音読モデルの結果評価\n",
        "result_o2p = eval_seq2seq(model=o2p, ds=psylex71_ds_o2p, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2928f6e9-2091-4116-8127-ccce94aae3f7",
      "metadata": {
        "id": "2928f6e9-2091-4116-8127-ccce94aae3f7"
      },
      "source": [
        "## 3.2 写字モデル o2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78df53d6-b0cb-4274-94ff-65ea78de8875",
      "metadata": {
        "id": "78df53d6-b0cb-4274-94ff-65ea78de8875"
      },
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "errors_o2o = fit_seq2seq(epochs=1o, model=o2o, dataloader=dl_o2o)\n",
        "\n",
        "# モデルの結果評価\n",
        "result_o2o = eval_seq2seq(model=o2p, ds=psylex71_ds_o2o, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b08c3ab5-9ae8-437a-b41c-e3631d2a9efd",
      "metadata": {
        "id": "b08c3ab5-9ae8-437a-b41c-e3631d2a9efd",
        "tags": []
      },
      "source": [
        "## 3.3 p2o 聞き書き ディクテーションモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58090cb-9cbd-4dac-b3ee-6742c844eb52",
      "metadata": {
        "id": "d58090cb-9cbd-4dac-b3ee-6742c844eb52",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "errors_p2o = fit_seq2seq(epochs=10, model=p2o, dataloader=dl_p2o);\n",
        "\n",
        "# モデルの結果評価\n",
        "result_p2o = eval_seq2seq(model=p2o, ds=psylex71_ds_p2o, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735710fa-92d0-4b6c-a718-e9d346b6b5de",
      "metadata": {
        "id": "735710fa-92d0-4b6c-a718-e9d346b6b5de"
      },
      "source": [
        "## 3.4 p2p 復唱モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3efdab2-0e0a-4ead-bb17-999473708607",
      "metadata": {
        "id": "c3efdab2-0e0a-4ead-bb17-999473708607"
      },
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "errors_p2p = fit_seq2seq(epochs=10, model=p2p, ds=psylex71_ds_p2p)\n",
        "\n",
        "# モデルの結果評価\n",
        "result_p2p = eval_seq2seq(model=p2p, ds=psylex71_ds_p2p, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9ba98f-7ab6-4151-a4a0-acf85f048918",
      "metadata": {
        "id": "bd9ba98f-7ab6-4151-a4a0-acf85f048918"
      },
      "source": [
        "## 3.5 o2s 黙読モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb2a9a0-35a8-44e6-a765-c2f5405036b7",
      "metadata": {
        "id": "7eb2a9a0-35a8-44e6-a765-c2f5405036b7"
      },
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "errors_o2s = fit_seq2vec(epochs=10, model=o2s, ds=psylex71_ds_o2s)\n",
        "\n",
        "# モデルの結果評価\n",
        "result_o2s = eval_seq2vec(model=o2s, ds=psylex71_ds_o2s, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea96bd8c-8d70-489d-af8d-7069bb884939",
      "metadata": {
        "id": "ea96bd8c-8d70-489d-af8d-7069bb884939"
      },
      "source": [
        "## 3.6 p2s 聞き取りモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021aac21-e0e0-47d2-bdf1-7248262ea635",
      "metadata": {
        "id": "021aac21-e0e0-47d2-bdf1-7248262ea635"
      },
      "outputs": [],
      "source": [
        "# モデルの訓練\n",
        "errors_p2s = fit_seq2vec(epochs=10, model=p2s, ds=psylex71_ds_p2s)\n",
        "\n",
        "# モデルの結果評価\n",
        "eval_seq2vec(model=p2s, ds=psylex71_ds_p2s, isPrint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eddc759-e57a-44a0-8fa6-13b616c13532",
      "metadata": {
        "id": "5eddc759-e57a-44a0-8fa6-13b616c13532"
      },
      "source": [
        "## 3.7 s2o 書き出しモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1bd025b-91b6-430c-ab65-0ce0f000f9e3",
      "metadata": {
        "id": "b1bd025b-91b6-430c-ab65-0ce0f000f9e3"
      },
      "outputs": [],
      "source": [
        "errors_s2o = fit_seq2seq(epochs=15, model=s2o, ds=psylex71_ds_s2o)\n",
        "result_s2o = eval_seq2seq(model=s2o, ds=psylex71_ds_s2o)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6f6925-fcbd-4e8b-9e83-7cef811253e5",
      "metadata": {
        "id": "0a6f6925-fcbd-4e8b-9e83-7cef811253e5"
      },
      "source": [
        "## 3.8 s2p 発話モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4067ab3b-0c2a-4026-88ae-d3d6dc1036b9",
      "metadata": {
        "id": "4067ab3b-0c2a-4026-88ae-d3d6dc1036b9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "errors_s2p = fit_seq2seq(epochs=15, model=s2p, ds=psylex71_ds_s2p)\n",
        "result_s2p = eval_seq2seq(model=s2p, ds=psylex71_ds_s2p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4079f615-f519-4c66-be04-39fe348a0b29",
      "metadata": {
        "id": "4079f615-f519-4c66-be04-39fe348a0b29"
      },
      "source": [
        "## 3.9 s2s 自発的納得モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9b2a2-e53d-4f04-9195-696a1c28f680",
      "metadata": {
        "id": "afe9b2a2-e53d-4f04-9195-696a1c28f680",
        "tags": []
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "dataloader = dl_o2p\n",
        "\n",
        "model = o2p\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "model.train()\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "losses = []\n",
        "\n",
        "dataloader = dl_o2p\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d93d3ed-cbbf-4973-bb0f-23cfe8273a09",
      "metadata": {
        "id": "9d93d3ed-cbbf-4973-bb0f-23cfe8273a09",
        "tags": []
      },
      "outputs": [],
      "source": [
        "errors_s2p = fit_seq2seq(epochs=15, model=s2p, ds=psylex71_ds_s2p)\n",
        "result_s2p = eval_seq2seq(model=s2p, ds=psylex71_ds_s2p)\n",
        "\n",
        "errors_s2o = fit_seq2seq(epochs=15, model=s2o, ds=psylex71_ds_s2o)\n",
        "result_s2o = eval_seq2seq(model=s2o, ds=psylex71_ds_s2o)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e9454ed-decd-460d-9e09-4a2fa220d5c9",
      "metadata": {
        "id": "9e9454ed-decd-460d-9e09-4a2fa220d5c9",
        "tags": []
      },
      "source": [
        "# 3 書記+意味->音韻 os2p モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "075d72b6-995e-467c-9657-e86291839280",
      "metadata": {
        "id": "075d72b6-995e-467c-9657-e86291839280"
      },
      "source": [
        "## 3.1 データセットの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90e714d-85c7-43c9-b97d-0217ff1f350a",
      "metadata": {
        "id": "d90e714d-85c7-43c9-b97d-0217ff1f350a"
      },
      "source": [
        "### ***<font style=\"color:teal\">書記符号化器から書記埋め込みベクトルを取り出す</font>***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33281dba-f6a5-4108-8e08-8cf2c5958b32",
      "metadata": {
        "id": "33281dba-f6a5-4108-8e08-8cf2c5958b32",
        "tags": []
      },
      "outputs": [],
      "source": [
        "orth_emb_vec = []\n",
        "_o2p.eval()\n",
        "ds = psylex71_ds_o2p\n",
        "for N in range(ds.__len__()):\n",
        "    inp, tch = ds.__getitem__(N)\n",
        "    enc_emb = _o2p.encoder_emb(inp)\n",
        "    enc_out, (hnx, cnx) = o2p.encoder(enc_emb)\n",
        "    orth_emb_vec.append(hnx.detach().squeeze(0).numpy())\n",
        "orth_emb = np.array(orth_emb_vec)\n",
        "print(f'orth_emb.shape:{orth_emb.shape}')\n",
        "print(f'len(grapheme):{len(grapheme)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b87cc89-8294-4abd-8555-20a895bc774c",
      "metadata": {
        "id": "2b87cc89-8294-4abd-8555-20a895bc774c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class OS2P_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 #phoneme:list=phoneme,\n",
        "                 grapheme:list=grapheme,\n",
        "                 orth_vecs:np.ndarray=orth_emb,\n",
        "                 w2v:gensim.models.keyedvectors.KeyedVectors=w2v_psylex71,\n",
        "                 seme_vecs:np.array=w2v_psylex71.vectors,\n",
        "                 old_ds:RAM.dataset.Psylex71_Dataset=psylex71_ds,\n",
        "                )->None:\n",
        "        self.ds_name = 'orth_seme_2_phon_dataset'\n",
        "        self.w2v = w2v\n",
        "\n",
        "        self.phoneme = ['<PAD>', '<SOW>', '<EOW>', '<UNK>', # 特殊トークン，純に，埋め草，語頭，語末，未知\n",
        "                        'a', 'i', 'u', 'e', 'o',            # 母音\n",
        "                        'a:', 'i:', 'u:', 'e:', 'o:',       # 長母音\n",
        "                        'N', 'Q',                           # 撥音，拗音\n",
        "                        'b', 'by', 'ch', 'd', 'dy', 'f', 'g', 'gy', 'h', 'hy', # 子音\n",
        "                        'j', 'k', 'ky', 'm', 'my', 'n', 'ny',  'p', 'py', 'r', # 子音\n",
        "                        'ry', 's', 'sy', 't', 'ty', 'w', 'y', 'z', 'zy']       # 子音\n",
        "\n",
        "        self.orth_vecs = orth_vecs\n",
        "        self.seme_vecs = seme_vecs\n",
        "        self.words = w2v.index_to_key\n",
        "        self.old_ds = old_ds\n",
        "        wrd2phn = {}\n",
        "        for wrd in self.words:\n",
        "            yomi = self.wrd2yomi(wrd)\n",
        "            phon = kunrei(yomi).split(' ')\n",
        "            wrd2phn[wrd] = phon\n",
        "        self.wrd2phn = wrd2phn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words) # 936\n",
        "\n",
        "    def __getitem__(self, idx:int)->list:\n",
        "        orth_vec = torch.tensor(self.orth_vecs[idx]).to(device)\n",
        "        seme_vec = torch.tensor(self.seme_vecs[idx]).to(device)\n",
        "        inp = torch.cat((orth_vec, seme_vec)).to(device)\n",
        "\n",
        "        wrd = self.words[idx]\n",
        "        phn_ids = self.wrd2phon_ids(wrd)\n",
        "        tch = phn_ids\n",
        "        # phon_ids = self.wrd2phn[wrd]\n",
        "        # tch = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "        # print(f'wrd:{wrd}, tch:{tch}, type(tch):{type(tch)}')\n",
        "        # sys.exit()\n",
        "        tch = torch.LongTensor(tch).to(device)\n",
        "        return inp, tch\n",
        "\n",
        "    def getitem(self, idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        phon = self.wrd2phn[wrd]\n",
        "        phon_ids = [self.phoneme.index(p) for p in phon]\n",
        "        phon_ids = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "        return wrd, phon, phon_ids\n",
        "\n",
        "    def phon_ids2phon(self, ids:list)->list:\n",
        "        return [self.phoneme[idx] for idx in ids]\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "        return self.phon_ids2phon(ids)\n",
        "\n",
        "    def phon_ids2phon(self, ids:list)->list:\n",
        "        return [self.phoneme[idx] for idx in ids]\n",
        "\n",
        "    def wrd2yomi(self, wrd:str)->list:\n",
        "        if wrd in self.words:\n",
        "            _yomi = self.old_ds.orth2info_dict[wrd]['ヨミ']\n",
        "        # else:\n",
        "        #     _yomi = self.mecab_yomi(wrd).strip().split()[0]\n",
        "        return _yomi\n",
        "\n",
        "    def wrd2phon_ids(self, wrd:str)->list:\n",
        "        _yomi = self.wrd2yomi(wrd)\n",
        "        _yomi = kunrei(_yomi).split(' ')\n",
        "        ids = [self.phoneme.index(idx) for idx in _yomi]\n",
        "        ids = [self.phoneme.index('<SOW>')] + ids + [self.phoneme.index('<EOW>')]\n",
        "        return ids\n",
        "\n",
        "    def wrd2info(self, wrd:str)->dict:\n",
        "        if wrd in self.words:\n",
        "            return self.old_ds.orth2info_dict[wrd]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "os2p_ds = OS2P_Dataset()\n",
        "#print(os2p_ds.__len__())\n",
        "Ns = np.random.permutation(os2p_ds.__len__())\n",
        "for N in Ns[:3]:\n",
        "    inp, tch = os2p_ds.__getitem__(N)\n",
        "    print(f'inp.size():{inp.size()}')\n",
        "    print(f'n_hid:{n_hid}')\n",
        "    print(f'tch:{tch}')\n",
        "    print(f'os2p_ds.phon_ids2phon(tch.detach().numpy()):{os2p_ds.phon_ids2phon(tch.detach().numpy())}')\n",
        "    print(f'os2p_ds.words[0]:{os2p_ds.words[N]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cbb0b8f-2fb7-4b3e-995c-4723d3d24b7c",
      "metadata": {
        "id": "8cbb0b8f-2fb7-4b3e-995c-4723d3d24b7c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class Vec2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 inp_dim:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 decoder:nn.Module=o2p.decoder,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.decoder = copy.deepcopy(decoder)\n",
        "\n",
        "        # 単語の意味ベクトル a.k.a 埋め込み表現 を decoder の中間層に接続するための変換層\n",
        "        # 別解としては，入力層に接続する方法があるが，それはまた別実装にする\n",
        "        self.enc_transform_layer = nn.Linear(\n",
        "            in_features=inp_dim,\n",
        "            out_features=n_hid)\n",
        "        self.decoder_emb = nn.Embedding(\n",
        "            num_embeddings=dec_vocab_size,\n",
        "            embedding_dim=n_hid,\n",
        "            padding_idx=0)\n",
        "\n",
        "        self.decoder = nn.LSTM(\n",
        "            input_size=n_hid,\n",
        "            hidden_size=n_hid,\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.bi_fact = 2 if bidirectional else 1\n",
        "        self.out_layer = nn.Linear(self.bi_fact * n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "        enc_emb = self.enc_transform_layer(enc_inp)\n",
        "        hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "        hnx = hnx.unsqueeze(0)\n",
        "        cnx = cnx.unsqueeze(0)\n",
        "\n",
        "        if self.bi_fact == 2:\n",
        "            hnx = hnx.repeat(2)\n",
        "            cnx = cnx.repeat(2)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "\n",
        "        batch_size = enc_inp.size(0)\n",
        "        exp_hid_size = self.decoder.get_expected_hidden_size(enc_inp, batch_sizes=[batch_size])\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        return self.out_layer(dec_out)\n",
        "\n",
        "# 以下確認作業\n",
        "ds = os2p_ds\n",
        "os2p = Vec2Seq(\n",
        "    inp_dim=ds.w2v.vector_size+n_hid,\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_hid=n_hid,\n",
        "    n_layers=n_layers,\n",
        "    bidirectional=bidirectional).to(device)\n",
        "print(os2p.eval())\n",
        "\n",
        "res = fit_seq2seq(epochs=1, model=os2p, ds=os2p_ds, interval=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2661a5fc-7d25-4c73-9b2a-eaeb010cf9b9",
      "metadata": {
        "id": "2661a5fc-7d25-4c73-9b2a-eaeb010cf9b9"
      },
      "source": [
        "## 2.3 モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a95cd9a-c188-4df6-ba6b-2b22f715dd6b",
      "metadata": {
        "id": "2a95cd9a-c188-4df6-ba6b-2b22f715dd6b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "res = fit_seq2seq(epochs=10, model=os2p, ds=os2p_ds, interval=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c25f089-a715-4fb1-9b29-46fbb0dd5e85",
      "metadata": {
        "id": "7c25f089-a715-4fb1-9b29-46fbb0dd5e85",
        "tags": []
      },
      "source": [
        "## 3.2 訓練結果の評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89521af1-523e-4af5-a128-979fd6583e08",
      "metadata": {
        "id": "89521af1-523e-4af5-a128-979fd6583e08",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os2p_errors = eval_seq2seq(model=os2p, ds=os2p_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dbb3741-7538-4609-a9c0-37f2ae7bee28",
      "metadata": {
        "id": "0dbb3741-7538-4609-a9c0-37f2ae7bee28",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os2p_errors.keys()\n",
        "for err in os2p_errors['エラー']:\n",
        "    print(err)\n",
        "print(f\"正解率: {os2p_errors['正解率']:.3f} %\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff132b69-c8f0-4540-a555-f1a9fe8f6c6e",
      "metadata": {
        "id": "ff132b69-c8f0-4540-a555-f1a9fe8f6c6e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(os2p.eval())\n",
        "state_dict = os2p.state_dict()\n",
        "fname = '2023_1117os2ps_hid128.pt'\n",
        "torch.save(state_dict, fname)\n",
        "\n",
        "os2p_saved = Vec2Seq(\n",
        "    inp_dim=ds.w2v.vector_size+n_hid,\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_hid=n_hid,\n",
        "    n_layers=n_layers,\n",
        "    bidirectional=bidirectional).to(device)\n",
        "os2p_saved.load_state_dict(state_dict)\n",
        "os2p_saved_errors = eval_seq2seq(model=os2p_saved, ds=os2p_ds)\n",
        "#os2p_saved_errors.keys()\n",
        "for err in os2p_saved_errors['エラー']:\n",
        "    print(err)\n",
        "print(f\"正解率: {os2p_saved_errors['正解率']:.3f} %\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867cff25-ca1a-4227-b8cc-d34558ca7b18",
      "metadata": {
        "id": "867cff25-ca1a-4227-b8cc-d34558ca7b18"
      },
      "source": [
        "## 3.1 データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310e2153-6cdb-4c78-ac53-c01e7eb753e3",
      "metadata": {
        "id": "310e2153-6cdb-4c78-ac53-c01e7eb753e3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "#enc_emb.dtype\n",
        "#enc_inp\n",
        "\n",
        "N = 0\n",
        "x, y = ds.__getitem__(N)\n",
        "enc_inp = torch.from_numpy(np.array(x)).to(device).unsqueeze(0)\n",
        "enc_emb = model.enc_transform_layer(enc_inp)\n",
        "hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "dec_inp = y.to(device)\n",
        "dec_emb = model.decoder_emb(dec_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522735bf-09c1-4ff1-a490-4e89c0de27ed",
      "metadata": {
        "id": "522735bf-09c1-4ff1-a490-4e89c0de27ed",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# isPrint = False\n",
        "# errors = []\n",
        "# for N in tqdm(range(_psylex71_ds.__len__())):\n",
        "# #for N in np.random.permutation(_psylex71_ds.__len__())[:100]:\n",
        "#     x, y = _psylex71_ds.__getitem__(N)\n",
        "#     enc_inp = torch.from_numpy(np.array(x)).to(device).unsqueeze(0)\n",
        "#     enc_emb = model.out_layer(enc_inp)\n",
        "#     hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "#     dec_inp = y.to(device)\n",
        "#     dec_emb = model.decoder_emb(dec_inp).to(device)\n",
        "#     dec_out, (hny, cny) = model.decoder(dec_emb,(hnx, cnx))\n",
        "#     dec_out = model.out_layer(dec_out).to('cpu')\n",
        "#     y_ids = np.argmax(dec_out.detach().numpy(),axis=1)\n",
        "\n",
        "#     n_correct = np.array((y_ids[1:-1] == _psylex71_ds.getitem(N)[2]).sum())\n",
        "#     isOK = n_correct == len(_psylex71_ds.getitem(N)[2])\n",
        "#     color = 'grey' if isOK else 'red'\n",
        "\n",
        "#     if not isOK:\n",
        "#         errors.append((N,y_ids))\n",
        "#         if isPrint:\n",
        "#             print(colored((f'{N:05d}', #y_ids,\n",
        "#                            \"\".join(p for p in _psylex71_ds.phon_ids2phn(y_ids[1:-1]))),color,attrs=[\"bold\"]), end=\" \")\n",
        "#             print(_psylex71_ds.getitem(N))\n",
        "\n",
        "# cr = len(errors) / _psylex71_ds.__len__()\n",
        "# print(f'総エラー数:{len(errors)}',\n",
        "#       f'正解率:{(1.-cr)*100:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20663884-3b9a-465f-b022-b55449aeacf3",
      "metadata": {
        "id": "20663884-3b9a-465f-b022-b55449aeacf3"
      },
      "source": [
        "# 4 聞き取り理解モデル p2s 音韻から意味"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33f3a0e-4a46-489b-ad89-6675ef03fc43",
      "metadata": {
        "id": "d33f3a0e-4a46-489b-ad89-6675ef03fc43",
        "tags": []
      },
      "outputs": [],
      "source": [
        "help(_psylex71_ds.w2v.similar_by_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b45a6d9-f49d-4eae-a768-f3050f022334",
      "metadata": {
        "id": "5b45a6d9-f49d-4eae-a768-f3050f022334",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class EncDec_s2s(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sem_dim:int,\n",
        "                 n_hid:int):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = nn.Linear(in_features=sem_dim,\n",
        "                                      out_features=n_hid)\n",
        "        self.out_layer = nn.Linear(in_features=n_hid,\n",
        "                                   out_features=sem_dim)\n",
        "\n",
        "    def forward(self, enc_inp):\n",
        "        hid = self.hidden_layer(enc_inp)\n",
        "        out = self.out_layer(hid)\n",
        "        return out\n",
        "\n",
        "\n",
        "n_hid = 128\n",
        "#model = EncDec_s2s(sem_dim=_psylex71_ds.w2v.vector_size,\n",
        "#                   n_hid=n_hid)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(_psylex71_ds.w2v.vector_size, n_hid),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(n_hid, n_hid),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(n_hid, _psylex71_ds.w2v.vector_size),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "epochs = 20\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "interval = int(_psylex71_ds.__len__()/batch_size) >> 2\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for x, y in dataloader:\n",
        "        tch = torch.tensor([_x.detach().numpy() for _x in x]).to(device)\n",
        "\n",
        "        out = model(tch)\n",
        "        loss = criterion_dec(out, tch)\n",
        "        losses.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item():.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec79cc4b-1865-4e9b-833b-da1c9a3857c7",
      "metadata": {
        "id": "ec79cc4b-1865-4e9b-833b-da1c9a3857c7"
      },
      "source": [
        "# 5 聞き取り書き取りモデル p2o 音韻から書記"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0586cf-b044-473a-8cb0-6948d5a4a18e",
      "metadata": {
        "id": "ce0586cf-b044-473a-8cb0-6948d5a4a18e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "model = p2o\n",
        "model.train()\n",
        "\n",
        "#epochs = 10\n",
        "epochs = 5\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "\n",
        "ds = _psylex71_ds_p2o\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "dataloader = dl_p2o\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch+1:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713f02ed-0e6c-439b-83ee-30ec9d04b1aa",
      "metadata": {
        "id": "713f02ed-0e6c-439b-83ee-30ec9d04b1aa"
      },
      "source": [
        "# 6 写字モデル o2o 書記から書記"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396a24b2-4c67-4151-85f3-26a222815efc",
      "metadata": {
        "id": "396a24b2-4c67-4151-85f3-26a222815efc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "model = o2o\n",
        "model.train()\n",
        "\n",
        "#epochs = 10\n",
        "epochs = 2\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "\n",
        "ds = _psylex71_ds_o2o\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "dataloader = dl_o2o\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch+1:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980bd3e6-ff0e-47a9-b988-acce950324d3",
      "metadata": {
        "id": "980bd3e6-ff0e-47a9-b988-acce950324d3"
      },
      "source": [
        "# 7 内部で納得モデル s2s 意味から意味"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678c1708-34f9-4542-9908-3d0a8fb9638b",
      "metadata": {
        "id": "678c1708-34f9-4542-9908-3d0a8fb9638b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = s2s\n",
        "model.eval()\n",
        "\n",
        "model.train()\n",
        "\n",
        "#epochs = 10\n",
        "epochs = 2\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "\n",
        "ds = _psylex71_ds_o2o\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "dataloader = dl_o2o\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch+1:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9326c7d4-1f49-479d-87ac-4015b1c8ef7d",
      "metadata": {
        "id": "9326c7d4-1f49-479d-87ac-4015b1c8ef7d"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "model = s2s\n",
        "model.train()\n",
        "\n",
        "#epochs = 10\n",
        "epochs = 2\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "\n",
        "ds = _psylex71_ds_s2s\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "dataloader = dl_s2s\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch+1:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced65f69-2dc2-46f8-ad7f-5303555bad1d",
      "metadata": {
        "id": "ced65f69-2dc2-46f8-ad7f-5303555bad1d"
      },
      "source": [
        "# 8 書き出しモデル s2o 意味から書記へ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff6e5bc-6da6-44cf-82d6-24f12194ffdf",
      "metadata": {
        "id": "bff6e5bc-6da6-44cf-82d6-24f12194ffdf"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "model = s2o\n",
        "model.train()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# 訓練ループ\n",
        "ds = _psylex71_ds_s2o\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "dataloader = dl_s2o\n",
        "losses = []\n",
        "#epochs = 10\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out = model(enc_inp, dec_inp)\n",
        "        loss = criterion(out[0], tch[0])\n",
        "        for h in range(1,len(tch)):\n",
        "            loss += criterion(out[h], tch[h])\n",
        "        losses.append(loss.item()/batch_size)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch+1:2d}, batch:{i:2d}, loss:{loss.item()/batch_size:.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a84910a-c15b-4b07-847a-61e4011041c0",
      "metadata": {
        "id": "6a84910a-c15b-4b07-847a-61e4011041c0"
      },
      "source": [
        "# 9 黙読モデル o2s 書記から意味へ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de4c982-0e03-4275-89ab-d4320c7ee0c4",
      "metadata": {
        "id": "1de4c982-0e03-4275-89ab-d4320c7ee0c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model = o2s\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "criterion_dec = nn.MSELoss()\n",
        "criterion_enc = nn.CrossEntropyLoss()\n",
        "\n",
        "ds = psylex71_ds_o2s\n",
        "dataloader = dl_o2s\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "epochs = 5\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        tch = torch.tensor([x.detach().numpy() for x in _tch]).to(device)\n",
        "        out, enc_out = model(enc_inp)\n",
        "        loss = criterion_dec(out, tch)\n",
        "        for _x, _y in zip(enc_out[:,:-1], enc_inp[:,1:]):\n",
        "            loss += criterion_enc(_x, _y)\n",
        "        losses.append(loss.item()/len(_inp))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(_inp):.3f}')\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdabfa8-390d-4ad3-8ad7-49ad66a7f908",
      "metadata": {
        "id": "5cdabfa8-390d-4ad3-8ad7-49ad66a7f908"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "model = o2s\n",
        "ds = psylex71_ds_o2s\n",
        "dataloader = dl_o2s\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "criterion_dec = nn.MSELoss()\n",
        "criterion_enc = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "#epochs = 10\n",
        "epochs = 2\n",
        "\n",
        "# 訓練ループ\n",
        "losses = []\n",
        "interval = int(ds.__len__()/batch_size) >> 2\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    i = 0\n",
        "    for _inp, _tch in dataloader:\n",
        "\n",
        "        enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "        #tch = torch.tensor([x.detach().numpy() for x in _tch]).to(device)\n",
        "        tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "        out, enc_out = model(enc_inp)\n",
        "        loss = criterion_dec(out, tch)\n",
        "        for _x, _y in zip(enc_out[:,:-1], enc_inp[:,1:]):\n",
        "\n",
        "            print(_x.size(), _y.size())\n",
        "            loss += criterion_enc(_x, _y)\n",
        "            sys.exit()\n",
        "        losses.append(loss.item()/len(_inp))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "        if (i % interval) == 0:\n",
        "            print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(_inp):.3f}')\n",
        "\n",
        "        #dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "        #out = model(enc_inp)  # , dec_inp)\n",
        "        #loss = criterion(out[0], tch[0])\n",
        "        #for h in range(1,len(tch)):\n",
        "        #    loss += criterion(out[h], tch[h])\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f'Training time {total_time_str}')\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8daded7d-74be-4292-9bf9-e6b8cbb82a4e",
      "metadata": {
        "id": "8daded7d-74be-4292-9bf9-e6b8cbb82a4e"
      },
      "source": [
        "# 10 書記から意味を解して音韻\n",
        "\n",
        "# 7) 書記から意味を介さず音韻\n",
        "# 8) 6 と 7 の比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0171f1b-c674-46ca-8a18-0bfb9a7a9d58",
      "metadata": {
        "id": "d0171f1b-c674-46ca-8a18-0bfb9a7a9d58",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#help(RAM.chars_joyo)\n",
        "j = RAM.chars_joyo()\n",
        "#print(dir(j))\n",
        "ch_list = ['<PAD>', '<SOW>', '<EOW>', '<UNK>'] + j.char_list\n",
        "not_chlist = []\n",
        "for N in range(_psylex71_ds.__len__()):\n",
        "    wrd = _psylex71_ds.getitem(N)[0]\n",
        "    for ch in wrd:\n",
        "        if (ch not in ch_list) and (ch not in not_chlist):\n",
        "            not_chlist.append(ch)\n",
        "print(len(not_chlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e937129e-1e76-42ad-a198-e3e3a474ed58",
      "metadata": {
        "id": "e937129e-1e76-42ad-a198-e3e3a474ed58",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(sorted(not_chlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701c70ce-432e-41cf-a66b-7ad86ccfe0fd",
      "metadata": {
        "id": "701c70ce-432e-41cf-a66b-7ad86ccfe0fd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#help(RAM.chars_joyo)\n",
        "print(len(grapheme))\n",
        "#print(grapheme)\n",
        "#print(chars_list + not_chars_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00941ab3-4748-48b8-8787-947623f0e525",
      "metadata": {
        "id": "00941ab3-4748-48b8-8787-947623f0e525",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # 訓練関数の定義\n",
        "# def fit_seq2vec(\n",
        "#     model:torch.nn.modules.module.Module=o2p,\n",
        "#     epochs:int=10,\n",
        "#     ds:Dataset=psylex71_ds_o2s,\n",
        "#     dataloader:torch.utils.data.dataloader.DataLoader=dl_o2s,\n",
        "#     optimizer:torch.optim=None,\n",
        "#     lr:float=0.001,\n",
        "#     criterion_dec:torch.nn.modules.loss=nn.MSELoss(),\n",
        "#     criterion_enc:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "#     interval:int=None,\n",
        "#     isPrint:bool=False,\n",
        "#     losses:list=None,\n",
        "#     isDraw:bool=True,):\n",
        "#     \"\"\" Seq2vec の訓練に用いる関数\"\"\"\n",
        "\n",
        "#     start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "#     if losses == None:\n",
        "#         losses = []\n",
        "\n",
        "#     model.train()\n",
        "\n",
        "#     if optimizer == None:\n",
        "#         optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#     criterion_dec = nn.MSELoss()\n",
        "#     criterion_enc = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "#     #criterion_enc = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "#     if interval == None:\n",
        "#         interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         i = 0\n",
        "#         for _inp, _tch in dataloader:\n",
        "#             enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "#             tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "#             out, enc_out = model(enc_inp)\n",
        "\n",
        "#             out = out.squeeze(0)\n",
        "#             loss = criterion_dec(out, tch)\n",
        "#             for _x, _y in zip(enc_out[:,:-1,:], enc_inp[:,1:]):\n",
        "#                 # print(f'enc_out[0].size():{enc_out[0].size()}',\n",
        "#                 #       f'enc_inp[0].size():{enc_inp[0].size()}')\n",
        "#                 # print(f'enc_out[0].dtype:{enc_out[0].dtype}',\n",
        "#                 #       f'enc_inp[0].dtype:{enc_inp[0].dtype}')\n",
        "#                 loss += criterion_enc(_x, _y)\n",
        "#                 # sys.exit()\n",
        "#             losses.append(loss.item()/len(_inp))\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             i += 1\n",
        "#             if (i % interval) == 0:\n",
        "#                 print(f'epoch:{epoch+1:2d}',\n",
        "#                       f'batch:{i:2d}',\n",
        "#                       f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "#     end_time = time.time()\n",
        "#     total_time = end_time - start_time\n",
        "#     total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "#     if isDraw:\n",
        "#         plt.plot(losses)\n",
        "#         plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "#         plt.show()\n",
        "\n",
        "#     return {'Training time': total_time_str,\n",
        "#             'losses': losses,\n",
        "#             'optimizer': optimizer,\n",
        "#             'time': total_time }\n",
        "\n",
        "# #fit_seq2vec(epochs=10, model=p2s, lr=0.0001, ds=psylex71_ds_p2s, dataloader=dl_p2s); # 聴理解モデル\n",
        "# fit_seq2vec(epochs=3, model=o2s, lr=0.0001, ds=psylex71_ds_o2s, dataloader=dl_o2s); # 印字理解モデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "327aeb62-9938-462f-bb71-6593268a5eea",
      "metadata": {
        "id": "327aeb62-9938-462f-bb71-6593268a5eea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61ffeaa-1407-4adf-90ba-cc01cfa0d53b",
      "metadata": {
        "id": "e61ffeaa-1407-4adf-90ba-cc01cfa0d53b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# start_time = time.time()\n",
        "\n",
        "# model = s2p\n",
        "# optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "# #epochs = 10\n",
        "# epochs = 2\n",
        "\n",
        "# model.train()\n",
        "# interval = int(ds.__len__()/batch_size) >> 2\n",
        "# losses = []\n",
        "# dataloader = dl_s2p\n",
        "# for epoch in range(epochs):\n",
        "#     i = 0\n",
        "#     for _inp, _tch in dataloader:\n",
        "#         enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "#         dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "#         tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "#         out = model(enc_inp, dec_inp)\n",
        "#         loss = criterion(out[0], tch[0])\n",
        "#         for h in range(1,len(tch)):\n",
        "#             loss += criterion(out[h], tch[h])\n",
        "#         losses.append(loss.item()/len(enc_inp))\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         i += 1\n",
        "#         if (i % interval) == 0:\n",
        "#             print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(_inp):.3f}')\n",
        "\n",
        "# end_time = time.time()\n",
        "# total_time = end_time - start_time\n",
        "# total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "# print(f'Training time {total_time_str}')\n",
        "\n",
        "# plt.plot(losses)\n",
        "# plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a180d4c-d735-4792-960b-54e36d977960",
      "metadata": {
        "id": "5a180d4c-d735-4792-960b-54e36d977960",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 軽く実行\n",
        "#result = fit_seq2seq(model=o2p, epochs=3, dataloader=dl_o2p) # 音読モデル\n",
        "#fit_seq2seq(model=o2p, dataloader=dl_o2p) # 音読モデル\n",
        "#fit_seq2seq(epochs=1, model=o2p, dataloader=dl_o2p); # 音読モデル\n",
        "#fit_seq2seq(epochs=1, model=p2p, daftaloader=dl_p2p)  # 復唱モデル\n",
        "#fit_seq2seq(epochs=1, model=p2o, dataloader=dl_p2o); # ディクテーションモデル\n",
        "#fit_seq2seq(epochs=1, model=o2o, dataloader=dl_o2o); # 写字モデル\n",
        "#result = fit_seq2seq(model=s2p, epochs=3, dataloader=dl_s2p) # 発話モデル\n",
        "#result = fit_seq2seq(model=s2o, epochs=3, dataloader=dl_s2o) # 書字モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1beca3b-deb3-4ce9-8e04-33b5eaf55439",
      "metadata": {
        "id": "d1beca3b-deb3-4ce9-8e04-33b5eaf55439"
      },
      "source": [
        "# 学習結果の検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f368ec96-fd7c-4ece-83fe-aa2d0ab67523",
      "metadata": {
        "id": "f368ec96-fd7c-4ece-83fe-aa2d0ab67523",
        "tags": []
      },
      "outputs": [],
      "source": [
        "eval_seq2seq(model=o2p, ds=psylex71_ds_o2p, isPrint=True)\n",
        "#eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "#eval_seq2seq(isPrint=True)\n",
        "#eval_seq2seq(model=o2p, ds=psylex71_ds_o2p)\n",
        "#eval_seq2seq(model=p2p, ds=psylex71_ds_p2p)\n",
        "#eval_seq2seq(model=o2o, ds=psylex71_ds_o2o)\n",
        "#eval_seq2seq(model=p2o, ds=psylex71_ds_p2o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd41ea7-4205-4b52-a75c-cda4bb5b2c11",
      "metadata": {
        "id": "8dd41ea7-4205-4b52-a75c-cda4bb5b2c11",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "isPrint = False\n",
        "errors = []\n",
        "for N in tqdm(range(ds.__len__())):\n",
        "    x, y = ds.__getitem__(N)\n",
        "    enc_inp, dec_inp = x.unsqueeze(0), y.unsqueeze(0)\n",
        "    grand_truth = y.detach().numpy()[1:-1]\n",
        "    y_hat = p2p(enc_inp, dec_inp).to('cpu')\n",
        "    y_hat = np.argmax(y_hat.squeeze(0).detach().numpy(), axis=1)[1:-1]\n",
        "\n",
        "    if len(y_hat) == len(grand_truth):\n",
        "        n_correct = np.array((y_hat == grand_truth).sum())\n",
        "        isOK = n_correct == len(grand_truth)\n",
        "    else:\n",
        "        isOK = False\n",
        "\n",
        "    if not isOK:\n",
        "        errors.append((N,y_hat))\n",
        "        if isPrint:\n",
        "            color = 'grey' if isOK else 'red'\n",
        "            print(colored((f'idx:{N:5d}',\n",
        "                           f'出力:{ds.phon_ids2phn(y_hat)}',\n",
        "                           f'正解:{ds.phon_ids2phn(grand_truth)}',\n",
        "                           f'単語:{ds.getitem(N)[0]}',\n",
        "                          ), color, attrs=['bold']))\n",
        "\n",
        "cr = len(errors) / N\n",
        "#cr = len(errors) / _psylex71_ds.__len__()\n",
        "print(f'総エラー数:{len(errors)}',\n",
        "      f'正解率:{(1.-cr)*100:.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b132dea-fec6-432e-ad42-fde5fc49e0d0",
      "metadata": {
        "id": "3b132dea-fec6-432e-ad42-fde5fc49e0d0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# isPrint = True\n",
        "# errors = []\n",
        "# model.eval()\n",
        "# for N in tqdm(range(ds.__len__())):\n",
        "#     x, y = ds.__getitem__(N)\n",
        "#     x, y = x[0].to(device), y[0].to(device) # ds.__getitem__(N)[1].to(device)\n",
        "\n",
        "#     enc_inp, dec_inp = x[1:].unsqueeze(0), x[:-1].unsqueeze(0)\n",
        "#     y = model(enc_inp, dec_inp).to('cpu')\n",
        "#     y_ids = np.argmax(y.squeeze(0).detach().numpy(), axis=1)[1:]\n",
        "#     y_phon = _psylex71_ds.phon_ids2phn(y_ids)\n",
        "#     grand_truth = _psylex71_ds.getitem(N)\n",
        "\n",
        "#     n_correct = np.array((y_ids == grand_truth[2]).sum())\n",
        "#     isOK = n_correct == len(grand_truth[2])\n",
        "\n",
        "#     if not isOK:\n",
        "#         errors.append((N,y_ids))\n",
        "#         if isPrint:\n",
        "#             color = 'grey' if isOK else 'red'\n",
        "#             print(colored((f'idx:{N:5d}',\n",
        "#                            f'出力:{y_phon}',\n",
        "#                            #f'出力ID:{y_ids}',\n",
        "#                            #f'{grand_truth[2]}',\n",
        "#                            f'正解:{_psylex71_ds.phon_ids2phn(grand_truth[2])}',\n",
        "#                            f'単語:{grand_truth[0]}',\n",
        "#                           ), color, attrs=['bold']))\n",
        "\n",
        "# cr = len(errors) / N\n",
        "# #cr = len(errors) / _psylex71_ds.__len__()\n",
        "# print(f'総エラー数:{len(errors)}',\n",
        "#       f'正解率:{(1.-cr)*100:.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd4c53b-20a0-4a43-923c-272ef4fbdd14",
      "metadata": {
        "id": "3fd4c53b-20a0-4a43-923c-272ef4fbdd14",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# isPrint = False\n",
        "# errors = []\n",
        "# ds = _psylex71_ds\n",
        "# model.eval()\n",
        "# for N in tqdm(range(ds.__len__())):\n",
        "#     x = ds.__getitem__(N)[1].to(device)\n",
        "\n",
        "#     enc_inp, dec_inp = x[1:].unsqueeze(0), x[:-1].unsqueeze(0)\n",
        "#     y = model(enc_inp, dec_inp).to('cpu')\n",
        "#     y_ids = np.argmax(y.squeeze(0).detach().numpy(), axis=1)[1:]\n",
        "#     y_phon = ds.phon_ids2phn(y_ids)\n",
        "#     grand_truth = ds.getitem(N)\n",
        "\n",
        "#     n_correct = np.array((y_ids == grand_truth[2]).sum())\n",
        "#     isOK = n_correct == len(grand_truth[2])\n",
        "\n",
        "#     if not isOK:\n",
        "#         errors.append((N,y_ids))\n",
        "#     if isPrint:\n",
        "#         color = 'grey' if isOK else 'red'\n",
        "#         print(colored((f'idx:{N:5d}',\n",
        "#                        f'出力:{y_phon}',\n",
        "#                        #f'出力ID:{y_ids}',\n",
        "#                        #f'{grand_truth[2]}',\n",
        "#                        f'正解:{ds.phon_ids2phn(grand_truth[2])}',\n",
        "#                        f'単語:{grand_truth[0]}',\n",
        "#                       ), color, attrs=['bold']))\n",
        "\n",
        "# cr = len(errors) / N\n",
        "# #cr = len(errors) / _psylex71_ds.__len__()\n",
        "# print(f'総エラー数:{len(errors)}',\n",
        "#       f'正解率:{(1.-cr)*100:.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939ed800-9e03-41c5-b195-fb28665b45e5",
      "metadata": {
        "id": "939ed800-9e03-41c5-b195-fb28665b45e5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# N=0\n",
        "# x, y = _psylex71_ds_p2p.__getitem__(N) # [1] .unsqueeze(0)\n",
        "# x = x.unsqueeze(0)\n",
        "# y = y.unsqueeze(0)\n",
        "# y_hat = model(x,y)\n",
        "# _psylex71_ds.phon_ids2phn(np.argmax(y_hat.squeeze(0).detach().numpy(),axis=1))\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72df88f9-cabd-4c85-a217-5b2e4e9bfeea",
      "metadata": {
        "id": "72df88f9-cabd-4c85-a217-5b2e4e9bfeea",
        "tags": []
      },
      "outputs": [],
      "source": [
        "errors = []\n",
        "p2p.eval()\n",
        "ds = _psylex71_ds_p2p\n",
        "isPrint = True\n",
        "\n",
        "for N in tqdm(range(ds.__len__())):\n",
        "#for N in np.random.permutation(_psylex71_ds.__len__())[:100]:\n",
        "    inp, tch = ds.__getitem__(N)\n",
        "\n",
        "    enc_inp, dec_inp = inp.unsqueeze(0), tch.unsqueeze(0)\n",
        "\n",
        "    tch = dec_inp.clone().detach().squeeze(0).numpy()\n",
        "\n",
        "    enc_emb = p2p.encoder_emb(enc_inp)\n",
        "    enc_out, (enc_hid, enc_cel) = p2p.encoder(enc_emb)\n",
        "    dec_emb = p2p.decoder_emb(dec_inp)\n",
        "    dec_out, (hny, cny) = model.decoder(dec_emb, (enc_hid, enc_cel))\n",
        "    enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "    # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "    sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "    # sim の各次元のサイズを記録\n",
        "    batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "    # sim に対して，ソフトマックスを行うため形状を変更\n",
        "    simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "    # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "    alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "    # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "    c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "    # torch.cat だから c_t と dec_out とで合成\n",
        "    dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "    dec_out_ = p2p.combine_layer(dec_out_)\n",
        "\n",
        "    #print(f'dec_out.size():{dec_out.size()}')\n",
        "\n",
        "    # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "    # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "    # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "    enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "    # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "    sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "    # sim の各次元のサイズを記録\n",
        "    batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "    # sim に対して，ソフトマックスを行うため形状を変更\n",
        "    simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "    # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "    alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "    # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "    c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "    # torch.cat だから c_t と dec_out とで合成\n",
        "    dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "    dec_out_ = p2p.combine_layer(dec_out_)\n",
        "    dec_out = p2p.out_layer(dec_out_)\n",
        "    y_ids = np.argmax(dec_out.detach().numpy(),axis=-1).squeeze()\n",
        "\n",
        "    n_correct = np.array((y_ids == tch)).sum()\n",
        "    isOK = n_correct == len(tch)\n",
        "    color = 'grey' if isOK else 'red'\n",
        "\n",
        "    if not isOK:\n",
        "        errors.append((N,y_ids))\n",
        "    if isPrint:\n",
        "        print(f'{N:05d}',\n",
        "              colored(\"\".join(p for p in ds.phon_ids2phn(y_ids[:])),color,attrs=[\"bold\"]),\n",
        "              colored(\"\".join(p for p in ds.phon_ids2phn(tch[:])),  color,attrs=['bold']),\n",
        "              y_ids,\n",
        "              tch,\n",
        "              end=\" \")\n",
        "        print(ds.getitem(N)[0])\n",
        "    #if N >= 19:\n",
        "    #    break\n",
        "\n",
        "\n",
        "cr = len(errors) / N\n",
        "#cr = len(errors) / _psylex71_ds.__len__()\n",
        "print(f'総エラー数:{len(errors)}',\n",
        "      f'正解率:{(1.-cr)*100:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dd4b2a5-9c07-41e9-a8eb-ed953bdfbaa9",
      "metadata": {
        "id": "6dd4b2a5-9c07-41e9-a8eb-ed953bdfbaa9"
      },
      "source": [
        "# temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9130e792-e6b5-46ed-bd04-6ceaab9ca607",
      "metadata": {
        "id": "9130e792-e6b5-46ed-bd04-6ceaab9ca607",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "model.eval()\n",
        "enc, dec = psylex71_ds_o2s.__getitem__(0)\n",
        "enc_inp, dec_inp = enc.to(device), dec.to(device)\n",
        "y, _ = model(enc_inp) # .to('cpu')\n",
        "y_vec = out.detach().squeeze(0).numpy()\n",
        "wrd = psylex71_ds_o2s.getitem(0)[0]\n",
        "t_vec = psylex71_ds_o2s.w2v.get_vector(wrd)\n",
        "#print(y_vec.shape, t_vec.shape)\n",
        "\n",
        "_cos = scipy.spatial.distance.cosine(y_vec, t_vec)\n",
        "_euc = scipy.spatial.distance.euclidean(y_vec, t_vec)\n",
        "#print(f'{_cos:.5f}, {_euc:.5f}')\n",
        "w2v_cos = psylex71_ds_o2s.w2v.cosine_similarities(y_vec,[t_vec])\n",
        "print(f'scipy_cos:{_cos:.3f}',\n",
        "      f'scipy_euc:{_euc:.3f}',\n",
        "      f'w2v_cos  :{1. - w2v_cos[0]:.3f}')\n",
        "\n",
        "#help(psylex71_ds_o2s.w2v.cosine_similarities) # (y_hat,_y))\n",
        "#print(psylex71_ds_o2s.w2v.cosine_similarities(y_hat,_y))\n",
        "\n",
        "#help(psylex71_ds_o2p.w2v.similarity) # print(y.detach().numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff95b0c2-67ec-4398-88bc-d6b340a3a2e1",
      "metadata": {
        "id": "ff95b0c2-67ec-4398-88bc-d6b340a3a2e1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# start_time = time.time()\n",
        "\n",
        "# model = p2s\n",
        "# model.train()\n",
        "# optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "# criterion_dec = nn.MSELoss()\n",
        "# criterion_enc = nn.CrossEntropyLoss()\n",
        "\n",
        "# ds = psylex71_ds_p2s\n",
        "# dataloader = dl_p2s\n",
        "# interval = int(ds.__len__()/batch_size) >> 2\n",
        "# epochs = 1\n",
        "# losses = []\n",
        "# for epoch in range(epochs):\n",
        "#     i = 0\n",
        "#     for _inp, _tch in dataloader:\n",
        "#         enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "#         tch = torch.tensor([x.detach().numpy() for x in _tch]).to(device)\n",
        "#         out, enc_out = model(enc_inp)\n",
        "#         loss = criterion_dec(out, tch)\n",
        "#         for _x, _y in zip(enc_out[:,:-1], enc_inp[:,1:]):\n",
        "#             loss += criterion_enc(_x, _y)\n",
        "#         losses.append(loss.item()/len(_inp))\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         i += 1\n",
        "#         if (i % interval) == 0:\n",
        "#             print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(_inp):.3f}')\n",
        "\n",
        "# end_time = time.time()\n",
        "# total_time = end_time - start_time\n",
        "# total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "# print(f'Training time {total_time_str}')\n",
        "\n",
        "# plt.plot(losses)\n",
        "# plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1acd2d79-83de-4740-bed4-1568db2e244d",
      "metadata": {
        "id": "1acd2d79-83de-4740-bed4-1568db2e244d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# start_time = time.time()\n",
        "\n",
        "# model = o2s\n",
        "# model.train()\n",
        "# optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "# criterion_dec = nn.MSELoss()\n",
        "# criterion_enc = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "# ds = psylex71_ds_o2s\n",
        "# dataloader = dl_o2s\n",
        "# interval = int(ds.__len__()/batch_size) >> 2\n",
        "# epochs = 1\n",
        "# losses = []\n",
        "# for epoch in range(epochs):\n",
        "#     i = 0\n",
        "#     for _inp, _tch in dataloader:\n",
        "#         enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "#         tch = torch.tensor([x.detach().numpy() for x in _tch]).to(device)\n",
        "#         out, enc_out = model(enc_inp)\n",
        "#         loss = criterion_dec(out, tch)\n",
        "#         for _x, _y in zip(enc_out[:,:-1], enc_inp[:,1:]):\n",
        "#             print(f'_x.argmax(dim=1):{_x.argmax(-1)}',\n",
        "#                   f'_x.size():{_x.size()}',\n",
        "#                   f'_y.size():{_y.size()}')\n",
        "#             loss += criterion_enc(_x, _y)\n",
        "#         losses.append(loss.item()/len(_inp))\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         i += 1\n",
        "#         if (i % interval) == 0:\n",
        "#             print(f'epoch:{epoch:2d}, batch:{i:2d}, loss:{loss.item()/len(_inp):.3f}')\n",
        "\n",
        "# end_time = time.time()\n",
        "# total_time = end_time - start_time\n",
        "# total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "# print(f'Training time {total_time_str}')\n",
        "\n",
        "# plt.plot(losses)\n",
        "# plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f1a1b7-f1db-424f-91c7-cb0e37f7c244",
      "metadata": {
        "id": "29f1a1b7-f1db-424f-91c7-cb0e37f7c244",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# print(ds.getitem(0))\n",
        "# print(ds.__getitem__(0))\n",
        "\n",
        "#             for _x, _y in zip(enc_out[:,:-1,:], enc_inp[:,1:]):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca9dddc-61ed-4927-8399-e287ec6268f7",
      "metadata": {
        "id": "dca9dddc-61ed-4927-8399-e287ec6268f7"
      },
      "source": [
        "## 2 学習結果の評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16062529-100f-4899-a0ce-f884c6c4a23f",
      "metadata": {
        "id": "16062529-100f-4899-a0ce-f884c6c4a23f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "p2s.eval()\n",
        "isPrint = False\n",
        "errors = []\n",
        "for N in tqdm(range(ds.__len__())):\n",
        "\n",
        "    x, y = ds.__getitem__(N)\n",
        "    enc_inp = x.to(device).unsqueeze(0)\n",
        "    out, enc_out = model(enc_inp)\n",
        "    out = out.detach().squeeze().numpy()\n",
        "    print(N)\n",
        "    print(ds.getitem(N)[0])\n",
        "    print(ds.w2v.similar_by_vector(out,topn=3))\n",
        "\n",
        "    break\n",
        "\n",
        "cr = len(errors) / _psylex71_ds.__len__()\n",
        "print(f'総エラー数:{len(errors)}',\n",
        "      f'正解率:{(1.-cr)*100:.3f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}