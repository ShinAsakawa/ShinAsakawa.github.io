{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2025notebooks/2025_0626psylex71_CDP%2Bja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db9a97b-ee8e-41b4-b88e-8018bfe1484c",
      "metadata": {
        "id": "2db9a97b-ee8e-41b4-b88e-8018bfe1484c"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/refs/heads/master/2025figs/1998Zorzi_CDP_fig1.svg\">\n",
        "Zorzi+(1998) Fig.1 Architecture of the model. The arrow means full connectivity between layers. Each box stand for a group of letters (26) or phonemes (44).<br/>\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/project-ccap/project-ccap.github.io/refs/heads/master/2025figs/1998Zorzi_CDP_fig8.svg\">\n",
        "<p>Zorzi+(1998) Fig.8. Architecture of the model with the hidden layer pathway. In both the direct pathway and the mediated pathway the layers are fully connected (arrows).</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f00f3ba-87a0-40f2-9b7b-141186681f58",
      "metadata": {
        "id": "1f00f3ba-87a0-40f2-9b7b-141186681f58"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f'device:{device}')\n",
        "\n",
        "# 必要なライブラリの輸入\n",
        "from collections import OrderedDict\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "# import time\n",
        "# import datetime\n",
        "import operator\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname\n",
        "    import ipynbname\n",
        "\n",
        "FILEPATH = str(ipynbname.path()).split('/')[-1]\n",
        "print(f'FILEPATH:{FILEPATH}')\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0b5de0-5e4f-4f23-9e38-b20c1255349f",
      "metadata": {
        "id": "7d0b5de0-5e4f-4f23-9e38-b20c1255349f"
      },
      "source": [
        "# モーラ分かち書きの定義    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036cb4be-72bf-438b-a0de-48cb61fb0ac8",
      "metadata": {
        "id": "036cb4be-72bf-438b-a0de-48cb61fb0ac8"
      },
      "outputs": [],
      "source": [
        "# モーラ分かち書きの定義\n",
        "# source https://qiita.com/shimajiroxyz/items/a133d990df2bc3affc12\n",
        "import re\n",
        "\n",
        "# 各条件を正規表現で表す\n",
        "c1 = '[ウクスツヌフムユルグズヅブプヴ][ァィェォ]' #ウ段＋「ァ/ィ/ェ/ォ」\n",
        "c2 = '[イキシチニヒミリギジヂビピ][ャュェョ]' #イ段（「イ」を除く）＋「ャ/ュ/ェ/ョ」\n",
        "c3 = '[テデ][ィュ]' #「テ/デ」＋「ャ/ィ/ュ/ョ」\n",
        "c4 = '[ァ-ヴー]' #カタカナ１文字（長音含む）\n",
        "\n",
        "cond = '('+c1+'|'+c2+'|'+c3+'|'+c4+')'\n",
        "re_mora = re.compile(cond)\n",
        "\n",
        "def moraWakachi(kana_text):\n",
        "    kana_text = kana_text.replace('ヱ','エ').replace('ヰ','イ')\n",
        "    return re_mora.findall(kana_text)\n",
        "\n",
        "# text = 'シンシュンシャンソンショー'\n",
        "# print(text)\n",
        "# print(moraWakachi(text))\n",
        "# print('')\n",
        "\n",
        "# text = 'トーキョートッキョキョカキョク'\n",
        "# print(text)\n",
        "# print(moraWakachi(text))\n",
        "# print('')\n",
        "\n",
        "# text = 'アウトバーン'\n",
        "# print(text)\n",
        "# print(moraWakachi(text))\n",
        "# print('')\n",
        "\n",
        "# text = 'ガッキュウホウカイ'\n",
        "# print(text)\n",
        "# print(moraWakachi(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b66d9b-816f-4cae-b183-7ebb9511b76b",
      "metadata": {
        "id": "b2b66d9b-816f-4cae-b183-7ebb9511b76b"
      },
      "source": [
        "# 文字の定義，(学習文字，かな，カナ，数字，記号など)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9026f18c-c1b7-44d3-85cf-c91aecacd9eb",
      "metadata": {
        "id": "9026f18c-c1b7-44d3-85cf-c91aecacd9eb"
      },
      "outputs": [],
      "source": [
        "# 書記素の定義，書記素のうちカタカナを音韻表現としても利用\n",
        "\n",
        "seed = 42\n",
        "special_tokens = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "alphabet_upper_chars='ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'\n",
        "alphabet_lower_chars='ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "num_chars='０１２３４５６７８９'\n",
        "hira_chars='ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん'\n",
        "kata_chars='ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "#kata_chars=kata_chars+'一'  # カタカナ文字に伸ばし記号を加える\n",
        "#phon_list = list(kata_chars+'一')\n",
        "\n",
        "# # 句点コード\n",
        "# from RAM.char_ja import kuten as kuten\n",
        "# kuten_chars=kuten().chars\n",
        "\n",
        "# # 常用漢字\n",
        "# from RAM.char_ja import chars_joyo as chars_joyo\n",
        "# joyo_chars = \"\".join([ch for ch in chars_joyo().char_list])\n",
        "\n",
        "# 学習漢字 学年別\n",
        "_gakushu_list = ['一右雨円王音下火花貝学気休玉金九空月犬見五口校左三山四子糸字耳七車手十出女小上森人水正生青石赤先千川早草足村大男竹中虫町天田土二日入年白八百文本名木目夕立力林六',\n",
        "'引羽雲園遠黄何夏家科歌画会回海絵外角楽活間丸岩顔帰汽記弓牛魚京強教近兄形計元原言古戸午後語交光公工広考行高合国黒今才細作算姉市思止紙寺時自室社弱首秋週春書少場色食心新親図数星晴声西切雪線船前組走多太体台谷知地池茶昼朝長鳥直通弟店点電冬刀東当答頭同道読内南肉馬買売麦半番父風分聞米歩母方北妹毎万明鳴毛門夜野矢友曜用来理里話',\n",
        "'悪安暗委意医育員飲院運泳駅横屋温化荷界開階寒感漢館岸期起客宮急球究級去橋業局曲銀区苦具君係軽決血研県庫湖向幸港号根祭坂皿仕使始指死詩歯事持次式実写者主取守酒受州拾終習集住重宿所暑助勝商昭消章乗植深申真神身進世整昔全想相送息速族他打対待代第題炭短談着柱注丁帳調追定庭笛鉄転登都度島投湯等豆動童農波配倍箱畑発反板悲皮美鼻筆氷表病秒品夫負部服福物平返勉放味命面問役薬油有由遊予様洋羊葉陽落流旅両緑礼列練路和',\n",
        "'愛案以位囲胃衣印栄英塩央億加果課貨芽改械害街各覚完官管観関願喜器希旗機季紀議救求泣給挙漁競共協鏡極訓軍郡型径景芸欠結健建験固候功好康航告差最菜材昨刷察札殺参散産残司史士氏試児治辞失借種周祝順初唱松焼照省笑象賞信臣成清静席積折節説戦浅選然倉巣争側束続卒孫帯隊達単置仲貯兆腸低停底的典伝徒努灯働堂得特毒熱念敗梅博飯費飛必標票不付府副粉兵別変辺便包法望牧末満未脈民無約勇要養浴利陸料良量輪類令例冷歴連労老録',\n",
        "'圧易移因営永衛液益演往応恩仮価可河過賀解快格確額刊幹慣眼基寄規技義逆久旧居許境興均禁句群経潔件券検険減現限個故護効厚構耕講鉱混査再妻採災際在罪財桜雑賛酸師志支枝資飼似示識質舎謝授修術述準序承招証常情条状織職制勢性政精製税績責接設絶舌銭祖素総像増造則測属損態貸退団断築張提程敵適統導銅徳独任燃能破判版犯比肥非備俵評貧婦富布武復複仏編弁保墓報豊暴貿防務夢迷綿輸余預容率略留領',\n",
        "'異遺域宇映延沿我灰拡閣革割株巻干看簡危揮机貴疑吸供胸郷勤筋敬系警劇激穴憲権絹厳源呼己誤后孝皇紅鋼降刻穀骨困砂座済裁策冊蚕姿私至視詞誌磁射捨尺若樹収宗就衆従縦縮熟純処署諸除傷将障城蒸針仁垂推寸盛聖誠宣専泉洗染善創奏層操窓装臓蔵存尊宅担探誕暖段値宙忠著庁潮頂賃痛展党糖討届難乳認納脳派俳拝背肺班晩否批秘腹奮並閉陛片補暮宝訪亡忘棒枚幕密盟模訳優郵幼欲翌乱卵覧裏律臨朗論']\n",
        "\n",
        "_l = []\n",
        "for g in _gakushu_list:\n",
        "    for ch in g:\n",
        "        _l += ch\n",
        "gakushu_chars = \"\".join(ch for ch in _l)\n",
        "\n",
        "grph_list = []\n",
        "#for x in [hira_chars]:                       # 数字は入力文字としない場合\n",
        "#for x in [hira_chars, gakushu_chars]:             # 数字は入力文字としない場合\n",
        "for x in [hira_chars, kata_chars, num_chars, gakushu_chars]: # 数字も入力文字とする場合\n",
        "    for ch in x:\n",
        "        grph_list.append(ch)\n",
        "print(f'len(grph_list):{len(grph_list)}')\n",
        "print(f'全書記素 grph_list:{\"\".join([ch for ch in grph_list])}')\n",
        "\n",
        "# print(f'len(phon_list):{len(phon_list)}')\n",
        "# print(f'全音素 phon_list:{phon_list}')\n",
        "\n",
        "print(f'入力層の素子数 len(grph_list) + len(special_tokens)={len(grph_list) + len(special_tokens)}')\n",
        "# print(f'出力層の素子数 len(phon_list) + len(special_tokens)={len(phon_list) + len(special_tokens)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d147219-23e6-43c4-9afe-c0b907d9659c",
      "metadata": {
        "id": "6d147219-23e6-43c4-9afe-c0b907d9659c"
      },
      "source": [
        "# NTT 日本語の語彙特性 単語頻度データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c06d8b9-36b3-4014-9975-d36f57e16ac2",
      "metadata": {
        "id": "7c06d8b9-36b3-4014-9975-d36f57e16ac2"
      },
      "outputs": [],
      "source": [
        "# NTT 日本語の語彙特性単語頻度データ psylex71.txt の読み込み\n",
        "#HOME = os.environ['HOME']\n",
        "ntt_base = os.path.join(HOME, 'study/2017_2009AmanoKondo_NTTKanjiData')\n",
        "psy71_fname = os.path.join(HOME, ntt_base, 'psylex71utf8_.txt')  # ファイル名\n",
        "psylex71raw = open(psy71_fname, 'r').readlines()\n",
        "psylex71raw = [lin.strip().split(' ')[:6] for lin in psylex71raw]   # 空白 ' ' で分離し，年度ごとの頻度を削除\n",
        "print(f'len(psylex71raw):{len(psylex71raw)}')\n",
        "#, psylex71raw[1]\n",
        "\n",
        "\n",
        "valid_chars = kata_chars + 'ー'\n",
        "mora_dict = OrderedDict()\n",
        "\n",
        "for x in tqdm(psylex71raw[1:]):\n",
        "    _word =  x[psylex_ids['_wrd']]\n",
        "    _yomi = x[psylex_ids['_yomi']]\n",
        "    is_valid = True\n",
        "    for ch in _yomi:\n",
        "        if not ch in valid_chars:\n",
        "            is_valid = False\n",
        "    if is_valid:\n",
        "        morae = moraWakachi(_yomi)\n",
        "        for m in morae:\n",
        "            if not m in mora_dict:\n",
        "                mora_dict[m] = 1\n",
        "            else:\n",
        "                mora_dict[m] += 1\n",
        "\n",
        "print(f'len(mora_dict):{len(mora_dict)}')\n",
        "mora_list = sorted(mora_dict.keys())\n",
        "\n",
        "is_graph = False\n",
        "print(len(mora_dict), mora_dict)\n",
        "if is_graph:\n",
        "    N_mora=np.array([v for v in mora_dict.values()]).sum()\n",
        "    mora_count_sorted = sorted(mora_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    figsize=(24,4)\n",
        "    topN = 100\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.bar(range(topN), [x[1]/N_mora for x in mora_count_sorted[:topN]])\n",
        "    plt.xticks(ticks=range(topN), labels=[c[0] for c in mora_count_sorted[:topN]])\n",
        "\n",
        "    plt.title(f'モーラ頻度 (上位:{topN} 語)')\n",
        "    plt.ylabel('相対頻度')\n",
        "    plt.show()\n",
        "    #len(mora_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc83ecee-5079-4d80-bfe5-350739a23978",
      "metadata": {
        "id": "dc83ecee-5079-4d80-bfe5-350739a23978"
      },
      "outputs": [],
      "source": [
        "maxlen_grph = 2        # 書記素最大文字数 + 2 しているのは, 単語の前後に特殊トークン <SOW> <EOW> をつけるため\n",
        "valid_chars=grph_list  # 書記素リスト grph_list を有効文字リスト valid_chars とする\n",
        "ng_yomi_words = []\n",
        "dups_idx = []\n",
        "_psylex71_ = []\n",
        "\n",
        "#grph_cands=valid_chars\n",
        "#phon_cands=kata_chars\n",
        "#phon_cands = phon_list\n",
        "\n",
        "# Psylex71 一行のデータは 0:共通ID, 1:独自ID, 2:表記, 3:ヨミ, 4:品詞, 5:頻度 を取り出す。\n",
        "#n_idx=0; n_wrd=2; n_yomi=3; n_pos=4; n_frq=5\n",
        "psylex_ids = {'_idx':0, '_idx2':1, '_wrd':2, '_yomi':3, '_pos':4, '_frq':5, '_mora':6}\n",
        "print(f'psylex_ids{psylex_ids}')\n",
        "\n",
        "\n",
        "Psylex71 = OrderedDict()\n",
        "for lin in psylex71raw:\n",
        "    wrd = lin[psylex＿ids['_wrd']]\n",
        "    idx = lin[psylex＿ids['_idx']]\n",
        "    yomi = lin[psylex＿ids['_yomi']]\n",
        "    pos = lin[psylex＿ids['_pos']]\n",
        "    frq = lin[psylex＿ids['_frq']]\n",
        "\n",
        "    # print(f'type(lin):{type(lin)}')\n",
        "    # print(f'lin:{lin}')\n",
        "    # sys.exit()\n",
        "\n",
        "    if len(wrd) == maxlen_grph:  # 長さが maxlen_grph 文字である語に対して処理を行う\n",
        "\n",
        "        # ヨミの中にカタカナ以外の文字が入っていれば NG_flag を True にする\n",
        "        is_kata_yomi = True\n",
        "        for p in yomi:\n",
        "            if not p in kata_chars:\n",
        "                is_kata_yomi = False\n",
        "\n",
        "        # ヨミにカタカナ以外の文字が含まれていれば ng_yomi_words に加える\n",
        "        if is_kata_yomi == False:\n",
        "            ng_yomi_words.append((wrd,yomi))\n",
        "        else:\n",
        "\n",
        "            # valid_chars (学習漢字+)で構成されているか否かを判断\n",
        "            is_valid_grph = True\n",
        "            for i in range(maxlen_grph):\n",
        "                if not wrd[i] in valid_chars:\n",
        "                    is_valid_grph = False\n",
        "\n",
        "            if is_valid_grph == True:\n",
        "\n",
        "                _mora = moraWakachi(yomi) # .strip()  # モーラ分かち書きを行う\n",
        "                if idx in Psylex71:   # すでに ID 番号が登録されていれば dups_idx リストに加える\n",
        "                    dups_idx.append((idx, lin, (Psylex71[idx]['単語'], Psylex71[idx]['ヨミ'], _mora)))\n",
        "\n",
        "                Psylex71[idx] = {'単語': wrd, 'モーラ':_mora, 'ヨミ': yomi, '品詞': pos,'頻度': frq}\n",
        "                _psylex71_.append(lin + [_mora])\n",
        "\n",
        "\n",
        "# 読み (音韻表現) の最大長値の探索\n",
        "maxlen_phon = 0\n",
        "for a in _psylex71_:\n",
        "    if len(a[psylex_ids['_mora']]) > maxlen_phon:\n",
        "         maxlen_phon = len(a[psylex_ids['_mora']])\n",
        "\n",
        "# 結果の表示\n",
        "print(f'読み込んだ psylex71.txt の単語数 len(psylex71raw):{len(psylex71raw)}')\n",
        "print(f'Psylex71 の総単語数 len(_psylex71_):{len(_psylex71_)}')\n",
        "print(f'作成したデータベース辞書の項目数 len(Psylex71):{len(Psylex71)}')\n",
        "print(f'ヨミの最長文字数 maxlen_phon:{maxlen_phon}')\n",
        "print(f'len(mora_list):{len(mora_list)}')\n",
        "#print(f'音素 (読みのカタカナ文字)数 len(phon_cands):{len(phon_cands)}')\n",
        "print(f'Psylex71 におけるカタカナ以外のヨミのある単語数 len(ng_yomi_words):{len(ng_yomi_words)}')\n",
        "print(f'Psylex71 における ID 番号の重複数 len(dups_idx):{len(dups_idx)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef1d47a-7c2d-4171-a920-df4a54263fb3",
      "metadata": {
        "id": "4ef1d47a-7c2d-4171-a920-df4a54263fb3"
      },
      "source": [
        "# `Psylex71_Dataset` (モデルに Psylex71 を学習させるためのクラス) の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bdb138-4ce6-45d7-b745-bde4934eb29e",
      "metadata": {
        "id": "f0bdb138-4ce6-45d7-b745-bde4934eb29e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "class Psylex71_Dataset(torch.utils.data.Dataset):\n",
        "    '''ニューラルネットワークモデルに Psylex71 を学習させるための PyTorch 用データセットのクラス'''\n",
        "\n",
        "    def __init__(self,\n",
        "                 dic=Psylex71,\n",
        "                 grph_list=grph_list,\n",
        "                 phon_list=mora_list,\n",
        "                 special_tokens=special_tokens,\n",
        "                 maxlen_phon=maxlen_phon +2, # ＋2 しているのは <SOW>,<EOW> という 2 つのスペシャルトークンを付加するため\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.dic = dic\n",
        "        self.special_tokens = special_tokens\n",
        "        self.maxlen_phon = maxlen_phon\n",
        "        self.grph_list = grph_list\n",
        "        self.phon_list = phon_list\n",
        "        self.input_cands = grph_list\n",
        "        #self.target_cands = special_tokens + phon_list\n",
        "        self.target_cands = special_tokens + mora_list\n",
        "        # self.inputs = [v['単語'] for v in dic.values()]\n",
        "        # self.targets = [v['ヨミ'] for v in dic.values()]\n",
        "        # self.targets = [v['モーラ'] for v in dic.values()]\n",
        "        self.inputs = [v['単語'] for v in dic.values()]\n",
        "        self.targets = [v['ヨミ'] for v in dic.values()]\n",
        "        self.targets = [v['モーラ'] for v in dic.values()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dic)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp, tgt = self.inputs[idx], self.targets[idx]\n",
        "\n",
        "        # 入力信号にも <SOW>, <EOW> トークンを付与する場合\n",
        "        #inp = [self.input_cands.index('<SOW>')]  + [self.input_cands.index(x) for x in inp]  + [self.input_cands.index('<EOW>')]\n",
        "\n",
        "        # 入力信号にはスペシャルトークンを付与しない場合\n",
        "        inp = [self.input_cands.index(x) for x in inp]\n",
        "\n",
        "        # ターゲット (教師)信号 には <SOW>, <EOW> を付与する\n",
        "        tgt = [self.target_cands.index('<SOW>')] + [self.target_cands.index(x) for x in tgt] + [self.target_cands.index('<EOW>')]\n",
        "\n",
        "        while len(tgt) < self.maxlen_phon:\n",
        "            tgt = tgt + [self.target_cands.index('<PAD>')]\n",
        "\n",
        "        inp, tgt = torch.LongTensor(inp), torch.LongTensor(tgt)\n",
        "        return inp, tgt\n",
        "\n",
        "    def getitem(self, idx):\n",
        "        #inp, tgt = self.inputs[idx], self.targets[idx]\n",
        "        wrd = self.inputs[idx]\n",
        "        phn = self.targets[idx]\n",
        "        return wrd, phn\n",
        "\n",
        "    def ids2argmax(self, ids):\n",
        "        out = np.array([torch.argmax(idx).numpy() for idx in ids], dtype=np.int32)\n",
        "        return out\n",
        "\n",
        "    def ids2tgt(self, ids):\n",
        "        #out = [self.target_cands[torch.argmax(idx)] for idx in ids]\n",
        "        out = [self.target_cands[idx - len(self.special_tokens)] for idx in ids]\n",
        "        return out\n",
        "\n",
        "    def ids2inp(self, ids):\n",
        "        out = [self.input_cands[idx] for idx in ids]\n",
        "        #out = [self.input_cands[idx - len(self.special_tokens)] for idx in ids]\n",
        "        return out\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "        ret = []\n",
        "        for idx in ids:\n",
        "            if idx == self.target_cands.index('<EOW>'):\n",
        "                return ret+['<EOW>']\n",
        "            ret.append(self.target_cands[idx])\n",
        "        return ret\n",
        "\n",
        "\n",
        "psylex71_ds = Psylex71_Dataset()\n",
        "\n",
        "_ds = psylex71_ds\n",
        "#for N in np.random.permutation(psylex71_ds.__len__())[:15]:\n",
        "for N in range(15):\n",
        "    inp, tgt = psylex71_ds.__getitem__(N)\n",
        "    print(f'_ds.ids2inp(inp):{_ds.ids2inp(inp)}',\n",
        "          f'{inp.numpy()}',\n",
        "          f'_ds.target_ids2target(tgt):{_ds.target_ids2target(tgt)}',\n",
        "          f'{tgt.numpy()}')\n",
        "\n",
        "\n",
        "train_size = int(_ds.__len__() * 0.7)\n",
        "train_size = int(_ds.__len__() * 0.05)\n",
        "valid_size = _ds.__len__() - train_size\n",
        "train_ds, valid_ds = torch.utils.data.random_split(dataset=_ds, lengths=(train_size, valid_size), generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "batch_size = 64\n",
        "#batch_size = 1024\n",
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(dataset=valid_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def _collate_fn(batch):\n",
        "    inps, tgts = list(zip(*batch))\n",
        "    inps = list(inps)\n",
        "    tgts = list(tgts)\n",
        "    return inps, tgts\n",
        "\n",
        "# batch_size = 4\n",
        "train_dl = torch.utils.data.DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=_collate_fn)\n",
        "\n",
        "valid_dl = torch.utils.data.DataLoader(\n",
        "    dataset=valid_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=_collate_fn)\n",
        "\n",
        "print(f'train_ds.__len__():{train_ds.__len__()}')\n",
        "\n",
        "_ds = train_ds\n",
        "for N in range(15):\n",
        "    inp, tgt = _ds.__getitem__(N)\n",
        "    print(f'_ds.dataset.ids2inp(inp):{_ds.dataset.ids2inp(inp)}',\n",
        "          f'{inp.numpy()}',\n",
        "          f'_ds.datsset.target_ids2target(tgt):{_ds.dataset.target_ids2target(tgt)}',\n",
        "          f'{tgt.numpy()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e5596b-b653-4be2-a304-454a71f9c6d3",
      "metadata": {
        "id": "41e5596b-b653-4be2-a304-454a71f9c6d3"
      },
      "source": [
        "# TLA モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6f586e-7ea0-4fda-96f0-6b805bdd65a0",
      "metadata": {
        "id": "dc6f586e-7ea0-4fda-96f0-6b805bdd65a0"
      },
      "outputs": [],
      "source": [
        "class TLA(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 # maxlen_phon+2 しているのは単語の前後に <SOW>, <EOW> トークンを付けるため\n",
        "                 inp_size= (len(grph_list)+len(special_tokens)), # * (maxlen_grph + 2),\n",
        "                 inp_len=maxlen_grph, #  + 2,\n",
        "                 out_size=len(mora_list)+len(special_tokens),\n",
        "                 out_len=maxlen_phon+2,\n",
        "                 hid_size=128,\n",
        "                 device=device,\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.inp_size=inp_size\n",
        "        self.inp_len=inp_len\n",
        "        self.out_size=out_size\n",
        "        self.out_len=out_len\n",
        "        self.hid_size=hid_size\n",
        "\n",
        "        self.emb_layers = [torch.nn.Embedding(num_embeddings=inp_size, embedding_dim=hid_size, padding_idx=0).to(device) for _ in range(inp_len)]\n",
        "        #self.emb_layer = torch.nn.Embedding(num_embeddings=inp_size, embedding_dim=hid_size, padding_idx=0).to(device)\n",
        "\n",
        "        self.hid_layer = torch.nn.Linear(in_features=hid_size * inp_len, out_features=hid_size).to(device)\n",
        "        #self.hid_layer = torch.nn.Linear(in_features=inp_len * inp_size, out_features=hid_size)\n",
        "\n",
        "        self.out_layers = [torch.nn.Linear(in_features=hid_size, out_features=out_size).to(device) for _ in range(out_len)]\n",
        "\n",
        "    def forward(self, inp):\n",
        "        X = inp\n",
        "        batch_size = X.size(0)\n",
        "        n_grph = X.size(1)\n",
        "\n",
        "        embs = []\n",
        "        for i in range(n_grph):\n",
        "            _emb = self.emb_layers[i](X[:,i])\n",
        "            #print(f'{i}:_emb.size():{_emb.size()}')\n",
        "            embs.append(_emb)\n",
        "\n",
        "        _embs = torch.concat(embs,dim=1)\n",
        "        X = _embs\n",
        "        X = self.hid_layer(X)         # 中間層次元へ変換\n",
        "\n",
        "        # 出力層の音韻表現ごとへ変換\n",
        "        outputs = []\n",
        "        for i in range(self.out_len):\n",
        "            _out = self.out_layers[i](X)\n",
        "            outputs.append(_out)\n",
        "\n",
        "        # softmax 変換\n",
        "        #outputs = [torch.nn.functional.softmax(out,dim=1) for out in outputs]\n",
        "        outputs = [torch.nn.functional.sigmoid(out) for out in outputs]\n",
        "\n",
        "        #outputs = torch.cat(outputs, dim=0)\n",
        "        # outputs = torch.stack(outputs)\n",
        "        # return outputs\n",
        "\n",
        "        O = torch.empty(self.out_len, batch_size, self.out_size)\n",
        "        for i in range(len(outputs)):\n",
        "            O[i] = outputs[i]\n",
        "        O = O.reshape(batch_size, self.out_len, self.out_size)\n",
        "        O = torch.Tensor(O)\n",
        "        return O\n",
        "\n",
        "tla = TLA(device=device)\n",
        "tla.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c4f3f15-e095-4d77-9e4b-602dbaf8896e",
      "metadata": {
        "id": "5c4f3f15-e095-4d77-9e4b-602dbaf8896e"
      },
      "outputs": [],
      "source": [
        "class vanilla_TLA(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 inp_size= (len(grph_list)+len(special_tokens)),\n",
        "                 inp_len=maxlen_grph,\n",
        "                 out_size=len(mora_list)+len(special_tokens),\n",
        "                 out_len=maxlen_phon+2,\n",
        "                 hid_size=128,\n",
        "                 device=device,\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.inp_size=inp_size\n",
        "        self.inp_len=inp_len\n",
        "        self.out_size=out_size\n",
        "        self.out_len=out_len\n",
        "        self.hid_size=hid_size\n",
        "\n",
        "        self.emb_layer = torch.nn.Linear(in_features=inp_size * inp_len, out_features=hid_size).to(device)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.out_layer = torch.nn.Linear(in_features=hid_size, out_features=out_size * out_len).to(device)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        X = inp\n",
        "        X = torch.nn.functional.one_hot(X, num_classes=self.inp_size)\n",
        "        X = X.reshape(X.size(0),-1)\n",
        "        X = X.float()\n",
        "        X = self.emb_layer(X)\n",
        "        X = self.tanh(X)\n",
        "        X = self.out_layer(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = X.reshape(X.size(0), self.out_len, self.out_size)\n",
        "\n",
        "        return X\n",
        "\n",
        "vanilla_tla = vanilla_TLA(device=device)\n",
        "vanilla_tla.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50214a92-8a3f-45b4-938e-b06715f65485",
      "metadata": {
        "id": "50214a92-8a3f-45b4-938e-b06715f65485"
      },
      "source": [
        "# 定義したモデルの試用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d54ba9e-47ad-48fc-b67d-45b4ccc3141b",
      "metadata": {
        "id": "4d54ba9e-47ad-48fc-b67d-45b4ccc3141b"
      },
      "outputs": [],
      "source": [
        "# idx に整数を指定して,対応するデータを取得する\n",
        "\n",
        "_ds = psylex71_ds\n",
        "_ds = train_ds\n",
        "idx = np.random.choice(_ds.__len__())\n",
        "idx = 0\n",
        "\n",
        "# データセットから返ってくる値は入力信号 inp と教師信号 tch\n",
        "inp, tch = _ds.__getitem__(idx)\n",
        "print(f'idx:{idx}:', f'inp:{inp}', f'tch:{tch}')\n",
        "#print(f'_ds.getitem({idx}):{_ds.getitem(idx)}')\n",
        "#print(f'_ds.getitem({idx}):{_ds.getitem(idx)}')\n",
        "\n",
        "# 入出力信号はトークン ID 番号であるため人間が読みやすいように変換して表示\n",
        "#print(f'_ds.ids2inp({inp}):{_ds.ids2inp(inp)}')\n",
        "#print(f'_ds.taregt_ids2target({tch}):{_ds.target_ids2target(tch)}')\n",
        "print(f'_ds.dataset.ids2inp({inp}):{_ds.dataset.ids2inp(inp)}')\n",
        "print(f'_ds.dataset.taregt_ids2target({tch}):{_ds.dataset.target_ids2target(tch)}')\n",
        "\n",
        "inp = pad_sequence(inp.unsqueeze(0), batch_first=True).to(device)\n",
        "\n",
        "outs = tla(inp)\n",
        "# _ds = train_ds\n",
        "print('出力:', _ds.dataset.target_ids2target([int(_out.argmax().numpy()) for _out in outs[0]]), end=\": \")\n",
        "print('出力 ids:', [int(_out.argmax().cpu().numpy()) for _out in outs[0]])\n",
        "\n",
        "tch = tch.cpu()\n",
        "print('教師:', train_ds.dataset.target_ids2target([idx.numpy() for idx in tch]), end=\": \")\n",
        "print('教師 ids:', [int(_tch.numpy()) for _tch in tch])\n",
        "\n",
        "# #len(_ds.indices)\n",
        "# psylex71_ds.__getitem__(_ds.indices[idx])\n",
        "# psylex71_ds.getitem(_ds.indices[idx])\n",
        "\n",
        "vanilla_tla.eval()\n",
        "outs = vanilla_tla(inp)\n",
        "\n",
        "#print('出力:', train_ds.dataset.ids2tgt([int(_out.argmax().numpy()) for _out in outs[0]]), end=\": \")\n",
        "print('出力:', train_ds.dataset.target_ids2target([int(_out.argmax().cpu().numpy()) for _out in outs[0]]), end=\": \")\n",
        "print('出力 ids:', [int(_out.argmax().cpu().numpy()) for _out in outs[0]])\n",
        "# print('教師:', train_ds.dataset.target_ids2target([idx.numpy() for idx in tch]), end=\": \")\n",
        "# print('教師 ids:', [int(_tch.numpy()) for _tch in tch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e26ed626-64ad-41f6-b62a-e51e1205166f",
      "metadata": {
        "id": "e26ed626-64ad-41f6-b62a-e51e1205166f"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "tla = vanilla_tla\n",
        "\n",
        "tla.train()\n",
        "optimizer = torch.optim.Adam(tla.parameters(), lr=1e-3)\n",
        "loss_f = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "inps, tchs = next(iter(train_dl))\n",
        "inps = pad_sequence(inps, batch_first=True).to(device)\n",
        "tchs = pad_sequence(tchs, batch_first=True).to(device)\n",
        "outs = tla(inps)\n",
        "# print(f'outs.size():{outs.size()}')\n",
        "# print(f'tchs.size():{tchs.size()}')\n",
        "# print(f'len(outs):{len(outs)}',\n",
        "#       f'len(inps):{len(inps)}',\n",
        "#       f'len(tchs):{len(tchs)}')\n",
        "# print(f'len(outs[0]):{len(outs[0])}',\n",
        "#       f'len(inps[0]):{len(inps[0])}',\n",
        "#       f'len(tchs[0]):{len(tchs[0])}')\n",
        "losses = 0.\n",
        "optimizer.zero_grad()\n",
        "for _out, _tch in tqdm(zip(outs, tchs)):\n",
        "    losses += loss_f(_out, _tch)\n",
        "    #print(loss)\n",
        "losses.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b880e29b-8c23-40a1-9b2b-bd333681c827",
      "metadata": {
        "id": "b880e29b-8c23-40a1-9b2b-bd333681c827"
      },
      "outputs": [],
      "source": [
        "# ミニバッチバージョン\n",
        "\n",
        "tla = vanilla_tla\n",
        "loss_f = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = torch.optim.Adam(tla.parameters(), lr=1e-2)\n",
        "epochs = 2\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    tla.train()\n",
        "    sum_loss = 0.\n",
        "    count  = 0\n",
        "\n",
        "    _dl = train_dl\n",
        "    for inps, tchs in _dl:\n",
        "    #for inps, tchs in tqdm(_dl):\n",
        "        inps = pad_sequence(inps, batch_first=True).to(device)\n",
        "        tchs = pad_sequence(tchs, batch_first=True).to(device)\n",
        "        outs = tla(inps)\n",
        "\n",
        "        losses = 0.\n",
        "        optimizer.zero_grad()\n",
        "        for j in range(len(tchs)):\n",
        "            loss = loss_f(outs[j],tchs[j])\n",
        "            losses += loss\n",
        "            sum_loss += loss.item()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        out_ids = [out.argmax(dim=1) for out in outs]\n",
        "        for tch, out in zip(tchs[:], out_ids[:]):\n",
        "            yesno = ((tch==out) * 1).sum().cpu().numpy() == len(tch)\n",
        "            count += 1 if yesno else 0\n",
        "\n",
        "    p_correct = count / _dl.__len__()\n",
        "    print(f'epoch:{epoch+1:03d}', end=\" \")\n",
        "    print(f'p_correct:{p_correct:7.3f}', end=\": \")\n",
        "    print(f'sum_loss:{sum_loss/_dl.__len__():.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827cf6b4-2b19-435f-9469-12f3de3ebfd4",
      "metadata": {
        "id": "827cf6b4-2b19-435f-9469-12f3de3ebfd4"
      },
      "outputs": [],
      "source": [
        "# オンラインバージョン\n",
        "loss_f = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = torch.optim.Adam(tla.parameters(), lr=0.01)\n",
        "\n",
        "tla.train()\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0.\n",
        "    for inp, tch in tqdm(train_ds):\n",
        "        inp = inp.unsqueeze(0).to(device)\n",
        "        outs = tla(inp)\n",
        "        outs =[out.cpu() for out in outs]\n",
        "        loss = 0.\n",
        "        for j in range(len(inp)):\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_f(outs[j],tch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "    print(f'epoch_loss:{epoch_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60fd1a05-872e-4c0b-98c5-1033cedb028f",
      "metadata": {
        "id": "60fd1a05-872e-4c0b-98c5-1033cedb028f"
      },
      "outputs": [],
      "source": [
        "#epoch_loss\n",
        "tla.eval()\n",
        "\n",
        "# idx に整数を指定して,対応するデータを取得する\n",
        "idx = np.random.choice(train_ds.__len__())\n",
        "\n",
        "# データセットから返ってくる値は入力信号 inp と教師信号 tch\n",
        "inp, tch = train_ds.__getitem__(idx)\n",
        "print(f'idx:{idx}:', f'inp:{inp}', f'tch:{tch}')\n",
        "\n",
        "# 入出力信号はトークン ID 番号であるため人間が読みやすいように変換して表示\n",
        "print(f'train_ds.dataset.ids2inp({inp}):{train_ds.dataset.ids2inp(inp)}')\n",
        "print(f'train_ds.dataset.ids2tgt({tch}):{train_ds.dataset.ids2tgt(tch)}')\n",
        "\n",
        "inp = pad_sequence(inp.unsqueeze(0), batch_first=True).to(device)\n",
        "\n",
        "outs = tla(inp)\n",
        "outs = [out.cpu() for out in outs]\n",
        "print('出力:', train_ds.dataset.ids2tgt([int(_out.argmax().numpy()) for _out in outs[0]]), end=\": \")\n",
        "print('出力 ids:', [int(_out.argmax().numpy()) for _out in outs[0]])\n",
        "#print('出力 ids:', [int(out.argmax().numpy()) for out in outs])\n",
        "\n",
        "tch = tch.cpu()\n",
        "print('教師:', train_ds.dataset.ids2tgt([idx.numpy() for idx in tch]), end=\": \")\n",
        "print('教師 ids:', [int(_tch.numpy()) for _tch in tch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9655808f-46aa-49ef-b14d-608907cf5b6c",
      "metadata": {
        "id": "9655808f-46aa-49ef-b14d-608907cf5b6c"
      },
      "outputs": [],
      "source": [
        "#print('出力:', train_ds.dataset.ids2tgt([int(out.argmax(dim=0).numpy()) for out in outs]), end=\": \")\n",
        "\n",
        "tla.eval()\n",
        "inps, tchs = next(iter(train_dl))\n",
        "inps = pad_sequence(inps, batch_first=True).to(device)\n",
        "tchs = pad_sequence(tchs, batch_first=True)\n",
        "outs = tla(inps)\n",
        "\n",
        "out_ids = [out.argmax(dim=1) for out in outs]\n",
        "count  = 0\n",
        "for tch, out in zip(tchs[:], out_ids[:]):\n",
        "    yesno = ((tch==out) * 1).sum().numpy() == len(tch)\n",
        "    count += 1 if yesno else 0\n",
        "    #print(yesno)\n",
        "    #sys.exit()\n",
        "print(f'count:{count}')\n",
        "#print(out_ids[:3])\n",
        "\n",
        "#print(tchs[:3])\n",
        "#print(f'outs:{[[(len(out), out.size(), out.argmax(dim=1))] for out in outs[:3]]}')\n",
        "len(outs)\n",
        "#len(outs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4345db72-4656-44bd-a7f0-e52f7362ceb5",
      "metadata": {
        "id": "4345db72-4656-44bd-a7f0-e52f7362ceb5"
      },
      "outputs": [],
      "source": [
        "#loss_f(outs[0], tchs[0]) #.size()\n",
        "#tchs[0].size()\n",
        "tchs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c65acd-4916-44bf-a084-2d1c92d97cd5",
      "metadata": {
        "id": "05c65acd-4916-44bf-a084-2d1c92d97cd5"
      },
      "outputs": [],
      "source": [
        "O = torch.empty(tch.size(0), tch.size(1), outs[0].size(1))\n",
        "O = torch.empty(tch.size(1), tch.size(0), outs[0].size(1))\n",
        "#print(O.size())\n",
        "#help(torch.Tensor)\n",
        "#tch.size()\n",
        "#outs[0].size()\n",
        "#[o.size() for o in outs]\n",
        "for j in range(outs[0].size(0)):\n",
        "    O[j] = o\n",
        "#outs[0][0].size()\n",
        "#outs[0][0]#[0]\n",
        "#print(type(O), O.size())\n",
        "O = O.reshape(tch.size(0), tch.size(1), outs[0].size(1))\n",
        "#print(type(O), O.size())\n",
        "#print(O[0].size(), outs[0].size())\n",
        "for j in range(O.size(0)):\n",
        "    print(j, loss_f(O[j], tch[j]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2b231c-e3de-4d88-9d2e-76f17f2ae630",
      "metadata": {
        "id": "0b2b231c-e3de-4d88-9d2e-76f17f2ae630"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "inp, tch = next(iter(train_dl))\n",
        "inp = pad_sequence(inp, batch_first=True).to(device)\n",
        "tch = pad_sequence(tch, batch_first=True)\n",
        "tla.eval()\n",
        "out = tla(inp)\n",
        "#out[0].argmax(dim=1)\n",
        "[_out.cpu().argmax(dim=1).numpy() for _out in out]\n",
        "[_out.size() for _out in out]\n",
        "[_out.detach().cpu().sum(dim=1) for _out in out]\n",
        "#[_out.detach().cpu().size() for _out in out]\n",
        "C = [(train_ds.dataset.ids2inp(_inp.cpu().numpy()),train_ds.dataset.ids2tgt(_tch.cpu().numpy())) for (_inp,_tch) in zip(inp, tch)]\n",
        "#C\n",
        "#criterion(out[0], tch[0])\n",
        "#out[0].size(), tch.size()\n",
        "#print(out[0].size(), tch[0])\n",
        "#criterion(out[0][0], tch[0])\n",
        "#type(out)\n",
        "#type(torch.tensor(out))\n",
        "#len(out)\n",
        "#out[0].size()\n",
        "print('out', len(out), type(out[0]), out[0].size())\n",
        "print('inp', len(inp), type(inp[0]), inp[0].size())\n",
        "print('tch', len(tch), type(tch[0]), tch[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a1c1def-cb9e-4969-8b43-43848f557ea6",
      "metadata": {
        "id": "1a1c1def-cb9e-4969-8b43-43848f557ea6"
      },
      "outputs": [],
      "source": [
        "inp, tch = next(iter(train_dl))\n",
        "# print('out', len(out), type(out[0]), out[0].size())\n",
        "# print('tch', len(tch), type(tch[0]), tch[0].size())\n",
        "\n",
        "inp = pad_sequence(inp, batch_first=True).to(device)\n",
        "tch = pad_sequence(tch, batch_first=True)\n",
        "\n",
        "# print('out', len(out), type(out[0]), out[0].size())\n",
        "# print('tch', len(tch), type(tch[0]), tch[0].size())\n",
        "tla.eval()\n",
        "out = tla(inp)\n",
        "print('out', len(out), type(out[0]), out[0].size())\n",
        "print('tch', len(tch), type(tch[0]), tch[0].size())\n",
        "#sys.exit()\n",
        "\n",
        "for j in range(tch.size(0)): #.size()[0]):\n",
        "    print('out[j]', len(out[j]), type(out[j]), out[j].size())\n",
        "    print('tch[j]', len(tch[j]), type(tch[j]), tch[j].size())\n",
        "    #loss_f(out[j], tch[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94175f22-dfc2-4e5a-9996-a6d3fe1db4dd",
      "metadata": {
        "id": "94175f22-dfc2-4e5a-9996-a6d3fe1db4dd"
      },
      "outputs": [],
      "source": [
        "print(tch.size(0), type(tch))\n",
        "print(out[0].size(), type(out[0]))\n",
        "print(tch[0])\n",
        "out[0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911c5bbc-443a-4583-96bc-5f54e0fdaa30",
      "metadata": {
        "id": "911c5bbc-443a-4583-96bc-5f54e0fdaa30"
      },
      "outputs": [],
      "source": [
        "inp, tch = train_ds.__getitem__(0)\n",
        "inp, tch = next(iter(train_dl))\n",
        "print(inp, tch)\n",
        "inp = pad_sequence(inp, batch_first=True).to(device)\n",
        "tch = pad_sequence(tch, batch_first=True)\n",
        "print(inp, tch)\n",
        "tla.eval()\n",
        "out = tla(inp)\n",
        "for j in range(len(out)):\n",
        "    print(out[j].size(), tch[j], tch[j].size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa37db84-8934-4e8f-b3b4-4455ed2911fa",
      "metadata": {
        "id": "aa37db84-8934-4e8f-b3b4-4455ed2911fa"
      },
      "outputs": [],
      "source": [
        "#help(criterion)\n",
        "# Example of target with class indices\n",
        "loss_f = torch.nn.CrossEntropyLoss()\n",
        "out = torch.randn(3, 5, requires_grad=True)\n",
        "tgt = torch.empty(3, dtype=torch.long).random_(5)\n",
        "loss = loss_f(out, tgt)\n",
        "loss.backward()\n",
        "\n",
        "print(f'type(out):{type(out)}', f'out:{out}')\n",
        "print(f'type(tgt):{type(tgt)}', f'tgt:{tgt}')\n",
        "print(f'type(loss):{type(loss)}', f'loss:{loss}')\n",
        "\n",
        "out = torch.randn(2, 3, 5, requires_grad=True)\n",
        "tgt = torch.empty(2, 3, dtype=torch.long).random_(5)\n",
        "loss = 0.\n",
        "for j in range(out.size()[0]):\n",
        "    # バッチ毎にまとめて loss 計算\n",
        "    loss += loss_f(out[j], tgt[j])\n",
        "    #loss += loss_f(out[j,:,:], tgt[j,:])\n",
        "    print(f'type(out[j,:,:]):{type(out[j,:,:])}', f'out[j,:,:]:{out[j,:,:]}')\n",
        "    print(f'type(tgt[j,:]):{type(tgt[j,:])}', f'tgt[j,:]:{tgt[j,:]}')\n",
        "    print(f'type(loss):{type(loss)}', f'loss:{loss}')\n",
        "\n",
        "#print(out.size())\n",
        "# loss = loss_f(out, tgt)\n",
        "# loss.backward()\n",
        "\n",
        "# print(f'type(input):{type(input)}', f'input:{input}')\n",
        "# print(f'type(target):{type(target)}', f'input:{target}')\n",
        "# print(f'type(output):{type(output)}', f'input:{output}')\n",
        "\n",
        "# # Example of target with class probabilities\n",
        "# input = torch.randn(3, 5, requires_grad=True)\n",
        "# target = torch.randn(3, 5).softmax(dim=1)\n",
        "# output = loss(input, target)\n",
        "# output.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7990987-693c-4c5b-b04e-9144781dcbff",
      "metadata": {
        "id": "f7990987-693c-4c5b-b04e-9144781dcbff"
      },
      "outputs": [],
      "source": [
        "tla.inp_size, tla.inp_len\n",
        "tla.hid_layer\n",
        "#tla.eval()\n",
        "#print(outs[0][0].argmax(dim=0))\n",
        "#print(outs[0][0].argmax(dim=1))\n",
        "#train_ds.dataset.ids2tgt([int(idx.numpy()) for idx in outs[0][0].argmax(dim=1)])\n",
        "#print(outs[0][0].size())\n",
        "#print(outs[0][0])\n",
        "#print(outs[0])\n",
        "#print(len(outs), outs[0].size())\n",
        "#maxlen_phon\n",
        "#tla.out_layers\n",
        "#print(f'len(outs):{len(outs)}')\n",
        "#print(f'len(outs[-]):{len(outs[-1])}')\n",
        "#print(f'outs[-1].size():{outs[-1].size()}')\n",
        "#len(outs[0])\n",
        "#outs[0][0] #.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9dd9b7-1905-40a9-8681-9712b6057e1a",
      "metadata": {
        "id": "3f9dd9b7-1905-40a9-8681-9712b6057e1a"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "tla.eval()\n",
        "optimizer = torch.optim.Adam(tla.parameters(), lr=0.01)\n",
        "idx = np.random.choice(train_ds.__len__())\n",
        "\n",
        "# データセットから返ってくる値は入力信号 inp と教師信号 tch\n",
        "inp, tch = train_ds.__getitem__(idx)\n",
        "print(f'idx:{idx}:', f'inp:{inp}', f'tch:{tch}')\n",
        "criterion:torch.nn.modules.loss=torch.nn.CrossEntropyLoss(ignore_index=-1),\n",
        "\n",
        "for inp, tgt in train_dl:\n",
        "    inp_ids = pad_sequence(inp, batch_first=True).to(device)\n",
        "\n",
        "    #outs = tla(inp.unsqueeze(0).to(device))\n",
        "    outs = tla(inp_ids) #.to(device)\n",
        "    print(f'inp_ids.size():{inp_ids.size()}',\n",
        "          f'type(inp_ids):{type(inp_ids)}',\n",
        "          f'len(outs):{len(outs)}',\n",
        "          f'type(outs):{type(outs)}')\n",
        "    sys.exit()\n",
        "    for out in outs: # ) #.size()\n",
        "        print(out.size())\n",
        "        #print(out.argmax()) #out.size())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb0dc3d-8d17-46a5-9165-9195f4cdd11b",
      "metadata": {
        "id": "1eb0dc3d-8d17-46a5-9165-9195f4cdd11b"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "optimizer = optim.Adam(tla.parameters(), lr=0.01)\n",
        "criterion:torch.nn.modules.loss=torch.nn.CrossEntropyLoss(ignore_index=-1),\n",
        "\n",
        "EPOCH_NUM = 30\n",
        "all_losses = []\n",
        "for epoch in range(1, EPOCH_NUM+1):\n",
        "\n",
        "    epoch_loss = 0 # epoch毎のloss\n",
        "    for inp, tgt in train_dl:\n",
        "        optimizer.zero_grad()  # 勾配の初期化\n",
        "\n",
        "        # データをテンソルに変換\n",
        "        inp_ids = pad_sequence(inp, batch_first=True).to(device)\n",
        "        tgt_ids = pad_sequence(tgt, batch_first=True).to(device)\n",
        "\n",
        "        out = tla(inp_ids)\n",
        "        print(type(out))\n",
        "\n",
        "        for j in range(out.size()[1]):\n",
        "            # バッチ毎にまとめて loss 計算\n",
        "            loss += criterion(out[:, j, :], tgt_ids[:, j])\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()  # 誤差逆伝播\n",
        "        optimizer.step()  # パラメータ更新\n",
        "\n",
        "    # 損失を表示\n",
        "    print(\"Epoch %d: %.2f\" % (epoch, epoch_loss))\n",
        "    all_losses.append(epoch_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e1cf12-3c3e-45f4-8d33-53623c95ba3b",
      "metadata": {
        "id": "47e1cf12-3c3e-45f4-8d33-53623c95ba3b"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def fit_tla(\n",
        "    model:torch.nn.modules.module.Module=tla,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=train_ds,\n",
        "    #batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    dataloader:torch.utils.data.dataloader.DataLoader=train_dl,\n",
        "    optimizer:torch.optim=None,\n",
        "    #criterion:torch.nn.modules.loss=torch.nn.NLLLoss(ignore_index=-1),\n",
        "    criterion:torch.nn.modules.loss=torch.nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for inp, tch in dataloader:\n",
        "            #_tch = torch.nn.functional.one_hot(tch, num_classes=(len(kata_list)+len(special_tokens))).to(device)\n",
        "            outs = model(inp)\n",
        "\n",
        "            print(f'train_ds.dataset.ids2inp({inp[0]}):{train_ds.dataset.ids2inp(inp[0])}')\n",
        "            print(f'train_ds.dataset.ids2tgt({tch[0]}):{train_ds.dataset.ids2tgt(tch[0])}')\n",
        "            XX = [out.argmax(dim=1).numpy() for out in outs]\n",
        "            #print(f'len(XX):{len(XX)}')\n",
        "            print(f'len(inp):{len(inp)}')\n",
        "            print(f'len(tch):{len(tch)}')\n",
        "            print(f'len(outs):{len(outs)}')\n",
        "            print(f'outs[0].size():{outs[0].size()}')\n",
        "            print(f'tch.size():{tch.size()}')\n",
        "            #print(f'_tch[0].size:{_tch[0].size}')\n",
        "            #print(f'train_ds.dataset.ids2tgt(XX[0]):{train_ds.dataset.ids2tgt(XX[0])}')\n",
        "            _outs = train_ds.dataset.ids2tgt([out.argmax().numpy() for out in outs])\n",
        "            print(f'出力:{\"\".join(ch for ch in _outs)}')\n",
        "\n",
        "            #loss = criterion(out[0], tch[0].long())\n",
        "            #loss = criterion(out[0], tch[0])\n",
        "            #loss = criterion(out[0], tch[0])\n",
        "            #loss = criterion(out[0][0], tch[0])\n",
        "            loss = criterion(outs[0], tch)\n",
        "            #sys.exit()\n",
        "\n",
        "            #loss = criterion(out, _tch)\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:2d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "fit_tla(epochs=1, model=tla, ds=train_ds,interval=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d54824f-2bc6-4d34-a9ac-bb35f192ffde",
      "metadata": {
        "id": "1d54824f-2bc6-4d34-a9ac-bb35f192ffde"
      },
      "outputs": [],
      "source": [
        "#len(kata_list)+len(special_tokens)\n",
        "#print(train_dl.batch_size)\n",
        "help(torch.nn.CrossEntropyLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e269cb6-dbe4-42c8-bd0f-76152cf5553f",
      "metadata": {
        "id": "0e269cb6-dbe4-42c8-bd0f-76152cf5553f"
      },
      "outputs": [],
      "source": [
        "for inp, out in valid_dl:\n",
        "    print(out[0].size())\n",
        "    print(torch.nn.functional.one_hot(out, num_classes=len(kata_list)+len(special_tokens))[0][0])\n",
        "    #print(torch.nn.functional.one_hot(out[0], num_classes=len(kata_list)+len(special_tokens))[0])\n",
        "    sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540894be-9de6-476c-8f12-f1f44e079e6e",
      "metadata": {
        "id": "540894be-9de6-476c-8f12-f1f44e079e6e"
      },
      "outputs": [],
      "source": [
        "help(torch.nn.functional.one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9511fa7e-7d68-467c-b618-8875d4b9cc54",
      "metadata": {
        "id": "9511fa7e-7d68-467c-b618-8875d4b9cc54"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65dbe30-fdcc-4a14-909d-a389fc39b4b6",
      "metadata": {
        "id": "f65dbe30-fdcc-4a14-909d-a389fc39b4b6"
      },
      "outputs": [],
      "source": [
        "# 上のセルで作成した Psylex71 を pandas のデータフレームに変換し， さらにエクセルファイルとして書き出す\n",
        "import pandas as pd\n",
        "\n",
        "NTT71 = pd.DataFrame.from_dict(data=Psylex71, orient='index')\n",
        "\n",
        "NTT71.columns=['単語','ヨミ','品詞','頻度']\n",
        "#NTT71.to_excel('NTT_Psylex71_学習漢字2文字語.xlsx')\n",
        "NTT71"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7e1a49-2f57-4030-8770-a613d21249ab",
      "metadata": {
        "id": "0f7e1a49-2f57-4030-8770-a613d21249ab"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class Seq2Seq_wAtt(nn.Module):\n",
        "    \"\"\" 注意つき符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "class Seq2Seq_(nn.Module):\n",
        "    \"\"\" 注意なし符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp) # .zero_()\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "# 以下確認作業\n",
        "ds = train_ds\n",
        "n_layers=1\n",
        "bidirectional=False\n",
        "n_hid = 128\n",
        "batch_size = 256\n",
        "cdp = Seq2Seq_(enc_vocab_size=len(ds.dataset.grph_list),\n",
        "#cdp = Seq2Seq_wAtt(enc_vocab_size=len(ds.dataset.grph_list),\n",
        "                   dec_vocab_size=len(ds.dataset.phon_list),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "print(cdp.eval())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d3d88a-c883-431f-a081-5bd0c716dcc8",
      "metadata": {
        "id": "25d3d88a-c883-431f-a081-5bd0c716dcc8"
      },
      "outputs": [],
      "source": [
        "# #print(dir(cdp.decoder))\n",
        "# print(torch.tensor([3,3]).zero_())\n",
        "print(dir(cdp.decoder))\n",
        "cdp.decoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f44038-21f8-4a6f-9042-a288f46c91f6",
      "metadata": {
        "id": "f2f44038-21f8-4a6f-9042-a288f46c91f6"
      },
      "outputs": [],
      "source": [
        "def fit_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=cdp,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=psylex71_ds,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    #dataloader:torch.utils.data.dataloader.DataLoader=dl_o2p,\n",
        "    optimizer:torch.optim=None,\n",
        "    criterion:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "    \"\"\" Seq2seq の訓練に用いる関数\"\"\"\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "        #interval = int(ds.__len__()/batch_size) >> 3\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for _inp, _tch in dataloader:\n",
        "            enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "            dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "            tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "            out = model(enc_inp, dec_inp)\n",
        "            loss = criterion(out[0], tch[0])\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:03d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "# _ = fit_seq2seq(epochs=2, model=cdp, ds=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac931f6-da47-405e-adc5-1fc9b991667d",
      "metadata": {
        "id": "cac931f6-da47-405e-adc5-1fc9b991667d"
      },
      "outputs": [],
      "source": [
        "def eval_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=cdp,\n",
        "    ds:Dataset=train_ds,\n",
        "    isPrint:bool=False,\n",
        "    errors:list=None):\n",
        "\n",
        "    model.eval()\n",
        "    if errors == None:\n",
        "        errors=[]\n",
        "\n",
        "    for N in tqdm(range(ds.__len__())):\n",
        "        x, y = ds.__getitem__(N)\n",
        "        enc_inp, dec_inp = x.unsqueeze(0).to(device), y.unsqueeze(0).to(device)\n",
        "        grand_truth = y.detach().numpy()[1:-1]\n",
        "        y_hat = model(enc_inp, dec_inp).to('cpu')\n",
        "        y_hat = np.argmax(y_hat.squeeze(0).detach().numpy(), axis=1)[1:-1]\n",
        "\n",
        "        if len(y_hat) == len(grand_truth):\n",
        "            n_correct = np.array((y_hat == grand_truth).sum())\n",
        "            isOK = n_correct == len(grand_truth)\n",
        "        else:\n",
        "            isOK = False\n",
        "\n",
        "        if not isOK:\n",
        "            #wrd = ds.getitem(N)[0]\n",
        "            wrd = ds.dataset.getitem(N) #[0]\n",
        "            _out = ds.dataset.target_ids2target(y_hat)\n",
        "            errors.append((N, wrd, _out,y_hat))\n",
        "            if isPrint:\n",
        "                color = 'grey' if isOK else 'red'\n",
        "                wrd = ds.getitem(N)[0]\n",
        "                print(colored(f'{N:05d}', color),\n",
        "                      colored(wrd, color='grey'), # , attrs=[\"bold\"]),\n",
        "                      colored(y_hat,color,attrs=[\"bold\"]),\n",
        "                      colored(ds.target_ids2target(y_hat), color, attrs=[\"bold\"]),\n",
        "                      f'<-{ds.target_ids2target(grand_truth)}')\n",
        "\n",
        "    cr = len(errors) / N\n",
        "    return {'エラー':errors,\n",
        "            '正解率': (1.-cr) * 100}\n",
        "\n",
        "#_ = eval_seq2seq(model=cdp, ds=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8c03dc-3f7d-486f-a2e8-99811d74ea74",
      "metadata": {
        "id": "2c8c03dc-3f7d-486f-a2e8-99811d74ea74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_epochs, eval_epochs = [],[]\n",
        "for _ in range(5):\n",
        "    train_epochs.append(fit_seq2seq(epochs=30, model=cdp, ds=train_ds, isDraw=False))\n",
        "    eval_epochs.append(eval_seq2seq(model=cdp, ds=valid_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23e9cfd-6162-4e95-8029-fcb97f8850ba",
      "metadata": {
        "id": "e23e9cfd-6162-4e95-8029-fcb97f8850ba"
      },
      "outputs": [],
      "source": [
        "eval_epochs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb72143c-3844-40cd-b3ab-5652ff665ae0",
      "metadata": {
        "id": "cb72143c-3844-40cd-b3ab-5652ff665ae0"
      },
      "outputs": [],
      "source": [
        "cdp.eval()\n",
        "inp, tch = psylex71_ds.__getitem__(0)\n",
        "cdp(inp.unsqueeze(0), tch.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2d002d-1531-4a84-abc5-b340c682cc7b",
      "metadata": {
        "id": "2e2d002d-1531-4a84-abc5-b340c682cc7b"
      },
      "source": [
        "# JALEX の処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f80b821-4aee-47c2-a640-e37b4f69eb1e",
      "metadata": {
        "id": "7f80b821-4aee-47c2-a640-e37b4f69eb1e"
      },
      "outputs": [],
      "source": [
        "len(valid_chars), len(grph_list)\n",
        "valid_chars = grph_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d0541c-7cf2-4bec-8e4c-c1facd78de7b",
      "metadata": {
        "id": "89d0541c-7cf2-4bec-8e4c-c1facd78de7b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mecab を使ってヨミを得るために MeCab を import する\n",
        "from ccap.mecab_settings import wakati, yomi #, parser\n",
        "\n",
        "jalex_base = os.path.join(HOME, 'study/2025_2014jalex')\n",
        "jalex_xls_fname = 'JALEX.xlsx'\n",
        "jalex_fname = os.path.join(jalex_base, jalex_xls_fname)\n",
        "DF = pd.read_excel(jalex_fname)\n",
        "jalex_words = DF['目標語']\n",
        "\n",
        "df_dict = DF.to_dict(orient='index')\n",
        "\n",
        "jalex_cands = []\n",
        "maxlen_grph = 8\n",
        "for idx, v in list(df_dict.items())[:]:\n",
        "    wrd = v['目標語']\n",
        "\n",
        "    is_valid = False\n",
        "    if len(wrd) <= maxlen_grph: # maxlen_grph 文字で構成された語のみを選択する\n",
        "        for w in wrd:\n",
        "            if w in valid_chars:\n",
        "                is_valid = True\n",
        "            else:\n",
        "                is_valid = False\n",
        "    if is_valid:\n",
        "        jalex_cands.append(v)\n",
        "        _yomi = \"\".join(c for c in yomi(wrd).strip())\n",
        "        morae = moraWakachi(_yomi)\n",
        "        for m in morae:\n",
        "            if not m in mora_dict:\n",
        "                print(f'モーラ:{m} not in dict')\n",
        "                sys.exit()\n",
        "                mora_dict[m] = 1\n",
        "            else:\n",
        "                mora_dict[m] += 1\n",
        "\n",
        "        df_dict[idx]['モーラ'] = morae\n",
        "        jalex_cands.append(v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b827dee-c2e0-4791-bb85-b4b9a3d15d44",
      "metadata": {
        "id": "9b827dee-c2e0-4791-bb85-b4b9a3d15d44"
      },
      "outputs": [],
      "source": [
        "print(len(mora_dict), sorted(mora_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074505f7-07ae-48fb-a7e8-cf2d4449c86a",
      "metadata": {
        "id": "074505f7-07ae-48fb-a7e8-cf2d4449c86a"
      },
      "outputs": [],
      "source": [
        "#moraWakachi(yomi('鼻血').strip())\n",
        "#print(valid_chars)\n",
        "print(list(df_dict.keys())[:10])\n",
        "df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6350f226-fbf8-4768-9394-04e20005bb7e",
      "metadata": {
        "id": "6350f226-fbf8-4768-9394-04e20005bb7e"
      },
      "outputs": [],
      "source": [
        "# MeCab を使ってヨミを得る\n",
        "_yomis = []\n",
        "for x in jalex_cands[:]:\n",
        "    wrd = x['目標語']\n",
        "    _yomi = yomi(wrd).strip()\n",
        "    _yomis.append(_yomi)\n",
        "print(len(_yomis))\n",
        "\n",
        "Jalex_df['ヨミ'] =_yomis\n",
        "Jalex_df.columns\n",
        "cols = ['目標語', 'ヨミ', '項目', '試行数', '平均反応時間 ミリ秒', '反応時間の標準偏差', '反応時間の標準誤差', '正解率', '英訳語', 'ONS 書記素隣接語数', 'PNS 音韻隣接語数', 'OLD20']\n",
        "Jalex_df = Jalex_df[cols]\n",
        "\n",
        "# エクセルファイルとして書き出す\n",
        "#Jalex_df.to_excel('2025_0610Jalex学習漢字2文字語.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7e8fef-9997-4c5a-bbce-934223d1763a",
      "metadata": {
        "id": "cc7e8fef-9997-4c5a-bbce-934223d1763a"
      },
      "outputs": [],
      "source": [
        "special_tokens = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "n_stokens = len(special_tokens)\n",
        "maxlen_grph = 4\n",
        "phon_maxlen = 10\n",
        "\n",
        "NTT71_data = []\n",
        "for x, v in NTT71[['語','ヨミ']].to_dict(orient='index').items():\n",
        "    orth, phon = v['語'], v['ヨミ']\n",
        "    #orth_idx = [gakushu_chars.index(o)+n_stokens for o in orth]\n",
        "    orth_idx = [valid_chars.index(o)+n_stokens for o in orth]\n",
        "    orth_idx = [special_tokens.index('<SOW>')] + orth_idx + [special_tokens.index('<EOW>')]\n",
        "\n",
        "    phon_idx = [kata_chars.index(p)+n_stokens for p in phon]\n",
        "    phon_idx = [special_tokens.index('<SOW>')] + phon_idx + [special_tokens.index('<EOW>')]\n",
        "    for j in range(phon_maxlen - len(phon_idx)):\n",
        "        phon_idx.append(special_tokens.index('<PAD>'))\n",
        "    NTT71_data.append((orth, orth_idx, phon, phon_idx))\n",
        "len(NTT71_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06926067-288a-4935-8933-17ed60ce73e4",
      "metadata": {
        "id": "06926067-288a-4935-8933-17ed60ce73e4"
      },
      "outputs": [],
      "source": [
        "inconsist = []\n",
        "for d in NTT71_data:\n",
        "    yomi2 = yomi(d[0]).strip()\n",
        "    if d[2] != yomi2:\n",
        "        inconsist.append((d[0], d[2], yomi2))\n",
        "print(f'ヨミが NTTPsylex71 と Mecab で不一致な語数 len(inconsist):{len(inconsist)}')\n",
        "\n",
        "print(NTT71_data[0])\n",
        "print(f'入力素子数:{(len(valid_chars) + len(special_tokens)) * maxlen_orth}')\n",
        "print(f'(len(kata_chars)+len(special_tokens)) * phon_maxlen:{(len(kata_chars)+len(special_tokens)) * phon_maxlen}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540c77ec-f1eb-4690-9a19-ba7dca252445",
      "metadata": {
        "id": "540c77ec-f1eb-4690-9a19-ba7dca252445"
      },
      "outputs": [],
      "source": [
        "print(gakushu_chars[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4def5f26-a714-4488-83d7-ff412e63ef35",
      "metadata": {
        "id": "4def5f26-a714-4488-83d7-ff412e63ef35"
      },
      "outputs": [],
      "source": [
        "target_words = []\n",
        "char_list = jchar_list\n",
        "char_list = gakushu_chars\n",
        "for wrd in jalex_words:\n",
        "    if len(wrd) == 2:\n",
        "        if (wrd[0] in char_list) and (wrd[1] in char_list):\n",
        "            target_words.append(wrd)\n",
        "print(f'len(target_words):{len(target_words)}')\n",
        "\n",
        "jalex_dict = {}\n",
        "for wrd in target_words[:100]:\n",
        "    #print(f'{wrd}:{yomi(wrd).strip()}')\n",
        "    jalex_dict[wrd] = (wrd, yomi(wrd).strip())\n",
        "print(jalex_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8090e2-5b26-425a-8ac3-874c2248eff8",
      "metadata": {
        "id": "0a8090e2-5b26-425a-8ac3-874c2248eff8"
      },
      "outputs": [],
      "source": [
        "# 日本語文字\n",
        "import IPython\n",
        "isColab = 'colab' in str(IPython.get_ipython())\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "alphabet_upper_chars = 'ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ'\n",
        "alphabet_lower_chars = 'ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ'\n",
        "num_chars = '０１２３４５６７８９'\n",
        "hira_chars = 'ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん'\n",
        "kata_chars = 'ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾタダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポマミムメモャヤュユョヨラリルレロヮワヰヱヲンヴヵヶ'\n",
        "\n",
        "jchars = ['<PAD>', '<EOW>', '<SOW>', '<UNK>']\n",
        "\n",
        "for ch in hira_chars+kata_chars+gakushu_chars:\n",
        "    for ch in x:\n",
        "        jchars.append(ch)\n",
        "print(f'len(jchars):{len(jchars)}')\n",
        "\n",
        "\n",
        "def make_psylex71_data(psylex71_fname:str=None):\n",
        "    \"\"\"\n",
        "    # NTT日本語語彙特性 (天野，近藤; 1999, 三省堂)より頻度情報を取得\n",
        "\n",
        "    戻り値:\n",
        "    * psylex71_freq_sorted: list 頻度順にソートされた単語リスト\n",
        "    * _psylex_dict: dict 単語をキーとした，品詞，頻度，よみ(カタカナ表記された) を値として持つ辞書\n",
        "    * all_words: list psylex71 全単語からなるリスト\n",
        "    * _psylex71_symbols: 登録単語の品詞が｢記｣である単語からなるリスト\n",
        "    \"\"\"\n",
        "\n",
        "    # NTT 日本語語彙特性の utf-8 へ変換済 `psylex71.txt` の読み込み\n",
        "    HOME = os.environ[\"HOME\"]\n",
        "    if isColab:\n",
        "        ntt_base = '/contents'\n",
        "    else:\n",
        "        ntt_base = os.path.join(HOME, 'study/2017_2009AmanoKondo_NTTKanjiData')\n",
        "\n",
        "    if psylex71_fname == None:\n",
        "        psy71_fname = 'psylex71utf8.txt'  # ファイル名\n",
        "        with open(os.path.join(ntt_base, psy71_fname), 'rt', encoding='utf-8') as f:\n",
        "            psylex71raw = f.readlines()\n",
        "    else:\n",
        "        with open(ps71_fname, 'r') as f:\n",
        "            psylex71raw = f.readlines()\n",
        "\n",
        "    # 空白で区切られたフィードの前頭 5 つ tmp に格納\n",
        "    tmp  = [line.strip().split(' ')[:6] for line in psylex71raw]\n",
        "\n",
        "    # 上で定義した tmp から 0:ID, 2:表記, 4:品詞, 5:頻度, 4:読み を取り出す。\n",
        "    tmp2 = [[int(line[0]), line[2], line[4], int(line[5]), line[3]] for line in tmp]\n",
        "\n",
        "    tmp3 = []\n",
        "    for line in tmp2:\n",
        "        wrd = line[1]\n",
        "        if len(wrd) == 2:\n",
        "            tmp3.append(line)\n",
        "\n",
        "    cands  = []\n",
        "    _dict = {}\n",
        "    for x in tmp3:\n",
        "        idx = x[0]\n",
        "        wrd = x[1]\n",
        "\n",
        "        wrd = wrd.replace('・', '')\n",
        "        if len(wrd) == 2:\n",
        "            if (wrd[0] in jchars) and (wrd[1] in jchars):\n",
        "                cands.append(x)\n",
        "                _dict[idx] = {'wrd': wrd, 'POS': x[2], 'Frq': int(x[3]), 'yomi': x[4]}\n",
        "\n",
        "\n",
        "    # Freq = np.zeros((len(_dict)), dtype=np.uint)\n",
        "    # for i, (k,v) in enumerate(_dict.items()):\n",
        "    #     Freq[i] = v['頻度']\n",
        "\n",
        "    # all_words = list(_dict.keys())\n",
        "    # Freq_sorted = np.argsort(Freq)[::-1]  # 頻度降順に並べ替え\n",
        "    # _freq_sorted = [all_words[idx] for idx in Freq_sorted]\n",
        "\n",
        "    # _char_freq = {}\n",
        "    # for wrd in _dict.keys():\n",
        "    #     for ch in wrd:\n",
        "    #         if not ch in _char_freq:\n",
        "    #             _char_freq[ch] = _dict[wrd]['頻度']\n",
        "    #         else:\n",
        "    #             _char_freq[ch] += _dict[wrd]['頻度']\n",
        "\n",
        "    # return _freq_sorted, _dict, all_words, _symbols, _char_freq\n",
        "    return cands, tmp3, _dict\n",
        "\n",
        "#psylex71_freq, psylex71_dict, all_words, psylex71_symbols, psylex71_char_freq = make_psylex71_data()\n",
        "#print(psylex71_dict)\n",
        "#print(all_words)\n",
        "\n",
        "psylex71_camds, X, dic = make_psylex71_data()\n",
        "print(psylex71_data[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c2ac4a-e177-42b8-a89c-8c8e81d1d82f",
      "metadata": {
        "id": "c1c2ac4a-e177-42b8-a89c-8c8e81d1d82f"
      },
      "outputs": [],
      "source": [
        "print(len(dic))\n",
        "print(len(X)) #X[-10:]\n",
        "print(len(psylex71_data))\n",
        "print(X[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807f6172-c5d2-4043-8ce1-c0f7e27c6b95",
      "metadata": {
        "id": "807f6172-c5d2-4043-8ce1-c0f7e27c6b95"
      },
      "outputs": [],
      "source": [
        "# Plaut の PMSP データを読み込む\n",
        "import IPython\n",
        "isColab = True if 'google.colab' in str(IPython.get_ipython()) else False\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "pmsp_url='https://www.cnbc.cmu.edu/~plaut/xerion/PMSPdata.txt'\n",
        "# このデータは以下のような一行一データであり tsv ファイルである。\n",
        "# 以下のような構造である\n",
        "#orth\\tphon\\ttype\\tSim 1\\t\\tSim 2 (raw)\\tSim 2 (sqrt)\\tSim 3 (RT)\\n',\n",
        "\n",
        "if isColab:\n",
        "    xerion_dir = ''\n",
        "else:\n",
        "    xerion_dir = 'study/2022plaut_homepage/xerion'\n",
        "pmsp_fname = 'PMSPdata.txt'\n",
        "fname = os.path.join(HOME, xerion_dir, pmsp_fname)\n",
        "\n",
        "# もしファイルが存在しなかったら ダウンロードする\n",
        "if not os.path.exists(fname):\n",
        "    r = requests.get(pmsp_url)\n",
        "    with open(fname, 'w') as f:\n",
        "        total_length = int(r.headers.get('content-length'))\n",
        "        print('Downloading {0} - {1} bytes'.format(pmsp_fname, (total_length)))\n",
        "        f.write(r.content)\n",
        "\n",
        "with open(fname, 'r') as f:\n",
        "    a = f.readlines()\n",
        "\n",
        "Z = {}\n",
        "for i,l in enumerate(a):\n",
        "    x = l.strip().split('\\t')\n",
        "    if len(x) != 7:\n",
        "        print(x)\n",
        "    else:\n",
        "        Z[i] = {'orth':x[0],\n",
        "                'phon':x[1],\n",
        "                'type':x[2],\n",
        "                'Sim1':np.float32(x[3]),\n",
        "                'Sim2_raw':np.float32(x[4]),\n",
        "                'Sim2_sqrt':np.float32(x[5]),\n",
        "                'Sim3_RT':np.float32(x[6]),\n",
        "               }\n",
        "\n",
        "orth_list =[v['orth'] for k, v in Z.items()]\n",
        "phon_list =[v['phon'] for k, v in Z.items()]\n",
        "\n",
        "Orth, Phon = {},{}\n",
        "Orth['<PAD>'] = {'idx': 0}\n",
        "Orth['<UNK>'] = {'idx': 1}\n",
        "Orth['<SOW>'] = {'idx': 2}\n",
        "Orth['<EOW>'] = {'idx': 3}\n",
        "Phon['<PAD>'] = {'idx': 0}\n",
        "Phon['<UNK>'] = {'idx': 1}\n",
        "Phon['<SOW>'] = {'idx': 2}\n",
        "Phon['<EOW>'] = {'idx': 3}\n",
        "\n",
        "ort2phn, phn2ort = {}, {}\n",
        "for o, p in zip(orth_list, phon_list):\n",
        "    for _o in o:\n",
        "        if not _o in Orth:\n",
        "            Orth[_o] = {'idx': len(Orth), 'cnt':1}\n",
        "        else:\n",
        "            Orth[_o]['cnt'] += 1\n",
        "    for _p in p:\n",
        "        if not _p in Phon:\n",
        "            Phon[_p] = {'idx': len(Phon), 'cnt':1}\n",
        "        else:\n",
        "            Phon[_p]['cnt'] += 1\n",
        "    ort2phn[o] = p\n",
        "    phn2ort[p] = o\n",
        "\n",
        "print(f'len(Orth):{len(Orth)}, Orth: {Orth}')\n",
        "print(f'len(Phon):{len(Phon)}, Phon: {Phon}')\n",
        "#print(sorted(set(Orth.keys())))\n",
        "#print(sorted(set(Phon.keys())))\n",
        "ort2idx = {k:v['idx'] for k, v in Orth.items()}\n",
        "#idx2ort = ort2idx.keys() # {v:k for k, v in ort2idx.items()}\n",
        "idx2ort = list(ort2idx.values()) # {v:k for k, v in ort2idx.items()}\n",
        "phn2idx = {k:v['idx'] for k, v in Phon.items()}\n",
        "idx2phn = list(phn2idx.values()) # {k:v['idx'] for k, v in Phon.items()}\n",
        "#idx2ort = {v:k for k, v in phn2idx.items()}\n",
        "print(f'len(ort2phn): {len(ort2phn)}')\n",
        "#print(f'ort2phn: {ort2phn}')\n",
        "print(f'len(phn2ort): {len(phn2ort)}')\n",
        "#print(f'phn2ort: {phn2ort}')\n",
        "print(f'ort2idx: {ort2idx}')\n",
        "print(f'idx2ort: {idx2ort}')\n",
        "print(f'phn2idx: {phn2idx}')\n",
        "print(f'idx2ort: {idx2ort}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6f2571-0d1b-4c2b-b4da-e8b615912b03",
      "metadata": {
        "id": "ca6f2571-0d1b-4c2b-b4da-e8b615912b03"
      },
      "outputs": [],
      "source": [
        "# D = Orth\n",
        "# count = {}\n",
        "# for k, v in D.items():\n",
        "#     if 'cnt' in list(v.keys()):\n",
        "#         count[k] = v['cnt']\n",
        "# count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "# plt.figure(figsize=(14,4))\n",
        "# N = np.array([x[1] for x in count.items()]).sum()\n",
        "# plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "# plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "# plt.title('文字頻度')\n",
        "# plt.grid()\n",
        "# #plt.savefig('2023_1113chihaya_charfreq.pdf')\n",
        "# plt.show()\n",
        "\n",
        "for D, _title in [(Phon, 'Phon'), (Orth, 'Orth')]:\n",
        "    count = {}\n",
        "    for k, v in D.items():\n",
        "        if k == '/':\n",
        "            continue\n",
        "        if 'cnt' in list(v.keys()):\n",
        "            count[k] = v['cnt']\n",
        "    count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    plt.figure(figsize=(14,4))\n",
        "    N = np.array([x[1] for x in count.items()]).sum()\n",
        "    plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "    plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "    plt.title(f'{_title} 文字頻度')\n",
        "    plt.grid()\n",
        "    #plt.savefig('2023_1113chihaya_charfreq.pdf')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb94292-05de-47a2-8409-de7d49d0ea06",
      "metadata": {
        "id": "3fb94292-05de-47a2-8409-de7d49d0ea06"
      },
      "outputs": [],
      "source": [
        "Phon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2142593-03a0-4982-8148-68ca8a64a43c",
      "metadata": {
        "id": "b2142593-03a0-4982-8148-68ca8a64a43c"
      },
      "outputs": [],
      "source": [
        "def pmsp_ort2idx(word:str,\n",
        "                 ort2idx:dict=ort2idx):\n",
        "    ret = [ort2idx[c] if c in ort2idx else ort2idx['<UNK>'] for c in word]\n",
        "    return ret\n",
        "\n",
        "\n",
        "def pmsp_idx2ort(ids:list,\n",
        "                idx2ort:list=idx2ort):\n",
        "    return [idx2ort.index(idx) for idx in ids]\n",
        "\n",
        "\n",
        "for i, wrd in enumerate(orth_list):\n",
        "    print(wrd, end=\": \") #, ort2idx['<SOW>'], end=\" \")\n",
        "    print(pmsp_ort2idx(wrd))\n",
        "    print(pmsp_idx2ort(pmsp_ort2idx(wrd)))\n",
        "    print(ort2phn[wrd])\n",
        "\n",
        "    if i >= 2:\n",
        "          break\n",
        "['grph', 'phon', 'type', 'Sim 1', '', 'Sim 2 (raw)', 'Sim 2 (sqrt)', 'Sim 3 (RT)']\n",
        "ace: [4, 5, 6]\n",
        "[4, 5, 6]\n",
        "/As/\n",
        "ache: [4, 5, 7, 6]\n",
        "[4, 5, 7, 6]\n",
        "/Ak/\n",
        "act: [4, 5, 8]\n",
        "[4, 5, 8]\n",
        "/@kt/\n",
        "#print(ort2idx)\n",
        "#print(idx2ort)\n",
        "#[1,2,3].index(2)\n",
        "idx2ort\n",
        "['<PAD>',\n",
        " '<UNK>',\n",
        " '<SOW>',\n",
        " '<EOW>',\n",
        " 'a',\n",
        " 'c',\n",
        " 'e',\n",
        " 'h',\n",
        " 't',\n",
        " 'd',\n",
        " 'f',\n",
        " 'g',\n",
        " 'i',\n",
        " 'l',\n",
        " 'm',\n",
        " 'r',\n",
        " 's',\n",
        " 'p',\n",
        " 'n',\n",
        " 'k',\n",
        " 'u',\n",
        " 'w',\n",
        " 'x',\n",
        " 'b',\n",
        " '*',\n",
        " 'y',\n",
        " 'z',\n",
        " 'o',\n",
        " 'v',\n",
        " 'j',\n",
        " 'q']\n",
        "# coding: utf-8\n",
        "#import argparse\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "#import data\n",
        "#import model\n",
        "\n",
        "# parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 RNN/LSTM/GRU/Transformer Language Model')\n",
        "# parser.add_argument('--data', type=str, default='./data/wikitext-2',\n",
        "#                     help='location of the data corpus')\n",
        "# parser.add_argument('--model', type=str, default='LSTM',\n",
        "#                     help='type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU, Transformer)')\n",
        "# parser.add_argument('--emsize', type=int, default=200,\n",
        "#                     help='size of word embeddings')\n",
        "# parser.add_argument('--nhid', type=int, default=200,\n",
        "#                     help='number of hidden units per layer')\n",
        "# parser.add_argument('--nlayers', type=int, default=2,\n",
        "#                     help='number of layers')\n",
        "# parser.add_argument('--lr', type=float, default=20,\n",
        "#                     help='initial learning rate')\n",
        "# parser.add_argument('--clip', type=float, default=0.25,\n",
        "#                     help='gradient clipping')\n",
        "# parser.add_argument('--epochs', type=int, default=40,\n",
        "#                     help='upper epoch limit')\n",
        "# parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
        "#                     help='batch size')\n",
        "# parser.add_argument('--bptt', type=int, default=35,\n",
        "#                     help='sequence length')\n",
        "# parser.add_argument('--dropout', type=float, default=0.2,\n",
        "#                     help='dropout applied to layers (0 = no dropout)')\n",
        "# parser.add_argument('--tied', action='store_true',\n",
        "#                     help='tie the word embedding and softmax weights')\n",
        "# parser.add_argument('--seed', type=int, default=1111,\n",
        "#                     help='random seed')\n",
        "# parser.add_argument('--cuda', action='store_true',\n",
        "#                     help='use CUDA')\n",
        "# parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
        "#                     help='report interval')\n",
        "# parser.add_argument('--save', type=str, default='model.pt',\n",
        "#                     help='path to save the final model')\n",
        "# parser.add_argument('--onnx-export', type=str, default='',\n",
        "#                     help='path to export the final model in onnx format')\n",
        "\n",
        "# parser.add_argument('--nhead', type=int, default=2,\n",
        "#                     help='the number of heads in the encoder/decoder of the transformer model')\n",
        "# parser.add_argument('--dry-run', action='store_true',\n",
        "#                     help='verify the code and the model')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "class _parser():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.data = '/Users/_asakawa/study/2020pytorch_examples.git/word_language_model/data/wikitext-2/'\n",
        "        self.model = 'LSTM'\n",
        "        self.emsize = 200\n",
        "        self.nhid = 200\n",
        "        self.nlayers = 2\n",
        "        self.lr = 20\n",
        "        self.clip = 0.25\n",
        "        self.epochs = 40\n",
        "        self.batch_size = 20\n",
        "        self.bptt = 35\n",
        "        self.dropout = 0.2\n",
        "        self.tied = True\n",
        "        self.seed = 42\n",
        "        self.cuda = False\n",
        "        self.log_interval=200\n",
        "        self.save='model.pt'\n",
        "        self.onnx_export = ''\n",
        "        self.nhead = 2\n",
        "        self.dry_run = True\n",
        "\n",
        "args = _parser()\n",
        "print(dir(args))\n",
        "print(args.data)\n",
        "\n",
        "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'batch_size', 'bptt', 'clip', 'cuda', 'data', 'dropout', 'dry_run', 'emsize', 'epochs', 'log_interval', 'lr', 'model', 'nhead', 'nhid', 'nlayers', 'onnx_export', 'save', 'seed', 'tied']\n",
        "/Users/_asakawa/study/2020pytorch_examples.git/word_language_model/data/wikitext-2/\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids\n",
        "\n",
        "corpus = Corpus(args.data)\n",
        "#corpus = data.Corpus(args.data)\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, args.batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)\n",
        "!pwd\n",
        "!gln -s /Users/_asakawa/study/2020pytorch_examples.git/word_language_model/model.py ./pytorch_official_model.py\n",
        "import pytorch_official_model as model\n",
        "/Users/_asakawa/study/2022ccap/notebooks\n",
        "gln: failed to create symbolic link './pytorch_official_model.py': File exists\n",
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "if args.model == 'Transformer':\n",
        "    model = model.TransformerModel(ntokens, args.emsize, args.nhead, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "else:\n",
        "    model = model.RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if args.model == 'Transformer':\n",
        "                output = model(data)\n",
        "                output = output.view(-1, ntokens)\n",
        "            else:\n",
        "                output, hidden = model(data, hidden)\n",
        "                hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if args.model != 'Transformer':\n",
        "        hidden = model.init_hidden(args.batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cbad9a9-1726-477d-990b-7d13149f41c2",
      "metadata": {
        "id": "0cbad9a9-1726-477d-990b-7d13149f41c2"
      },
      "outputs": [],
      "source": [
        "Not_list = []\n",
        "for ch in kuten_chars:\n",
        "    if not ch in jchar_list:\n",
        "        Not_list.append(ch)\n",
        "    else:\n",
        "        jchar_list.append(ch)\n",
        "\n",
        "print(len(Not_list))\n",
        "#kuten_chars\n",
        "#print(\"\".join([ch for ch in joyo_chars]))\n",
        "print(f'len(jchar_list):{len(jchar_list)}')\n",
        "print(f'jchar_list:{\"\".join([ch for ch in jchar_list])}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:anaconda3]",
      "language": "python",
      "name": "conda-env-anaconda3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}